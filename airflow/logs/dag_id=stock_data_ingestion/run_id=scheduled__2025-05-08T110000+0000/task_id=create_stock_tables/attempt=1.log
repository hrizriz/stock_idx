[2025-05-11T02:50:06.844+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-05-11T02:50:06.890+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-11T02:50:06.902+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-11T02:50:06.902+0700] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-05-11T02:50:06.924+0700] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): create_stock_tables> on 2025-05-08 11:00:00+00:00
[2025-05-11T02:50:06.933+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'stock_data_ingestion', 'create_stock_tables', 'scheduled__2025-05-08T11:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/stock_data_ingestion.py', '--cfg-path', '/tmp/tmpznukl3fn']
[2025-05-11T02:50:06.936+0700] {standard_task_runner.py:91} INFO - Job 20: Subtask create_stock_tables
[2025-05-11T02:50:06.938+0700] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=1985) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-11T02:50:06.940+0700] {standard_task_runner.py:63} INFO - Started process 1995 to run task
[2025-05-11T02:50:07.013+0700] {task_command.py:426} INFO - Running <TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [running]> on host f94ba298fced
[2025-05-11T02:50:07.146+0700] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='stock_data_ingestion' AIRFLOW_CTX_TASK_ID='create_stock_tables' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-08T11:00:00+00:00'
[2025-05-11T02:50:07.148+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-05-11T02:50:07.174+0700] {logging_mixin.py:188} INFO - ✅ Tabel stock telah dibuat atau sudah ada sebelumnya
[2025-05-11T02:50:07.174+0700] {python.py:237} INFO - Done. Returned value was: None
[2025-05-11T02:50:07.175+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-05-11T02:50:07.191+0700] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=stock_data_ingestion, task_id=create_stock_tables, run_id=scheduled__2025-05-08T11:00:00+00:00, execution_date=20250508T110000, start_date=20250510T195006, end_date=20250510T195007
[2025-05-11T02:50:07.235+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-05-11T02:50:07.272+0700] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-11T02:50:07.279+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-05-11T16:24:04.771+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-05-11T16:24:04.879+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-11T16:24:04.905+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-11T16:24:04.906+0700] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-05-11T16:24:04.946+0700] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): create_stock_tables> on 2025-05-08 11:00:00+00:00
[2025-05-11T16:24:04.964+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'stock_data_ingestion', 'create_stock_tables', 'scheduled__2025-05-08T11:00:00+00:00', '--job-id', '7', '--raw', '--subdir', 'DAGS_FOLDER/stock_data_ingestion.py', '--cfg-path', '/tmp/tmpmj43cczv']
[2025-05-11T16:24:04.971+0700] {standard_task_runner.py:91} INFO - Job 7: Subtask create_stock_tables
[2025-05-11T16:24:04.978+0700] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=278) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-11T16:24:04.982+0700] {standard_task_runner.py:63} INFO - Started process 281 to run task
[2025-05-11T16:24:05.166+0700] {task_command.py:426} INFO - Running <TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [running]> on host 615e6c656dab
[2025-05-11T16:24:05.654+0700] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='stock_data_ingestion' AIRFLOW_CTX_TASK_ID='create_stock_tables' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-08T11:00:00+00:00'
[2025-05-11T16:24:05.656+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-05-11T16:24:05.772+0700] {logging_mixin.py:188} INFO - ✅ Tabel stock telah dibuat atau sudah ada sebelumnya
[2025-05-11T16:24:05.780+0700] {python.py:237} INFO - Done. Returned value was: None
[2025-05-11T16:24:05.781+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-05-11T16:24:05.824+0700] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=stock_data_ingestion, task_id=create_stock_tables, run_id=scheduled__2025-05-08T11:00:00+00:00, execution_date=20250508T110000, start_date=20250511T092404, end_date=20250511T092405
[2025-05-11T16:24:05.888+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-05-11T16:24:06.173+0700] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-11T16:24:06.177+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-05-12T03:26:11.847+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-05-12T03:26:11.938+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T03:26:11.965+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T03:26:11.967+0700] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-05-12T03:26:12.001+0700] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): create_stock_tables> on 2025-05-08 11:00:00+00:00
[2025-05-12T03:26:12.015+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'stock_data_ingestion', 'create_stock_tables', 'scheduled__2025-05-08T11:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/stock_data_ingestion.py', '--cfg-path', '/tmp/tmpzhkvpb_2']
[2025-05-12T03:26:12.024+0700] {standard_task_runner.py:91} INFO - Job 12: Subtask create_stock_tables
[2025-05-12T03:26:12.038+0700] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2598) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-12T03:26:12.040+0700] {standard_task_runner.py:63} INFO - Started process 2614 to run task
[2025-05-12T03:26:12.141+0700] {task_command.py:426} INFO - Running <TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [running]> on host b08a3a418dc4
[2025-05-12T03:26:12.305+0700] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='stock_data_ingestion' AIRFLOW_CTX_TASK_ID='create_stock_tables' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-08T11:00:00+00:00'
[2025-05-12T03:26:12.307+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-05-12T03:26:12.342+0700] {logging_mixin.py:188} INFO - ✅ Tabel stock telah dibuat atau sudah ada sebelumnya
[2025-05-12T03:26:12.343+0700] {python.py:237} INFO - Done. Returned value was: None
[2025-05-12T03:26:12.344+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-05-12T03:26:12.366+0700] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=stock_data_ingestion, task_id=create_stock_tables, run_id=scheduled__2025-05-08T11:00:00+00:00, execution_date=20250508T110000, start_date=20250511T202611, end_date=20250511T202612
[2025-05-12T03:26:12.418+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-05-12T03:26:12.483+0700] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-12T03:26:12.491+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-05-12T05:48:37.640+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-05-12T05:48:37.708+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T05:48:37.725+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T05:48:37.725+0700] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-05-12T05:48:37.749+0700] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): create_stock_tables> on 2025-05-08 11:00:00+00:00
[2025-05-12T05:48:37.759+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'stock_data_ingestion', 'create_stock_tables', 'scheduled__2025-05-08T11:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/stock_data_ingestion.py', '--cfg-path', '/tmp/tmpt8h9l_qc']
[2025-05-12T05:48:37.763+0700] {standard_task_runner.py:91} INFO - Job 9: Subtask create_stock_tables
[2025-05-12T05:48:37.765+0700] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=428) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-12T05:48:37.766+0700] {standard_task_runner.py:63} INFO - Started process 430 to run task
[2025-05-12T05:48:37.861+0700] {task_command.py:426} INFO - Running <TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [running]> on host 84b3813fe61b
[2025-05-12T05:48:38.297+0700] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='stock_data_ingestion' AIRFLOW_CTX_TASK_ID='create_stock_tables' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-08T11:00:00+00:00'
[2025-05-12T05:48:38.299+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-05-12T05:48:38.335+0700] {logging_mixin.py:188} INFO - ✅ Tabel stock telah dibuat atau sudah ada sebelumnya
[2025-05-12T05:48:38.337+0700] {python.py:237} INFO - Done. Returned value was: None
[2025-05-12T05:48:38.339+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-05-12T05:48:38.359+0700] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=stock_data_ingestion, task_id=create_stock_tables, run_id=scheduled__2025-05-08T11:00:00+00:00, execution_date=20250508T110000, start_date=20250511T224837, end_date=20250511T224838
[2025-05-12T05:48:38.424+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-05-12T05:48:38.696+0700] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-12T05:48:38.701+0700] {local_task_job_runner.py:222} INFO - ::endgroup::
[2025-05-12T15:56:59.315+0700] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2025-05-12T15:56:59.486+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T15:56:59.521+0700] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [queued]>
[2025-05-12T15:56:59.523+0700] {taskinstance.py:2306} INFO - Starting attempt 1 of 2
[2025-05-12T15:56:59.574+0700] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): create_stock_tables> on 2025-05-08 11:00:00+00:00
[2025-05-12T15:56:59.596+0700] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'stock_data_ingestion', 'create_stock_tables', 'scheduled__2025-05-08T11:00:00+00:00', '--job-id', '9', '--raw', '--subdir', 'DAGS_FOLDER/stock_data_ingestion.py', '--cfg-path', '/tmp/tmp12kyhpok']
[2025-05-12T15:56:59.606+0700] {standard_task_runner.py:91} INFO - Job 9: Subtask create_stock_tables
[2025-05-12T15:56:59.615+0700] {logging_mixin.py:188} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61 DeprecationWarning: This process (pid=2030) is multi-threaded, use of fork() may lead to deadlocks in the child.
[2025-05-12T15:56:59.617+0700] {standard_task_runner.py:63} INFO - Started process 2042 to run task
[2025-05-12T15:56:59.924+0700] {task_command.py:426} INFO - Running <TaskInstance: stock_data_ingestion.create_stock_tables scheduled__2025-05-08T11:00:00+00:00 [running]> on host 8d034d8013d1
[2025-05-12T15:57:00.550+0700] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='stock_data_ingestion' AIRFLOW_CTX_TASK_ID='create_stock_tables' AIRFLOW_CTX_EXECUTION_DATE='2025-05-08T11:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-05-08T11:00:00+00:00'
[2025-05-12T15:57:00.552+0700] {taskinstance.py:430} INFO - ::endgroup::
[2025-05-12T15:57:00.658+0700] {logging_mixin.py:188} INFO - ✅ Tabel stock telah dibuat atau sudah ada sebelumnya
[2025-05-12T15:57:00.659+0700] {python.py:237} INFO - Done. Returned value was: None
[2025-05-12T15:57:00.660+0700] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2025-05-12T15:57:00.690+0700] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=stock_data_ingestion, task_id=create_stock_tables, run_id=scheduled__2025-05-08T11:00:00+00:00, execution_date=20250508T110000, start_date=20250512T085659, end_date=20250512T085700
[2025-05-12T15:57:00.776+0700] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2025-05-12T15:57:01.080+0700] {taskinstance.py:3503} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-05-12T15:57:01.088+0700] {local_task_job_runner.py:222} INFO - ::endgroup::

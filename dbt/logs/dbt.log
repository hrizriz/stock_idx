[0m07:42:48.888273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b51a2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b51b740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b51bad0>]}


============================== 07:42:48.897839 | caaca679-cc2c-4c20-92c0-81014c199bf4 ==============================
[0m07:42:48.897839 [info ] [MainThread]: Running with dbt=1.9.4
[0m07:42:48.899797 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': 'logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m07:42:48.906949 [error] [MainThread]: Encountered an error:
Runtime Error
  No dbt_project.yml found at expected path /opt/airflow/dbt/dbt_project.yml
  Verify that each entry within packages.yml (and their transitive dependencies) contains a file named dbt_project.yml
  
[0m07:42:48.909383 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.10359623, "process_in_blocks": "0", "process_kernel_time": 0.349871, "process_mem_max_rss": "100384", "process_out_blocks": "1912", "process_user_time": 2.788972}
[0m07:42:48.911391 [debug] [MainThread]: Command `dbt run` failed at 07:42:48.911229 after 0.11 seconds
[0m07:42:48.913007 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b37b650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b37af90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f779b6b9ac0>]}
[0m07:42:48.914657 [debug] [MainThread]: Flushing usage events
[0m07:42:50.118148 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:45:00.377843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f394970bd40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39495279e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39497091c0>]}


============================== 07:45:00.388089 | 943e431a-70ee-4d4e-90bd-5ad7b32d677e ==============================
[0m07:45:00.388089 [info ] [MainThread]: Running with dbt=1.9.4
[0m07:45:00.390049 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m07:45:00.706647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39493d6300>]}
[0m07:45:00.798508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3949096030>]}
[0m07:45:00.800928 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:45:00.944127 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m07:45:00.950891 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m07:45:00.952531 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3948be08f0>]}
[0m07:45:03.366155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3947532390>]}
[0m07:45:03.590905 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:45:03.605247 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:45:03.674554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3946960320>]}
[0m07:45:03.676744 [info ] [MainThread]: Found 7 models, 4 data tests, 1 source, 434 macros
[0m07:45:03.678707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f394c7bed50>]}
[0m07:45:03.682659 [info ] [MainThread]: 
[0m07:45:03.684588 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:45:03.686220 [info ] [MainThread]: 
[0m07:45:03.688222 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:45:03.697354 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:45:03.698334 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:45:03.699523 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:45:03.763606 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:45:03.764261 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:45:03.764781 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:45:03.766088 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:45:03.767597 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:45:03.769260 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:45:03.770739 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:03.772560 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:03.774161 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:03.785991 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.015 seconds
[0m07:45:03.786802 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.014 seconds
[0m07:45:03.789305 [debug] [ThreadPool]: On list_airflow: Close
[0m07:45:03.789983 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.016 seconds
[0m07:45:03.792841 [debug] [ThreadPool]: On list_airflow: Close
[0m07:45:03.796706 [debug] [ThreadPool]: On list_airflow: Close
[0m07:45:03.800092 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m07:45:03.800798 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m07:45:03.801465 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m07:45:03.802918 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m07:45:03.804552 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m07:45:03.806136 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m07:45:03.814877 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:45:03.819757 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:45:03.823660 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:45:03.825146 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m07:45:03.827270 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m07:45:03.828765 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m07:45:03.830197 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.831750 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.833265 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.842779 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m07:45:03.844672 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:45:03.847464 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m07:45:03.846629 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m07:45:03.845704 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:45:03.849922 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:45:03.850644 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:45:03.851787 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:45:03.853168 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m07:45:03.855420 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m07:45:03.856826 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m07:45:03.858990 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:45:03.859937 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:45:03.861911 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:45:03.863719 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m07:45:03.865237 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m07:45:03.867842 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m07:45:03.869338 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:45:03.871738 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:45:03.873040 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m07:45:03.874276 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m07:45:03.875792 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m07:45:03.878336 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m07:45:03.880994 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m07:45:03.882375 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m07:45:03.885582 [debug] [ThreadPool]: SQL status: COMMIT in 0.008 seconds
[0m07:45:03.886897 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m07:45:03.890022 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m07:45:03.890943 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m07:45:03.891815 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m07:45:03.901116 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:45:03.904456 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:45:03.907986 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:45:03.909584 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m07:45:03.911239 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m07:45:03.912544 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m07:45:03.913984 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.915270 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.916542 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:45:03.926309 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m07:45:03.928332 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m07:45:03.929387 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:45:03.930879 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:45:03.932602 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:45:03.946358 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m07:45:03.942774 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:45:03.940018 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m07:45:03.954948 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m07:45:03.957042 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m07:45:03.966607 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m07:45:03.970010 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m07:45:03.972967 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m07:45:03.983472 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m07:45:03.988978 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m07:45:03.993423 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m07:45:03.995337 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m07:45:03.997283 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m07:45:04.014298 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.016163 [debug] [MainThread]: On master: BEGIN
[0m07:45:04.017617 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:45:04.026874 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m07:45:04.028393 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.030098 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:45:04.035174 [debug] [MainThread]: SQL status: SELECT 0 in 0.003 seconds
[0m07:45:04.037987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3949f08dd0>]}
[0m07:45:04.039575 [debug] [MainThread]: On master: ROLLBACK
[0m07:45:04.041074 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.042789 [debug] [MainThread]: On master: BEGIN
[0m07:45:04.044891 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m07:45:04.046350 [debug] [MainThread]: On master: COMMIT
[0m07:45:04.047661 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.049043 [debug] [MainThread]: On master: COMMIT
[0m07:45:04.050569 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:04.051939 [debug] [MainThread]: On master: Close
[0m07:45:04.060614 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m07:45:04.063773 [info ] [Thread-1 (]: 1 of 7 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m07:45:04.065449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m07:45:04.066914 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m07:45:04.081201 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.104844 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m07:45:04.158171 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.178704 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.179992 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m07:45:04.181222 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:04.190799 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m07:45:04.193005 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.194520 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m07:45:04.198426 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m07:45:04.208934 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.210767 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m07:45:04.212901 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:45:04.236015 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m07:45:04.237685 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.239153 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m07:45:04.243071 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m07:45:04.254168 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m07:45:04.262723 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:45:04.264462 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m07:45:04.266657 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m07:45:04.270837 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m07:45:04.274049 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3949874fe0>]}
[0m07:45:04.276431 [info ] [Thread-1 (]: 1 of 7 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.21s]
[0m07:45:04.278385 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m07:45:04.280936 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m07:45:04.281628 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m07:45:04.283210 [info ] [Thread-3 (]: 2 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m07:45:04.284892 [info ] [Thread-4 (]: 3 of 7 START sql table model public_core.dim_companies ......................... [RUN]
[0m07:45:04.286628 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m07:45:04.288246 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m07:45:04.289950 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m07:45:04.291433 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m07:45:04.297493 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m07:45:04.302368 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m07:45:04.313782 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m07:45:04.327168 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m07:45:04.356716 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m07:45:04.363950 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m07:45:04.373918 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:45:04.376354 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m07:45:04.378080 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:45:04.378910 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:45:04.380869 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m07:45:04.384005 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:45:04.393170 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m07:45:04.394904 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:45:04.396389 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m07:45:04.397275 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m07:45:04.399215 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:45:04.401998 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m07:45:04.412353 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.011 seconds
[0m07:45:04.419606 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.016 seconds
[0m07:45:04.423208 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:45:04.429101 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:45:04.431021 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m07:45:04.432802 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m07:45:04.435341 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:45:04.436919 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:45:04.439963 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m07:45:04.443405 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m07:45:04.445360 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:45:04.447086 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:45:04.448748 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m07:45:04.450287 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m07:45:04.454706 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m07:45:04.455933 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m07:45:04.460116 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m07:45:04.464535 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m07:45:04.469786 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:45:04.471996 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:45:04.473904 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m07:45:04.475867 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m07:45:04.478231 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.479982 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.482383 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m07:45:04.485451 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m07:45:04.487668 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3944510290>]}
[0m07:45:04.489699 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39446608c0>]}
[0m07:45:04.492486 [info ] [Thread-4 (]: 3 of 7 OK created sql table model public_core.dim_companies .................... [[32mSELECT 959[0m in 0.20s]
[0m07:45:04.495044 [info ] [Thread-3 (]: 2 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 959[0m in 0.20s]
[0m07:45:04.497108 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m07:45:04.499143 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m07:45:04.501726 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance
[0m07:45:04.502425 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m07:45:04.503135 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m07:45:04.504203 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m07:45:04.505927 [info ] [Thread-1 (]: 4 of 7 START sql table model public_analytics.stock_performance ................ [RUN]
[0m07:45:04.507909 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m07:45:04.510416 [info ] [Thread-4 (]: 6 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m07:45:04.512255 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m07:45:04.513843 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance)
[0m07:45:04.515638 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_daily)
[0m07:45:04.517610 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_monthly)
[0m07:45:04.519306 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m07:45:04.520707 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance
[0m07:45:04.522397 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m07:45:04.524095 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m07:45:04.525940 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m07:45:04.532375 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance"
[0m07:45:04.539936 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m07:45:04.545929 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m07:45:04.551899 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m07:45:04.560169 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m07:45:04.567714 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance
[0m07:45:04.568968 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m07:45:04.569796 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m07:45:04.577450 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance"
[0m07:45:04.578276 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m07:45:04.585417 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m07:45:04.592842 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m07:45:04.595225 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:45:04.597701 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:45:04.599785 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m07:45:04.601366 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:45:04.602964 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: BEGIN
[0m07:45:04.604433 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:45:04.606367 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:45:04.608628 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m07:45:04.611039 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:04.613225 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m07:45:04.618993 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m07:45:04.616443 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:45:04.624328 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m07:45:04.627563 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:45:04.628553 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m07:45:04.630270 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m07:45:04.632012 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m07:45:04.632893 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m07:45:04.633687 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:45:04.636689 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:45:04.638356 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:45:04.640389 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance__dbt_tmp"
  
  
    as
  
  (
    

-- Model analitik yang menghitung performa saham per minggu
WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Mengelompokkan data per minggu
weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

-- Mendapatkan harga pembukaan dan penutupan
weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    -- Join untuk mendapatkan harga pembukaan (pada hari pertama minggu)
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    -- Join untuk mendapatkan harga penutupan (pada hari terakhir minggu)
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
  );
  
[0m07:45:04.643056 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m07:45:04.645247 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m07:45:04.654001 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.018 seconds
[0m07:45:04.661008 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:45:04.661985 [debug] [Thread-2 (]: SQL status: SELECT 959 in 0.014 seconds
[0m07:45:04.662668 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.016 seconds
[0m07:45:04.664062 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.016 seconds
[0m07:45:04.664843 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m07:45:04.670633 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:45:04.676494 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:45:04.683091 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:45:04.685402 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:45:04.686783 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m07:45:04.688510 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */
alter table "airflow"."public_analytics"."stock_performance__dbt_tmp" rename to "stock_performance"
[0m07:45:04.690305 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m07:45:04.693605 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m07:45:04.695860 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:45:04.697458 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:45:04.698910 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:45:04.699997 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:45:04.702849 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m07:45:04.705661 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: COMMIT
[0m07:45:04.708497 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m07:45:04.710608 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m07:45:04.712335 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:45:04.713908 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:45:04.715457 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:45:04.717810 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m07:45:04.719502 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: COMMIT
[0m07:45:04.720194 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m07:45:04.721473 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m07:45:04.724679 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m07:45:04.728651 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m07:45:04.729432 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m07:45:04.735580 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m07:45:04.736480 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m07:45:04.738433 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:45:04.744269 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance__dbt_backup"
[0m07:45:04.746457 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:45:04.751139 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m07:45:04.753032 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m07:45:04.755117 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:45:04.756714 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m07:45:04.759494 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:45:04.762263 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.764080 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */
drop table if exists "airflow"."public_analytics"."stock_performance__dbt_backup" cascade
[0m07:45:04.766487 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.768016 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m07:45:04.771234 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m07:45:04.773481 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.776660 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m07:45:04.778951 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:45:04.780885 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3948b5bd70>]}
[0m07:45:04.783703 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: Close
[0m07:45:04.785730 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3947118050>]}
[0m07:45:04.788457 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m07:45:04.790504 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 0.26s]
[0m07:45:04.792932 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3947119700>]}
[0m07:45:04.794645 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.27s]
[0m07:45:04.796759 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '943e431a-70ee-4d4e-90bd-5ad7b32d677e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3944539e80>]}
[0m07:45:04.799689 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m07:45:04.801837 [info ] [Thread-1 (]: 4 of 7 OK created sql table model public_analytics.stock_performance ........... [[32mSELECT 959[0m in 0.28s]
[0m07:45:04.803762 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m07:45:04.805755 [info ] [Thread-4 (]: 6 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 0.28s]
[0m07:45:04.809130 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance
[0m07:45:04.812069 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m07:45:04.816760 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.818006 [debug] [MainThread]: On master: BEGIN
[0m07:45:04.819163 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:45:04.829392 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:45:04.831025 [debug] [MainThread]: On master: COMMIT
[0m07:45:04.832671 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:04.834136 [debug] [MainThread]: On master: COMMIT
[0m07:45:04.835956 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:04.837500 [debug] [MainThread]: On master: Close
[0m07:45:04.839102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:45:04.840398 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance' was properly closed.
[0m07:45:04.841921 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m07:45:04.843629 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m07:45:04.845022 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m07:45:04.846540 [info ] [MainThread]: 
[0m07:45:04.848042 [info ] [MainThread]: Finished running 6 table models, 1 view model in 0 hours 0 minutes and 1.16 seconds (1.16s).
[0m07:45:04.851362 [debug] [MainThread]: Command end result
[0m07:45:04.917765 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:45:04.927059 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:45:04.943171 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:45:04.944610 [info ] [MainThread]: 
[0m07:45:04.946116 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:45:04.947570 [info ] [MainThread]: 
[0m07:45:04.949024 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m07:45:04.951135 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.6690826, "process_in_blocks": "0", "process_kernel_time": 0.39125, "process_mem_max_rss": "129580", "process_out_blocks": "448", "process_user_time": 6.229917}
[0m07:45:04.952803 [debug] [MainThread]: Command `dbt run` succeeded at 07:45:04.952629 after 4.67 seconds
[0m07:45:04.954510 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39498171a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3948a8b830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f39469216d0>]}
[0m07:45:04.956100 [debug] [MainThread]: Flushing usage events
[0m07:45:06.512014 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:45:14.428388 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee678f5f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee87a6660>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee6d9fe30>]}


============================== 07:45:14.437761 | 346ec6e2-71d0-47d1-b5e1-cf739fd5c1de ==============================
[0m07:45:14.437761 [info ] [MainThread]: Running with dbt=1.9.4
[0m07:45:14.439581 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:45:14.732770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee666b8f0>]}
[0m07:45:14.823126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee6261580>]}
[0m07:45:14.825203 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:45:14.954766 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m07:45:15.343684 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:45:15.345179 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:45:15.420378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee4ba3fe0>]}
[0m07:45:15.598996 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:45:15.614760 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:45:15.673315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee47df890>]}
[0m07:45:15.674903 [info ] [MainThread]: Found 7 models, 4 data tests, 1 source, 434 macros
[0m07:45:15.676549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee47c3410>]}
[0m07:45:15.680315 [info ] [MainThread]: 
[0m07:45:15.682024 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:45:15.683861 [info ] [MainThread]: 
[0m07:45:15.685993 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:45:15.694677 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m07:45:15.695735 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m07:45:15.696639 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m07:45:15.762138 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:45:15.762780 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:45:15.763345 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:45:15.764761 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m07:45:15.766393 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m07:45:15.768555 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m07:45:15.770014 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:15.771617 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:15.772982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:45:15.785358 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m07:45:15.787370 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:45:15.788323 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m07:45:15.789003 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m07:45:15.790124 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m07:45:15.791929 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:45:15.793255 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:45:15.795919 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m07:45:15.797607 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m07:45:15.798580 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m07:45:15.803672 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m07:45:15.804352 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m07:45:15.805077 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.004 seconds
[0m07:45:15.806473 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m07:45:15.808620 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m07:45:15.811621 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m07:45:15.814950 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m07:45:15.816787 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m07:45:15.827831 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:15.829619 [debug] [MainThread]: On master: BEGIN
[0m07:45:15.831812 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:45:15.842191 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:45:15.843986 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:15.845930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:45:15.857354 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m07:45:15.860595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '346ec6e2-71d0-47d1-b5e1-cf739fd5c1de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee47ac290>]}
[0m07:45:15.862479 [debug] [MainThread]: On master: ROLLBACK
[0m07:45:15.864845 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:15.866812 [debug] [MainThread]: On master: BEGIN
[0m07:45:15.869781 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m07:45:15.871362 [debug] [MainThread]: On master: COMMIT
[0m07:45:15.872711 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:15.874007 [debug] [MainThread]: On master: COMMIT
[0m07:45:15.875684 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:15.877299 [debug] [MainThread]: On master: Close
[0m07:45:15.887899 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:45:15.888664 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:45:15.889386 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:45:15.890316 [debug] [Thread-4 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:45:15.891397 [info ] [Thread-1 (]: 1 of 4 START test not_null_dim_companies_symbol ................................ [RUN]
[0m07:45:15.892940 [info ] [Thread-2 (]: 2 of 4 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m07:45:15.894772 [info ] [Thread-3 (]: 3 of 4 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m07:45:15.896629 [info ] [Thread-4 (]: 4 of 4 START test unique_dim_companies_symbol .................................. [RUN]
[0m07:45:15.898433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m07:45:15.900698 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m07:45:15.902598 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m07:45:15.904350 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b'
[0m07:45:15.905967 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:45:15.907365 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:45:15.908943 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:45:15.910278 [debug] [Thread-4 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:45:15.940438 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:45:15.942009 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:45:15.948335 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:45:15.958173 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:45:15.968858 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:45:15.986829 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:45:15.993688 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:45:15.997252 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:45:16.002352 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:45:16.003356 [debug] [Thread-4 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:45:16.007838 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:45:16.015528 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:45:16.024612 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:45:16.026821 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m07:45:16.028345 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:45:16.029978 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:45:16.031243 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:45:16.033585 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:45:16.034501 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m07:45:16.036697 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m07:45:16.040286 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m07:45:16.042372 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:45:16.044337 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:45:16.045951 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:45:16.049577 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m07:45:16.053568 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:45:16.055456 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m07:45:16.059173 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m07:45:16.066928 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m07:45:16.068208 [debug] [Thread-4 (]: SQL status: BEGIN in 0.024 seconds
[0m07:45:16.069174 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m07:45:16.070040 [debug] [Thread-3 (]: SQL status: BEGIN in 0.028 seconds
[0m07:45:16.071677 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m07:45:16.073197 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:45:16.074952 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:45:16.076509 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:45:16.078699 [info ] [Thread-1 (]: 1 of 4 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.18s]
[0m07:45:16.080355 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m07:45:16.082161 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m07:45:16.084243 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m07:45:16.086353 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:45:16.089772 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m07:45:16.090562 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m07:45:16.091556 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.001 seconds
[0m07:45:16.095241 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m07:45:16.098038 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m07:45:16.101542 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m07:45:16.103853 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m07:45:16.105436 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m07:45:16.107292 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m07:45:16.110236 [info ] [Thread-4 (]: 4 of 4 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.21s]
[0m07:45:16.112471 [info ] [Thread-2 (]: 2 of 4 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.21s]
[0m07:45:16.114520 [info ] [Thread-3 (]: 3 of 4 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.21s]
[0m07:45:16.116586 [debug] [Thread-4 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:45:16.118806 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:45:16.120817 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:45:16.126682 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:16.128052 [debug] [MainThread]: On master: BEGIN
[0m07:45:16.129378 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:45:16.138863 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m07:45:16.140482 [debug] [MainThread]: On master: COMMIT
[0m07:45:16.141911 [debug] [MainThread]: Using postgres connection "master"
[0m07:45:16.143264 [debug] [MainThread]: On master: COMMIT
[0m07:45:16.144888 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:45:16.146251 [debug] [MainThread]: On master: Close
[0m07:45:16.147833 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:45:16.149625 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m07:45:16.151320 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m07:45:16.152690 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m07:45:16.153923 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m07:45:16.155286 [info ] [MainThread]: 
[0m07:45:16.156788 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 0.47 seconds (0.47s).
[0m07:45:16.159402 [debug] [MainThread]: Command end result
[0m07:45:16.222294 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:45:16.229604 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:45:16.244862 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:45:16.246286 [info ] [MainThread]: 
[0m07:45:16.247654 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:45:16.249026 [info ] [MainThread]: 
[0m07:45:16.251095 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:45:16.253137 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.9175725, "process_in_blocks": "0", "process_kernel_time": 0.408499, "process_mem_max_rss": "122632", "process_out_blocks": "0", "process_user_time": 3.766169}
[0m07:45:16.254753 [debug] [MainThread]: Command `dbt test` succeeded at 07:45:16.254571 after 1.92 seconds
[0m07:45:16.256218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee65facc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee4ba3d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee6d30290>]}
[0m07:45:16.257801 [debug] [MainThread]: Flushing usage events
[0m07:45:17.352297 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:48:52.295305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70549d02c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70544fc800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70549f5610>]}


============================== 07:48:52.305438 | 9454fd87-099e-4a0a-b3fd-1ef916059147 ==============================
[0m07:48:52.305438 [info ] [MainThread]: Running with dbt=1.9.4
[0m07:48:52.307610 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m07:48:52.647648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70542a7860>]}
[0m07:48:52.751574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7055283a10>]}
[0m07:48:52.754111 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:48:52.900299 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m07:48:53.352513 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:48:53.354465 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:48:53.455226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7053b890d0>]}
[0m07:48:53.665460 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:48:53.682280 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:48:53.759561 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7052fc9310>]}
[0m07:48:53.761229 [info ] [MainThread]: Found 7 models, 4 data tests, 1 source, 434 macros
[0m07:48:53.762958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7052fec2c0>]}
[0m07:48:53.767349 [info ] [MainThread]: 
[0m07:48:53.769192 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:48:53.770896 [info ] [MainThread]: 
[0m07:48:53.773066 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:48:53.782662 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:48:53.783788 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:48:53.784776 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m07:48:53.856547 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:48:53.857392 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:48:53.858105 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m07:48:53.859580 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:48:53.861353 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:48:53.863267 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m07:48:53.865300 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:48:53.866834 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:48:53.868606 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:48:53.883100 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.018 seconds
[0m07:48:53.885288 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m07:48:53.886054 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.019 seconds
[0m07:48:53.888109 [debug] [ThreadPool]: On list_airflow: Close
[0m07:48:53.891440 [debug] [ThreadPool]: On list_airflow: Close
[0m07:48:53.894748 [debug] [ThreadPool]: On list_airflow: Close
[0m07:48:53.899834 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m07:48:53.901081 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m07:48:53.901840 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m07:48:53.903516 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m07:48:53.905641 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m07:48:53.908064 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m07:48:53.917569 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:48:53.921747 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:48:53.926234 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:48:53.928397 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m07:48:53.930382 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m07:48:53.931956 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m07:48:53.933697 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:53.935450 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:53.936923 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:53.948014 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:48:53.949424 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:48:53.950930 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:48:53.952767 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:48:53.953634 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m07:48:53.955189 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m07:48:53.957608 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m07:48:53.959401 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:48:53.962097 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:48:53.963504 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:48:53.964612 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m07:48:53.967151 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m07:48:53.969971 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m07:48:53.972333 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m07:48:53.973932 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m07:48:53.975448 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m07:48:53.977919 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m07:48:53.979419 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m07:48:53.981012 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m07:48:53.982532 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m07:48:53.987902 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m07:48:53.989523 [debug] [ThreadPool]: SQL status: COMMIT in 0.004 seconds
[0m07:48:53.991606 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m07:48:53.994750 [debug] [ThreadPool]: SQL status: COMMIT in 0.008 seconds
[0m07:48:53.996478 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m07:48:53.999294 [debug] [ThreadPool]: SQL status: COMMIT in 0.009 seconds
[0m07:48:54.001286 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m07:48:54.005668 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_analytics)
[0m07:48:54.007156 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_core)
[0m07:48:54.008179 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m07:48:54.018625 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:48:54.022920 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:48:54.027524 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:48:54.029565 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m07:48:54.031286 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m07:48:54.033189 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m07:48:54.035035 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:54.036611 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:54.038334 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:48:54.050584 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m07:48:54.051637 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m07:48:54.053116 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:48:54.054581 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m07:48:54.055767 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:48:54.058052 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m07:48:54.060023 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:48:54.061968 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m07:48:54.065502 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m07:48:54.067911 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m07:48:54.071977 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m07:48:54.072985 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m07:48:54.074187 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m07:48:54.075659 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m07:48:54.078814 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m07:48:54.081990 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m07:48:54.085541 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m07:48:54.087268 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m07:48:54.098209 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:54.100205 [debug] [MainThread]: On master: BEGIN
[0m07:48:54.101978 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:48:54.113179 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m07:48:54.115218 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:54.117421 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:48:54.203407 [debug] [MainThread]: SQL status: SELECT 0 in 0.084 seconds
[0m07:48:54.207421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7053345eb0>]}
[0m07:48:54.209566 [debug] [MainThread]: On master: ROLLBACK
[0m07:48:54.211765 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:54.213571 [debug] [MainThread]: On master: BEGIN
[0m07:48:54.215786 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m07:48:54.217689 [debug] [MainThread]: On master: COMMIT
[0m07:48:54.219296 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:54.220850 [debug] [MainThread]: On master: COMMIT
[0m07:48:54.222780 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:48:54.224707 [debug] [MainThread]: On master: Close
[0m07:48:54.234214 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m07:48:54.236281 [info ] [Thread-1 (]: 1 of 7 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m07:48:54.238174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m07:48:54.240356 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m07:48:54.254364 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.268562 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m07:48:54.329421 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.342886 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.344351 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m07:48:54.345735 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:48:54.356186 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m07:48:54.358359 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.360208 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m07:48:54.364671 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m07:48:54.376004 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.378064 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m07:48:54.380454 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:48:54.405396 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m07:48:54.407749 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.409538 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m07:48:54.418395 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m07:48:54.429651 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m07:48:54.439387 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m07:48:54.441483 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m07:48:54.443567 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m07:48:54.448203 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m07:48:54.451759 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7053b88ef0>]}
[0m07:48:54.454076 [info ] [Thread-1 (]: 1 of 7 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.21s]
[0m07:48:54.456368 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m07:48:54.459232 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m07:48:54.460022 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m07:48:54.461780 [info ] [Thread-3 (]: 2 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m07:48:54.463613 [info ] [Thread-4 (]: 3 of 7 START sql table model public_core.dim_companies ......................... [RUN]
[0m07:48:54.465564 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m07:48:54.467385 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m07:48:54.469295 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m07:48:54.470935 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m07:48:54.476693 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m07:48:54.482153 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m07:48:54.493421 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m07:48:54.494320 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m07:48:54.546712 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m07:48:54.547647 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m07:48:54.558778 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:48:54.559859 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:48:54.561258 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m07:48:54.563034 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m07:48:54.564648 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:48:54.566525 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:48:54.578269 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m07:48:54.580589 [debug] [Thread-3 (]: SQL status: BEGIN in 0.014 seconds
[0m07:48:54.581851 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:48:54.583647 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:48:54.585514 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m07:48:54.587368 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m07:48:54.677803 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.088 seconds
[0m07:48:54.687249 [debug] [Thread-3 (]: SQL status: SELECT 18219 in 0.097 seconds
[0m07:48:54.690911 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:48:54.697310 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:48:54.699103 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m07:48:54.701285 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m07:48:54.703550 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:48:54.705494 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:48:54.708464 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m07:48:54.712071 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m07:48:54.713940 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:48:54.715894 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:48:54.717690 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m07:48:54.719534 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m07:48:54.805178 [debug] [Thread-4 (]: SQL status: COMMIT in 0.083 seconds
[0m07:48:54.806751 [debug] [Thread-3 (]: SQL status: COMMIT in 0.084 seconds
[0m07:48:54.812693 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m07:48:54.817441 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m07:48:54.823586 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m07:48:54.825924 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m07:48:54.827630 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m07:48:54.829619 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m07:48:54.831874 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:54.833874 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:54.836578 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m07:48:54.840502 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m07:48:54.842700 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70503f0680>]}
[0m07:48:54.844660 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7050215910>]}
[0m07:48:54.846669 [info ] [Thread-4 (]: 3 of 7 OK created sql table model public_core.dim_companies .................... [[32mSELECT 960[0m in 0.38s]
[0m07:48:54.849285 [info ] [Thread-3 (]: 2 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 18219[0m in 0.38s]
[0m07:48:54.851566 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m07:48:54.853767 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m07:48:54.856493 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance
[0m07:48:54.857300 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m07:48:54.858118 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m07:48:54.859212 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m07:48:54.861238 [info ] [Thread-1 (]: 4 of 7 START sql table model public_analytics.stock_performance ................ [RUN]
[0m07:48:54.863341 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m07:48:54.865374 [info ] [Thread-4 (]: 6 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m07:48:54.867477 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m07:48:54.869418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance)
[0m07:48:54.871459 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_daily)
[0m07:48:54.873627 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_monthly)
[0m07:48:54.875384 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m07:48:54.877176 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance
[0m07:48:54.878845 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m07:48:54.880451 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m07:48:54.882093 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m07:48:54.891067 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance"
[0m07:48:54.899103 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m07:48:54.906787 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m07:48:54.913848 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m07:48:54.936477 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m07:48:54.938914 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance
[0m07:48:54.940333 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m07:48:54.947793 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m07:48:54.954347 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance"
[0m07:48:54.955648 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m07:48:54.963042 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m07:48:54.974100 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m07:48:54.980302 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:48:54.982691 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m07:48:54.983856 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:48:54.984806 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:48:54.986591 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m07:48:54.987550 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:48:54.989477 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: BEGIN
[0m07:48:54.991506 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m07:48:54.994846 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m07:48:54.996631 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:48:54.998599 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:48:55.000600 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:48:55.003234 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m07:48:55.009820 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:48:55.013944 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m07:48:55.016313 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m07:48:55.018854 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:48:55.020360 [debug] [Thread-3 (]: SQL status: BEGIN in 0.020 seconds
[0m07:48:55.021313 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m07:48:55.025032 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance__dbt_tmp"
  
  
    as
  
  (
    

-- Model analitik yang menghitung performa saham per minggu
WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Mengelompokkan data per minggu
weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

-- Mendapatkan harga pembukaan dan penutupan
weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    -- Join untuk mendapatkan harga pembukaan (pada hari pertama minggu)
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    -- Join untuk mendapatkan harga penutupan (pada hari terakhir minggu)
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
  );
  
[0m07:48:55.027803 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:48:55.030036 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:48:55.033299 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m07:48:55.035481 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m07:48:55.059382 [debug] [Thread-2 (]: SQL status: SELECT 959 in 0.020 seconds
[0m07:48:55.068980 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:48:55.071467 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m07:48:55.074241 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:48:55.077547 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m07:48:55.079056 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:48:55.080713 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m07:48:55.083671 [debug] [Thread-2 (]: SQL status: COMMIT in 0.001 seconds
[0m07:48:55.089319 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m07:48:55.091663 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m07:48:55.093273 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m07:48:55.095196 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:55.098802 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m07:48:55.100731 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705025e420>]}
[0m07:48:55.102816 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.23s]
[0m07:48:55.105793 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m07:48:55.107091 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.084 seconds
[0m07:48:55.116194 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:48:55.118046 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m07:48:55.119994 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m07:48:55.124108 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m07:48:55.126006 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:48:55.127378 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m07:48:55.131321 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m07:48:55.136455 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m07:48:55.138852 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m07:48:55.140679 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m07:48:55.142606 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:55.143842 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.106 seconds
[0m07:48:55.147905 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m07:48:55.174890 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:48:55.182451 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705039d580>]}
[0m07:48:55.184360 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m07:48:55.187175 [info ] [Thread-4 (]: 6 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 0.31s]
[0m07:48:55.190569 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:48:55.192224 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m07:48:55.195834 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m07:48:55.198614 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:48:55.200222 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m07:48:55.203689 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m07:48:55.211408 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m07:48:55.213617 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m07:48:55.215609 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m07:48:55.217992 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:55.222450 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m07:48:55.224848 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705023f650>]}
[0m07:48:55.227175 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 0.35s]
[0m07:48:55.230199 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m07:48:55.296174 [debug] [Thread-1 (]: SQL status: SELECT 4795 in 0.264 seconds
[0m07:48:55.303075 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:48:55.305134 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */
alter table "airflow"."public_analytics"."stock_performance__dbt_tmp" rename to "stock_performance"
[0m07:48:55.307637 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m07:48:55.310957 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: COMMIT
[0m07:48:55.312684 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:48:55.314497 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: COMMIT
[0m07:48:55.319814 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m07:48:55.325623 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance__dbt_backup"
[0m07:48:55.327862 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance"
[0m07:48:55.329605 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance"} */
drop table if exists "airflow"."public_analytics"."stock_performance__dbt_backup" cascade
[0m07:48:55.331725 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m07:48:55.335261 [debug] [Thread-1 (]: On model.idx_stock.stock_performance: Close
[0m07:48:55.337230 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9454fd87-099e-4a0a-b3fd-1ef916059147', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7050363080>]}
[0m07:48:55.339635 [info ] [Thread-1 (]: 4 of 7 OK created sql table model public_analytics.stock_performance ........... [[32mSELECT 4795[0m in 0.47s]
[0m07:48:55.341875 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance
[0m07:48:55.345951 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:55.347866 [debug] [MainThread]: On master: BEGIN
[0m07:48:55.349674 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:48:55.362030 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m07:48:55.364539 [debug] [MainThread]: On master: COMMIT
[0m07:48:55.366756 [debug] [MainThread]: Using postgres connection "master"
[0m07:48:55.368725 [debug] [MainThread]: On master: COMMIT
[0m07:48:55.371057 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:48:55.373291 [debug] [MainThread]: On master: Close
[0m07:48:55.375558 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:48:55.377762 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance' was properly closed.
[0m07:48:55.379584 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m07:48:55.381413 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m07:48:55.383118 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m07:48:55.384954 [info ] [MainThread]: 
[0m07:48:55.386766 [info ] [MainThread]: Finished running 6 table models, 1 view model in 0 hours 0 minutes and 1.61 seconds (1.61s).
[0m07:48:55.391097 [debug] [MainThread]: Command end result
[0m07:48:55.472336 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:48:55.482325 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:48:55.502333 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:48:55.504254 [info ] [MainThread]: 
[0m07:48:55.506780 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:48:55.508731 [info ] [MainThread]: 
[0m07:48:55.510626 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m07:48:55.513359 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.3230286, "process_in_blocks": "0", "process_kernel_time": 0.425287, "process_mem_max_rss": "124280", "process_out_blocks": "2360", "process_user_time": 5.291364}
[0m07:48:55.515682 [debug] [MainThread]: Command `dbt run` succeeded at 07:48:55.515439 after 3.33 seconds
[0m07:48:55.517771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f705679be60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7056008650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7054fcb9b0>]}
[0m07:48:55.519660 [debug] [MainThread]: Flushing usage events
[0m07:48:57.089103 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m07:49:06.808565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7765a7dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb775ea0560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7766219a0>]}


============================== 07:49:06.819351 | ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37 ==============================
[0m07:49:06.819351 [info ] [MainThread]: Running with dbt=1.9.4
[0m07:49:06.821560 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m07:49:07.165859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7759af1a0>]}
[0m07:49:07.275469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb77597e2d0>]}
[0m07:49:07.278119 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m07:49:07.440175 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m07:49:07.896022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:49:07.897785 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:49:07.979341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb775956f30>]}
[0m07:49:08.153972 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:49:08.168408 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:49:08.217907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb773fe3470>]}
[0m07:49:08.219868 [info ] [MainThread]: Found 7 models, 4 data tests, 1 source, 434 macros
[0m07:49:08.221612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb7759c8380>]}
[0m07:49:08.225975 [info ] [MainThread]: 
[0m07:49:08.227763 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m07:49:08.229505 [info ] [MainThread]: 
[0m07:49:08.231644 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m07:49:08.239872 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m07:49:08.240948 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m07:49:08.241898 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m07:49:08.309187 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:49:08.309915 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:49:08.310537 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:49:08.312028 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m07:49:08.313980 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m07:49:08.315790 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m07:49:08.317527 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:08.319173 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:08.320709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:49:08.332337 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:49:08.333419 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:49:08.334686 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m07:49:08.335780 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m07:49:08.337693 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m07:49:08.339347 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m07:49:08.341161 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m07:49:08.343008 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m07:49:08.344717 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m07:49:08.349719 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m07:49:08.350809 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.003 seconds
[0m07:49:08.351477 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m07:49:08.353624 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m07:49:08.356971 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m07:49:08.359789 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m07:49:08.361908 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m07:49:08.363521 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m07:49:08.365006 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m07:49:08.378042 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.379695 [debug] [MainThread]: On master: BEGIN
[0m07:49:08.381567 [debug] [MainThread]: Opening a new connection, currently in state init
[0m07:49:08.391630 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:49:08.393549 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.395570 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m07:49:08.405308 [debug] [MainThread]: SQL status: SELECT 1 in 0.008 seconds
[0m07:49:08.408632 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec86c2ed-4ae9-4dc2-87ce-80cc0e07aa37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb77597fb60>]}
[0m07:49:08.410425 [debug] [MainThread]: On master: ROLLBACK
[0m07:49:08.412315 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.414002 [debug] [MainThread]: On master: BEGIN
[0m07:49:08.416114 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m07:49:08.418139 [debug] [MainThread]: On master: COMMIT
[0m07:49:08.419693 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.421222 [debug] [MainThread]: On master: COMMIT
[0m07:49:08.423098 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:49:08.424791 [debug] [MainThread]: On master: Close
[0m07:49:08.434821 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:49:08.435625 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:49:08.436352 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:49:08.437091 [debug] [Thread-4 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:49:08.438263 [info ] [Thread-1 (]: 1 of 4 START test not_null_dim_companies_symbol ................................ [RUN]
[0m07:49:08.440006 [info ] [Thread-2 (]: 2 of 4 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m07:49:08.442082 [info ] [Thread-3 (]: 3 of 4 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m07:49:08.444031 [info ] [Thread-4 (]: 4 of 4 START test unique_dim_companies_symbol .................................. [RUN]
[0m07:49:08.446055 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m07:49:08.447836 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m07:49:08.449628 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m07:49:08.451333 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b'
[0m07:49:08.454145 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:49:08.455852 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:49:08.457522 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:49:08.459103 [debug] [Thread-4 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:49:08.491866 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:49:08.493836 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:49:08.500795 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:49:08.510637 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:49:08.519001 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:49:08.520688 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:49:08.521496 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:49:08.538418 [debug] [Thread-4 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:49:08.546894 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:49:08.550227 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:49:08.554902 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:49:08.559509 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:49:08.569119 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:49:08.570308 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:49:08.571356 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:49:08.572730 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m07:49:08.575105 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:49:08.575874 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m07:49:08.577791 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m07:49:08.579646 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m07:49:08.581503 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m07:49:08.583351 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m07:49:08.585107 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m07:49:08.588050 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m07:49:08.595946 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m07:49:08.598390 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m07:49:08.600578 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m07:49:08.602579 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m07:49:08.603972 [debug] [Thread-3 (]: SQL status: BEGIN in 0.019 seconds
[0m07:49:08.605745 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m07:49:08.607515 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m07:49:08.610420 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m07:49:08.611192 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m07:49:08.613021 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m07:49:08.614854 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m07:49:08.622243 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m07:49:08.623983 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m07:49:08.626038 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m07:49:08.629486 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m07:49:08.630323 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m07:49:08.633924 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m07:49:08.635366 [info ] [Thread-1 (]: 1 of 4 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.19s]
[0m07:49:08.636345 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.003 seconds
[0m07:49:08.639465 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m07:49:08.642949 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m07:49:08.645263 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m07:49:08.648765 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m07:49:08.650890 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m07:49:08.652750 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m07:49:08.655495 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m07:49:08.657262 [info ] [Thread-4 (]: 4 of 4 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.21s]
[0m07:49:08.659256 [info ] [Thread-3 (]: 3 of 4 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.21s]
[0m07:49:08.661302 [info ] [Thread-2 (]: 2 of 4 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.21s]
[0m07:49:08.663421 [debug] [Thread-4 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m07:49:08.665692 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m07:49:08.667813 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m07:49:08.673716 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.675305 [debug] [MainThread]: On master: BEGIN
[0m07:49:08.676866 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m07:49:08.687411 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m07:49:08.689725 [debug] [MainThread]: On master: COMMIT
[0m07:49:08.691486 [debug] [MainThread]: Using postgres connection "master"
[0m07:49:08.693362 [debug] [MainThread]: On master: COMMIT
[0m07:49:08.695929 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m07:49:08.697717 [debug] [MainThread]: On master: Close
[0m07:49:08.699709 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:49:08.701201 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m07:49:08.702944 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m07:49:08.704575 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m07:49:08.706263 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m07:49:08.708033 [info ] [MainThread]: 
[0m07:49:08.709906 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m07:49:08.713318 [debug] [MainThread]: Command end result
[0m07:49:08.783155 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m07:49:08.791424 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m07:49:08.809251 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m07:49:08.811168 [info ] [MainThread]: 
[0m07:49:08.812895 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:49:08.814646 [info ] [MainThread]: 
[0m07:49:08.816561 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m07:49:08.819301 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.1473994, "process_in_blocks": "0", "process_kernel_time": 0.449055, "process_mem_max_rss": "124816", "process_out_blocks": "0", "process_user_time": 5.448537}
[0m07:49:08.824679 [debug] [MainThread]: Command `dbt test` succeeded at 07:49:08.824357 after 2.15 seconds
[0m07:49:08.826805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb775a637d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb77947ec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb777eebf50>]}
[0m07:49:08.828727 [debug] [MainThread]: Flushing usage events
[0m07:49:09.923581 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:02:46.099581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d18d4650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cfa48d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cfa487d0>]}


============================== 11:02:46.112432 | 371faa05-dbf8-4e5e-886c-58d18b1e457d ==============================
[0m11:02:46.112432 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:02:46.114331 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:02:46.500308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cf841490>]}
[0m11:02:46.608134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cf768740>]}
[0m11:02:46.610624 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:02:46.763640 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:02:47.297052 [debug] [MainThread]: Partial parsing enabled: 1 files deleted, 0 files added, 0 files changed.
[0m11:02:47.299191 [debug] [MainThread]: Partial parsing: deleted file: idx_stock://models/marts/analytics/stock_performance.sql
[0m11:02:47.425804 [warn ] [MainThread]: [[33mWARNING[0m]: Did not find matching node for patch with name 'stock_performance' in the 'models' section of file 'models/schema.yml'
[0m11:02:47.601100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ce1aac00>]}
[0m11:02:47.787738 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:02:47.804351 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:02:47.849406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ce532780>]}
[0m11:02:47.851459 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:02:47.853367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ce19c8f0>]}
[0m11:02:47.858139 [info ] [MainThread]: 
[0m11:02:47.860168 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:02:47.862013 [info ] [MainThread]: 
[0m11:02:47.864293 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:02:47.872769 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:02:47.874035 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:02:47.875481 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:02:47.947670 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:02:47.948416 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:02:47.949049 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:02:47.950576 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:02:47.952452 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:02:47.954346 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:02:47.956123 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:47.957888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:47.959470 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:02:47.973417 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.015 seconds
[0m11:02:47.974168 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.018 seconds
[0m11:02:47.974929 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.015 seconds
[0m11:02:47.977768 [debug] [ThreadPool]: On list_airflow: Close
[0m11:02:47.980710 [debug] [ThreadPool]: On list_airflow: Close
[0m11:02:47.984034 [debug] [ThreadPool]: On list_airflow: Close
[0m11:02:47.990693 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m11:02:47.991778 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m11:02:47.992757 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m11:02:48.002956 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:02:48.007008 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:02:48.011164 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:02:48.012864 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:02:48.014577 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:02:48.016351 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:02:48.017950 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:02:48.019443 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:02:48.020831 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:02:48.032959 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:02:48.034049 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m11:02:48.035893 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m11:02:48.037289 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:02:48.038966 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:02:48.040635 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:02:48.042634 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:02:48.044485 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:02:48.046591 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:02:48.053361 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.005 seconds
[0m11:02:48.054215 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m11:02:48.057351 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:02:48.058161 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m11:02:48.060998 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:02:48.063498 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:02:48.066331 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:02:48.068359 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:02:48.073051 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:02:48.084381 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:48.086036 [debug] [MainThread]: On master: BEGIN
[0m11:02:48.087770 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:02:48.098576 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:02:48.100558 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:48.102665 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:02:48.114540 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m11:02:48.118063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cedf26c0>]}
[0m11:02:48.120134 [debug] [MainThread]: On master: ROLLBACK
[0m11:02:48.122329 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:48.124270 [debug] [MainThread]: On master: BEGIN
[0m11:02:48.126459 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:02:48.128166 [debug] [MainThread]: On master: COMMIT
[0m11:02:48.129823 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:48.131372 [debug] [MainThread]: On master: COMMIT
[0m11:02:48.133255 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:02:48.134878 [debug] [MainThread]: On master: Close
[0m11:02:48.142523 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m11:02:48.144502 [info ] [Thread-1 (]: 1 of 6 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m11:02:48.146319 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m11:02:48.148055 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m11:02:48.161177 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.173053 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m11:02:48.231547 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.245114 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.246564 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m11:02:48.247991 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:02:48.258275 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m11:02:48.260336 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.262237 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m11:02:48.272338 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m11:02:48.283002 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.284926 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m11:02:48.287747 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:48.293627 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.295621 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m11:02:48.298029 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:48.326156 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:02:48.328062 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.329782 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:02:48.336033 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m11:02:48.346916 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m11:02:48.355764 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:02:48.357640 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m11:02:48.366106 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m11:02:48.370870 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m11:02:48.374530 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0cd973a40>]}
[0m11:02:48.376651 [info ] [Thread-1 (]: 1 of 6 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.23s]
[0m11:02:48.378717 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m11:02:48.381356 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m11:02:48.382094 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m11:02:48.383821 [info ] [Thread-3 (]: 2 of 6 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m11:02:48.385914 [info ] [Thread-4 (]: 3 of 6 START sql table model public_core.dim_companies ......................... [RUN]
[0m11:02:48.387913 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m11:02:48.389870 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m11:02:48.391588 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m11:02:48.393156 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m11:02:48.398718 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m11:02:48.404434 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m11:02:48.414010 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m11:02:48.415065 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m11:02:48.466267 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m11:02:48.467205 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m11:02:48.476661 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:48.477788 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:48.478820 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m11:02:48.480299 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m11:02:48.481930 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:02:48.483670 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:02:48.494081 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m11:02:48.496056 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:48.497802 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m11:02:48.499630 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m11:02:48.501476 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:48.504342 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m11:02:50.487827 [debug] [Thread-4 (]: SQL status: SELECT 961 in 1.981 seconds
[0m11:02:50.508530 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:50.510967 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m11:02:50.513098 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:02:50.513953 [debug] [Thread-3 (]: SQL status: SELECT 295508 in 2.011 seconds
[0m11:02:50.519983 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:50.526576 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:50.528479 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m11:02:50.530559 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m11:02:50.533020 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:50.534944 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:02:50.537961 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:02:50.545245 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:50.547111 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:50.549252 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m11:02:50.551500 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:02:50.554142 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:50.559253 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:02:50.561310 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m11:02:50.563027 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:50.569158 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m11:02:50.571602 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:02:50.578573 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:02:50.582080 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m11:02:50.582998 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m11:02:50.590124 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m11:02:50.591067 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.006 seconds
[0m11:02:50.593293 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:02:50.597236 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m11:02:50.599376 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m11:02:50.601936 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c5603c20>]}
[0m11:02:50.605210 [info ] [Thread-4 (]: 3 of 6 OK created sql table model public_core.dim_companies .................... [[32mSELECT 961[0m in 2.21s]
[0m11:02:50.607844 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m11:02:50.609783 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m11:02:50.611489 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m11:02:50.612320 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m11:02:50.613211 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m11:02:50.615671 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m11:02:50.618008 [info ] [Thread-1 (]: 4 of 6 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m11:02:50.620508 [info ] [Thread-2 (]: 5 of 6 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m11:02:50.623072 [info ] [Thread-4 (]: 6 of 6 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m11:02:50.625471 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c561f170>]}
[0m11:02:50.627357 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m11:02:50.629510 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m11:02:50.631714 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_weekly)
[0m11:02:50.633932 [info ] [Thread-3 (]: 2 of 6 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 295508[0m in 2.24s]
[0m11:02:50.635821 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m11:02:50.637927 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m11:02:50.640062 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m11:02:50.642674 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m11:02:50.650577 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m11:02:50.658102 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m11:02:50.665345 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m11:02:50.677031 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m11:02:50.678812 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m11:02:50.685211 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m11:02:50.687204 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m11:02:50.694542 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m11:02:50.703677 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m11:02:50.714812 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.716294 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:50.718104 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m11:02:50.719611 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:50.721032 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m11:02:50.722893 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:02:50.724779 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m11:02:50.726940 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:02:50.730710 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m11:02:50.739571 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m11:02:50.741841 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.743799 [debug] [Thread-2 (]: SQL status: BEGIN in 0.017 seconds
[0m11:02:50.745519 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m11:02:50.747075 [debug] [Thread-4 (]: SQL status: BEGIN in 0.016 seconds
[0m11:02:50.748907 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:50.752525 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:50.755079 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m11:02:50.758035 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m11:02:50.811282 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.060 seconds
[0m11:02:50.818082 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.820127 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m11:02:50.822606 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:50.829692 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.831781 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m11:02:50.834283 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:50.838259 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:02:50.840303 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.842325 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:02:50.846153 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:02:50.851752 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m11:02:50.854611 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:02:50.857159 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m11:02:50.862943 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:02:50.867091 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m11:02:50.869495 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c77bcb90>]}
[0m11:02:50.872141 [info ] [Thread-1 (]: 4 of 6 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.24s]
[0m11:02:50.875358 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m11:02:53.606976 [debug] [Thread-2 (]: SQL status: SELECT 959 in 2.846 seconds
[0m11:02:53.615062 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:53.617283 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m11:02:53.620055 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:53.627004 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:53.629204 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m11:02:53.631886 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:53.636047 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:02:53.638158 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:53.639971 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:02:53.647175 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m11:02:53.652679 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m11:02:53.655145 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:02:53.657213 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m11:02:53.664680 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.005 seconds
[0m11:02:53.668389 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m11:02:53.670690 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c7718c50>]}
[0m11:02:53.673196 [info ] [Thread-2 (]: 5 of 6 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 3.04s]
[0m11:02:53.675871 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m11:02:53.795767 [debug] [Thread-4 (]: SQL status: SELECT 959 in 3.034 seconds
[0m11:02:53.802251 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:53.804299 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m11:02:53.807090 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:53.814032 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:53.816123 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m11:02:53.818971 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:02:53.822559 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:02:53.824435 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:53.826221 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:02:53.833238 [debug] [Thread-4 (]: SQL status: COMMIT in 0.005 seconds
[0m11:02:53.838466 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m11:02:53.840848 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:02:53.842730 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m11:02:53.850489 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.006 seconds
[0m11:02:53.854227 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m11:02:53.856520 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '371faa05-dbf8-4e5e-886c-58d18b1e457d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0c77bcaa0>]}
[0m11:02:53.858971 [info ] [Thread-4 (]: 6 of 6 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 3.22s]
[0m11:02:53.861198 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m11:02:53.865167 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:53.867001 [debug] [MainThread]: On master: BEGIN
[0m11:02:53.868726 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:02:53.879438 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:02:53.881425 [debug] [MainThread]: On master: COMMIT
[0m11:02:53.883199 [debug] [MainThread]: Using postgres connection "master"
[0m11:02:53.884935 [debug] [MainThread]: On master: COMMIT
[0m11:02:53.886834 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:02:53.888579 [debug] [MainThread]: On master: Close
[0m11:02:53.890493 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:02:53.892300 [debug] [MainThread]: Connection 'model.idx_stock.daily_stock_metrics' was properly closed.
[0m11:02:53.893997 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m11:02:53.895678 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m11:02:53.897373 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m11:02:53.899301 [info ] [MainThread]: 
[0m11:02:53.901056 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 0 minutes and 6.04 seconds (6.04s).
[0m11:02:53.904857 [debug] [MainThread]: Command end result
[0m11:02:53.976686 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:02:53.985829 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:02:54.002454 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:02:54.004069 [info ] [MainThread]: 
[0m11:02:54.006048 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:02:54.007752 [info ] [MainThread]: 
[0m11:02:54.009452 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m11:02:54.012342 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.020961, "process_in_blocks": "0", "process_kernel_time": 0.742908, "process_mem_max_rss": "122920", "process_out_blocks": "0", "process_user_time": 5.300752}
[0m11:02:54.014842 [debug] [MainThread]: Command `dbt run` succeeded at 11:02:54.014614 after 8.02 seconds
[0m11:02:54.016742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d18d4650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d0b535f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0d0aff1a0>]}
[0m11:02:54.018543 [debug] [MainThread]: Flushing usage events
[0m11:02:55.493841 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:03:05.731735 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee7599100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee52909e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee5291100>]}


============================== 11:03:05.741117 | 770d8eda-3b3f-4904-8d37-62ac88a24fa4 ==============================
[0m11:03:05.741117 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:03:05.743060 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:03:06.047700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee50a0590>]}
[0m11:03:06.162920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee53ea1e0>]}
[0m11:03:06.165389 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:03:06.302814 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:03:06.751743 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:03:06.753494 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:03:06.836401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee3d477d0>]}
[0m11:03:07.007265 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:03:07.022742 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:03:07.104547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee399efc0>]}
[0m11:03:07.106491 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:03:07.108508 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee52d9850>]}
[0m11:03:07.113190 [info ] [MainThread]: 
[0m11:03:07.115215 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:03:07.117011 [info ] [MainThread]: 
[0m11:03:07.119402 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:03:07.128971 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m11:03:07.130291 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m11:03:07.131391 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m11:03:07.203138 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:03:07.204007 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:03:07.204672 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:03:07.206108 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:03:07.207782 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:03:07.209545 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:03:07.211403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:07.213226 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:07.214716 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:03:07.229397 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m11:03:07.232328 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m11:03:07.233932 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m11:03:07.234646 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:03:07.236635 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:03:07.238344 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:03:07.240395 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:03:07.242478 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:03:07.244226 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:03:07.251254 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m11:03:07.252007 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m11:03:07.252725 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.006 seconds
[0m11:03:07.255641 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:03:07.258712 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:03:07.262008 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:03:07.264249 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:03:07.265789 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:03:07.267684 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:03:07.282197 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.284102 [debug] [MainThread]: On master: BEGIN
[0m11:03:07.285907 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:03:07.297535 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:03:07.299569 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.301712 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:03:07.312845 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m11:03:07.316481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '770d8eda-3b3f-4904-8d37-62ac88a24fa4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee505ecc0>]}
[0m11:03:07.318935 [debug] [MainThread]: On master: ROLLBACK
[0m11:03:07.321538 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.323422 [debug] [MainThread]: On master: BEGIN
[0m11:03:07.325671 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:03:07.327685 [debug] [MainThread]: On master: COMMIT
[0m11:03:07.329535 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.331305 [debug] [MainThread]: On master: COMMIT
[0m11:03:07.333418 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:03:07.335341 [debug] [MainThread]: On master: Close
[0m11:03:07.344133 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:03:07.345066 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:03:07.345920 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:03:07.346750 [debug] [Thread-4 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:03:07.348024 [info ] [Thread-1 (]: 1 of 4 START test not_null_dim_companies_symbol ................................ [RUN]
[0m11:03:07.350188 [info ] [Thread-2 (]: 2 of 4 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m11:03:07.352336 [info ] [Thread-3 (]: 3 of 4 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m11:03:07.354442 [info ] [Thread-4 (]: 4 of 4 START test unique_dim_companies_symbol .................................. [RUN]
[0m11:03:07.356456 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m11:03:07.358285 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m11:03:07.360136 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m11:03:07.362084 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b'
[0m11:03:07.363842 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:03:07.365630 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:03:07.367533 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:03:07.369296 [debug] [Thread-4 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:03:07.406996 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:03:07.409229 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:03:07.416161 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:03:07.426083 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:03:07.435862 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:03:07.436933 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:03:07.443929 [debug] [Thread-4 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:03:07.444745 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:03:07.471884 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:03:07.475098 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:03:07.479678 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:03:07.484329 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:03:07.494791 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:03:07.496085 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:03:07.497681 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:03:07.498738 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m11:03:07.500513 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:03:07.501307 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m11:03:07.503206 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m11:03:07.505260 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:03:07.507179 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m11:03:07.508672 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:03:07.510325 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:03:07.513209 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:03:07.522294 [debug] [Thread-2 (]: SQL status: BEGIN in 0.017 seconds
[0m11:03:07.524716 [debug] [Thread-4 (]: SQL status: BEGIN in 0.016 seconds
[0m11:03:07.525826 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:03:07.527685 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m11:03:07.529202 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:03:07.531528 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m11:03:07.532721 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m11:03:07.535058 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:03:07.537001 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m11:03:07.538903 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:03:07.541948 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m11:03:07.544869 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m11:03:07.545768 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m11:03:07.548131 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m11:03:07.556576 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m11:03:07.557462 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.009 seconds
[0m11:03:07.558266 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.018 seconds
[0m11:03:07.561174 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m11:03:07.563234 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m11:03:07.566637 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m11:03:07.570219 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m11:03:07.572742 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m11:03:07.574708 [info ] [Thread-4 (]: 4 of 4 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.21s]
[0m11:03:07.576696 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m11:03:07.578619 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m11:03:07.580654 [info ] [Thread-1 (]: 1 of 4 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.22s]
[0m11:03:07.582565 [debug] [Thread-4 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:03:07.585078 [info ] [Thread-3 (]: 3 of 4 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.22s]
[0m11:03:07.587089 [info ] [Thread-2 (]: 2 of 4 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.23s]
[0m11:03:07.589170 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:03:07.592941 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:03:07.595230 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:03:07.601564 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.603224 [debug] [MainThread]: On master: BEGIN
[0m11:03:07.604725 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:03:07.615508 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:03:07.617423 [debug] [MainThread]: On master: COMMIT
[0m11:03:07.619166 [debug] [MainThread]: Using postgres connection "master"
[0m11:03:07.620904 [debug] [MainThread]: On master: COMMIT
[0m11:03:07.622830 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:03:07.624593 [debug] [MainThread]: On master: Close
[0m11:03:07.626544 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:03:07.628057 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m11:03:07.630567 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m11:03:07.632367 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m11:03:07.634007 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m11:03:07.635719 [info ] [MainThread]: 
[0m11:03:07.637430 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m11:03:07.640505 [debug] [MainThread]: Command end result
[0m11:03:07.708463 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:03:07.717590 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:03:07.733777 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:03:07.735358 [info ] [MainThread]: 
[0m11:03:07.736866 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:03:07.738574 [info ] [MainThread]: 
[0m11:03:07.740118 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m11:03:07.742351 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.1101623, "process_in_blocks": "0", "process_kernel_time": 0.30142, "process_mem_max_rss": "122372", "process_out_blocks": "0", "process_user_time": 5.606415}
[0m11:03:07.744057 [debug] [MainThread]: Command `dbt test` succeeded at 11:03:07.743820 after 2.11 seconds
[0m11:03:07.745592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee52ae780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee5cd3e60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ee3d93fb0>]}
[0m11:03:07.747238 [debug] [MainThread]: Flushing usage events
[0m11:03:08.829352 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:26:32.134603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a6bea150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a69a7860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a6f97dd0>]}


============================== 11:26:32.144716 | 276ea3a1-67ff-4715-a61a-d640b54f41bc ==============================
[0m11:26:32.144716 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:26:32.146403 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:26:32.451858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a6422ff0>]}
[0m11:26:32.584023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a6426c00>]}
[0m11:26:32.586757 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:26:32.749856 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:26:33.173298 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:26:33.175595 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_performance_daily.sql
[0m11:26:33.728362 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a49b7dd0>]}
[0m11:26:33.900281 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:26:33.914793 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:26:33.954550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a5190c80>]}
[0m11:26:33.956880 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:26:33.959292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a45b3980>]}
[0m11:26:33.963684 [info ] [MainThread]: 
[0m11:26:33.965853 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:26:33.967579 [info ] [MainThread]: 
[0m11:26:33.969647 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:26:33.977849 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:26:33.979014 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:26:33.980222 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:26:34.043441 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:26:34.044730 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:26:34.045563 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:26:34.047256 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:26:34.049012 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:26:34.050640 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:26:34.052517 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:26:34.054182 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:26:34.055830 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:26:34.069033 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.017 seconds
[0m11:26:34.071960 [debug] [ThreadPool]: On list_airflow: Close
[0m11:26:34.074076 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.020 seconds
[0m11:26:34.077655 [debug] [ThreadPool]: On list_airflow: Close
[0m11:26:34.078369 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.023 seconds
[0m11:26:34.082551 [debug] [ThreadPool]: On list_airflow: Close
[0m11:26:34.086133 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m11:26:34.087186 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m11:26:34.088282 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m11:26:34.101114 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:26:34.104668 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:26:34.111122 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:26:34.112839 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:26:34.114398 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:26:34.115883 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:26:34.117405 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:26:34.118757 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:26:34.119934 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:26:34.130843 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m11:26:34.131833 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m11:26:34.133363 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:26:34.134129 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m11:26:34.135986 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:26:34.137587 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:26:34.139098 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:26:34.140656 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:26:34.143988 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:26:34.146747 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m11:26:34.149475 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:26:34.150129 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.004 seconds
[0m11:26:34.150882 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m11:26:34.152521 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:26:34.155163 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:26:34.158429 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:26:34.162294 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:26:34.163523 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:26:34.173840 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:34.176024 [debug] [MainThread]: On master: BEGIN
[0m11:26:34.177550 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:26:34.188759 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:26:34.190656 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:34.193164 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:26:34.204480 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m11:26:34.207611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a1ba55b0>]}
[0m11:26:34.209734 [debug] [MainThread]: On master: ROLLBACK
[0m11:26:34.211453 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:34.212874 [debug] [MainThread]: On master: BEGIN
[0m11:26:34.214774 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:26:34.216382 [debug] [MainThread]: On master: COMMIT
[0m11:26:34.217928 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:34.219276 [debug] [MainThread]: On master: COMMIT
[0m11:26:34.220806 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:26:34.222092 [debug] [MainThread]: On master: Close
[0m11:26:34.230300 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m11:26:34.232219 [info ] [Thread-1 (]: 1 of 6 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m11:26:34.234002 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m11:26:34.235572 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m11:26:34.247715 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.260785 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m11:26:34.314852 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.327650 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.329103 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m11:26:34.330351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:26:34.339614 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m11:26:34.341739 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.343629 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m11:26:34.349277 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m11:26:34.359438 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.361255 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m11:26:34.363554 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:26:34.368596 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.370975 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m11:26:34.373529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:26:34.398995 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:26:34.401010 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.403218 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:26:34.407053 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:26:34.417896 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m11:26:34.426990 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:26:34.428715 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m11:26:34.433975 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.004 seconds
[0m11:26:34.438442 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m11:26:34.442453 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a85be4e0>]}
[0m11:26:34.444641 [info ] [Thread-1 (]: 1 of 6 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.21s]
[0m11:26:34.446654 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m11:26:34.449078 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m11:26:34.449894 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m11:26:34.451608 [info ] [Thread-3 (]: 2 of 6 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m11:26:34.453456 [info ] [Thread-4 (]: 3 of 6 START sql table model public_core.dim_companies ......................... [RUN]
[0m11:26:34.455103 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m11:26:34.456810 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m11:26:34.458750 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m11:26:34.460353 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m11:26:34.465641 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m11:26:34.470693 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m11:26:34.481080 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m11:26:34.482060 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m11:26:34.531808 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m11:26:34.532487 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m11:26:34.545349 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:34.547013 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:34.547678 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m11:26:34.549214 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m11:26:34.550762 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:26:34.552269 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:26:34.562907 [debug] [Thread-4 (]: SQL status: BEGIN in 0.012 seconds
[0m11:26:34.564426 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m11:26:34.566015 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:34.567827 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:34.569491 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m11:26:34.571512 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m11:26:35.572017 [debug] [Thread-3 (]: SQL status: SELECT 295508 in 0.997 seconds
[0m11:26:35.582721 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:35.584296 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m11:26:35.586241 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:26:35.591813 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:35.593434 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m11:26:35.595375 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:26:35.598167 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:26:35.599576 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:35.600979 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:26:35.615674 [debug] [Thread-3 (]: SQL status: COMMIT in 0.011 seconds
[0m11:26:35.620313 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m11:26:35.625920 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:26:35.626600 [debug] [Thread-4 (]: SQL status: SELECT 961 in 1.053 seconds
[0m11:26:35.628018 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m11:26:35.633261 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:35.636241 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m11:26:35.638518 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:26:35.644138 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:35.645834 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m11:26:35.646523 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.012 seconds
[0m11:26:35.648231 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:26:35.650927 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m11:26:35.653796 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:26:35.655672 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a1ac7c20>]}
[0m11:26:35.657164 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:35.659496 [info ] [Thread-3 (]: 2 of 6 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 295508[0m in 1.20s]
[0m11:26:35.660974 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:26:35.662930 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m11:26:35.666380 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m11:26:35.670478 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m11:26:35.671932 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:26:35.673320 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m11:26:35.678252 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:26:35.681064 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m11:26:35.682911 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a1b9a4e0>]}
[0m11:26:35.684870 [info ] [Thread-4 (]: 3 of 6 OK created sql table model public_core.dim_companies .................... [[32mSELECT 961[0m in 1.23s]
[0m11:26:35.686794 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m11:26:35.689234 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m11:26:35.690359 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m11:26:35.691158 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m11:26:35.692855 [info ] [Thread-1 (]: 4 of 6 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m11:26:35.694883 [info ] [Thread-2 (]: 5 of 6 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m11:26:35.696903 [info ] [Thread-3 (]: 6 of 6 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m11:26:35.699098 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m11:26:35.700903 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_monthly)
[0m11:26:35.702678 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m11:26:35.704295 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m11:26:35.705976 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m11:26:35.708019 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m11:26:35.713974 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m11:26:35.719798 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m11:26:35.726019 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m11:26:35.735093 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m11:26:35.735886 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m11:26:35.743002 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m11:26:35.745833 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m11:26:35.751712 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m11:26:35.758011 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m11:26:35.768330 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:26:35.770317 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:35.771436 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m11:26:35.773834 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m11:26:35.775189 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:35.776548 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:26:35.778343 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:26:35.780133 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m11:26:35.786708 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:26:35.793760 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m11:26:35.795690 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:35.797485 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m11:26:35.802462 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m11:26:35.804485 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:26:35.806201 [debug] [Thread-3 (]: SQL status: BEGIN in 0.019 seconds
[0m11:26:35.808884 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m11:26:35.811204 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:35.819470 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m11:26:35.816546 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "WHEN"
LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                 ^

[0m11:26:35.823857 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: ROLLBACK
[0m11:26:35.834986 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m11:26:35.850058 [debug] [Thread-1 (]: Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql
[0m11:26:35.852345 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a00f8140>]}
[0m11:26:35.854875 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model public_analytics.stock_performance_daily . [[31mERROR[0m in 0.15s]
[0m11:26:35.858473 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m11:26:35.860661 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_performance_daily' to be skipped because of status 'error'.  Reason: Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql.
[0m11:26:37.880802 [debug] [Thread-2 (]: SQL status: SELECT 959 in 2.081 seconds
[0m11:26:37.886748 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:37.888687 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m11:26:37.891327 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:26:37.896850 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:37.898604 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m11:26:37.901065 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:26:37.906272 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:26:37.908056 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:37.909900 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:26:37.919551 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m11:26:37.925299 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m11:26:37.927304 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:26:37.928842 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m11:26:37.933675 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:26:37.937352 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m11:26:37.940200 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a1d00620>]}
[0m11:26:37.942245 [info ] [Thread-2 (]: 5 of 6 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 2.24s]
[0m11:26:37.944278 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m11:26:38.051463 [debug] [Thread-3 (]: SQL status: SELECT 959 in 2.229 seconds
[0m11:26:38.057317 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:38.059043 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m11:26:38.061113 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:26:38.066211 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:38.067763 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m11:26:38.069683 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:26:38.072977 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:26:38.074708 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:38.076160 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:26:38.080065 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m11:26:38.084222 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m11:26:38.086033 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:26:38.087541 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m11:26:38.092971 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:26:38.095739 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m11:26:38.097495 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '276ea3a1-67ff-4715-a61a-d640b54f41bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a1d01d90>]}
[0m11:26:38.099453 [info ] [Thread-3 (]: 6 of 6 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 2.39s]
[0m11:26:38.101322 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m11:26:38.104673 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:38.106218 [debug] [MainThread]: On master: BEGIN
[0m11:26:38.107513 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:26:38.116673 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m11:26:38.118461 [debug] [MainThread]: On master: COMMIT
[0m11:26:38.120129 [debug] [MainThread]: Using postgres connection "master"
[0m11:26:38.121899 [debug] [MainThread]: On master: COMMIT
[0m11:26:38.123958 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:26:38.125545 [debug] [MainThread]: On master: Close
[0m11:26:38.127311 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:26:38.128897 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m11:26:38.130432 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m11:26:38.131925 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m11:26:38.133515 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m11:26:38.135129 [info ] [MainThread]: 
[0m11:26:38.136648 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 0 minutes and 4.17 seconds (4.17s).
[0m11:26:38.139898 [debug] [MainThread]: Command end result
[0m11:26:38.267631 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:26:38.276399 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:26:38.292236 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:26:38.293766 [info ] [MainThread]: 
[0m11:26:38.295378 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:26:38.296850 [info ] [MainThread]: 
[0m11:26:38.298602 [error] [MainThread]:   Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql
[0m11:26:38.300098 [info ] [MainThread]: 
[0m11:26:38.301564 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:26:38.303746 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.2624264, "process_in_blocks": "0", "process_kernel_time": 0.600783, "process_mem_max_rss": "129684", "process_out_blocks": "0", "process_user_time": 4.786238}
[0m11:26:38.306187 [debug] [MainThread]: Command `dbt run` failed at 11:26:38.305976 after 6.27 seconds
[0m11:26:38.307815 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a85cb650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a85c8aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa4a80e3bc0>]}
[0m11:26:38.309382 [debug] [MainThread]: Flushing usage events
[0m11:26:39.935531 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:27:49.689474 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec660ba70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec6609e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec8108080>]}


============================== 11:27:49.698870 | e1e083e2-0444-41ff-935c-7fcd5246a24e ==============================
[0m11:27:49.698870 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:27:49.700790 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:27:49.998468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec5cfd550>]}
[0m11:27:50.096918 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec5ebf5f0>]}
[0m11:27:50.099105 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:27:50.225607 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:27:50.615126 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:27:50.617722 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m11:27:51.143574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec41aec60>]}
[0m11:27:51.327292 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:27:51.342869 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:27:51.391298 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3def320>]}
[0m11:27:51.393195 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:27:51.394664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec3db8800>]}
[0m11:27:51.398693 [info ] [MainThread]: 
[0m11:27:51.400269 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:27:51.401942 [info ] [MainThread]: 
[0m11:27:51.403893 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:27:51.412553 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:27:51.413837 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:27:51.415222 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:27:51.482869 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:27:51.483523 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:27:51.484234 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:27:51.485369 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:27:51.486771 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:27:51.488116 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:27:51.489704 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:27:51.491513 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:27:51.493054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:27:51.511687 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.019 seconds
[0m11:27:51.515624 [debug] [ThreadPool]: On list_airflow: Close
[0m11:27:51.513027 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.022 seconds
[0m11:27:51.512285 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.023 seconds
[0m11:27:51.519353 [debug] [ThreadPool]: On list_airflow: Close
[0m11:27:51.522143 [debug] [ThreadPool]: On list_airflow: Close
[0m11:27:51.529721 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m11:27:51.531008 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m11:27:51.532038 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m11:27:51.541633 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:27:51.546948 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:27:51.551029 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:27:51.552386 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:27:51.553798 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:27:51.555075 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:27:51.556797 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:27:51.558465 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:27:51.560195 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:27:51.574290 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m11:27:51.578670 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:27:51.581245 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m11:27:51.587036 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:27:51.590348 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:27:51.588328 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m11:27:51.593191 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:27:51.594888 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:27:51.582642 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:27:51.601565 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.009 seconds
[0m11:27:51.608708 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:27:51.602499 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m11:27:51.625620 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:27:51.622178 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:27:51.609995 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.006 seconds
[0m11:27:51.633663 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:27:51.628215 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:27:51.635731 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:27:51.660850 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:51.662615 [debug] [MainThread]: On master: BEGIN
[0m11:27:51.664602 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:27:51.676179 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:27:51.677937 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:51.679899 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:27:51.695011 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m11:27:51.697917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec15cdd00>]}
[0m11:27:51.699324 [debug] [MainThread]: On master: ROLLBACK
[0m11:27:51.700893 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:51.702048 [debug] [MainThread]: On master: BEGIN
[0m11:27:51.703517 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m11:27:51.705177 [debug] [MainThread]: On master: COMMIT
[0m11:27:51.707103 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:51.709307 [debug] [MainThread]: On master: COMMIT
[0m11:27:51.710727 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:27:51.712019 [debug] [MainThread]: On master: Close
[0m11:27:51.720381 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m11:27:51.721975 [info ] [Thread-1 (]: 1 of 6 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m11:27:51.724370 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m11:27:51.725831 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m11:27:51.737955 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.747475 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m11:27:51.812066 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.820719 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.822112 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m11:27:51.823746 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:27:51.832913 [debug] [Thread-1 (]: SQL status: BEGIN in 0.009 seconds
[0m11:27:51.834729 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.836190 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m11:27:51.840442 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m11:27:51.850211 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.851716 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m11:27:51.853607 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:27:51.859835 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.861305 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m11:27:51.862975 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:51.894293 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:27:51.896157 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.897661 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:27:51.905217 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m11:27:51.960033 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m11:27:51.991711 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:27:51.997466 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m11:27:52.011204 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.009 seconds
[0m11:27:52.024164 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m11:27:52.031240 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec7de6870>]}
[0m11:27:52.034720 [info ] [Thread-1 (]: 1 of 6 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.30s]
[0m11:27:52.037481 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m11:27:52.040924 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m11:27:52.042289 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m11:27:52.044448 [info ] [Thread-3 (]: 2 of 6 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m11:27:52.046558 [info ] [Thread-4 (]: 3 of 6 START sql table model public_core.dim_companies ......................... [RUN]
[0m11:27:52.048609 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.daily_stock_metrics)
[0m11:27:52.050457 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m11:27:52.052079 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m11:27:52.053651 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m11:27:52.059668 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m11:27:52.066550 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m11:27:52.075961 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m11:27:52.076855 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m11:27:52.158607 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m11:27:52.160841 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m11:27:52.171708 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:52.173328 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:52.174579 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m11:27:52.176463 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m11:27:52.178119 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:27:52.179798 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:27:52.194361 [debug] [Thread-4 (]: SQL status: BEGIN in 0.015 seconds
[0m11:27:52.195138 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m11:27:52.196543 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:52.198093 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:52.199992 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m11:27:52.201862 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m11:27:53.141442 [debug] [Thread-3 (]: SQL status: SELECT 295508 in 0.936 seconds
[0m11:27:53.152320 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:53.154277 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m11:27:53.156982 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:27:53.163021 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:53.165012 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m11:27:53.166991 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:53.169784 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:27:53.171168 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:53.173100 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:27:53.185135 [debug] [Thread-3 (]: SQL status: COMMIT in 0.010 seconds
[0m11:27:53.190015 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m11:27:53.195104 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:27:53.196564 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m11:27:53.207048 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.009 seconds
[0m11:27:53.209927 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m11:27:53.211602 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec14c9400>]}
[0m11:27:53.213289 [info ] [Thread-3 (]: 2 of 6 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 295508[0m in 1.16s]
[0m11:27:53.215001 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m11:27:53.231513 [debug] [Thread-4 (]: SQL status: SELECT 961 in 1.028 seconds
[0m11:27:53.236992 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:53.239195 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m11:27:53.241499 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:53.247009 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:53.248784 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m11:27:53.250983 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:53.253948 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:27:53.255628 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:53.257530 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:27:53.261572 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m11:27:53.265995 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m11:27:53.267938 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:27:53.269592 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m11:27:53.274605 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:27:53.277919 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m11:27:53.280039 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec14d6000>]}
[0m11:27:53.282051 [info ] [Thread-4 (]: 3 of 6 OK created sql table model public_core.dim_companies .................... [[32mSELECT 961[0m in 1.23s]
[0m11:27:53.284143 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m11:27:53.286714 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m11:27:53.287499 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m11:27:53.288353 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m11:27:53.290369 [info ] [Thread-1 (]: 4 of 6 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m11:27:53.292297 [info ] [Thread-2 (]: 5 of 6 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m11:27:53.294260 [info ] [Thread-3 (]: 6 of 6 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m11:27:53.296073 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m11:27:53.297502 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_monthly)
[0m11:27:53.299162 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m11:27:53.300771 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m11:27:53.302223 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m11:27:53.303769 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m11:27:53.309885 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m11:27:53.317416 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m11:27:53.323593 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m11:27:53.334245 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m11:27:53.335184 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m11:27:53.340845 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m11:27:53.341620 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m11:27:53.346730 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m11:27:53.353504 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m11:27:53.360545 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:27:53.361757 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:53.363254 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m11:27:53.364398 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:53.365466 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m11:27:53.367082 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:27:53.368687 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m11:27:53.370290 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:27:53.373180 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:27:53.381836 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m11:27:53.384219 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:27:53.385466 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m11:27:53.387045 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m11:27:53.388488 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m11:27:53.390789 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:53.394132 [debug] [Thread-1 (]: Postgres adapter: Postgres error: syntax error at or near "WHEN"
LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                 ^

[0m11:27:53.395784 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:53.398092 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m11:27:53.400125 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: ROLLBACK
[0m11:27:53.402353 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m11:27:53.406797 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m11:27:53.417893 [debug] [Thread-1 (]: Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql
[0m11:27:53.420207 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec39a70b0>]}
[0m11:27:53.422703 [error] [Thread-1 (]: 4 of 6 ERROR creating sql table model public_analytics.stock_performance_daily . [[31mERROR[0m in 0.12s]
[0m11:27:53.425059 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m11:27:53.427416 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_performance_daily' to be skipped because of status 'error'.  Reason: Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql.
[0m11:27:55.458786 [debug] [Thread-2 (]: SQL status: SELECT 959 in 2.050 seconds
[0m11:27:55.464397 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:55.466085 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m11:27:55.468054 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:55.473781 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:55.475277 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m11:27:55.477272 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:55.480012 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:27:55.481499 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:55.482908 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:27:55.491042 [debug] [Thread-2 (]: SQL status: COMMIT in 0.007 seconds
[0m11:27:55.496577 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m11:27:55.498646 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:27:55.500407 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m11:27:55.505289 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:27:55.509281 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m11:27:55.511581 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec398c860>]}
[0m11:27:55.513899 [info ] [Thread-2 (]: 5 of 6 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 2.21s]
[0m11:27:55.515942 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m11:27:55.606167 [debug] [Thread-3 (]: SQL status: SELECT 959 in 2.201 seconds
[0m11:27:55.611884 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:55.613873 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m11:27:55.616068 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:55.621750 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:55.623645 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m11:27:55.625833 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:27:55.629192 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:27:55.631086 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:55.632801 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:27:55.640556 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m11:27:55.645243 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m11:27:55.647219 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:27:55.648791 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m11:27:55.656439 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m11:27:55.659578 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m11:27:55.661647 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e1e083e2-0444-41ff-935c-7fcd5246a24e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec39031d0>]}
[0m11:27:55.663838 [info ] [Thread-3 (]: 6 of 6 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 2.36s]
[0m11:27:55.665944 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m11:27:55.669568 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:55.671467 [debug] [MainThread]: On master: BEGIN
[0m11:27:55.673089 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:27:55.682561 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m11:27:55.684405 [debug] [MainThread]: On master: COMMIT
[0m11:27:55.686156 [debug] [MainThread]: Using postgres connection "master"
[0m11:27:55.688150 [debug] [MainThread]: On master: COMMIT
[0m11:27:55.690224 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:27:55.691855 [debug] [MainThread]: On master: Close
[0m11:27:55.693708 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:27:55.695265 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m11:27:55.696798 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m11:27:55.698244 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m11:27:55.699592 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m11:27:55.701017 [info ] [MainThread]: 
[0m11:27:55.702518 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 0 minutes and 4.30 seconds (4.30s).
[0m11:27:55.706093 [debug] [MainThread]: Command end result
[0m11:27:55.836740 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:27:55.845340 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:27:55.860683 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:27:55.862081 [info ] [MainThread]: 
[0m11:27:55.863397 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m11:27:55.864912 [info ] [MainThread]: 
[0m11:27:55.866702 [error] [MainThread]:   Database Error in model stock_performance_daily (models/marts/analytics/stock_performance_daily.sql)
  syntax error at or near "WHEN"
  LINE 28:         WHEN s.prev_close > 0 THEN (s.close - s.prev_close) ...
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_performance_daily.sql
[0m11:27:55.868394 [info ] [MainThread]: 
[0m11:27:55.870841 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
[0m11:27:55.873828 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.2744064, "process_in_blocks": "0", "process_kernel_time": 0.259958, "process_mem_max_rss": "130316", "process_out_blocks": "0", "process_user_time": 4.919216}
[0m11:27:55.875821 [debug] [MainThread]: Command `dbt run` failed at 11:27:55.875666 after 6.28 seconds
[0m11:27:55.877521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec032ed20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec032dc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ec032ec00>]}
[0m11:27:55.879219 [debug] [MainThread]: Flushing usage events
[0m11:27:57.801306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:28:30.862782 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe778560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbfc47860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe845970>]}


============================== 11:28:30.872225 | 411f0299-15e2-4e58-b3df-486512ac8342 ==============================
[0m11:28:30.872225 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:28:30.874179 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:28:31.179015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdc02e2810>]}
[0m11:28:31.270564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbedad9d0>]}
[0m11:28:31.272909 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:28:31.401812 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:28:31.786052 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:28:31.788842 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_performance_daily.sql
[0m11:28:32.427398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe1aaf00>]}
[0m11:28:32.651591 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:28:32.664495 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:28:32.699311 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbcf39e80>]}
[0m11:28:32.701670 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:28:32.704584 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbcffbd70>]}
[0m11:28:32.709684 [info ] [MainThread]: 
[0m11:28:32.711353 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:28:32.712789 [info ] [MainThread]: 
[0m11:28:32.714492 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:28:32.722658 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:28:32.723625 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:28:32.724494 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:28:32.787967 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:28:32.789082 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:28:32.789701 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:28:32.790932 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:28:32.792499 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:28:32.794075 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:28:32.795494 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:32.797289 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:32.798630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:32.811427 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.016 seconds
[0m11:28:32.814385 [debug] [ThreadPool]: On list_airflow: Close
[0m11:28:32.817644 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.020 seconds
[0m11:28:32.819165 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.020 seconds
[0m11:28:32.823029 [debug] [ThreadPool]: On list_airflow: Close
[0m11:28:32.826152 [debug] [ThreadPool]: On list_airflow: Close
[0m11:28:32.831723 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m11:28:32.832819 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m11:28:32.833874 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m11:28:32.845785 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:28:32.849182 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:28:32.853808 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:28:32.855608 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:28:32.857148 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:28:32.858398 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:28:32.859883 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:28:32.861229 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:28:32.862545 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:28:32.875286 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m11:28:32.876492 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m11:28:32.878279 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m11:28:32.879558 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:28:32.881201 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:28:32.882871 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:28:32.884323 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:28:32.886480 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:28:32.888930 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:28:32.894088 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.003 seconds
[0m11:28:32.894871 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m11:28:32.895458 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.004 seconds
[0m11:28:32.898189 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:28:32.901050 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:28:32.904753 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:28:32.907032 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:28:32.908323 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:28:32.909916 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:28:32.925263 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:32.927147 [debug] [MainThread]: On master: BEGIN
[0m11:28:32.928920 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:28:32.939675 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:28:32.941812 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:32.943800 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:28:32.954422 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m11:28:32.957676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe779610>]}
[0m11:28:32.959370 [debug] [MainThread]: On master: ROLLBACK
[0m11:28:32.961222 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:32.962656 [debug] [MainThread]: On master: BEGIN
[0m11:28:32.964432 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m11:28:32.966324 [debug] [MainThread]: On master: COMMIT
[0m11:28:32.968162 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:32.971276 [debug] [MainThread]: On master: COMMIT
[0m11:28:32.973227 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:32.974842 [debug] [MainThread]: On master: Close
[0m11:28:32.981859 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m11:28:32.983739 [info ] [Thread-1 (]: 1 of 6 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m11:28:32.985633 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m11:28:32.987548 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m11:28:32.999840 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.013103 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m11:28:33.066274 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.078742 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.080294 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m11:28:33.081564 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:28:33.091337 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m11:28:33.093434 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.095230 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m11:28:33.099756 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m11:28:33.110715 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.112708 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m11:28:33.115059 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:33.121445 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.123333 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m11:28:33.125527 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:33.150933 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:28:33.153507 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.155369 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:28:33.161191 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m11:28:33.171882 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m11:28:33.181178 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:28:33.183178 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m11:28:33.190995 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m11:28:33.196014 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m11:28:33.199782 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdc03b6600>]}
[0m11:28:33.202507 [info ] [Thread-1 (]: 1 of 6 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.21s]
[0m11:28:33.205132 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m11:28:33.210358 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m11:28:33.211239 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m11:28:33.213004 [info ] [Thread-3 (]: 2 of 6 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m11:28:33.214766 [info ] [Thread-4 (]: 3 of 6 START sql table model public_core.dim_companies ......................... [RUN]
[0m11:28:33.216641 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m11:28:33.218795 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m11:28:33.221108 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m11:28:33.222978 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m11:28:33.230904 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m11:28:33.236680 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m11:28:33.246670 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m11:28:33.247607 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m11:28:33.294648 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m11:28:33.295500 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m11:28:33.305851 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:33.306725 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:33.307868 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m11:28:33.309125 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m11:28:33.310443 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:28:33.311822 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:28:33.322301 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m11:28:33.324075 [debug] [Thread-4 (]: SQL status: BEGIN in 0.012 seconds
[0m11:28:33.325083 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:33.326692 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:33.328426 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m11:28:33.330099 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m11:28:34.641100 [debug] [Thread-3 (]: SQL status: SELECT 295508 in 1.309 seconds
[0m11:28:34.654170 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:34.656231 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m11:28:34.658548 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:34.664108 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:34.664948 [debug] [Thread-4 (]: SQL status: SELECT 961 in 1.332 seconds
[0m11:28:34.666466 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m11:28:34.672328 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:34.674832 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:34.675844 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m11:28:34.678979 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:28:34.681143 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:28:34.682198 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:34.687755 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:34.689636 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:28:34.691155 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m11:28:34.694489 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:28:34.698300 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:28:34.700020 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:34.702281 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:28:34.737268 [debug] [Thread-3 (]: SQL status: COMMIT in 0.044 seconds
[0m11:28:34.738825 [debug] [Thread-4 (]: SQL status: COMMIT in 0.035 seconds
[0m11:28:34.742406 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m11:28:34.746970 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m11:28:34.752692 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:28:34.754950 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:28:34.756754 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m11:28:34.758520 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m11:28:34.764722 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:28:34.768367 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m11:28:34.770798 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbc736bd0>]}
[0m11:28:34.772374 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.012 seconds
[0m11:28:34.773604 [info ] [Thread-4 (]: 3 of 6 OK created sql table model public_core.dim_companies .................... [[32mSELECT 961[0m in 1.55s]
[0m11:28:34.777052 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m11:28:34.779203 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m11:28:34.781182 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdb98cdbb0>]}
[0m11:28:34.783417 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m11:28:34.784693 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m11:28:34.785587 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m11:28:34.786651 [info ] [Thread-3 (]: 2 of 6 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 295508[0m in 1.56s]
[0m11:28:34.788560 [info ] [Thread-1 (]: 4 of 6 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m11:28:34.790748 [info ] [Thread-2 (]: 5 of 6 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m11:28:34.793077 [info ] [Thread-4 (]: 6 of 6 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m11:28:34.795231 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m11:28:34.797164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m11:28:34.798961 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m11:28:34.800851 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_weekly)
[0m11:28:34.804059 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m11:28:34.805705 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m11:28:34.807276 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m11:28:34.814879 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m11:28:34.821309 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m11:28:34.827482 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m11:28:34.835746 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m11:28:34.837038 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m11:28:34.843034 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m11:28:34.843911 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m11:28:34.849612 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m11:28:34.857613 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m11:28:34.864105 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.865286 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:34.866843 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m11:28:34.868931 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:34.869678 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m11:28:34.871637 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:28:34.873764 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m11:28:34.875696 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:28:34.878822 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m11:28:34.887641 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m11:28:34.889759 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.892528 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m11:28:34.891478 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m11:28:34.894470 [debug] [Thread-4 (]: SQL status: BEGIN in 0.016 seconds
[0m11:28:34.899566 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:34.904516 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m11:28:34.902133 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:34.910922 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m11:28:34.949491 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.055 seconds
[0m11:28:34.956252 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.958196 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m11:28:34.960301 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:28:34.965763 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.968044 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m11:28:34.970394 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:28:34.973567 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:28:34.975240 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.976911 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:28:34.981092 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m11:28:34.986982 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m11:28:34.988949 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:28:34.990622 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m11:28:34.994885 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:28:34.997974 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m11:28:34.999845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdb98f2030>]}
[0m11:28:35.002387 [info ] [Thread-1 (]: 4 of 6 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.20s]
[0m11:28:35.004606 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m11:28:37.030063 [debug] [Thread-2 (]: SQL status: SELECT 959 in 2.120 seconds
[0m11:28:37.037607 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:37.039845 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m11:28:37.041785 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:37.047108 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:37.048468 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m11:28:37.051402 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:37.054787 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:28:37.056268 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:37.057911 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:28:37.065819 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m11:28:37.072982 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m11:28:37.075175 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:28:37.076720 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m11:28:37.080803 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m11:28:37.084182 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m11:28:37.086342 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdb8737170>]}
[0m11:28:37.088568 [info ] [Thread-2 (]: 5 of 6 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 2.29s]
[0m11:28:37.090671 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m11:28:37.177574 [debug] [Thread-4 (]: SQL status: SELECT 959 in 2.265 seconds
[0m11:28:37.243761 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:37.246048 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m11:28:37.249272 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:37.256256 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:37.258301 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m11:28:37.260769 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:28:37.263846 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:28:37.265794 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:37.267781 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:28:37.282123 [debug] [Thread-4 (]: SQL status: COMMIT in 0.013 seconds
[0m11:28:37.286917 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m11:28:37.288994 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:28:37.290662 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m11:28:37.297920 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.006 seconds
[0m11:28:37.301319 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m11:28:37.303516 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '411f0299-15e2-4e58-b3df-486512ac8342', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbc7dfb60>]}
[0m11:28:37.305808 [info ] [Thread-4 (]: 6 of 6 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 2.50s]
[0m11:28:37.307867 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m11:28:37.311536 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:37.313178 [debug] [MainThread]: On master: BEGIN
[0m11:28:37.314680 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:28:37.324454 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m11:28:37.326196 [debug] [MainThread]: On master: COMMIT
[0m11:28:37.327829 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:37.329279 [debug] [MainThread]: On master: COMMIT
[0m11:28:37.330852 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:37.332682 [debug] [MainThread]: On master: Close
[0m11:28:37.334972 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:28:37.337054 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m11:28:37.338600 [debug] [MainThread]: Connection 'model.idx_stock.daily_stock_metrics' was properly closed.
[0m11:28:37.339998 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m11:28:37.341371 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m11:28:37.342968 [info ] [MainThread]: 
[0m11:28:37.344456 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 0 minutes and 4.63 seconds (4.63s).
[0m11:28:37.347564 [debug] [MainThread]: Command end result
[0m11:28:37.416901 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:28:37.425193 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:28:37.441475 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:28:37.443459 [info ] [MainThread]: 
[0m11:28:37.445493 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:28:37.447170 [info ] [MainThread]: 
[0m11:28:37.448951 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m11:28:37.451712 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.6828995, "process_in_blocks": "0", "process_kernel_time": 0.283461, "process_mem_max_rss": "129372", "process_out_blocks": "0", "process_user_time": 4.950449}
[0m11:28:37.453819 [debug] [MainThread]: Command `dbt run` succeeded at 11:28:37.453609 after 6.69 seconds
[0m11:28:37.455577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbef2d5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe4bcb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcdbe48e8a0>]}
[0m11:28:37.457218 [debug] [MainThread]: Flushing usage events
[0m11:28:38.893142 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:28:47.335817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81db371f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81daccf800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81dad0be00>]}


============================== 11:28:47.344646 | d61e12e1-5004-44c9-aa23-735c6caeb7bb ==============================
[0m11:28:47.344646 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:28:47.347000 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m11:28:47.727122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81da781280>]}
[0m11:28:47.837672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81dc1b01d0>]}
[0m11:28:47.841570 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:28:48.010387 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:28:48.474657 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:28:48.476200 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:28:48.565946 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81d9d50ad0>]}
[0m11:28:48.869496 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:28:48.891464 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:28:48.974165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81d8da3080>]}
[0m11:28:48.977618 [info ] [MainThread]: Found 6 models, 4 data tests, 1 source, 434 macros
[0m11:28:48.980382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81d8d22270>]}
[0m11:28:48.986968 [info ] [MainThread]: 
[0m11:28:48.989241 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:28:48.991210 [info ] [MainThread]: 
[0m11:28:48.994018 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:28:49.005303 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m11:28:49.006912 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m11:28:49.008635 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m11:28:49.113402 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:28:49.114572 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:28:49.115442 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:28:49.116997 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:28:49.118791 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:28:49.120543 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:28:49.122327 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:49.123967 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:49.125794 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:28:49.143680 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m11:28:49.146739 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m11:28:49.148973 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m11:28:49.150224 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:28:49.152037 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:28:49.154092 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:28:49.155969 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:28:49.157980 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:28:49.159860 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:28:49.167020 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.005 seconds
[0m11:28:49.171069 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:28:49.171921 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m11:28:49.172733 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m11:28:49.174405 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:28:49.177738 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:28:49.181240 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:28:49.187764 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:28:49.189377 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:28:49.203025 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.204759 [debug] [MainThread]: On master: BEGIN
[0m11:28:49.206773 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:28:49.218990 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m11:28:49.220930 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.222871 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:28:49.234983 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m11:28:49.238570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd61e12e1-5004-44c9-aa23-735c6caeb7bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81da71b980>]}
[0m11:28:49.240150 [debug] [MainThread]: On master: ROLLBACK
[0m11:28:49.242041 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.243385 [debug] [MainThread]: On master: BEGIN
[0m11:28:49.245497 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:28:49.247429 [debug] [MainThread]: On master: COMMIT
[0m11:28:49.248938 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.250392 [debug] [MainThread]: On master: COMMIT
[0m11:28:49.251995 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:49.253356 [debug] [MainThread]: On master: Close
[0m11:28:49.262369 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:28:49.263485 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:28:49.264435 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:28:49.265374 [debug] [Thread-4 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:28:49.266557 [info ] [Thread-1 (]: 1 of 4 START test not_null_dim_companies_symbol ................................ [RUN]
[0m11:28:49.268628 [info ] [Thread-2 (]: 2 of 4 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m11:28:49.270662 [info ] [Thread-3 (]: 3 of 4 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m11:28:49.272892 [info ] [Thread-4 (]: 4 of 4 START test unique_dim_companies_symbol .................................. [RUN]
[0m11:28:49.275072 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m11:28:49.277700 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m11:28:49.280878 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m11:28:49.283526 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b'
[0m11:28:49.285633 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:28:49.287920 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:28:49.290240 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:28:49.292869 [debug] [Thread-4 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:28:49.336442 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:28:49.338702 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:28:49.346347 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:28:49.357481 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:28:49.366615 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:28:49.367888 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:28:49.375048 [debug] [Thread-4 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:28:49.387043 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:28:49.399331 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:28:49.403024 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:28:49.408425 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:28:49.413311 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:28:49.423609 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:28:49.425309 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:28:49.426623 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:28:49.427520 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m11:28:49.428532 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:28:49.429984 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m11:28:49.431825 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m11:28:49.433678 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:28:49.435289 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m11:28:49.436975 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:28:49.438822 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:28:49.441805 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:28:49.451747 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m11:28:49.453590 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:28:49.455166 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m11:28:49.456934 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m11:28:49.459629 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:28:49.464563 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m11:28:49.461398 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m11:28:49.465646 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m11:28:49.467546 [debug] [Thread-3 (]: SQL status: BEGIN in 0.025 seconds
[0m11:28:49.479497 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:28:49.477850 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m11:28:49.470000 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:28:49.485708 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m11:28:49.483882 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m11:28:49.481540 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m11:28:49.487115 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.019 seconds
[0m11:28:49.490115 [info ] [Thread-1 (]: 1 of 4 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.21s]
[0m11:28:49.491173 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.003 seconds
[0m11:28:49.495386 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m11:28:49.496272 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.004 seconds
[0m11:28:49.498171 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:28:49.501931 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m11:28:49.504385 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m11:28:49.507735 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m11:28:49.511748 [debug] [Thread-4 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m11:28:49.513657 [info ] [Thread-2 (]: 2 of 4 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.24s]
[0m11:28:49.515409 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m11:28:49.517075 [info ] [Thread-4 (]: 4 of 4 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.23s]
[0m11:28:49.519014 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:28:49.521551 [info ] [Thread-3 (]: 3 of 4 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.24s]
[0m11:28:49.523429 [debug] [Thread-4 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:28:49.527373 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:28:49.532703 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.534624 [debug] [MainThread]: On master: BEGIN
[0m11:28:49.536257 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:28:49.547277 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m11:28:49.549281 [debug] [MainThread]: On master: COMMIT
[0m11:28:49.551197 [debug] [MainThread]: Using postgres connection "master"
[0m11:28:49.552981 [debug] [MainThread]: On master: COMMIT
[0m11:28:49.555096 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m11:28:49.557009 [debug] [MainThread]: On master: Close
[0m11:28:49.559235 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:28:49.561112 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m11:28:49.563344 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m11:28:49.565909 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m11:28:49.567861 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m11:28:49.570098 [info ] [MainThread]: 
[0m11:28:49.572489 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m11:28:49.576018 [debug] [MainThread]: Command end result
[0m11:28:49.650554 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:28:49.660355 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:28:49.679190 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:28:49.680932 [info ] [MainThread]: 
[0m11:28:49.682566 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:28:49.684234 [info ] [MainThread]: 
[0m11:28:49.686073 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m11:28:49.688715 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.4576879, "process_in_blocks": "0", "process_kernel_time": 0.355766, "process_mem_max_rss": "122892", "process_out_blocks": "0", "process_user_time": 4.6645}
[0m11:28:49.691157 [debug] [MainThread]: Command `dbt test` succeeded at 11:28:49.690925 after 2.46 seconds
[0m11:28:49.693134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81da780830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81d9d6f7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81daa08b60>]}
[0m11:28:49.695246 [debug] [MainThread]: Flushing usage events
[0m11:28:51.159501 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:19:43.453358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9084affcb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f908414e930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9084b23a10>]}


============================== 21:19:43.462297 | fc981424-92da-4c5c-8237-3db9fd2f0eed ==============================
[0m21:19:43.462297 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:19:43.464203 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:19:43.777041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9084138dd0>]}
[0m21:19:43.864934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f908494c890>]}
[0m21:19:43.871190 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:19:44.005775 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:19:44.417874 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m21:19:44.420611 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m21:19:45.112548 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9081f4c7d0>]}
[0m21:19:45.281749 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:19:45.296200 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:19:45.363942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9081bd5a90>]}
[0m21:19:45.365983 [info ] [MainThread]: Found 6 models, 5 data tests, 1 source, 434 macros
[0m21:19:45.367689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90823577d0>]}
[0m21:19:45.371973 [info ] [MainThread]: 
[0m21:19:45.373887 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:19:45.375548 [info ] [MainThread]: 
[0m21:19:45.377615 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:19:45.385844 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:19:45.388167 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:19:45.389300 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:19:45.463256 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:19:45.464016 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:19:45.464921 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:19:45.466358 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:19:45.468277 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:19:45.469913 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:19:45.471785 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:45.473662 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:45.475405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:19:45.489030 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.015 seconds
[0m21:19:45.492227 [debug] [ThreadPool]: On list_airflow: Close
[0m21:19:45.492951 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.021 seconds
[0m21:19:45.493818 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.018 seconds
[0m21:19:45.497865 [debug] [ThreadPool]: On list_airflow: Close
[0m21:19:45.501086 [debug] [ThreadPool]: On list_airflow: Close
[0m21:19:45.504674 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m21:19:45.505610 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m21:19:45.506436 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m21:19:45.508185 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m21:19:45.510298 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m21:19:45.512298 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m21:19:45.521658 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m21:19:45.525728 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m21:19:45.530085 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m21:19:45.531733 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m21:19:45.533555 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m21:19:45.535082 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m21:19:45.536659 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.538225 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.539943 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.550350 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m21:19:45.552170 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m21:19:45.553042 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m21:19:45.553774 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m21:19:45.555624 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m21:19:45.557395 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m21:19:45.559146 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m21:19:45.561402 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m21:19:45.564440 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m21:19:45.565286 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m21:19:45.567210 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:19:45.569042 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:19:45.570627 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m21:19:45.573047 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m21:19:45.575466 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m21:19:45.577225 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m21:19:45.578773 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m21:19:45.580453 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m21:19:45.581965 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m21:19:45.583619 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m21:19:45.585084 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m21:19:45.592167 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m21:19:45.593970 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m21:19:45.597366 [debug] [ThreadPool]: SQL status: COMMIT in 0.010 seconds
[0m21:19:45.598049 [debug] [ThreadPool]: SQL status: COMMIT in 0.010 seconds
[0m21:19:45.599519 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m21:19:45.601068 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m21:19:45.606498 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_core)
[0m21:19:45.607556 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_staging)
[0m21:19:45.608507 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m21:19:45.618421 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:19:45.622442 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:19:45.626574 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:19:45.628200 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m21:19:45.630031 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m21:19:45.631870 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m21:19:45.633524 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.635233 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.636976 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:19:45.648230 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m21:19:45.649666 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m21:19:45.650380 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m21:19:45.651117 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:19:45.652904 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:19:45.654497 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:19:45.656482 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m21:19:45.658359 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m21:19:45.660423 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m21:19:45.666903 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:19:45.667613 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m21:19:45.668243 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m21:19:45.671025 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m21:19:45.674053 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m21:19:45.677053 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m21:19:45.679243 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m21:19:45.681194 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m21:19:45.682921 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m21:19:45.695043 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:45.697064 [debug] [MainThread]: On master: BEGIN
[0m21:19:45.698875 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:19:45.709374 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m21:19:45.711369 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:45.713522 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:19:45.719663 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m21:19:45.723024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90843e2030>]}
[0m21:19:45.724957 [debug] [MainThread]: On master: ROLLBACK
[0m21:19:45.726905 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:45.728805 [debug] [MainThread]: On master: BEGIN
[0m21:19:45.731105 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:19:45.732768 [debug] [MainThread]: On master: COMMIT
[0m21:19:45.734417 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:45.736061 [debug] [MainThread]: On master: COMMIT
[0m21:19:45.737842 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:19:45.739443 [debug] [MainThread]: On master: Close
[0m21:19:45.747048 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m21:19:45.749159 [info ] [Thread-1 (]: 1 of 6 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m21:19:45.751012 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m21:19:45.752717 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m21:19:45.766921 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.781405 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m21:19:45.838668 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.851175 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.852592 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m21:19:45.853920 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:45.864062 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m21:19:45.866128 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.867935 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m21:19:45.874398 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m21:19:45.884717 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.886655 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m21:19:45.888938 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:45.912613 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:19:45.914537 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.916398 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:19:45.923587 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:19:45.934595 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m21:19:45.943426 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:19:45.945360 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m21:19:45.947679 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m21:19:45.952335 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m21:19:45.956034 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9083379e80>]}
[0m21:19:45.958246 [info ] [Thread-1 (]: 1 of 6 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.20s]
[0m21:19:45.960311 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m21:19:45.962999 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m21:19:45.964081 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m21:19:45.965732 [info ] [Thread-3 (]: 2 of 6 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m21:19:45.967864 [info ] [Thread-4 (]: 3 of 6 START sql table model public_core.dim_companies ......................... [RUN]
[0m21:19:45.969467 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m21:19:45.971298 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m21:19:45.972897 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m21:19:45.974611 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m21:19:45.980048 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m21:19:45.985267 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m21:19:45.996192 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m21:19:45.997223 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m21:19:46.047814 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m21:19:46.047171 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m21:19:46.058536 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:19:46.059491 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:19:46.060879 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m21:19:46.062358 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m21:19:46.063860 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:19:46.065348 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:19:46.074996 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m21:19:46.076435 [debug] [Thread-4 (]: SQL status: BEGIN in 0.011 seconds
[0m21:19:46.077333 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:19:46.079182 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:19:46.081188 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m21:19:46.083219 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m21:19:49.026725 [debug] [Thread-3 (]: SQL status: SELECT 700061 in 2.942 seconds
[0m21:19:49.038395 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:19:49.040139 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m21:19:49.042062 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:19:49.045350 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:19:49.046915 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:19:49.048319 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:19:49.056276 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m21:19:49.063038 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m21:19:49.070014 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:19:49.072195 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m21:19:49.074361 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:19:49.077841 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m21:19:49.080231 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90803f1070>]}
[0m21:19:49.082440 [info ] [Thread-3 (]: 2 of 6 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 700061[0m in 3.11s]
[0m21:19:49.084514 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m21:19:49.108170 [debug] [Thread-4 (]: SQL status: SELECT 962 in 3.023 seconds
[0m21:19:49.114607 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:19:49.116386 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m21:19:49.118385 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:19:49.121246 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:19:49.122808 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:19:49.124282 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:19:49.127896 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m21:19:49.132598 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m21:19:49.134559 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:19:49.136191 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m21:19:49.138110 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:19:49.141143 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m21:19:49.142870 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90803d2600>]}
[0m21:19:49.144904 [info ] [Thread-4 (]: 3 of 6 OK created sql table model public_core.dim_companies .................... [[32mSELECT 962[0m in 3.17s]
[0m21:19:49.146910 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m21:19:49.149434 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m21:19:49.150527 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m21:19:49.151414 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m21:19:49.152840 [info ] [Thread-1 (]: 4 of 6 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m21:19:49.154556 [info ] [Thread-2 (]: 5 of 6 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m21:19:49.156738 [info ] [Thread-3 (]: 6 of 6 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m21:19:49.158235 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m21:19:49.160140 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_monthly)
[0m21:19:49.161947 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m21:19:49.163589 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m21:19:49.165486 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m21:19:49.167388 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m21:19:49.174813 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m21:19:49.181172 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m21:19:49.188294 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m21:19:49.198428 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m21:19:49.200135 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m21:19:49.206276 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m21:19:49.207367 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m21:19:49.213351 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m21:19:49.220866 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m21:19:49.228817 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:19:49.229897 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:19:49.231731 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m21:19:49.235473 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:19:49.236355 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m21:19:49.238205 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:19:49.240187 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m21:19:49.242108 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:19:49.245060 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:19:49.254225 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m21:19:49.255899 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:19:49.258188 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m21:19:49.259496 [debug] [Thread-3 (]: SQL status: BEGIN in 0.017 seconds
[0m21:19:49.260370 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m21:19:49.263549 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:19:49.265759 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:19:49.267983 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m21:19:49.270403 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m21:19:49.380972 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.107 seconds
[0m21:19:49.387444 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:19:49.389354 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m21:19:49.391716 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:49.395019 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:19:49.396614 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:19:49.398026 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:19:49.401427 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:19:49.406446 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m21:19:49.408833 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:19:49.410697 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m21:19:49.412839 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:19:49.416374 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m21:19:49.418691 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90802177a0>]}
[0m21:19:49.420828 [info ] [Thread-1 (]: 4 of 6 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.26s]
[0m21:19:49.423397 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m21:19:53.679936 [debug] [Thread-2 (]: SQL status: SELECT 959 in 4.418 seconds
[0m21:19:53.688279 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:19:53.690625 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m21:19:53.693149 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:19:53.696968 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:19:53.698933 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:19:53.700767 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:19:53.759680 [debug] [Thread-2 (]: SQL status: COMMIT in 0.057 seconds
[0m21:19:53.824591 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m21:19:53.826985 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:19:53.828935 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m21:19:53.831304 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:19:53.834797 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m21:19:53.836955 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9080251fa0>]}
[0m21:19:53.839007 [info ] [Thread-2 (]: 5 of 6 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 4.68s]
[0m21:19:53.841390 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m21:19:54.027845 [debug] [Thread-3 (]: SQL status: SELECT 959 in 4.755 seconds
[0m21:19:54.034080 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:19:54.036056 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m21:19:54.038388 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:19:54.041418 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:19:54.043205 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:19:54.045083 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:19:54.056454 [debug] [Thread-3 (]: SQL status: COMMIT in 0.010 seconds
[0m21:19:54.060918 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m21:19:54.062839 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:19:54.064568 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m21:19:54.066566 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:19:54.069434 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m21:19:54.071151 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fc981424-92da-4c5c-8237-3db9fd2f0eed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90803a5fa0>]}
[0m21:19:54.073055 [info ] [Thread-3 (]: 6 of 6 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 4.91s]
[0m21:19:54.075007 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m21:19:54.078505 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:54.080465 [debug] [MainThread]: On master: BEGIN
[0m21:19:54.082102 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:19:54.092098 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m21:19:54.093910 [debug] [MainThread]: On master: COMMIT
[0m21:19:54.095665 [debug] [MainThread]: Using postgres connection "master"
[0m21:19:54.100386 [debug] [MainThread]: On master: COMMIT
[0m21:19:54.102582 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:19:54.104348 [debug] [MainThread]: On master: Close
[0m21:19:54.106249 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:19:54.107979 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m21:19:54.109586 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m21:19:54.111154 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m21:19:54.112876 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m21:19:54.114452 [info ] [MainThread]: 
[0m21:19:54.116020 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 0 minutes and 8.74 seconds (8.74s).
[0m21:19:54.119308 [debug] [MainThread]: Command end result
[0m21:19:54.185004 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:19:54.192774 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:19:54.209915 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:19:54.211653 [info ] [MainThread]: 
[0m21:19:54.213429 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:19:54.215440 [info ] [MainThread]: 
[0m21:19:54.217329 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m21:19:54.220115 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.859008, "process_in_blocks": "0", "process_kernel_time": 0.423886, "process_mem_max_rss": "129948", "process_out_blocks": "2360", "process_user_time": 4.889484}
[0m21:19:54.222395 [debug] [MainThread]: Command `dbt run` succeeded at 21:19:54.222167 after 10.86 seconds
[0m21:19:54.224091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90858e0d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9081b13b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f908023c560>]}
[0m21:19:54.225900 [debug] [MainThread]: Flushing usage events
[0m21:19:55.643811 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:20:03.060021 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4f933e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4740e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a5d9c9e0>]}


============================== 21:20:03.068529 | 375fa78c-4d83-431f-b44e-506e8c196a3a ==============================
[0m21:20:03.068529 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:20:03.070300 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m21:20:03.359664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4385760>]}
[0m21:20:03.469307 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4861d90>]}
[0m21:20:03.472492 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:20:03.620130 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:20:04.043632 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:20:04.045494 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:20:04.125812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a3595190>]}
[0m21:20:04.289602 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:20:04.301882 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:20:04.362955 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a259fa10>]}
[0m21:20:04.374595 [info ] [MainThread]: Found 6 models, 5 data tests, 1 source, 434 macros
[0m21:20:04.376399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4c623c0>]}
[0m21:20:04.381242 [info ] [MainThread]: 
[0m21:20:04.383280 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:20:04.385250 [info ] [MainThread]: 
[0m21:20:04.387353 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:20:04.398301 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m21:20:04.399732 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m21:20:04.401042 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m21:20:04.478995 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:20:04.480146 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:20:04.480930 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:20:04.486210 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m21:20:04.484322 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m21:20:04.482398 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m21:20:04.488048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:04.489972 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:04.492087 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:20:04.512091 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m21:20:04.514196 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:20:04.515873 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m21:20:04.520107 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m21:20:04.522047 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:20:04.526061 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m21:20:04.529501 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m21:20:04.523510 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m21:20:04.535589 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:20:04.533691 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m21:20:04.532891 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m21:20:04.537153 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m21:20:04.540658 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m21:20:04.542579 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m21:20:04.545143 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m21:20:04.549962 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.006 seconds
[0m21:20:04.554062 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m21:20:04.555769 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m21:20:04.566908 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:04.568572 [debug] [MainThread]: On master: BEGIN
[0m21:20:04.570000 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:20:04.581216 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m21:20:04.584070 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:04.586040 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:20:04.601168 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m21:20:04.604933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '375fa78c-4d83-431f-b44e-506e8c196a3a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a60304d0>]}
[0m21:20:04.606820 [debug] [MainThread]: On master: ROLLBACK
[0m21:20:04.608750 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:04.610215 [debug] [MainThread]: On master: BEGIN
[0m21:20:04.612347 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:20:04.614334 [debug] [MainThread]: On master: COMMIT
[0m21:20:04.615842 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:04.617212 [debug] [MainThread]: On master: COMMIT
[0m21:20:04.619059 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:20:04.621146 [debug] [MainThread]: On master: Close
[0m21:20:04.631533 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m21:20:04.632513 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m21:20:04.633400 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m21:20:04.634648 [debug] [Thread-4 (]: Began running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m21:20:04.635996 [info ] [Thread-1 (]: 1 of 5 START test not_null_dim_companies_symbol ................................ [RUN]
[0m21:20:04.638200 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m21:20:04.640458 [info ] [Thread-3 (]: 3 of 5 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m21:20:04.642576 [info ] [Thread-4 (]: 4 of 5 START test not_null_stock_performance_monthly_symbol .................... [RUN]
[0m21:20:04.644871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m21:20:04.646980 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m21:20:04.648775 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m21:20:04.650973 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce'
[0m21:20:04.652738 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m21:20:04.655318 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m21:20:04.657458 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m21:20:04.659580 [debug] [Thread-4 (]: Began compiling node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m21:20:04.709036 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m21:20:04.713656 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m21:20:04.721711 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m21:20:04.729602 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m21:20:04.740116 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m21:20:04.742046 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m21:20:04.744032 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m21:20:04.751565 [debug] [Thread-4 (]: Began executing node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m21:20:04.795829 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m21:20:04.808124 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m21:20:04.812978 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m21:20:04.818038 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m21:20:04.828757 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m21:20:04.830678 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m21:20:04.832009 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m21:20:04.833657 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m21:20:04.835027 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m21:20:04.844934 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:20:04.839830 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m21:20:04.842637 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: BEGIN
[0m21:20:04.851237 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:20:04.849273 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:20:04.837263 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m21:20:04.865435 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:20:04.861553 [debug] [Thread-3 (]: SQL status: BEGIN in 0.017 seconds
[0m21:20:04.869626 [debug] [Thread-4 (]: SQL status: BEGIN in 0.018 seconds
[0m21:20:04.879249 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m21:20:04.880822 [debug] [Thread-1 (]: SQL status: BEGIN in 0.031 seconds
[0m21:20:04.882081 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m21:20:04.884174 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m21:20:04.886051 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m21:20:04.888082 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m21:20:04.890359 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m21:20:04.892862 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_analytics"."stock_performance_monthly"
where symbol is null



      
    ) dbt_internal_test
[0m21:20:04.895325 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m21:20:04.897496 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m21:20:04.901835 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.001 seconds
[0m21:20:04.902915 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.003 seconds
[0m21:20:04.919897 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m21:20:04.916037 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: ROLLBACK
[0m21:20:04.906335 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m21:20:04.922352 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m21:20:04.931095 [info ] [Thread-3 (]: 3 of 5 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.28s]
[0m21:20:04.934004 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m21:20:04.936229 [debug] [Thread-3 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m21:20:04.938255 [info ] [Thread-3 (]: 5 of 5 START test unique_dim_companies_symbol .................................. [RUN]
[0m21:20:04.940817 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m21:20:04.942575 [debug] [Thread-3 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m21:20:04.924662 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: Close
[0m21:20:04.960699 [info ] [Thread-4 (]: 4 of 5 PASS not_null_stock_performance_monthly_symbol .......................... [[32mPASS[0m in 0.31s]
[0m21:20:04.963058 [debug] [Thread-4 (]: Finished running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m21:20:04.928794 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m21:20:04.958155 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m21:20:04.966272 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m21:20:04.969962 [info ] [Thread-1 (]: 1 of 5 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.32s]
[0m21:20:04.975310 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m21:20:04.982250 [debug] [Thread-3 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m21:20:04.989925 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m21:20:05.003212 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m21:20:05.005036 [debug] [Thread-3 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m21:20:05.007291 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.103 seconds
[0m21:20:05.012992 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m21:20:05.008753 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:20:05.015840 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m21:20:05.020149 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.37s]
[0m21:20:05.022881 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m21:20:05.031940 [debug] [Thread-3 (]: SQL status: BEGIN in 0.023 seconds
[0m21:20:05.033742 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m21:20:05.035447 [debug] [Thread-3 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m21:20:05.039301 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.002 seconds
[0m21:20:05.043254 [debug] [Thread-3 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m21:20:05.045188 [debug] [Thread-3 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m21:20:05.047431 [info ] [Thread-3 (]: 5 of 5 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.11s]
[0m21:20:05.049998 [debug] [Thread-3 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m21:20:05.054144 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:05.055771 [debug] [MainThread]: On master: BEGIN
[0m21:20:05.057254 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:20:05.069611 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m21:20:05.071672 [debug] [MainThread]: On master: COMMIT
[0m21:20:05.073311 [debug] [MainThread]: Using postgres connection "master"
[0m21:20:05.075070 [debug] [MainThread]: On master: COMMIT
[0m21:20:05.077398 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:20:05.079372 [debug] [MainThread]: On master: Close
[0m21:20:05.081511 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:20:05.083225 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m21:20:05.084997 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m21:20:05.086549 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m21:20:05.088125 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce' was properly closed.
[0m21:20:05.089782 [info ] [MainThread]: 
[0m21:20:05.091652 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 0.70 seconds (0.70s).
[0m21:20:05.096549 [debug] [MainThread]: Command end result
[0m21:20:05.192829 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:20:05.202647 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:20:05.222894 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:20:05.224843 [info ] [MainThread]: 
[0m21:20:05.226924 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:20:05.228902 [info ] [MainThread]: 
[0m21:20:05.231043 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m21:20:05.233984 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.264859, "process_in_blocks": "0", "process_kernel_time": 0.262545, "process_mem_max_rss": "123308", "process_out_blocks": "0", "process_user_time": 3.978578}
[0m21:20:05.236555 [debug] [MainThread]: Command `dbt test` succeeded at 21:20:05.236298 after 2.27 seconds
[0m21:20:05.238556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4ff2db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a4ff37a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87a0244080>]}
[0m21:20:05.240236 [debug] [MainThread]: Flushing usage events
[0m21:20:06.297958 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:04:35.827566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa822922c30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa82322daf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8223c95e0>]}


============================== 22:04:35.841195 | e18f6ac5-3158-42d5-9760-3f22a62164aa ==============================
[0m22:04:35.841195 [info ] [MainThread]: Running with dbt=1.9.4
[0m22:04:35.843363 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:04:36.234813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa821778c80>]}
[0m22:04:36.337677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8217788f0>]}
[0m22:04:36.340106 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:04:36.494249 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m22:04:37.129015 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m22:04:37.131357 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/technical_indicators_rsi.sql
[0m22:04:37.133480 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/technical_indicators_macd.sql
[0m22:04:37.674785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa820d13890>]}
[0m22:04:37.867742 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:04:37.884865 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:04:37.932132 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81f92c740>]}
[0m22:04:37.934538 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m22:04:37.937139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81fd29520>]}
[0m22:04:37.942343 [info ] [MainThread]: 
[0m22:04:37.944762 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:04:37.946688 [info ] [MainThread]: 
[0m22:04:37.948860 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:04:37.958283 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:04:37.959624 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:04:37.960770 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:04:38.033748 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:04:38.035380 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:04:38.036156 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:04:38.037872 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:04:38.039870 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:04:38.041743 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:04:38.043588 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:04:38.045255 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:04:38.046989 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:04:38.060487 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.017 seconds
[0m22:04:38.061223 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.016 seconds
[0m22:04:38.064332 [debug] [ThreadPool]: On list_airflow: Close
[0m22:04:38.065204 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.018 seconds
[0m22:04:38.068792 [debug] [ThreadPool]: On list_airflow: Close
[0m22:04:38.073494 [debug] [ThreadPool]: On list_airflow: Close
[0m22:04:38.078743 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m22:04:38.080005 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m22:04:38.081247 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m22:04:38.092311 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:04:38.096641 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:04:38.100892 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:04:38.103201 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m22:04:38.105355 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m22:04:38.107207 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m22:04:38.109131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:04:38.110772 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:04:38.112235 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:04:38.126226 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m22:04:38.128214 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m22:04:38.129046 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:04:38.130350 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m22:04:38.131682 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:04:38.133740 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m22:04:38.136128 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:04:38.138196 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m22:04:38.141172 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m22:04:38.146219 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m22:04:38.146975 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m22:04:38.147830 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.004 seconds
[0m22:04:38.150497 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m22:04:38.154135 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m22:04:38.157600 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m22:04:38.159758 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m22:04:38.161076 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m22:04:38.162859 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m22:04:38.178100 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:38.179766 [debug] [MainThread]: On master: BEGIN
[0m22:04:38.181327 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:04:38.192723 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m22:04:38.194615 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:38.196709 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:04:38.213561 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m22:04:38.217211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81cf45940>]}
[0m22:04:38.219826 [debug] [MainThread]: On master: ROLLBACK
[0m22:04:38.222135 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:38.224050 [debug] [MainThread]: On master: BEGIN
[0m22:04:38.226387 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:04:38.228275 [debug] [MainThread]: On master: COMMIT
[0m22:04:38.230020 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:38.231620 [debug] [MainThread]: On master: COMMIT
[0m22:04:38.233914 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:04:38.236073 [debug] [MainThread]: On master: Close
[0m22:04:38.245089 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m22:04:38.247322 [info ] [Thread-1 (]: 1 of 8 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m22:04:38.249164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m22:04:38.251106 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m22:04:38.264688 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.278122 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m22:04:38.339454 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.354496 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.356071 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m22:04:38.357572 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:04:38.368579 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m22:04:38.370504 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.372353 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m22:04:38.382018 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m22:04:38.393868 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.396047 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m22:04:38.399062 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:38.405462 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.407588 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m22:04:38.410299 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:38.442620 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m22:04:38.444919 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.446954 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m22:04:38.456990 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m22:04:38.470429 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m22:04:38.480511 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:04:38.482654 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m22:04:38.494322 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.009 seconds
[0m22:04:38.507144 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m22:04:38.512943 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa822489970>]}
[0m22:04:38.516403 [info ] [Thread-1 (]: 1 of 8 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.26s]
[0m22:04:38.520271 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m22:04:38.525227 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m22:04:38.526362 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m22:04:38.528223 [info ] [Thread-3 (]: 2 of 8 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m22:04:38.530651 [info ] [Thread-4 (]: 3 of 8 START sql table model public_core.dim_companies ......................... [RUN]
[0m22:04:38.532361 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m22:04:38.534596 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m22:04:38.536890 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m22:04:38.539042 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m22:04:38.545374 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m22:04:38.551208 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m22:04:38.564339 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m22:04:38.565473 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m22:04:38.628716 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m22:04:38.629744 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m22:04:38.642555 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:38.643699 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:38.645281 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m22:04:38.647075 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m22:04:38.648859 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:04:38.650607 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:04:38.661780 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m22:04:38.663381 [debug] [Thread-3 (]: SQL status: BEGIN in 0.013 seconds
[0m22:04:38.664812 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:38.666914 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:38.669823 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m22:04:38.672317 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m22:04:42.790435 [debug] [Thread-3 (]: SQL status: SELECT 700061 in 4.115 seconds
[0m22:04:42.804415 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:42.806614 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m22:04:42.809471 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:42.817296 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:42.819696 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m22:04:42.838634 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.017 seconds
[0m22:04:42.842642 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m22:04:42.845398 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:42.847514 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m22:04:42.855855 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m22:04:42.861471 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m22:04:42.869683 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:04:42.872103 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m22:04:42.942821 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.069 seconds
[0m22:04:42.946691 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m22:04:42.949319 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81f967da0>]}
[0m22:04:42.951768 [info ] [Thread-3 (]: 2 of 8 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 700061[0m in 4.42s]
[0m22:04:42.954028 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m22:04:43.119632 [debug] [Thread-4 (]: SQL status: SELECT 962 in 4.445 seconds
[0m22:04:43.128140 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:43.130659 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m22:04:43.133704 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:43.145235 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:43.147610 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m22:04:43.151109 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:43.155107 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m22:04:43.157433 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:43.159487 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m22:04:43.164279 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m22:04:43.171558 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m22:04:43.174305 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:04:43.176234 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m22:04:43.182004 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.004 seconds
[0m22:04:43.186092 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m22:04:43.188974 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c67ca70>]}
[0m22:04:43.191687 [info ] [Thread-4 (]: 3 of 8 OK created sql table model public_core.dim_companies .................... [[32mSELECT 962[0m in 4.65s]
[0m22:04:43.195160 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m22:04:43.198955 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m22:04:43.200071 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m22:04:43.201116 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m22:04:43.202042 [debug] [Thread-4 (]: Began running node model.idx_stock.technical_indicators_macd
[0m22:04:43.203893 [info ] [Thread-1 (]: 4 of 8 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m22:04:43.205952 [info ] [Thread-2 (]: 5 of 8 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m22:04:43.208683 [info ] [Thread-3 (]: 6 of 8 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m22:04:43.211163 [info ] [Thread-4 (]: 7 of 8 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m22:04:43.212889 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m22:04:43.215218 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m22:04:43.217450 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m22:04:43.219582 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_macd)
[0m22:04:43.221350 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m22:04:43.223403 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m22:04:43.225543 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m22:04:43.227589 [debug] [Thread-4 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m22:04:43.235418 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m22:04:43.242564 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m22:04:43.250384 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m22:04:43.257396 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m22:04:43.267741 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m22:04:43.268874 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m22:04:43.276446 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m22:04:43.277253 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m22:04:43.285153 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m22:04:43.286092 [debug] [Thread-4 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m22:04:43.293142 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m22:04:43.302983 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m22:04:43.310806 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.313068 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:43.315111 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m22:04:43.316480 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:04:43.318497 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m22:04:43.319573 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:43.321268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:04:43.323586 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m22:04:43.325968 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:04:43.328374 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m22:04:43.332188 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:04:43.335929 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:04:43.341796 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m22:04:43.344937 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.349407 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m22:04:43.350813 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m22:04:43.352720 [debug] [Thread-4 (]: SQL status: BEGIN in 0.020 seconds
[0m22:04:43.354292 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:43.357174 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m22:04:43.359107 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:04:43.361458 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m22:04:43.364100 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:43.374250 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m22:04:43.366770 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m22:04:43.682596 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.326 seconds
[0m22:04:43.698976 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.705383 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m22:04:43.708312 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:43.725424 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.728120 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m22:04:43.732064 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:43.737968 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m22:04:43.740055 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.741992 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m22:04:43.753256 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m22:04:43.761043 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m22:04:43.764979 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:04:43.767344 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m22:04:43.776189 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m22:04:43.780763 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m22:04:43.784337 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c675c70>]}
[0m22:04:43.787605 [info ] [Thread-1 (]: 4 of 8 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.57s]
[0m22:04:43.790713 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m22:04:43.792785 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m22:04:43.795115 [info ] [Thread-1 (]: 8 of 8 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m22:04:43.798547 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_rsi)
[0m22:04:43.800947 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m22:04:43.812604 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m22:04:43.829636 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m22:04:43.838310 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m22:04:43.853966 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:04:43.855860 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m22:04:43.857572 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:04:43.871986 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:04:43.874380 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:04:43.877729 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m22:04:50.035169 [debug] [Thread-2 (]: SQL status: SELECT 959 in 6.667 seconds
[0m22:04:50.043414 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:50.045337 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m22:04:50.048971 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:50.056144 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:50.058531 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m22:04:50.060969 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m22:04:50.064725 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m22:04:50.066834 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:50.068679 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m22:04:50.078065 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m22:04:50.086241 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m22:04:50.088832 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:04:50.090584 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m22:04:50.102746 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.010 seconds
[0m22:04:50.106999 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m22:04:50.109595 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c661700>]}
[0m22:04:50.112444 [info ] [Thread-2 (]: 5 of 8 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 6.89s]
[0m22:04:50.114621 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m22:04:50.848479 [debug] [Thread-3 (]: SQL status: SELECT 959 in 7.473 seconds
[0m22:04:50.855755 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:50.859202 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m22:04:50.861817 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:50.869039 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:50.871480 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m22:04:50.874332 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:50.878588 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m22:04:50.880686 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:50.898551 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m22:04:50.906069 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m22:04:50.912260 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m22:04:50.914656 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:04:50.916739 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m22:04:50.925030 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m22:04:50.929159 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m22:04:50.931707 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c68b6e0>]}
[0m22:04:50.934428 [info ] [Thread-3 (]: 6 of 8 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 7.71s]
[0m22:04:50.937245 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m22:04:54.222227 [debug] [Thread-4 (]: SQL status: SELECT 700061 in 10.846 seconds
[0m22:04:54.231149 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:04:54.232930 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m22:04:54.235299 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:54.239737 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m22:04:54.241563 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:04:54.243543 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m22:04:54.263912 [debug] [Thread-4 (]: SQL status: COMMIT in 0.018 seconds
[0m22:04:54.272702 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m22:04:54.275321 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:04:54.277327 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m22:04:54.279772 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:04:54.283762 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: Close
[0m22:04:54.286788 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c6a0650>]}
[0m22:04:54.289851 [info ] [Thread-4 (]: 7 of 8 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 700061[0m in 11.07s]
[0m22:04:54.292226 [debug] [Thread-4 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m22:04:56.590925 [debug] [Thread-1 (]: SQL status: SELECT 699099 in 12.712 seconds
[0m22:04:56.596364 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:04:56.598005 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m22:04:56.665906 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:04:56.669351 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m22:04:56.671258 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:04:56.672842 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m22:04:56.680925 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m22:04:56.685368 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m22:04:56.687680 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:04:56.689304 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m22:04:56.691446 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:04:56.694416 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m22:04:56.696223 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e18f6ac5-3158-42d5-9760-3f22a62164aa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa81c662000>]}
[0m22:04:56.698202 [info ] [Thread-1 (]: 8 of 8 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 699099[0m in 12.90s]
[0m22:04:56.700207 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m22:04:56.704087 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:56.705935 [debug] [MainThread]: On master: BEGIN
[0m22:04:56.707746 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:04:56.717968 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m22:04:56.719828 [debug] [MainThread]: On master: COMMIT
[0m22:04:56.721617 [debug] [MainThread]: Using postgres connection "master"
[0m22:04:56.723405 [debug] [MainThread]: On master: COMMIT
[0m22:04:56.725291 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:04:56.726879 [debug] [MainThread]: On master: Close
[0m22:04:56.728686 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:04:56.730122 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m22:04:56.731697 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m22:04:56.733476 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m22:04:56.734932 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m22:04:56.736998 [info ] [MainThread]: 
[0m22:04:56.738941 [info ] [MainThread]: Finished running 7 table models, 1 view model in 0 hours 0 minutes and 18.79 seconds (18.79s).
[0m22:04:56.742955 [debug] [MainThread]: Command end result
[0m22:04:56.812140 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:04:56.821860 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:04:56.839422 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m22:04:56.841170 [info ] [MainThread]: 
[0m22:04:56.842915 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:04:56.844770 [info ] [MainThread]: 
[0m22:04:56.846537 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m22:04:56.849643 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 21.158976, "process_in_blocks": "0", "process_kernel_time": 0.701912, "process_mem_max_rss": "129108", "process_out_blocks": "0", "process_user_time": 6.016395}
[0m22:04:56.852180 [debug] [MainThread]: Command `dbt run` succeeded at 22:04:56.851789 after 21.16 seconds
[0m22:04:56.854391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa823c67f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa821d4ecf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8253ef0e0>]}
[0m22:04:56.856302 [debug] [MainThread]: Flushing usage events
[0m22:04:59.937466 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:05:08.037265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cbb0faa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cdc44530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cbfd8860>]}


============================== 22:05:08.047255 | d2755739-8363-4dda-8d8f-7100e8fcf056 ==============================
[0m22:05:08.047255 [info ] [MainThread]: Running with dbt=1.9.4
[0m22:05:08.049194 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m22:05:08.438966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cd992d50>]}
[0m22:05:08.574334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cb7c1ac0>]}
[0m22:05:08.577576 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:05:08.778433 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m22:05:09.302905 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:05:09.304811 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:05:09.393285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cb708da0>]}
[0m22:05:09.589319 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:05:09.605636 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:05:09.665199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92c9908200>]}
[0m22:05:09.667148 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m22:05:09.668959 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92c9d166f0>]}
[0m22:05:09.673724 [info ] [MainThread]: 
[0m22:05:09.675921 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:05:09.678143 [info ] [MainThread]: 
[0m22:05:09.680441 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:05:09.690531 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m22:05:09.692142 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m22:05:09.694691 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m22:05:09.766714 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:05:09.767581 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:05:09.768347 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:05:09.770093 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m22:05:09.772164 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m22:05:09.774193 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m22:05:09.776608 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:05:09.778692 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:05:09.780739 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:05:09.796230 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:05:09.797927 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m22:05:09.798884 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m22:05:09.800095 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:05:09.802172 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:05:09.804083 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:05:09.805949 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m22:05:09.808557 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m22:05:09.811245 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m22:05:09.819826 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.005 seconds
[0m22:05:09.820732 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m22:05:09.821528 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m22:05:09.825086 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m22:05:09.829517 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m22:05:09.833295 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m22:05:09.835803 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m22:05:09.837923 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m22:05:09.840374 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m22:05:09.857840 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:09.860662 [debug] [MainThread]: On master: BEGIN
[0m22:05:09.862690 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:05:09.874723 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m22:05:09.877535 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:09.879728 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:05:09.897979 [debug] [MainThread]: SQL status: SELECT 1 in 0.016 seconds
[0m22:05:09.902801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd2755739-8363-4dda-8d8f-7100e8fcf056', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cb6dfe00>]}
[0m22:05:09.905308 [debug] [MainThread]: On master: ROLLBACK
[0m22:05:09.907838 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:09.910577 [debug] [MainThread]: On master: BEGIN
[0m22:05:09.913477 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:05:09.915929 [debug] [MainThread]: On master: COMMIT
[0m22:05:09.918216 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:09.920216 [debug] [MainThread]: On master: COMMIT
[0m22:05:09.922712 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:05:09.924943 [debug] [MainThread]: On master: Close
[0m22:05:09.933708 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m22:05:09.934684 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m22:05:09.935553 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m22:05:09.936453 [debug] [Thread-4 (]: Began running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m22:05:09.937789 [info ] [Thread-1 (]: 1 of 5 START test not_null_dim_companies_symbol ................................ [RUN]
[0m22:05:09.939927 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m22:05:09.942390 [info ] [Thread-3 (]: 3 of 5 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m22:05:09.944927 [info ] [Thread-4 (]: 4 of 5 START test not_null_stock_performance_monthly_symbol .................... [RUN]
[0m22:05:09.946988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m22:05:09.949116 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m22:05:09.950963 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m22:05:09.953056 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce'
[0m22:05:09.955460 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m22:05:09.957877 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m22:05:09.960404 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m22:05:09.962451 [debug] [Thread-4 (]: Began compiling node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m22:05:10.013556 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m22:05:10.016571 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m22:05:10.024326 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m22:05:10.032790 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m22:05:10.044598 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m22:05:10.045914 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m22:05:10.047540 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m22:05:10.059843 [debug] [Thread-4 (]: Began executing node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m22:05:10.092499 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m22:05:10.095061 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m22:05:10.100699 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m22:05:10.107171 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m22:05:10.119677 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m22:05:10.121869 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m22:05:10.123949 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m22:05:10.125970 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m22:05:10.127280 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m22:05:10.129351 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: BEGIN
[0m22:05:10.131777 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:05:10.133971 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m22:05:10.136296 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m22:05:10.138728 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:05:10.143150 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:05:10.145549 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:05:10.159668 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m22:05:10.162008 [debug] [Thread-4 (]: SQL status: BEGIN in 0.023 seconds
[0m22:05:10.163364 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m22:05:10.165813 [debug] [Thread-3 (]: SQL status: BEGIN in 0.020 seconds
[0m22:05:10.168175 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m22:05:10.170252 [debug] [Thread-2 (]: SQL status: BEGIN in 0.027 seconds
[0m22:05:10.172075 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m22:05:10.174197 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m22:05:10.176476 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_analytics"."stock_performance_monthly"
where symbol is null



      
    ) dbt_internal_test
[0m22:05:10.178719 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m22:05:10.181765 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m22:05:10.182843 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m22:05:10.185433 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m22:05:10.186399 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.002 seconds
[0m22:05:10.197394 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m22:05:10.198421 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.010 seconds
[0m22:05:10.203373 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: ROLLBACK
[0m22:05:10.206009 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m22:05:10.210013 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m22:05:10.212442 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: Close
[0m22:05:10.214865 [info ] [Thread-1 (]: 1 of 5 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.27s]
[0m22:05:10.216961 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m22:05:10.221915 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m22:05:10.219470 [info ] [Thread-4 (]: 4 of 5 PASS not_null_stock_performance_monthly_symbol .......................... [[32mPASS[0m in 0.27s]
[0m22:05:10.226146 [info ] [Thread-3 (]: 3 of 5 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.27s]
[0m22:05:10.228533 [debug] [Thread-1 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m22:05:10.231092 [debug] [Thread-4 (]: Finished running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m22:05:10.233349 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m22:05:10.235280 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_companies_symbol .................................. [RUN]
[0m22:05:10.239622 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m22:05:10.241331 [debug] [Thread-1 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m22:05:10.253891 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m22:05:10.268830 [debug] [Thread-1 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m22:05:10.273999 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m22:05:10.287488 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m22:05:10.289392 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m22:05:10.291104 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:05:10.303536 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m22:05:10.305678 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m22:05:10.307726 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m22:05:10.312713 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.003 seconds
[0m22:05:10.313693 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.114 seconds
[0m22:05:10.317501 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m22:05:10.321825 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m22:05:10.324510 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m22:05:10.326950 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m22:05:10.329326 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.09s]
[0m22:05:10.331779 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.38s]
[0m22:05:10.334467 [debug] [Thread-1 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m22:05:10.337040 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m22:05:10.343798 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:10.345734 [debug] [MainThread]: On master: BEGIN
[0m22:05:10.347530 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:05:10.360238 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m22:05:10.362230 [debug] [MainThread]: On master: COMMIT
[0m22:05:10.363996 [debug] [MainThread]: Using postgres connection "master"
[0m22:05:10.365792 [debug] [MainThread]: On master: COMMIT
[0m22:05:10.367778 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:05:10.369541 [debug] [MainThread]: On master: Close
[0m22:05:10.371440 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:05:10.373127 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m22:05:10.374820 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m22:05:10.376840 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m22:05:10.378495 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce' was properly closed.
[0m22:05:10.380279 [info ] [MainThread]: 
[0m22:05:10.382139 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 0.70 seconds (0.70s).
[0m22:05:10.385810 [debug] [MainThread]: Command end result
[0m22:05:10.483944 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:05:10.495503 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:05:10.526139 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m22:05:10.528190 [info ] [MainThread]: 
[0m22:05:10.530494 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:05:10.533110 [info ] [MainThread]: 
[0m22:05:10.535796 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m22:05:10.539208 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.5991235, "process_in_blocks": "0", "process_kernel_time": 0.333554, "process_mem_max_rss": "123212", "process_out_blocks": "0", "process_user_time": 4.47772}
[0m22:05:10.542209 [debug] [MainThread]: Command `dbt test` succeeded at 22:05:10.541678 after 2.60 seconds
[0m22:05:10.544529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cbb0faa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cc32d550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92cc32e840>]}
[0m22:05:10.546855 [debug] [MainThread]: Flushing usage events
[0m22:05:11.701671 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:00:55.218665 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f073545e270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f073540c8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07353dbe30>]}


============================== 00:00:55.256876 | ee4d6aa5-e8f7-4b81-a947-c5886b353594 ==============================
[0m00:00:55.256876 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:00:55.263383 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:00:56.216025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0734e68320>]}
[0m00:00:56.472137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0734ebc500>]}
[0m00:00:56.477084 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:00:56.715183 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:00:58.636340 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:00:58.639538 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:00:58.788767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07341c8b90>]}
[0m00:00:59.057943 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:00:59.087409 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:00:59.181289 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07335d98b0>]}
[0m00:00:59.184623 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m00:00:59.188497 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0734e6b3e0>]}
[0m00:00:59.196836 [info ] [MainThread]: 
[0m00:00:59.200032 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:00:59.203321 [info ] [MainThread]: 
[0m00:00:59.206333 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:00:59.223728 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:00:59.226428 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:00:59.228425 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:00:59.397654 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:00:59.399080 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:00:59.400049 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:00:59.401963 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:00:59.404192 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:00:59.406373 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:00:59.408550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:59.410823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:59.413248 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:00:59.439183 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.031 seconds
[0m00:00:59.440240 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.029 seconds
[0m00:00:59.444486 [debug] [ThreadPool]: On list_airflow: Close
[0m00:00:59.449390 [debug] [ThreadPool]: On list_airflow: Close
[0m00:00:59.450494 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.037 seconds
[0m00:00:59.459792 [debug] [ThreadPool]: On list_airflow: Close
[0m00:00:59.467200 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m00:00:59.468613 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m00:00:59.470429 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m00:00:59.484350 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:00:59.489023 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:00:59.498151 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:00:59.500030 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m00:00:59.502412 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m00:00:59.504528 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m00:00:59.506488 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:59.508693 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:59.512003 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:00:59.536372 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m00:00:59.540762 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:00:59.543595 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m00:00:59.538928 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m00:00:59.546956 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:00:59.549270 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m00:00:59.551423 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m00:00:59.558198 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:00:59.560710 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m00:00:59.555927 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m00:00:59.566199 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m00:00:59.568089 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.013 seconds
[0m00:00:59.569834 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m00:00:59.571381 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m00:00:59.576727 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m00:00:59.587821 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m00:00:59.590371 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m00:00:59.592551 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m00:00:59.612151 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:59.615290 [debug] [MainThread]: On master: BEGIN
[0m00:00:59.620073 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:00:59.638059 [debug] [MainThread]: SQL status: BEGIN in 0.018 seconds
[0m00:00:59.640741 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:59.643848 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:00:59.668456 [debug] [MainThread]: SQL status: SELECT 1 in 0.022 seconds
[0m00:00:59.673540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0736c18a10>]}
[0m00:00:59.676731 [debug] [MainThread]: On master: ROLLBACK
[0m00:00:59.680149 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:59.682922 [debug] [MainThread]: On master: BEGIN
[0m00:00:59.686929 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:00:59.689684 [debug] [MainThread]: On master: COMMIT
[0m00:00:59.692785 [debug] [MainThread]: Using postgres connection "master"
[0m00:00:59.696070 [debug] [MainThread]: On master: COMMIT
[0m00:00:59.700205 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:00:59.704420 [debug] [MainThread]: On master: Close
[0m00:00:59.728562 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m00:00:59.735569 [info ] [Thread-1 (]: 1 of 8 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m00:00:59.742603 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m00:00:59.748581 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m00:00:59.796111 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m00:00:59.845234 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m00:00:59.974342 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.064304 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.067293 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m00:01:00.069556 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:00.084207 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m00:01:00.086852 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.089319 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m00:01:00.112514 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.020 seconds
[0m00:01:00.135057 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.138897 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m00:01:00.144395 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m00:01:00.156558 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.160443 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m00:01:00.165491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:00.228390 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m00:01:00.232238 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.235632 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m00:01:00.248574 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m00:01:00.271168 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m00:01:00.289803 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:01:00.293678 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m00:01:00.306483 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.009 seconds
[0m00:01:00.316680 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m00:01:00.324807 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07370a7560>]}
[0m00:01:00.329364 [info ] [Thread-1 (]: 1 of 8 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.58s]
[0m00:01:00.333812 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m00:01:00.339614 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m00:01:00.342081 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m00:01:00.345664 [info ] [Thread-3 (]: 2 of 8 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m00:01:00.349916 [info ] [Thread-4 (]: 3 of 8 START sql table model public_core.dim_companies ......................... [RUN]
[0m00:01:00.354079 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.daily_stock_metrics)
[0m00:01:00.358187 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m00:01:00.361891 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m00:01:00.365331 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m00:01:00.378123 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m00:01:00.388697 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m00:01:00.412211 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m00:01:00.414492 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m00:01:00.556357 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m00:01:00.564882 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m00:01:00.585830 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:00.588058 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:00.591279 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m00:01:00.595133 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m00:01:00.599122 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:01:00.602960 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:01:00.625956 [debug] [Thread-4 (]: SQL status: BEGIN in 0.027 seconds
[0m00:01:00.629680 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m00:01:00.632333 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:00.635990 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:00.640158 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m00:01:00.644509 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m00:01:06.326664 [debug] [Thread-3 (]: SQL status: SELECT 700061 in 5.676 seconds
[0m00:01:06.344847 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:06.347258 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m00:01:06.350311 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:06.357928 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:06.360514 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m00:01:06.366075 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:06.370481 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m00:01:06.372817 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:06.375247 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m00:01:06.427744 [debug] [Thread-3 (]: SQL status: COMMIT in 0.050 seconds
[0m00:01:06.433980 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m00:01:06.441254 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:01:06.443853 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m00:01:06.549283 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.103 seconds
[0m00:01:06.553750 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m00:01:06.557001 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0730fb7470>]}
[0m00:01:06.560566 [info ] [Thread-3 (]: 2 of 8 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 700061[0m in 6.20s]
[0m00:01:06.564029 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m00:01:06.738287 [debug] [Thread-4 (]: SQL status: SELECT 962 in 6.090 seconds
[0m00:01:06.746986 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:06.749715 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m00:01:06.753477 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:06.762175 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:06.764856 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m00:01:06.768459 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:06.774341 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m00:01:06.777397 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:06.780492 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m00:01:06.790863 [debug] [Thread-4 (]: SQL status: COMMIT in 0.007 seconds
[0m00:01:06.799092 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m00:01:06.802511 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:01:06.805453 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m00:01:06.813729 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.005 seconds
[0m00:01:06.819500 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m00:01:06.823109 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07310aa750>]}
[0m00:01:06.826472 [info ] [Thread-4 (]: 3 of 8 OK created sql table model public_core.dim_companies .................... [[32mSELECT 962[0m in 6.47s]
[0m00:01:06.829839 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m00:01:06.835596 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m00:01:06.837222 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m00:01:06.838595 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m00:01:06.840152 [debug] [Thread-4 (]: Began running node model.idx_stock.technical_indicators_macd
[0m00:01:06.842744 [info ] [Thread-1 (]: 4 of 8 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m00:01:06.846264 [info ] [Thread-2 (]: 5 of 8 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m00:01:06.849705 [info ] [Thread-3 (]: 6 of 8 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m00:01:06.853290 [info ] [Thread-4 (]: 7 of 8 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m00:01:06.855936 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m00:01:06.859438 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_monthly)
[0m00:01:06.862497 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m00:01:06.865535 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_macd)
[0m00:01:06.868386 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m00:01:06.871330 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m00:01:06.874382 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m00:01:06.877324 [debug] [Thread-4 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m00:01:06.888646 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m00:01:06.909220 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m00:01:06.921354 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m00:01:06.932051 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m00:01:06.947407 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m00:01:06.949403 [debug] [Thread-4 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m00:01:06.951479 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m00:01:06.964720 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m00:01:06.963877 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m00:01:06.974429 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m00:01:06.987376 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m00:01:06.997182 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m00:01:07.011746 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.015083 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:07.017084 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m00:01:07.019430 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:07.021151 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:07.022947 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m00:01:07.026180 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:07.029242 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m00:01:07.032473 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m00:01:07.035130 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:01:07.040664 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m00:01:07.043456 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:01:07.058088 [debug] [Thread-1 (]: SQL status: BEGIN in 0.032 seconds
[0m00:01:07.061834 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.066714 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m00:01:07.070282 [debug] [Thread-3 (]: SQL status: BEGIN in 0.035 seconds
[0m00:01:07.075765 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:07.080083 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m00:01:07.082602 [debug] [Thread-4 (]: SQL status: BEGIN in 0.042 seconds
[0m00:01:07.084023 [debug] [Thread-2 (]: SQL status: BEGIN in 0.041 seconds
[0m00:01:07.088403 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:07.092876 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:07.101986 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m00:01:07.105891 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m00:01:07.565969 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.496 seconds
[0m00:01:07.573909 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.576097 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m00:01:07.579407 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:01:07.587953 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.590137 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m00:01:07.592756 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:01:07.597120 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m00:01:07.599466 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.601776 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m00:01:07.624034 [debug] [Thread-1 (]: SQL status: COMMIT in 0.020 seconds
[0m00:01:07.630941 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m00:01:07.633471 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:01:07.635545 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m00:01:07.645257 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m00:01:07.650052 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m00:01:07.652854 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0730624620>]}
[0m00:01:07.655835 [info ] [Thread-1 (]: 4 of 8 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.80s]
[0m00:01:07.659507 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m00:01:07.662466 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m00:01:07.665346 [info ] [Thread-1 (]: 8 of 8 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m00:01:07.668307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_rsi)
[0m00:01:07.670928 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m00:01:07.687226 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m00:01:07.704272 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m00:01:07.715233 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m00:01:07.735163 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:07.737410 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m00:01:07.739512 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:07.753854 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m00:01:07.756277 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:07.758728 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m00:01:14.169534 [debug] [Thread-2 (]: SQL status: SELECT 959 in 7.051 seconds
[0m00:01:14.180918 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:14.184391 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m00:01:14.189143 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:14.197944 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:14.200285 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m00:01:14.203128 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:14.207070 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m00:01:14.209118 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:14.211017 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m00:01:14.225406 [debug] [Thread-2 (]: SQL status: COMMIT in 0.012 seconds
[0m00:01:14.232979 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m00:01:14.235747 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:01:14.237726 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m00:01:14.248971 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.009 seconds
[0m00:01:14.254469 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m00:01:14.257697 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0730610dd0>]}
[0m00:01:14.261370 [info ] [Thread-2 (]: 5 of 8 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 7.40s]
[0m00:01:14.272098 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m00:01:14.844711 [debug] [Thread-3 (]: SQL status: SELECT 959 in 7.758 seconds
[0m00:01:14.854498 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:14.857468 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m00:01:14.861029 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:14.872633 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:14.875386 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m00:01:14.878870 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:14.885265 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m00:01:14.888577 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:14.891194 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m00:01:14.918335 [debug] [Thread-3 (]: SQL status: COMMIT in 0.024 seconds
[0m00:01:14.929632 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m00:01:14.933436 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:01:14.936150 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m00:01:14.950137 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.011 seconds
[0m00:01:14.956078 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m00:01:14.959771 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f073065bef0>]}
[0m00:01:14.964127 [info ] [Thread-3 (]: 6 of 8 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 8.10s]
[0m00:01:14.968986 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m00:01:18.921896 [debug] [Thread-4 (]: SQL status: SELECT 700061 in 11.815 seconds
[0m00:01:18.934647 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:18.937334 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m00:01:18.941038 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:18.950797 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:18.953458 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m00:01:18.956688 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:01:18.962315 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m00:01:18.965055 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:18.967672 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m00:01:19.005612 [debug] [Thread-4 (]: SQL status: COMMIT in 0.031 seconds
[0m00:01:19.016213 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m00:01:19.021211 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:01:19.024179 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m00:01:19.084568 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.057 seconds
[0m00:01:19.089690 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: Close
[0m00:01:19.093141 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07310b6e70>]}
[0m00:01:19.096485 [info ] [Thread-4 (]: 7 of 8 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 700061[0m in 12.23s]
[0m00:01:19.101253 [debug] [Thread-4 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m00:01:24.179623 [debug] [Thread-1 (]: SQL status: SELECT 699099 in 16.417 seconds
[0m00:01:24.202094 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:24.207679 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m00:01:24.217418 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m00:01:24.237080 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:24.242424 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m00:01:24.250519 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m00:01:24.262024 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m00:01:24.268134 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:24.273731 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m00:01:24.298355 [debug] [Thread-1 (]: SQL status: COMMIT in 0.019 seconds
[0m00:01:24.314840 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m00:01:24.323254 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:01:24.328746 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m00:01:24.387703 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.053 seconds
[0m00:01:24.397961 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m00:01:24.403976 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ee4d6aa5-e8f7-4b81-a947-c5886b353594', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07310db9e0>]}
[0m00:01:24.410695 [info ] [Thread-1 (]: 8 of 8 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 699099[0m in 16.74s]
[0m00:01:24.418616 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m00:01:24.433882 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:24.439817 [debug] [MainThread]: On master: BEGIN
[0m00:01:24.445332 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:01:24.485830 [debug] [MainThread]: SQL status: BEGIN in 0.040 seconds
[0m00:01:24.493644 [debug] [MainThread]: On master: COMMIT
[0m00:01:24.500302 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:24.506070 [debug] [MainThread]: On master: COMMIT
[0m00:01:24.512936 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:01:24.519882 [debug] [MainThread]: On master: Close
[0m00:01:24.527358 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:01:24.533505 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m00:01:24.539493 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m00:01:24.545358 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m00:01:24.551905 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m00:01:24.558445 [info ] [MainThread]: 
[0m00:01:24.566138 [info ] [MainThread]: Finished running 7 table models, 1 view model in 0 hours 0 minutes and 25.35 seconds (25.35s).
[0m00:01:24.584787 [debug] [MainThread]: Command end result
[0m00:01:24.871624 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:01:24.906163 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:01:24.971026 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:01:24.977312 [info ] [MainThread]: 
[0m00:01:24.984957 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:01:24.991094 [info ] [MainThread]: 
[0m00:01:24.998048 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m00:01:25.008809 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 30.097565, "process_in_blocks": "0", "process_kernel_time": 1.294245, "process_mem_max_rss": "123568", "process_out_blocks": "0", "process_user_time": 10.263671}
[0m00:01:25.017951 [debug] [MainThread]: Command `dbt run` succeeded at 00:01:25.016951 after 30.11 seconds
[0m00:01:25.024756 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07354c5280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07359fc260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0735ac6270>]}
[0m00:01:25.031074 [debug] [MainThread]: Flushing usage events
[0m00:01:26.898177 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:01:46.533455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9ffdcfb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa09aac00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa09abf20>]}


============================== 00:01:46.567445 | 6a6762ed-9ecc-4868-adbd-74fe43b2c9a7 ==============================
[0m00:01:46.567445 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:01:46.574197 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m00:01:47.782662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9fcf70b0>]}
[0m00:01:48.049772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa1095760>]}
[0m00:01:48.055621 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:01:48.318621 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:01:49.954491 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:01:49.960064 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:01:50.106792 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9ef99250>]}
[0m00:01:50.501199 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:01:50.531471 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:01:50.652020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9fdcec90>]}
[0m00:01:50.655923 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m00:01:50.659803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9ef83680>]}
[0m00:01:50.668975 [info ] [MainThread]: 
[0m00:01:50.673207 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:01:50.676730 [info ] [MainThread]: 
[0m00:01:50.681068 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:01:50.698868 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m00:01:50.701535 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m00:01:50.704154 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m00:01:50.891539 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:01:50.893365 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:01:50.894943 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:01:50.897920 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m00:01:50.901668 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m00:01:50.905263 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m00:01:50.908947 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:01:50.912696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:01:50.916358 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:01:50.939877 [debug] [ThreadPool]: SQL status: BEGIN in 0.031 seconds
[0m00:01:50.944278 [debug] [ThreadPool]: SQL status: BEGIN in 0.031 seconds
[0m00:01:50.946260 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m00:01:50.947731 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:01:50.951271 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:01:50.954379 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:01:50.958250 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m00:01:50.962275 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m00:01:50.966027 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m00:01:50.980129 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.008 seconds
[0m00:01:50.981811 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.012 seconds
[0m00:01:50.983293 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m00:01:50.989548 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m00:01:50.996176 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m00:01:51.002589 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m00:01:51.006889 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m00:01:51.010401 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m00:01:51.013863 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m00:01:51.042621 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.047040 [debug] [MainThread]: On master: BEGIN
[0m00:01:51.050521 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:01:51.073361 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m00:01:51.076665 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.080733 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:01:51.112376 [debug] [MainThread]: SQL status: SELECT 1 in 0.028 seconds
[0m00:01:51.120001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a6762ed-9ecc-4868-adbd-74fe43b2c9a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a9fcf7e60>]}
[0m00:01:51.124130 [debug] [MainThread]: On master: ROLLBACK
[0m00:01:51.128302 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.131793 [debug] [MainThread]: On master: BEGIN
[0m00:01:51.137033 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:01:51.140688 [debug] [MainThread]: On master: COMMIT
[0m00:01:51.144095 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.147562 [debug] [MainThread]: On master: COMMIT
[0m00:01:51.151963 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:01:51.155740 [debug] [MainThread]: On master: Close
[0m00:01:51.171209 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:01:51.173437 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m00:01:51.175137 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m00:01:51.176977 [debug] [Thread-4 (]: Began running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m00:01:51.179465 [info ] [Thread-1 (]: 1 of 5 START test not_null_dim_companies_symbol ................................ [RUN]
[0m00:01:51.184116 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m00:01:51.188331 [info ] [Thread-3 (]: 3 of 5 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m00:01:51.192186 [info ] [Thread-4 (]: 4 of 5 START test not_null_stock_performance_monthly_symbol .................... [RUN]
[0m00:01:51.196499 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m00:01:51.200774 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m00:01:51.206694 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m00:01:51.210867 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce'
[0m00:01:51.214946 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:01:51.218582 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m00:01:51.222412 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m00:01:51.226201 [debug] [Thread-4 (]: Began compiling node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m00:01:51.320377 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:01:51.329905 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m00:01:51.336343 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m00:01:51.353375 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m00:01:51.371444 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:01:51.375365 [debug] [Thread-4 (]: Began executing node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m00:01:51.383158 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m00:01:51.384813 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m00:01:51.463611 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:01:51.486713 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m00:01:51.489224 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m00:01:51.497600 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m00:01:51.516668 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:01:51.519560 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m00:01:51.522447 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m00:01:51.525148 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m00:01:51.528800 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m00:01:51.530533 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: BEGIN
[0m00:01:51.534400 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m00:01:51.538159 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:51.542004 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m00:01:51.545819 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:01:51.549374 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:01:51.555964 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:01:51.584537 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m00:01:51.587026 [debug] [Thread-3 (]: SQL status: BEGIN in 0.037 seconds
[0m00:01:51.590031 [debug] [Thread-4 (]: SQL status: BEGIN in 0.044 seconds
[0m00:01:51.592057 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:01:51.595285 [debug] [Thread-2 (]: SQL status: BEGIN in 0.039 seconds
[0m00:01:51.597023 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m00:01:51.601198 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m00:01:51.604817 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m00:01:51.608708 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m00:01:51.612731 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m00:01:51.616763 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_analytics"."stock_performance_monthly"
where symbol is null



      
    ) dbt_internal_test
[0m00:01:51.622611 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m00:01:51.624585 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m00:01:51.632611 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.004 seconds
[0m00:01:51.640391 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.009 seconds
[0m00:01:51.649212 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m00:01:51.658631 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m00:01:51.666438 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: ROLLBACK
[0m00:01:51.670262 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m00:01:51.673819 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m00:01:51.677472 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: Close
[0m00:01:51.681217 [info ] [Thread-1 (]: 1 of 5 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.48s]
[0m00:01:51.685809 [info ] [Thread-3 (]: 3 of 5 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.48s]
[0m00:01:51.689416 [info ] [Thread-4 (]: 4 of 5 PASS not_null_stock_performance_monthly_symbol .......................... [[32mPASS[0m in 0.48s]
[0m00:01:51.692766 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:01:51.697737 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m00:01:51.701704 [debug] [Thread-4 (]: Finished running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m00:01:51.705588 [debug] [Thread-1 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:01:51.714212 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_companies_symbol .................................. [RUN]
[0m00:01:51.718316 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m00:01:51.721957 [debug] [Thread-1 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:01:51.744222 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:01:51.773641 [debug] [Thread-1 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:01:51.783594 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:01:51.785374 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.132 seconds
[0m00:01:51.794877 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m00:01:51.799036 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m00:01:51.803632 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.60s]
[0m00:01:51.808295 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m00:01:51.816186 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:01:51.820031 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m00:01:51.823638 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:01:51.845616 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m00:01:51.849380 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:01:51.852443 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m00:01:51.859383 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.004 seconds
[0m00:01:51.866137 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m00:01:51.870069 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m00:01:51.874567 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.16s]
[0m00:01:51.878316 [debug] [Thread-1 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:01:51.885821 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.889649 [debug] [MainThread]: On master: BEGIN
[0m00:01:51.892789 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:01:51.914589 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m00:01:51.918454 [debug] [MainThread]: On master: COMMIT
[0m00:01:51.922387 [debug] [MainThread]: Using postgres connection "master"
[0m00:01:51.925857 [debug] [MainThread]: On master: COMMIT
[0m00:01:51.929820 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:01:51.933973 [debug] [MainThread]: On master: Close
[0m00:01:51.938043 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:01:51.941412 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m00:01:51.944744 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m00:01:51.948167 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m00:01:51.951846 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce' was properly closed.
[0m00:01:51.955654 [info ] [MainThread]: 
[0m00:01:51.959051 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 1.28 seconds (1.28s).
[0m00:01:51.967107 [debug] [MainThread]: Command end result
[0m00:01:52.117505 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:01:52.136306 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:01:52.173566 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:01:52.177254 [info ] [MainThread]: 
[0m00:01:52.181551 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:01:52.185159 [info ] [MainThread]: 
[0m00:01:52.188874 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m00:01:52.194279 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 5.957972, "process_in_blocks": "0", "process_kernel_time": 0.887643, "process_mem_max_rss": "124152", "process_out_blocks": "0", "process_user_time": 9.684295}
[0m00:01:52.198520 [debug] [MainThread]: Command `dbt test` succeeded at 00:01:52.198156 after 5.96 seconds
[0m00:01:52.202228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa3963170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa021fd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3aa0838110>]}
[0m00:01:52.206322 [debug] [MainThread]: Flushing usage events
[0m00:01:54.135755 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:30:03.903176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae225249e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20f53f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20f53da0>]}


============================== 11:30:03.932912 | 4b19675c-20f0-435a-93e1-68a50bc039b5 ==============================
[0m11:30:03.932912 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:30:03.937504 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:30:04.728028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20478650>]}
[0m11:30:04.937423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20423680>]}
[0m11:30:04.942394 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:30:05.288904 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:30:07.318094 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:30:07.324763 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:30:07.711023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1f96cf50>]}
[0m11:30:08.074411 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:30:08.135816 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:30:08.239768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1edbc6b0>]}
[0m11:30:08.244343 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m11:30:08.248116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20323020>]}
[0m11:30:08.257577 [info ] [MainThread]: 
[0m11:30:08.261266 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:30:08.265281 [info ] [MainThread]: 
[0m11:30:08.269629 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:30:08.291164 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:30:08.293659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:30:08.296124 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m11:30:08.493298 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:30:08.494563 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:30:08.495749 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m11:30:08.498132 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:30:08.501440 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:30:08.504399 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m11:30:08.507413 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:30:08.510548 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:30:08.513639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:30:08.537388 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.030 seconds
[0m11:30:08.538830 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.025 seconds
[0m11:30:08.540545 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.030 seconds
[0m11:30:08.544570 [debug] [ThreadPool]: On list_airflow: Close
[0m11:30:08.549355 [debug] [ThreadPool]: On list_airflow: Close
[0m11:30:08.554471 [debug] [ThreadPool]: On list_airflow: Close
[0m11:30:08.568427 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m11:30:08.570081 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m11:30:08.571921 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m11:30:08.590133 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:30:08.596115 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:30:08.603623 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:30:08.606494 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:30:08.609628 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:30:08.612512 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:30:08.615890 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:30:08.619614 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:30:08.622668 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m11:30:08.649996 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m11:30:08.652368 [debug] [ThreadPool]: SQL status: BEGIN in 0.036 seconds
[0m11:30:08.655333 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:30:08.658723 [debug] [ThreadPool]: SQL status: BEGIN in 0.036 seconds
[0m11:30:08.660586 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:30:08.663899 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:30:08.666771 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:30:08.669302 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:30:08.674547 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:30:08.680056 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m11:30:08.685111 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:30:08.686212 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.009 seconds
[0m11:30:08.687235 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m11:30:08.690047 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:30:08.695008 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:30:08.699892 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:30:08.706285 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:30:08.710074 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:30:08.729610 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:08.732543 [debug] [MainThread]: On master: BEGIN
[0m11:30:08.735370 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:30:08.757777 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m11:30:08.763239 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:08.769736 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:30:08.830627 [debug] [MainThread]: SQL status: SELECT 1 in 0.054 seconds
[0m11:30:08.843484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1e147e90>]}
[0m11:30:08.850627 [debug] [MainThread]: On master: ROLLBACK
[0m11:30:08.856378 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:08.861123 [debug] [MainThread]: On master: BEGIN
[0m11:30:08.867144 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:30:08.872923 [debug] [MainThread]: On master: COMMIT
[0m11:30:08.879274 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:08.887618 [debug] [MainThread]: On master: COMMIT
[0m11:30:08.894587 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m11:30:08.899272 [debug] [MainThread]: On master: Close
[0m11:30:08.917220 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m11:30:08.921466 [info ] [Thread-1 (]: 1 of 8 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m11:30:08.926278 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m11:30:08.929710 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m11:30:08.960928 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.005277 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m11:30:09.112114 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.136724 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.140288 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m11:30:09.144132 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:09.178610 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m11:30:09.196035 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.208915 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m11:30:09.263277 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.045 seconds
[0m11:30:09.315580 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.324179 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m11:30:09.339873 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.008 seconds
[0m11:30:09.368293 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.376065 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m11:30:09.385696 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m11:30:09.556269 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:30:09.564059 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.570682 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m11:30:09.588897 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m11:30:09.643930 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m11:30:09.686033 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m11:30:09.692887 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m11:30:09.716893 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.018 seconds
[0m11:30:09.738564 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m11:30:09.753311 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae2257aab0>]}
[0m11:30:09.761550 [info ] [Thread-1 (]: 1 of 8 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.82s]
[0m11:30:09.770076 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m11:30:09.783548 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m11:30:09.787087 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m11:30:09.795488 [info ] [Thread-3 (]: 2 of 8 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m11:30:09.804890 [info ] [Thread-4 (]: 3 of 8 START sql table model public_core.dim_companies ......................... [RUN]
[0m11:30:09.814062 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m11:30:09.823735 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m11:30:09.831455 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m11:30:09.841268 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m11:30:09.870025 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m11:30:09.890467 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m11:30:09.928235 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m11:30:09.934080 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m11:30:10.294449 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m11:30:10.316809 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m11:30:10.364957 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:10.379646 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:10.387150 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m11:30:10.402010 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m11:30:10.409794 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:30:10.415608 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:30:10.464804 [debug] [Thread-3 (]: SQL status: BEGIN in 0.050 seconds
[0m11:30:10.466548 [debug] [Thread-4 (]: SQL status: BEGIN in 0.057 seconds
[0m11:30:10.468226 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:10.471018 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:10.473905 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m11:30:10.477091 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m11:30:17.247484 [debug] [Thread-3 (]: SQL status: SELECT 700061 in 6.768 seconds
[0m11:30:17.275734 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:17.278785 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m11:30:17.284539 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:17.302818 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:17.306787 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m11:30:17.310818 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:17.319318 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:30:17.323562 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:17.326606 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m11:30:17.339067 [debug] [Thread-3 (]: SQL status: COMMIT in 0.008 seconds
[0m11:30:17.349623 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m11:30:17.362483 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m11:30:17.365812 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m11:30:17.412582 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.043 seconds
[0m11:30:17.418145 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m11:30:17.421039 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c473e30>]}
[0m11:30:17.434288 [info ] [Thread-3 (]: 2 of 8 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 700061[0m in 7.61s]
[0m11:30:17.438120 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m11:30:17.835642 [debug] [Thread-4 (]: SQL status: SELECT 962 in 7.354 seconds
[0m11:30:17.874090 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:17.879580 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m11:30:17.886262 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m11:30:17.907804 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:17.912135 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m11:30:17.918438 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m11:30:17.926550 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:30:17.931913 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:17.936851 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m11:30:17.945983 [debug] [Thread-4 (]: SQL status: COMMIT in 0.004 seconds
[0m11:30:17.963238 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m11:30:17.969687 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m11:30:17.974133 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m11:30:17.985474 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.007 seconds
[0m11:30:17.994519 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m11:30:18.000718 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c56e390>]}
[0m11:30:18.006907 [info ] [Thread-4 (]: 3 of 8 OK created sql table model public_core.dim_companies .................... [[32mSELECT 962[0m in 8.18s]
[0m11:30:18.013075 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m11:30:18.020622 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m11:30:18.023133 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m11:30:18.025643 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m11:30:18.028258 [debug] [Thread-4 (]: Began running node model.idx_stock.technical_indicators_macd
[0m11:30:18.033270 [info ] [Thread-1 (]: 4 of 8 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m11:30:18.038628 [info ] [Thread-2 (]: 5 of 8 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m11:30:18.044610 [info ] [Thread-3 (]: 6 of 8 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m11:30:18.050041 [info ] [Thread-4 (]: 7 of 8 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m11:30:18.055592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m11:30:18.060800 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_monthly)
[0m11:30:18.065672 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m11:30:18.071567 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_macd)
[0m11:30:18.077634 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m11:30:18.087738 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m11:30:18.095700 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m11:30:18.101096 [debug] [Thread-4 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m11:30:18.147071 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m11:30:18.182002 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m11:30:18.218345 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m11:30:18.238136 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m11:30:18.255790 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m11:30:18.259696 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m11:30:18.267690 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m11:30:18.278576 [debug] [Thread-4 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m11:30:18.282579 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m11:30:18.297250 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m11:30:18.318820 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m11:30:18.328705 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m11:30:18.342929 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.346236 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:18.348622 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:18.351706 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m11:30:18.354558 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:18.357518 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m11:30:18.361134 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m11:30:18.365451 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:18.369813 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m11:30:18.373313 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:30:18.376133 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:30:18.381371 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m11:30:18.395397 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m11:30:18.398884 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.402777 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m11:30:18.405790 [debug] [Thread-2 (]: SQL status: BEGIN in 0.032 seconds
[0m11:30:18.413622 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:18.417277 [debug] [Thread-3 (]: SQL status: BEGIN in 0.041 seconds
[0m11:30:18.420910 [debug] [Thread-4 (]: SQL status: BEGIN in 0.039 seconds
[0m11:30:18.423449 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m11:30:18.426898 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:18.429984 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:18.435701 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m11:30:18.442329 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m11:30:18.735235 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.324 seconds
[0m11:30:18.743958 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.745905 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m11:30:18.748786 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:18.757359 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.759608 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m11:30:18.762171 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:30:18.766922 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:30:18.769137 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.771226 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m11:30:18.782387 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m11:30:18.792086 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m11:30:18.795291 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m11:30:18.798053 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m11:30:18.805179 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m11:30:18.809664 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m11:30:18.812926 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1edbf7a0>]}
[0m11:30:18.817782 [info ] [Thread-1 (]: 4 of 8 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.76s]
[0m11:30:18.820780 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m11:30:18.822857 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m11:30:18.824908 [info ] [Thread-1 (]: 8 of 8 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m11:30:18.827400 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_rsi)
[0m11:30:18.829693 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m11:30:18.838961 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m11:30:18.855145 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m11:30:18.866189 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m11:30:18.882781 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:18.884912 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m11:30:18.887012 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:30:18.903735 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m11:30:18.906268 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:18.909431 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m11:30:25.909594 [debug] [Thread-2 (]: SQL status: SELECT 959 in 7.476 seconds
[0m11:30:25.918486 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:25.920706 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m11:30:25.923663 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:25.932170 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:25.934589 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m11:30:25.937379 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m11:30:25.943309 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:30:25.946039 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:25.948217 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m11:30:25.953547 [debug] [Thread-2 (]: SQL status: COMMIT in 0.003 seconds
[0m11:30:25.961638 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m11:30:25.964205 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m11:30:25.966322 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m11:30:25.977518 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.009 seconds
[0m11:30:25.981936 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m11:30:25.984338 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c305e50>]}
[0m11:30:25.986946 [info ] [Thread-2 (]: 5 of 8 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 7.92s]
[0m11:30:25.989892 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m11:30:26.771694 [debug] [Thread-3 (]: SQL status: SELECT 959 in 8.326 seconds
[0m11:30:26.784620 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:26.787975 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m11:30:26.792762 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:26.807637 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:26.811840 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m11:30:26.815997 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:26.822013 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:30:26.825816 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:26.829828 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m11:30:26.841878 [debug] [Thread-3 (]: SQL status: COMMIT in 0.008 seconds
[0m11:30:26.851533 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m11:30:26.855217 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m11:30:26.858464 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m11:30:26.869682 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m11:30:26.876631 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m11:30:26.880554 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c33c710>]}
[0m11:30:26.884121 [info ] [Thread-3 (]: 6 of 8 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 8.82s]
[0m11:30:26.889154 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m11:30:32.910279 [debug] [Thread-4 (]: SQL status: SELECT 700061 in 14.463 seconds
[0m11:30:32.919788 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:32.922768 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m11:30:32.926511 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:32.936684 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:32.939565 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m11:30:32.943118 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m11:30:32.950502 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m11:30:32.953146 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:32.955965 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m11:30:32.971549 [debug] [Thread-4 (]: SQL status: COMMIT in 0.013 seconds
[0m11:30:32.980608 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m11:30:32.983611 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m11:30:32.986060 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m11:30:33.021712 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.033 seconds
[0m11:30:33.026672 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: Close
[0m11:30:33.029769 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c4508c0>]}
[0m11:30:33.033228 [info ] [Thread-4 (]: 7 of 8 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 700061[0m in 14.96s]
[0m11:30:33.036124 [debug] [Thread-4 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m11:30:38.618306 [debug] [Thread-1 (]: SQL status: SELECT 699099 in 19.708 seconds
[0m11:30:38.645688 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:38.653015 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m11:30:38.663246 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m11:30:38.690589 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:38.698790 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m11:30:38.708108 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m11:30:38.728282 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m11:30:38.742268 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:38.750231 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m11:30:38.767045 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m11:30:38.790282 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m11:30:38.800333 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m11:30:38.808587 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m11:30:38.890297 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.072 seconds
[0m11:30:38.904984 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m11:30:38.913656 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b19675c-20f0-435a-93e1-68a50bc039b5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1e96e390>]}
[0m11:30:38.924310 [info ] [Thread-1 (]: 8 of 8 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 699099[0m in 20.09s]
[0m11:30:38.934728 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m11:30:38.953390 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:38.961191 [debug] [MainThread]: On master: BEGIN
[0m11:30:38.967789 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:30:39.021641 [debug] [MainThread]: SQL status: BEGIN in 0.054 seconds
[0m11:30:39.029903 [debug] [MainThread]: On master: COMMIT
[0m11:30:39.038029 [debug] [MainThread]: Using postgres connection "master"
[0m11:30:39.045712 [debug] [MainThread]: On master: COMMIT
[0m11:30:39.055190 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m11:30:39.062350 [debug] [MainThread]: On master: Close
[0m11:30:39.072667 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:30:39.081265 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m11:30:39.090336 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m11:30:39.099649 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m11:30:39.106445 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m11:30:39.114194 [info ] [MainThread]: 
[0m11:30:39.123583 [info ] [MainThread]: Finished running 7 table models, 1 view model in 0 hours 0 minutes and 30.84 seconds (30.84s).
[0m11:30:39.146261 [debug] [MainThread]: Command end result
[0m11:30:39.543539 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:30:39.563838 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:30:39.602846 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:30:39.607828 [info ] [MainThread]: 
[0m11:30:39.613122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:30:39.621546 [info ] [MainThread]: 
[0m11:30:39.624693 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m11:30:39.628670 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 36.12732, "process_in_blocks": "0", "process_kernel_time": 1.101992, "process_mem_max_rss": "123892", "process_out_blocks": "0", "process_user_time": 11.310445}
[0m11:30:39.632864 [debug] [MainThread]: Command `dbt run` succeeded at 11:30:39.632379 after 36.13 seconds
[0m11:30:39.635840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae21084ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae20344440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fae1c34ade0>]}
[0m11:30:39.638314 [debug] [MainThread]: Flushing usage events
[0m11:30:41.580057 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m11:31:07.225288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdafe85c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf6c6240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdafe85b80>]}


============================== 11:31:07.246612 | d6017c39-632b-498e-96d5-757eeee7cee2 ==============================
[0m11:31:07.246612 [info ] [MainThread]: Running with dbt=1.9.4
[0m11:31:07.250954 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:31:08.006966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf3aa390>]}
[0m11:31:08.168719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdafcd6c30>]}
[0m11:31:08.173567 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m11:31:08.445316 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m11:31:10.122183 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:31:10.130925 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:31:10.550040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdae9e0950>]}
[0m11:31:11.135973 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:31:11.170460 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:31:11.285648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdad9f8320>]}
[0m11:31:11.290134 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m11:31:11.294810 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf3ac0e0>]}
[0m11:31:11.304228 [info ] [MainThread]: 
[0m11:31:11.308761 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m11:31:11.312511 [info ] [MainThread]: 
[0m11:31:11.316671 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m11:31:11.335903 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m11:31:11.338883 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m11:31:11.341829 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m11:31:11.518682 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:31:11.520307 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:31:11.522004 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:31:11.525374 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m11:31:11.529740 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m11:31:11.533386 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m11:31:11.536814 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:11.540387 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:11.544132 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:31:11.569640 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m11:31:11.573622 [debug] [ThreadPool]: SQL status: BEGIN in 0.029 seconds
[0m11:31:11.576289 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m11:31:11.578501 [debug] [ThreadPool]: SQL status: BEGIN in 0.038 seconds
[0m11:31:11.581483 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m11:31:11.585168 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m11:31:11.589087 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m11:31:11.593047 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m11:31:11.598700 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m11:31:11.605251 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.009 seconds
[0m11:31:11.612436 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m11:31:11.614022 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.012 seconds
[0m11:31:11.615594 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.011 seconds
[0m11:31:11.619100 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m11:31:11.626620 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m11:31:11.633545 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m11:31:11.641097 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m11:31:11.644211 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m11:31:11.672516 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:11.677649 [debug] [MainThread]: On master: BEGIN
[0m11:31:11.681147 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:31:11.703676 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m11:31:11.709213 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:11.713297 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m11:31:11.737765 [debug] [MainThread]: SQL status: SELECT 1 in 0.020 seconds
[0m11:31:11.745453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6017c39-632b-498e-96d5-757eeee7cee2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdb10a4440>]}
[0m11:31:11.749674 [debug] [MainThread]: On master: ROLLBACK
[0m11:31:11.753677 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:11.757540 [debug] [MainThread]: On master: BEGIN
[0m11:31:11.762145 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m11:31:11.766162 [debug] [MainThread]: On master: COMMIT
[0m11:31:11.769769 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:11.773734 [debug] [MainThread]: On master: COMMIT
[0m11:31:11.778122 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m11:31:11.781883 [debug] [MainThread]: On master: Close
[0m11:31:11.798623 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:31:11.800383 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:31:11.802085 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:31:11.803799 [debug] [Thread-4 (]: Began running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m11:31:11.807647 [info ] [Thread-1 (]: 1 of 5 START test not_null_dim_companies_symbol ................................ [RUN]
[0m11:31:11.812206 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m11:31:11.816530 [info ] [Thread-3 (]: 3 of 5 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m11:31:11.820736 [info ] [Thread-4 (]: 4 of 5 START test not_null_stock_performance_monthly_symbol .................... [RUN]
[0m11:31:11.825243 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m11:31:11.829280 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m11:31:11.833224 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m11:31:11.837728 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce'
[0m11:31:11.842070 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:31:11.845889 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:31:11.849623 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:31:11.853496 [debug] [Thread-4 (]: Began compiling node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m11:31:11.957793 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:31:11.955275 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:31:11.966263 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:31:11.981960 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m11:31:12.000634 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:31:12.003588 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:31:12.006787 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:31:12.015786 [debug] [Thread-4 (]: Began executing node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m11:31:12.143754 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:31:12.153286 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:31:12.185198 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m11:31:12.207231 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:31:12.219808 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:31:12.223444 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:31:12.228478 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m11:31:12.233044 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m11:31:12.240730 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m11:31:12.245506 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: BEGIN
[0m11:31:12.248544 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:31:12.252568 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m11:31:12.256659 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:31:12.260603 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m11:31:12.264193 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m11:31:12.290874 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m11:31:12.302196 [debug] [Thread-1 (]: SQL status: BEGIN in 0.045 seconds
[0m11:31:12.306262 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m11:31:12.310644 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m11:31:12.314660 [debug] [Thread-3 (]: SQL status: BEGIN in 0.062 seconds
[0m11:31:12.322378 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m11:31:12.328232 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m11:31:12.326406 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.010 seconds
[0m11:31:12.319699 [debug] [Thread-4 (]: SQL status: BEGIN in 0.059 seconds
[0m11:31:12.337259 [debug] [Thread-2 (]: SQL status: BEGIN in 0.046 seconds
[0m11:31:12.348883 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.013 seconds
[0m11:31:12.364020 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m11:31:12.361390 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m11:31:12.369291 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m11:31:12.378603 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m11:31:12.382548 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_analytics"."stock_performance_monthly"
where symbol is null



      
    ) dbt_internal_test
[0m11:31:12.387096 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m11:31:12.390908 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m11:31:12.395298 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m11:31:12.403343 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.005 seconds
[0m11:31:12.401692 [info ] [Thread-1 (]: 1 of 5 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.58s]
[0m11:31:12.410989 [info ] [Thread-3 (]: 3 of 5 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.58s]
[0m11:31:12.417781 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: ROLLBACK
[0m11:31:12.422937 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m11:31:12.428011 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m11:31:12.432090 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: Close
[0m11:31:12.435505 [debug] [Thread-1 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:31:12.447420 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_companies_symbol .................................. [RUN]
[0m11:31:12.443642 [info ] [Thread-4 (]: 4 of 5 PASS not_null_stock_performance_monthly_symbol .......................... [[32mPASS[0m in 0.61s]
[0m11:31:12.450983 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m11:31:12.456141 [debug] [Thread-4 (]: Finished running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m11:31:12.460265 [debug] [Thread-1 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:31:12.494620 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:31:12.531026 [debug] [Thread-1 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:31:12.544604 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:31:12.547466 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.139 seconds
[0m11:31:12.563108 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m11:31:12.568618 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m11:31:12.574295 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.74s]
[0m11:31:12.581508 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m11:31:12.584318 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:31:12.591932 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m11:31:12.596944 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m11:31:12.626491 [debug] [Thread-1 (]: SQL status: BEGIN in 0.029 seconds
[0m11:31:12.631124 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m11:31:12.635663 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m11:31:12.646738 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.005 seconds
[0m11:31:12.657093 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m11:31:12.664170 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m11:31:12.673786 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.22s]
[0m11:31:12.679658 [debug] [Thread-1 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m11:31:12.690369 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:12.694693 [debug] [MainThread]: On master: BEGIN
[0m11:31:12.698742 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m11:31:12.730262 [debug] [MainThread]: SQL status: BEGIN in 0.031 seconds
[0m11:31:12.734738 [debug] [MainThread]: On master: COMMIT
[0m11:31:12.741714 [debug] [MainThread]: Using postgres connection "master"
[0m11:31:12.746286 [debug] [MainThread]: On master: COMMIT
[0m11:31:12.751020 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m11:31:12.756085 [debug] [MainThread]: On master: Close
[0m11:31:12.760930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:31:12.767759 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m11:31:12.773067 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m11:31:12.777684 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m11:31:12.784136 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce' was properly closed.
[0m11:31:12.789971 [info ] [MainThread]: 
[0m11:31:12.795147 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 1.47 seconds (1.47s).
[0m11:31:12.807150 [debug] [MainThread]: Command end result
[0m11:31:13.039001 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m11:31:13.063735 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m11:31:13.145211 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m11:31:13.152433 [info ] [MainThread]: 
[0m11:31:13.161356 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:31:13.171087 [info ] [MainThread]: 
[0m11:31:13.179755 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m11:31:13.195429 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 6.2553596, "process_in_blocks": "0", "process_kernel_time": 0.903143, "process_mem_max_rss": "123828", "process_out_blocks": "0", "process_user_time": 10.415602}
[0m11:31:13.206768 [debug] [MainThread]: Command `dbt test` succeeded at 11:31:13.204706 after 6.27 seconds
[0m11:31:13.216496 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf8b6930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf3136e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdaf310650>]}
[0m11:31:13.226430 [debug] [MainThread]: Flushing usage events
[0m11:31:14.756809 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:54:42.391748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0ba129c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0d4aff50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0baf50d0>]}


============================== 12:54:42.402003 | f871d214-f47f-4c14-83a5-8f76a8502eb7 ==============================
[0m12:54:42.402003 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:54:42.403823 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:54:42.734315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0b036900>]}
[0m12:54:42.824711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0c44c200>]}
[0m12:54:42.827032 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:54:42.968711 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m12:54:43.460154 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:54:43.462120 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:54:43.536123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0a5d27e0>]}
[0m12:54:43.701690 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:54:43.716309 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:54:43.788020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e09505c10>]}
[0m12:54:43.789905 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m12:54:43.791871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0a53e300>]}
[0m12:54:43.796687 [info ] [MainThread]: 
[0m12:54:43.798404 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:54:43.799994 [info ] [MainThread]: 
[0m12:54:43.801995 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:54:43.810408 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m12:54:43.811630 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m12:54:43.812665 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m12:54:43.895768 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m12:54:43.896597 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m12:54:43.897388 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m12:54:43.899133 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m12:54:43.900870 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m12:54:43.903362 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m12:54:43.905288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:43.906964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:43.909338 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:54:43.930399 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.023 seconds
[0m12:54:43.931198 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.022 seconds
[0m12:54:43.931915 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.027 seconds
[0m12:54:43.935760 [debug] [ThreadPool]: On list_airflow: Close
[0m12:54:43.939291 [debug] [ThreadPool]: On list_airflow: Close
[0m12:54:43.942926 [debug] [ThreadPool]: On list_airflow: Close
[0m12:54:43.950418 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m12:54:43.951353 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m12:54:43.952301 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m12:54:43.961845 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m12:54:43.965373 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m12:54:43.968859 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m12:54:43.970448 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m12:54:43.971945 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m12:54:43.973470 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m12:54:43.975277 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:43.977068 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:43.978558 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m12:54:43.987971 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m12:54:43.990426 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m12:54:43.992695 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m12:54:43.994063 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m12:54:43.994810 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m12:54:43.996585 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m12:54:43.999171 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m12:54:44.000659 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m12:54:44.002455 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m12:54:44.003243 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.005 seconds
[0m12:54:44.008329 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m12:54:44.009404 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m12:54:44.010210 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m12:54:44.011694 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m12:54:44.014150 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m12:54:44.016838 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m12:54:44.021389 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m12:54:44.023021 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m12:54:44.033643 [debug] [MainThread]: Using postgres connection "master"
[0m12:54:44.035290 [debug] [MainThread]: On master: BEGIN
[0m12:54:44.036845 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:54:44.047154 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m12:54:44.048853 [debug] [MainThread]: Using postgres connection "master"
[0m12:54:44.050404 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:54:44.062014 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m12:54:44.064829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e091048c0>]}
[0m12:54:44.066380 [debug] [MainThread]: On master: ROLLBACK
[0m12:54:44.067914 [debug] [MainThread]: Using postgres connection "master"
[0m12:54:44.069239 [debug] [MainThread]: On master: BEGIN
[0m12:54:44.070937 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m12:54:44.072489 [debug] [MainThread]: On master: COMMIT
[0m12:54:44.073985 [debug] [MainThread]: Using postgres connection "master"
[0m12:54:44.075691 [debug] [MainThread]: On master: COMMIT
[0m12:54:44.077546 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:54:44.079010 [debug] [MainThread]: On master: Close
[0m12:54:44.085702 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m12:54:44.087596 [info ] [Thread-1 (]: 1 of 8 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m12:54:44.089929 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m12:54:44.092010 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m12:54:44.104203 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.118133 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m12:54:44.170507 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.183455 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.184927 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m12:54:44.186261 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:44.196108 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m12:54:44.197814 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.199503 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m12:54:44.211482 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m12:54:44.221290 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.223023 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m12:54:44.225727 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:44.232534 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.234376 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m12:54:44.236600 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:44.262465 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m12:54:44.264182 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.265780 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m12:54:44.275972 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m12:54:44.285713 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m12:54:44.294252 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m12:54:44.296078 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m12:54:44.304929 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m12:54:44.309900 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m12:54:44.313582 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0baf5b20>]}
[0m12:54:44.315709 [info ] [Thread-1 (]: 1 of 8 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.22s]
[0m12:54:44.317744 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m12:54:44.320417 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m12:54:44.321128 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m12:54:44.322866 [info ] [Thread-3 (]: 2 of 8 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m12:54:44.324929 [info ] [Thread-4 (]: 3 of 8 START sql table model public_core.dim_companies ......................... [RUN]
[0m12:54:44.327337 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m12:54:44.329200 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m12:54:44.331118 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m12:54:44.332628 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m12:54:44.338057 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m12:54:44.343702 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m12:54:44.352870 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m12:54:44.353809 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m12:54:44.402479 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m12:54:44.398257 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m12:54:44.412665 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:44.413481 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:44.414593 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m12:54:44.415831 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m12:54:44.417233 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:54:44.418573 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:54:44.428957 [debug] [Thread-4 (]: SQL status: BEGIN in 0.010 seconds
[0m12:54:44.429775 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m12:54:44.431270 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:44.432956 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:44.434568 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m12:54:44.436388 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m12:54:47.883526 [debug] [Thread-3 (]: SQL status: SELECT 700061 in 3.444 seconds
[0m12:54:47.898064 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:47.899615 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m12:54:47.901353 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:54:47.906982 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:47.908611 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m12:54:47.910727 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:54:47.913536 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m12:54:47.915130 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:47.916464 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m12:54:47.950163 [debug] [Thread-3 (]: SQL status: COMMIT in 0.032 seconds
[0m12:54:47.955387 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m12:54:47.960956 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m12:54:47.963009 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m12:54:48.034473 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.070 seconds
[0m12:54:48.038305 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m12:54:48.040874 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e02fa8170>]}
[0m12:54:48.043121 [info ] [Thread-3 (]: 2 of 8 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 700061[0m in 3.71s]
[0m12:54:48.045209 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m12:54:48.328271 [debug] [Thread-4 (]: SQL status: SELECT 962 in 3.890 seconds
[0m12:54:48.336435 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:48.338153 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m12:54:48.340436 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:48.346279 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:48.347834 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m12:54:48.349720 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:54:48.353015 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m12:54:48.354665 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:48.356636 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m12:54:48.360164 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m12:54:48.364783 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m12:54:48.366879 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m12:54:48.368759 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m12:54:48.374710 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.004 seconds
[0m12:54:48.378047 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m12:54:48.380064 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e00e1e810>]}
[0m12:54:48.382470 [info ] [Thread-4 (]: 3 of 8 OK created sql table model public_core.dim_companies .................... [[32mSELECT 962[0m in 4.05s]
[0m12:54:48.384665 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m12:54:48.387485 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m12:54:48.388674 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m12:54:48.389612 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m12:54:48.390681 [debug] [Thread-4 (]: Began running node model.idx_stock.technical_indicators_macd
[0m12:54:48.392131 [info ] [Thread-1 (]: 4 of 8 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m12:54:48.394104 [info ] [Thread-2 (]: 5 of 8 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m12:54:48.396263 [info ] [Thread-3 (]: 6 of 8 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m12:54:48.398411 [info ] [Thread-4 (]: 7 of 8 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m12:54:48.400592 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m12:54:48.402575 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_monthly)
[0m12:54:48.404291 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m12:54:48.406392 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_macd)
[0m12:54:48.408359 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m12:54:48.410267 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m12:54:48.411966 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m12:54:48.413816 [debug] [Thread-4 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m12:54:48.420891 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m12:54:48.427597 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m12:54:48.434050 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m12:54:48.440704 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m12:54:48.449699 [debug] [Thread-4 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m12:54:48.457365 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m12:54:48.458251 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m12:54:48.459108 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m12:54:48.460365 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m12:54:48.467223 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m12:54:48.475147 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m12:54:48.481805 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m12:54:48.497225 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.499374 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:48.501261 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:48.502493 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m12:54:48.503434 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:54:48.506069 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m12:54:48.510272 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m12:54:48.512508 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:48.514619 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m12:54:48.516506 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:54:48.518253 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:54:48.522154 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m12:54:48.533506 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m12:54:48.536151 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.538054 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m12:54:48.540463 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m12:54:48.543213 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:48.544448 [debug] [Thread-2 (]: SQL status: BEGIN in 0.026 seconds
[0m12:54:48.545417 [debug] [Thread-4 (]: SQL status: BEGIN in 0.023 seconds
[0m12:54:48.548593 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m12:54:48.550830 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:48.553101 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:54:48.557071 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m12:54:48.559485 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m12:54:48.860174 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.313 seconds
[0m12:54:48.867388 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.869223 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m12:54:48.872375 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:48.879593 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.881549 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m12:54:48.883745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:54:48.888899 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m12:54:48.891219 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.893096 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m12:54:48.909101 [debug] [Thread-1 (]: SQL status: COMMIT in 0.014 seconds
[0m12:54:48.915228 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m12:54:48.918003 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m12:54:48.920118 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m12:54:48.928948 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m12:54:48.933359 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m12:54:48.935904 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e00e7a5a0>]}
[0m12:54:48.938637 [info ] [Thread-1 (]: 4 of 8 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.54s]
[0m12:54:48.941929 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m12:54:48.944341 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m12:54:48.947112 [info ] [Thread-1 (]: 8 of 8 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m12:54:48.950569 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_rsi)
[0m12:54:48.953215 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m12:54:48.965581 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m12:54:48.982696 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m12:54:48.994071 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m12:54:49.008079 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:54:49.009857 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m12:54:49.011546 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:54:49.028071 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m12:54:49.031036 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:54:49.034116 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m12:54:56.596276 [debug] [Thread-2 (]: SQL status: SELECT 959 in 8.030 seconds
[0m12:54:56.604829 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:56.606691 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m12:54:56.609687 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:56.618445 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:56.620812 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m12:54:56.623360 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m12:54:56.627142 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m12:54:56.629094 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:56.631464 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m12:54:56.667803 [debug] [Thread-2 (]: SQL status: COMMIT in 0.034 seconds
[0m12:54:56.673816 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m12:54:56.675992 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m12:54:56.677691 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m12:54:56.694875 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.015 seconds
[0m12:54:56.699891 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m12:54:56.702993 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e00e7b4d0>]}
[0m12:54:56.713332 [info ] [Thread-2 (]: 5 of 8 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 8.30s]
[0m12:54:56.716785 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m12:54:56.854731 [debug] [Thread-3 (]: SQL status: SELECT 959 in 8.299 seconds
[0m12:54:56.862110 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:56.864183 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m12:54:56.867495 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:56.874736 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:56.876613 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m12:54:56.878991 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:54:56.883447 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m12:54:56.885798 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:56.887537 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m12:54:56.917794 [debug] [Thread-3 (]: SQL status: COMMIT in 0.028 seconds
[0m12:54:56.925700 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m12:54:56.928262 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m12:54:56.930126 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m12:54:56.942859 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.011 seconds
[0m12:54:56.946872 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m12:54:56.949199 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e02f77da0>]}
[0m12:54:56.951672 [info ] [Thread-3 (]: 6 of 8 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 8.54s]
[0m12:54:56.955370 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m12:55:00.115058 [debug] [Thread-4 (]: SQL status: SELECT 700061 in 11.548 seconds
[0m12:55:00.127479 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:55:00.129559 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m12:55:00.132573 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:55:00.138798 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:55:00.140962 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m12:55:00.183308 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.041 seconds
[0m12:55:00.187760 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m12:55:00.190027 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:55:00.192269 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m12:55:00.201323 [debug] [Thread-4 (]: SQL status: COMMIT in 0.007 seconds
[0m12:55:00.206887 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m12:55:00.209415 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m12:55:00.213735 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m12:55:00.294225 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.078 seconds
[0m12:55:00.298491 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: Close
[0m12:55:00.301060 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e00e3ac30>]}
[0m12:55:00.303728 [info ] [Thread-4 (]: 7 of 8 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 700061[0m in 11.89s]
[0m12:55:00.306162 [debug] [Thread-4 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m12:55:02.388775 [debug] [Thread-1 (]: SQL status: SELECT 699099 in 13.352 seconds
[0m12:55:02.395554 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:55:02.397438 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m12:55:02.399978 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:55:02.405566 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:55:02.407246 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m12:55:02.409401 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m12:55:02.412977 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m12:55:02.414794 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:55:02.416489 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m12:55:02.452849 [debug] [Thread-1 (]: SQL status: COMMIT in 0.035 seconds
[0m12:55:02.458562 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m12:55:02.461281 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m12:55:02.463589 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m12:55:02.508293 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.043 seconds
[0m12:55:02.512811 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m12:55:02.515585 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f871d214-f47f-4c14-83a5-8f76a8502eb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e02f8bc50>]}
[0m12:55:02.517995 [info ] [Thread-1 (]: 8 of 8 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 699099[0m in 13.57s]
[0m12:55:02.520846 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m12:55:02.526044 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:02.528174 [debug] [MainThread]: On master: BEGIN
[0m12:55:02.530342 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:55:02.544021 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m12:55:02.546395 [debug] [MainThread]: On master: COMMIT
[0m12:55:02.548317 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:02.550108 [debug] [MainThread]: On master: COMMIT
[0m12:55:02.552394 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:55:02.554189 [debug] [MainThread]: On master: Close
[0m12:55:02.556327 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:55:02.558234 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m12:55:02.560133 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m12:55:02.562393 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m12:55:02.564044 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m12:55:02.566153 [info ] [MainThread]: 
[0m12:55:02.568079 [info ] [MainThread]: Finished running 7 table models, 1 view model in 0 hours 0 minutes and 18.76 seconds (18.76s).
[0m12:55:02.572850 [debug] [MainThread]: Command end result
[0m12:55:02.651683 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:55:02.662255 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:55:02.681545 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:55:02.684678 [info ] [MainThread]: 
[0m12:55:02.686707 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:55:02.688771 [info ] [MainThread]: 
[0m12:55:02.690831 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
[0m12:55:02.695154 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 20.400227, "process_in_blocks": "0", "process_kernel_time": 0.646148, "process_mem_max_rss": "123260", "process_out_blocks": "2360", "process_user_time": 4.583614}
[0m12:55:02.697518 [debug] [MainThread]: Command `dbt run` succeeded at 12:55:02.697315 after 20.40 seconds
[0m12:55:02.699368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0b7ff650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0b2519a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5e0b975b20>]}
[0m12:55:02.701290 [debug] [MainThread]: Flushing usage events
[0m12:55:04.309141 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m12:55:13.466581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c069b6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c0879460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c069b0b0>]}


============================== 12:55:13.487371 | ef56d5cd-324e-477a-af3b-d773f67747c7 ==============================
[0m12:55:13.487371 [info ] [MainThread]: Running with dbt=1.9.4
[0m12:55:13.490481 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:55:13.881562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7bff7b5c0>]}
[0m12:55:13.993586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c009f650>]}
[0m12:55:13.995881 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m12:55:14.178495 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m12:55:14.780388 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:55:14.782449 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:55:14.893930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7bf5909b0>]}
[0m12:55:15.101022 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:55:15.118574 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:55:15.182596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7be5c1040>]}
[0m12:55:15.185149 [info ] [MainThread]: Found 8 models, 5 data tests, 1 source, 434 macros
[0m12:55:15.187572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7bfff73e0>]}
[0m12:55:15.193119 [info ] [MainThread]: 
[0m12:55:15.195610 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m12:55:15.197460 [info ] [MainThread]: 
[0m12:55:15.200002 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m12:55:15.209710 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m12:55:15.211226 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m12:55:15.212572 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m12:55:15.288464 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m12:55:15.289309 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m12:55:15.290085 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m12:55:15.291698 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m12:55:15.293425 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m12:55:15.294983 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m12:55:15.296724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:15.298549 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:15.300300 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:55:15.312663 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m12:55:15.313672 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m12:55:15.315747 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m12:55:15.316688 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m12:55:15.318811 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m12:55:15.321003 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m12:55:15.322746 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m12:55:15.324752 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m12:55:15.328038 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m12:55:15.332901 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m12:55:15.335097 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m12:55:15.337658 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m12:55:15.338388 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.007 seconds
[0m12:55:15.343609 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m12:55:15.345834 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m12:55:15.349089 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m12:55:15.351805 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m12:55:15.355081 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m12:55:15.368759 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.371227 [debug] [MainThread]: On master: BEGIN
[0m12:55:15.372970 [debug] [MainThread]: Opening a new connection, currently in state init
[0m12:55:15.384975 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m12:55:15.386918 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.388923 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m12:55:15.405485 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m12:55:15.409084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ef56d5cd-324e-477a-af3b-d773f67747c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7bfff70e0>]}
[0m12:55:15.411197 [debug] [MainThread]: On master: ROLLBACK
[0m12:55:15.413195 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.414920 [debug] [MainThread]: On master: BEGIN
[0m12:55:15.417421 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m12:55:15.419342 [debug] [MainThread]: On master: COMMIT
[0m12:55:15.421157 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.422791 [debug] [MainThread]: On master: COMMIT
[0m12:55:15.424735 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:55:15.426372 [debug] [MainThread]: On master: Close
[0m12:55:15.434864 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m12:55:15.435874 [debug] [Thread-2 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m12:55:15.436667 [debug] [Thread-3 (]: Began running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m12:55:15.437483 [debug] [Thread-4 (]: Began running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m12:55:15.438644 [info ] [Thread-1 (]: 1 of 5 START test not_null_dim_companies_symbol ................................ [RUN]
[0m12:55:15.440627 [info ] [Thread-2 (]: 2 of 5 START test not_null_stg_daily_stock_summary_date ........................ [RUN]
[0m12:55:15.442311 [info ] [Thread-3 (]: 3 of 5 START test not_null_stg_daily_stock_summary_symbol ...................... [RUN]
[0m12:55:15.444221 [info ] [Thread-4 (]: 4 of 5 START test not_null_stock_performance_monthly_symbol .................... [RUN]
[0m12:55:15.446067 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m12:55:15.447912 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86)
[0m12:55:15.450113 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef)
[0m12:55:15.452399 [debug] [Thread-4 (]: Acquiring new postgres connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce'
[0m12:55:15.454180 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m12:55:15.456038 [debug] [Thread-2 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m12:55:15.457739 [debug] [Thread-3 (]: Began compiling node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m12:55:15.459473 [debug] [Thread-4 (]: Began compiling node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m12:55:15.497700 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m12:55:15.501815 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m12:55:15.509193 [debug] [Thread-3 (]: Writing injected SQL for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m12:55:15.517196 [debug] [Thread-4 (]: Writing injected SQL for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m12:55:15.527001 [debug] [Thread-4 (]: Began executing node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m12:55:15.528805 [debug] [Thread-2 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m12:55:15.535947 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m12:55:15.536838 [debug] [Thread-3 (]: Began executing node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m12:55:15.563206 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m12:55:15.566502 [debug] [Thread-4 (]: Writing runtime sql for node "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m12:55:15.571250 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m12:55:15.576218 [debug] [Thread-3 (]: Writing runtime sql for node "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m12:55:15.586592 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m12:55:15.588886 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m12:55:15.590277 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: BEGIN
[0m12:55:15.591796 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m12:55:15.593094 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m12:55:15.594463 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: BEGIN
[0m12:55:15.596486 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m12:55:15.598327 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m12:55:15.600641 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: BEGIN
[0m12:55:15.602844 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:55:15.606008 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:15.607710 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m12:55:15.616450 [debug] [Thread-2 (]: SQL status: BEGIN in 0.020 seconds
[0m12:55:15.622788 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"
[0m12:55:15.624735 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m12:55:15.626043 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select date
from "airflow"."public_staging"."stg_daily_stock_summary"
where date is null



      
    ) dbt_internal_test
[0m12:55:15.627240 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m12:55:15.628239 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m12:55:15.630553 [debug] [Thread-4 (]: Using postgres connection "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"
[0m12:55:15.635142 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m12:55:15.637254 [debug] [Thread-3 (]: Using postgres connection "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"
[0m12:55:15.639317 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_analytics"."stock_performance_monthly"
where symbol is null



      
    ) dbt_internal_test
[0m12:55:15.641562 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m12:55:15.643831 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_staging"."stg_daily_stock_summary"
where symbol is null



      
    ) dbt_internal_test
[0m12:55:15.647440 [debug] [Thread-4 (]: SQL status: SELECT 1 in 0.001 seconds
[0m12:55:15.649184 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m12:55:15.657808 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: ROLLBACK
[0m12:55:15.658798 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.009 seconds
[0m12:55:15.664425 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m12:55:15.667350 [debug] [Thread-4 (]: On test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce: Close
[0m12:55:15.671423 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: ROLLBACK
[0m12:55:15.674010 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m12:55:15.676796 [info ] [Thread-4 (]: 4 of 5 PASS not_null_stock_performance_monthly_symbol .......................... [[32mPASS[0m in 0.22s]
[0m12:55:15.679412 [debug] [Thread-3 (]: On test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef: Close
[0m12:55:15.682713 [info ] [Thread-1 (]: 1 of 5 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.24s]
[0m12:55:15.689894 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m12:55:15.687705 [info ] [Thread-3 (]: 3 of 5 PASS not_null_stg_daily_stock_summary_symbol ............................ [[32mPASS[0m in 0.24s]
[0m12:55:15.685067 [debug] [Thread-4 (]: Finished running node test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce
[0m12:55:15.692026 [debug] [Thread-1 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m12:55:15.694492 [debug] [Thread-3 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef
[0m12:55:15.698231 [info ] [Thread-1 (]: 5 of 5 START test unique_dim_companies_symbol .................................. [RUN]
[0m12:55:15.702167 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m12:55:15.704349 [debug] [Thread-1 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m12:55:15.718500 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m12:55:15.733197 [debug] [Thread-1 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m12:55:15.738805 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m12:55:15.755290 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m12:55:15.757291 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m12:55:15.759404 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m12:55:15.772654 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m12:55:15.775215 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m12:55:15.777297 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m12:55:15.781884 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m12:55:15.786090 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m12:55:15.788781 [debug] [Thread-1 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m12:55:15.791993 [info ] [Thread-1 (]: 5 of 5 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.09s]
[0m12:55:15.795107 [debug] [Thread-1 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m12:55:15.802137 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.169 seconds
[0m12:55:15.806287 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: ROLLBACK
[0m12:55:15.808675 [debug] [Thread-2 (]: On test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86: Close
[0m12:55:15.811281 [info ] [Thread-2 (]: 2 of 5 PASS not_null_stg_daily_stock_summary_date .............................. [[32mPASS[0m in 0.36s]
[0m12:55:15.813977 [debug] [Thread-2 (]: Finished running node test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86
[0m12:55:15.818762 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.820928 [debug] [MainThread]: On master: BEGIN
[0m12:55:15.822856 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m12:55:15.836545 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m12:55:15.838912 [debug] [MainThread]: On master: COMMIT
[0m12:55:15.841327 [debug] [MainThread]: Using postgres connection "master"
[0m12:55:15.843371 [debug] [MainThread]: On master: COMMIT
[0m12:55:15.846189 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m12:55:15.849081 [debug] [MainThread]: On master: Close
[0m12:55:15.852577 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:55:15.854691 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_date.4dbf1cac86' was properly closed.
[0m12:55:15.856631 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stg_daily_stock_summary_symbol.2e7596cfef' was properly closed.
[0m12:55:15.858604 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m12:55:15.860615 [debug] [MainThread]: Connection 'test.idx_stock.not_null_stock_performance_monthly_symbol.034c3463ce' was properly closed.
[0m12:55:15.862550 [info ] [MainThread]: 
[0m12:55:15.864720 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 0.66 seconds (0.66s).
[0m12:55:15.869496 [debug] [MainThread]: Command end result
[0m12:55:15.954249 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m12:55:15.964410 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m12:55:15.986398 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m12:55:15.988436 [info ] [MainThread]: 
[0m12:55:15.990603 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:55:15.992402 [info ] [MainThread]: 
[0m12:55:15.994228 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m12:55:15.996983 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.6536014, "process_in_blocks": "0", "process_kernel_time": 0.722345, "process_mem_max_rss": "121376", "process_out_blocks": "0", "process_user_time": 4.611135}
[0m12:55:16.000043 [debug] [MainThread]: Command `dbt test` succeeded at 12:55:15.999645 after 2.66 seconds
[0m12:55:16.002734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c04aa3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c0c517f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7be597440>]}
[0m12:55:16.004744 [debug] [MainThread]: Flushing usage events
[0m12:55:17.108283 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:40:04.638358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b8637b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b8ce7530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b925a870>]}


============================== 15:40:04.649642 | 7b26b1cb-fc69-4929-90cb-862e0335acbb ==============================
[0m15:40:04.649642 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:40:04.652491 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:40:05.040678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b26b1cb-fc69-4929-90cb-862e0335acbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b8c1d850>]}
[0m15:40:05.153613 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b26b1cb-fc69-4929-90cb-862e0335acbb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b8cce0f0>]}
[0m15:40:05.156123 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:40:05.322812 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:40:05.972633 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:40:05.975437 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/news_sentiment_analysis.sql
[0m15:40:05.979950 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m15:40:06.954726 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.news_sentiment_analysis' (models/marts/analytics/news_sentiment_analysis.sql) depends on a source named 'stockbit.stockbit_ticker_sentiment' which was not found
[0m15:40:06.957628 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4870062, "process_in_blocks": "0", "process_kernel_time": 0.475107, "process_mem_max_rss": "116044", "process_out_blocks": "856", "process_user_time": 5.034122}
[0m15:40:06.959660 [debug] [MainThread]: Command `dbt run` failed at 15:40:06.959446 after 2.49 seconds
[0m15:40:06.961482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b86363f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b73286e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26b6380440>]}
[0m15:40:06.963194 [debug] [MainThread]: Flushing usage events
[0m15:40:08.224680 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:43:34.348011 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6172a097c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6172a506e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f617299e5a0>]}


============================== 15:43:34.357488 | be79e370-4d76-4da6-b0e5-48d74e908fb7 ==============================
[0m15:43:34.357488 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:43:34.359682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m15:43:34.702103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6172459c40>]}
[0m15:43:34.810412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f617245a360>]}
[0m15:43:34.813034 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:43:34.973298 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:43:35.532196 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
[0m15:43:35.535032 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/news_sentiment_analysis.sql
[0m15:43:35.538321 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m15:43:36.396227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6173e23950>]}
[0m15:43:36.588581 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:43:36.607493 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:43:36.693661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6170115970>]}
[0m15:43:36.695849 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m15:43:36.699287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6170134ec0>]}
[0m15:43:36.703690 [info ] [MainThread]: 
[0m15:43:36.706020 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:43:36.708205 [info ] [MainThread]: 
[0m15:43:36.710604 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:43:36.713864 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:43:36.791829 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:43:36.793619 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:43:36.795243 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:36.808558 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.013 seconds
[0m15:43:36.811930 [debug] [ThreadPool]: On list_airflow: Close
[0m15:43:36.814915 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m15:43:36.817191 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m15:43:36.827118 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:43:36.829071 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m15:43:36.831124 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:36.843190 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m15:43:36.845797 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:43:36.848589 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m15:43:36.851687 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m15:43:36.854903 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:43:36.856965 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:43:36.858898 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:43:36.866901 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m15:43:36.868915 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m15:43:36.879962 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m15:43:36.882647 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m15:43:36.884271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m15:43:36.899661 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:43:36.903890 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:43:36.908305 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:43:36.910263 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:43:36.912085 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:43:36.913877 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:43:36.916163 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:43:36.918127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:36.919805 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:36.933141 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m15:43:36.935811 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m15:43:36.937195 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:43:36.938988 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m15:43:36.940184 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:43:36.942374 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:43:36.944826 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:43:36.947182 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:43:36.950990 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:43:36.953991 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m15:43:36.957545 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:43:36.958325 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m15:43:36.959098 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m15:43:36.961025 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:43:36.964999 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:43:36.968789 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:43:36.972456 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:43:36.974445 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:43:36.986805 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:36.988904 [debug] [MainThread]: On master: BEGIN
[0m15:43:36.990677 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:43:37.003294 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m15:43:37.005298 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:37.007321 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:43:37.014115 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m15:43:37.017838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61709bfd40>]}
[0m15:43:37.019753 [debug] [MainThread]: On master: ROLLBACK
[0m15:43:37.021760 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:37.023364 [debug] [MainThread]: On master: BEGIN
[0m15:43:37.025548 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:43:37.027384 [debug] [MainThread]: On master: COMMIT
[0m15:43:37.029132 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:37.031119 [debug] [MainThread]: On master: COMMIT
[0m15:43:37.033317 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:43:37.035393 [debug] [MainThread]: On master: Close
[0m15:43:37.044000 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m15:43:37.046360 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m15:43:37.049110 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.news_sentiment_analysis)
[0m15:43:37.051086 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m15:43:37.067769 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m15:43:37.083049 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m15:43:37.156582 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m15:43:37.171531 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:43:37.173211 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m15:43:37.174790 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:43:37.186360 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m15:43:37.188372 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:43:37.190358 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM "airflow"."kontan"."kontan_ticker_sentiment"
),

stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m15:43:37.193563 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "kontan.kontan_ticker_sentiment" does not exist
LINE 22:     FROM "airflow"."kontan"."kontan_ticker_sentiment"
                  ^

[0m15:43:37.198873 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m15:43:37.205231 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m15:43:37.215147 [debug] [Thread-1 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "kontan.kontan_ticker_sentiment" does not exist
  LINE 22:     FROM "airflow"."kontan"."kontan_ticker_sentiment"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:43:37.218855 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be79e370-4d76-4da6-b0e5-48d74e908fb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61730c5fa0>]}
[0m15:43:37.221005 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.17s]
[0m15:43:37.223132 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m15:43:37.225281 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "kontan.kontan_ticker_sentiment" does not exist
  LINE 22:     FROM "airflow"."kontan"."kontan_ticker_sentiment"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m15:43:37.229819 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:37.232190 [debug] [MainThread]: On master: BEGIN
[0m15:43:37.233985 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:43:37.245383 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m15:43:37.247855 [debug] [MainThread]: On master: COMMIT
[0m15:43:37.249715 [debug] [MainThread]: Using postgres connection "master"
[0m15:43:37.251519 [debug] [MainThread]: On master: COMMIT
[0m15:43:37.253715 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:43:37.255586 [debug] [MainThread]: On master: Close
[0m15:43:37.257739 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:43:37.259518 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m15:43:37.261244 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m15:43:37.262950 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m15:43:37.265409 [info ] [MainThread]: 
[0m15:43:37.267300 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m15:43:37.269823 [debug] [MainThread]: Command end result
[0m15:43:37.346313 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:43:37.356611 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:43:37.376440 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:43:37.378358 [info ] [MainThread]: 
[0m15:43:37.380461 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:43:37.382556 [info ] [MainThread]: 
[0m15:43:37.384701 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "kontan.kontan_ticker_sentiment" does not exist
  LINE 22:     FROM "airflow"."kontan"."kontan_ticker_sentiment"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:43:37.386523 [info ] [MainThread]: 
[0m15:43:37.388584 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:43:37.391788 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.1354935, "process_in_blocks": "0", "process_kernel_time": 0.375614, "process_mem_max_rss": "130400", "process_out_blocks": "448", "process_user_time": 4.962063}
[0m15:43:37.394209 [debug] [MainThread]: Command `dbt run` failed at 15:43:37.393954 after 3.14 seconds
[0m15:43:37.396052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6172fdb650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6170dc2450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f616ecbe870>]}
[0m15:43:37.398565 [debug] [MainThread]: Flushing usage events
[0m15:43:38.826921 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:47:06.100968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45785b9070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4579920b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4577b72450>]}


============================== 15:47:06.112687 | 7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7 ==============================
[0m15:47:06.112687 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:47:06.114792 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'send_anonymous_usage_stats': 'True'}
[0m15:47:06.549287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4578158440>]}
[0m15:47:06.658099 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45776ccbf0>]}
[0m15:47:06.661269 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:47:06.830938 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:47:07.397630 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m15:47:07.400426 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m15:47:07.402333 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/news_sentiment_analysis.sql
[0m15:47:08.376235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45757312b0>]}
[0m15:47:08.587935 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:47:08.607268 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:47:08.656060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f457531fe30>]}
[0m15:47:08.660552 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m15:47:08.662862 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45757f7920>]}
[0m15:47:08.667214 [info ] [MainThread]: 
[0m15:47:08.669427 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:47:08.671358 [info ] [MainThread]: 
[0m15:47:08.675647 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:47:08.680929 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:47:08.757592 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:47:08.761108 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:47:08.763156 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:08.779302 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.016 seconds
[0m15:47:08.782916 [debug] [ThreadPool]: On list_airflow: Close
[0m15:47:08.795849 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m15:47:08.797211 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m15:47:08.798784 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m15:47:08.812101 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:47:08.815953 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:47:08.820211 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:47:08.822238 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:47:08.825694 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:47:08.828496 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:47:08.830686 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:47:08.832817 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:08.834487 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:47:08.850412 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m15:47:08.852033 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m15:47:08.852818 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m15:47:08.854337 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:47:08.856669 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:47:08.860504 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:47:08.862782 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:47:08.865007 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:47:08.867332 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:47:08.874307 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m15:47:08.876774 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m15:47:08.877955 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m15:47:08.880884 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:47:08.884239 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:47:08.887666 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:47:08.890123 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:47:08.892629 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:47:08.894583 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:47:08.914584 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:08.916880 [debug] [MainThread]: On master: BEGIN
[0m15:47:08.918654 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:47:08.932284 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m15:47:08.934788 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:08.937134 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:47:08.944998 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m15:47:08.949332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f457756c3e0>]}
[0m15:47:08.951782 [debug] [MainThread]: On master: ROLLBACK
[0m15:47:08.954205 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:08.956343 [debug] [MainThread]: On master: BEGIN
[0m15:47:08.959311 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:47:08.961554 [debug] [MainThread]: On master: COMMIT
[0m15:47:08.963656 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:08.965545 [debug] [MainThread]: On master: COMMIT
[0m15:47:08.967685 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:47:08.969722 [debug] [MainThread]: On master: Close
[0m15:47:08.980467 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m15:47:08.982895 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m15:47:08.985109 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.news_sentiment_analysis)
[0m15:47:08.987130 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m15:47:09.003883 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m15:47:09.027144 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m15:47:09.160498 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m15:47:09.174046 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:47:09.176156 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m15:47:09.178134 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:47:09.190214 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m15:47:09.193041 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:47:09.195248 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m15:47:09.198458 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public_analytics.daily_stock_metrics" does not exist
LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                  ^

[0m15:47:09.204167 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m15:47:09.209928 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m15:47:09.218821 [debug] [Thread-1 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:47:09.223449 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7b30e57f-36d8-4ce0-aa70-5c30fd8edcc7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f457531c920>]}
[0m15:47:09.226535 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.24s]
[0m15:47:09.229823 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m15:47:09.232505 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m15:47:09.237749 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:09.240047 [debug] [MainThread]: On master: BEGIN
[0m15:47:09.242293 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:47:09.254912 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m15:47:09.258270 [debug] [MainThread]: On master: COMMIT
[0m15:47:09.260539 [debug] [MainThread]: Using postgres connection "master"
[0m15:47:09.262585 [debug] [MainThread]: On master: COMMIT
[0m15:47:09.265056 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:47:09.267095 [debug] [MainThread]: On master: Close
[0m15:47:09.269292 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:47:09.271069 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m15:47:09.273115 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m15:47:09.274958 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m15:47:09.276998 [info ] [MainThread]: 
[0m15:47:09.278926 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.60 seconds (0.60s).
[0m15:47:09.281833 [debug] [MainThread]: Command end result
[0m15:47:09.367222 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:47:09.378814 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:47:09.398933 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:47:09.400830 [info ] [MainThread]: 
[0m15:47:09.403073 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:47:09.405033 [info ] [MainThread]: 
[0m15:47:09.407692 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:47:09.410554 [info ] [MainThread]: 
[0m15:47:09.413722 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:47:09.417075 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.4285011, "process_in_blocks": "0", "process_kernel_time": 0.390208, "process_mem_max_rss": "127508", "process_out_blocks": "0", "process_user_time": 5.212782}
[0m15:47:09.419644 [debug] [MainThread]: Command `dbt run` failed at 15:47:09.419383 after 3.43 seconds
[0m15:47:09.421949 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45778b1fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45767f0800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4575babce0>]}
[0m15:47:09.424350 [debug] [MainThread]: Flushing usage events
[0m15:47:10.704402 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:52:19.380872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26715bd6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26719becf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2674b5d160>]}


============================== 15:52:19.392923 | 5577265e-f705-4aa2-aa30-55fdd50d7251 ==============================
[0m15:52:19.392923 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:52:19.395111 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'send_anonymous_usage_stats': 'True'}
[0m15:52:19.779840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f267100d760>]}
[0m15:52:19.976922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f267100caa0>]}
[0m15:52:19.979756 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:52:20.251812 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:52:21.078400 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:52:21.083024 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:52:21.256500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26708e7110>]}
[0m15:52:21.506207 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:52:21.528041 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:52:21.584101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26705f6cf0>]}
[0m15:52:21.586952 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m15:52:21.589453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f266fd59c70>]}
[0m15:52:21.595469 [info ] [MainThread]: 
[0m15:52:21.598961 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:52:21.601950 [info ] [MainThread]: 
[0m15:52:21.604700 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:52:21.609523 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:52:21.700451 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:52:21.702453 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:52:21.704454 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:52:21.721597 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.017 seconds
[0m15:52:21.726349 [debug] [ThreadPool]: On list_airflow: Close
[0m15:52:21.739057 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m15:52:21.740777 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m15:52:21.742783 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m15:52:21.755024 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:52:21.760200 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:52:21.765395 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:52:21.767654 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:52:21.769704 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:52:21.772029 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:52:21.774489 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:52:21.776951 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:52:21.778982 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:52:21.793873 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m15:52:21.796711 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:52:21.798944 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m15:52:21.799975 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m15:52:21.801398 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:52:21.804063 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:52:21.806300 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:52:21.810609 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:52:21.812954 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:52:21.814183 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m15:52:21.821477 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:52:21.823797 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m15:52:21.825377 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m15:52:21.828350 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:52:21.831724 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:52:21.835750 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:52:21.839676 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:52:21.842460 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:52:21.856474 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:21.858614 [debug] [MainThread]: On master: BEGIN
[0m15:52:21.860811 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:52:21.877045 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m15:52:21.880022 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:21.882602 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:52:21.889797 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m15:52:21.894635 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f266fd83590>]}
[0m15:52:21.897056 [debug] [MainThread]: On master: ROLLBACK
[0m15:52:21.899176 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:21.901695 [debug] [MainThread]: On master: BEGIN
[0m15:52:21.904616 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:52:21.906759 [debug] [MainThread]: On master: COMMIT
[0m15:52:21.909421 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:21.912621 [debug] [MainThread]: On master: COMMIT
[0m15:52:21.915037 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:52:21.917237 [debug] [MainThread]: On master: Close
[0m15:52:21.928881 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m15:52:21.931572 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m15:52:21.933977 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.news_sentiment_analysis)
[0m15:52:21.936308 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m15:52:21.954443 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m15:52:21.973128 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m15:52:22.050732 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m15:52:22.064723 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:52:22.066494 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m15:52:22.068261 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:52:22.080478 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m15:52:22.083118 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:52:22.085493 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m15:52:22.088762 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public_analytics.daily_stock_metrics" does not exist
LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                  ^

[0m15:52:22.092529 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m15:52:22.096163 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m15:52:22.105383 [debug] [Thread-1 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:52:22.109388 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5577265e-f705-4aa2-aa30-55fdd50d7251', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2671037260>]}
[0m15:52:22.112207 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.17s]
[0m15:52:22.115033 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m15:52:22.118085 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m15:52:22.124441 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:22.126691 [debug] [MainThread]: On master: BEGIN
[0m15:52:22.128988 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:52:22.142187 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m15:52:22.144802 [debug] [MainThread]: On master: COMMIT
[0m15:52:22.146874 [debug] [MainThread]: Using postgres connection "master"
[0m15:52:22.149117 [debug] [MainThread]: On master: COMMIT
[0m15:52:22.151651 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:52:22.153513 [debug] [MainThread]: On master: Close
[0m15:52:22.155924 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:52:22.157695 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m15:52:22.159630 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m15:52:22.161605 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m15:52:22.163652 [info ] [MainThread]: 
[0m15:52:22.166235 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.56 seconds (0.56s).
[0m15:52:22.169241 [debug] [MainThread]: Command end result
[0m15:52:22.250181 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:52:22.260122 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:52:22.277470 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:52:22.279119 [info ] [MainThread]: 
[0m15:52:22.281173 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:52:22.283466 [info ] [MainThread]: 
[0m15:52:22.285742 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:52:22.287691 [info ] [MainThread]: 
[0m15:52:22.289636 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:52:22.292581 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0533404, "process_in_blocks": "0", "process_kernel_time": 0.409342, "process_mem_max_rss": "121288", "process_out_blocks": "0", "process_user_time": 4.762351}
[0m15:52:22.294880 [debug] [MainThread]: Command `dbt run` failed at 15:52:22.294654 after 3.06 seconds
[0m15:52:22.296658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f266fd63410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26713023f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f26713012b0>]}
[0m15:52:22.298679 [debug] [MainThread]: Flushing usage events
[0m15:52:23.691251 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:57:37.896276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae3164d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae2dde480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae3164da0>]}


============================== 15:57:37.906488 | 0eeed645-4a65-4b90-8268-961795aa5912 ==============================
[0m15:57:37.906488 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:57:37.908628 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:57:38.244397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae25db2f0>]}
[0m15:57:38.345035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae32bc1a0>]}
[0m15:57:38.348079 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:57:38.507538 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:57:39.022553 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:57:39.024415 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:57:39.102728 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae1bcd7f0>]}
[0m15:57:39.273080 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:57:39.289957 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:57:39.369572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae0ff56a0>]}
[0m15:57:39.371677 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m15:57:39.373662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae25dcbc0>]}
[0m15:57:39.377624 [info ] [MainThread]: 
[0m15:57:39.379584 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:57:39.381924 [info ] [MainThread]: 
[0m15:57:39.383946 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:57:39.387746 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:57:39.455296 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:57:39.457243 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:57:39.459023 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:39.472887 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.014 seconds
[0m15:57:39.476198 [debug] [ThreadPool]: On list_airflow: Close
[0m15:57:39.478929 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m15:57:39.481697 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m15:57:39.492598 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:57:39.494565 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m15:57:39.496484 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:39.508276 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m15:57:39.510227 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:57:39.511715 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m15:57:39.514425 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m15:57:39.517083 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:57:39.518733 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:57:39.520084 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:57:39.527162 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m15:57:39.528796 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m15:57:39.538341 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_analytics)
[0m15:57:39.541358 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m15:57:39.543035 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m15:57:39.554652 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:57:39.558776 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:57:39.564546 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:57:39.566548 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:57:39.568844 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:57:39.570794 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:57:39.572801 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:57:39.574930 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:39.576556 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:57:39.592888 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m15:57:39.593771 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m15:57:39.595736 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:57:39.598143 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:57:39.600789 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:57:39.602587 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m15:57:39.607239 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:57:39.609172 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:57:39.604202 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:57:39.610235 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m15:57:39.616748 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:57:39.618099 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m15:57:39.619232 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m15:57:39.621317 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:57:39.624132 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:57:39.627632 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:57:39.631986 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:57:39.634016 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:57:39.645177 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.647756 [debug] [MainThread]: On master: BEGIN
[0m15:57:39.649965 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:57:39.661556 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m15:57:39.664339 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.666881 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:57:39.674837 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m15:57:39.678522 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae0bac6e0>]}
[0m15:57:39.681087 [debug] [MainThread]: On master: ROLLBACK
[0m15:57:39.683745 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.686119 [debug] [MainThread]: On master: BEGIN
[0m15:57:39.688745 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:57:39.690695 [debug] [MainThread]: On master: COMMIT
[0m15:57:39.692610 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.694373 [debug] [MainThread]: On master: COMMIT
[0m15:57:39.696715 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:57:39.699398 [debug] [MainThread]: On master: Close
[0m15:57:39.707513 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m15:57:39.709879 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m15:57:39.711989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.news_sentiment_analysis)
[0m15:57:39.714599 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m15:57:39.730802 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m15:57:39.747250 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m15:57:39.817516 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m15:57:39.832896 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:57:39.834578 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m15:57:39.835993 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:57:39.848350 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m15:57:39.850469 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:57:39.852763 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m15:57:39.855798 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public_analytics.daily_stock_metrics" does not exist
LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                  ^

[0m15:57:39.865235 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m15:57:39.868294 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m15:57:39.876356 [debug] [Thread-1 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:57:39.882429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0eeed645-4a65-4b90-8268-961795aa5912', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae1bfa2a0>]}
[0m15:57:39.884973 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.17s]
[0m15:57:39.887446 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m15:57:39.889872 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m15:57:39.894728 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.896980 [debug] [MainThread]: On master: BEGIN
[0m15:57:39.899115 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:57:39.911358 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m15:57:39.914529 [debug] [MainThread]: On master: COMMIT
[0m15:57:39.916813 [debug] [MainThread]: Using postgres connection "master"
[0m15:57:39.919015 [debug] [MainThread]: On master: COMMIT
[0m15:57:39.921359 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:57:39.923548 [debug] [MainThread]: On master: Close
[0m15:57:39.925878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:57:39.927916 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m15:57:39.930730 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m15:57:39.933205 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m15:57:39.935273 [info ] [MainThread]: 
[0m15:57:39.937470 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.55 seconds (0.55s).
[0m15:57:39.940330 [debug] [MainThread]: Command end result
[0m15:57:40.049546 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:57:40.063725 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:57:40.089132 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:57:40.091749 [info ] [MainThread]: 
[0m15:57:40.094733 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:57:40.097733 [info ] [MainThread]: 
[0m15:57:40.100967 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m15:57:40.103339 [info ] [MainThread]: 
[0m15:57:40.106176 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m15:57:40.110299 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3268225, "process_in_blocks": "0", "process_kernel_time": 0.43557, "process_mem_max_rss": "120904", "process_out_blocks": "2360", "process_user_time": 4.30621}
[0m15:57:40.113528 [debug] [MainThread]: Command `dbt run` failed at 15:57:40.113152 after 2.33 seconds
[0m15:57:40.116134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae25de720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae25dcbc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ae30d50a0>]}
[0m15:57:40.118175 [debug] [MainThread]: Flushing usage events
[0m15:57:41.819008 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:02:58.308211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf7636c500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf76089340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf75a80bf0>]}


============================== 16:02:58.320635 | c55b7e46-1a51-45ac-9ae8-344db5966aa7 ==============================
[0m16:02:58.320635 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:02:58.322869 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:02:58.812774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf7608bfb0>]}
[0m16:02:58.953128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf75e0f620>]}
[0m16:02:58.955992 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:02:59.303633 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:03:00.003818 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:03:00.005716 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:03:00.090834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf74d96ba0>]}
[0m16:03:00.310792 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:03:00.330485 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:03:00.379826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf74da8440>]}
[0m16:03:00.382219 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m16:03:00.384341 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf749f3ce0>]}
[0m16:03:00.389207 [info ] [MainThread]: 
[0m16:03:00.391699 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:03:00.394213 [info ] [MainThread]: 
[0m16:03:00.396394 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:03:00.400514 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:03:00.480813 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:03:00.483936 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:03:00.486708 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:03:00.506504 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.020 seconds
[0m16:03:00.511079 [debug] [ThreadPool]: On list_airflow: Close
[0m16:03:00.523732 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m16:03:00.525266 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m16:03:00.526869 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m16:03:00.542283 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:03:00.546885 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:03:00.552147 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:03:00.554234 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:03:00.556016 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:03:00.557945 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:03:00.559984 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:03:00.561781 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:03:00.563500 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:03:00.577166 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:03:00.580355 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m16:03:00.586570 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m16:03:00.584398 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:03:00.587704 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:03:00.589961 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:03:00.592371 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:03:00.595385 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:03:00.597860 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:03:00.605608 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m16:03:00.606443 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m16:03:00.607384 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m16:03:00.611401 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:03:00.616303 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:03:00.619858 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:03:00.622765 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:03:00.624395 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:03:00.626942 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:03:00.647199 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.650065 [debug] [MainThread]: On master: BEGIN
[0m16:03:00.652193 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:03:00.666487 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m16:03:00.669282 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.671858 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:03:00.680862 [debug] [MainThread]: SQL status: SELECT 0 in 0.006 seconds
[0m16:03:00.684818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf74dabd40>]}
[0m16:03:00.686871 [debug] [MainThread]: On master: ROLLBACK
[0m16:03:00.688999 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.690886 [debug] [MainThread]: On master: BEGIN
[0m16:03:00.693854 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:03:00.696240 [debug] [MainThread]: On master: COMMIT
[0m16:03:00.698064 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.699813 [debug] [MainThread]: On master: COMMIT
[0m16:03:00.701870 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:03:00.704152 [debug] [MainThread]: On master: Close
[0m16:03:00.718950 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m16:03:00.721455 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m16:03:00.723725 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.news_sentiment_analysis)
[0m16:03:00.725797 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m16:03:00.744249 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m16:03:00.759526 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m16:03:00.846217 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m16:03:00.862079 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:03:00.864175 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m16:03:00.866470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:03:00.880893 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m16:03:00.884926 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:03:00.887529 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m16:03:00.891029 [debug] [Thread-1 (]: Postgres adapter: Postgres error: relation "public_analytics.daily_stock_metrics" does not exist
LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                  ^

[0m16:03:00.898075 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m16:03:00.901809 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m16:03:00.910533 [debug] [Thread-1 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m16:03:00.915388 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c55b7e46-1a51-45ac-9ae8-344db5966aa7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf741a9220>]}
[0m16:03:00.918561 [error] [Thread-1 (]: 1 of 1 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.19s]
[0m16:03:00.921027 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m16:03:00.923379 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m16:03:00.929691 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.932153 [debug] [MainThread]: On master: BEGIN
[0m16:03:00.934448 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:03:00.948071 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m16:03:00.951032 [debug] [MainThread]: On master: COMMIT
[0m16:03:00.953272 [debug] [MainThread]: Using postgres connection "master"
[0m16:03:00.954919 [debug] [MainThread]: On master: COMMIT
[0m16:03:00.957193 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:03:00.959283 [debug] [MainThread]: On master: Close
[0m16:03:00.962192 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:03:00.964434 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m16:03:00.966843 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m16:03:00.968843 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m16:03:00.970813 [info ] [MainThread]: 
[0m16:03:00.972895 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.57 seconds (0.57s).
[0m16:03:00.976011 [debug] [MainThread]: Command end result
[0m16:03:01.061832 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:03:01.072353 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:03:01.090289 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:03:01.092217 [info ] [MainThread]: 
[0m16:03:01.094494 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:03:01.096607 [info ] [MainThread]: 
[0m16:03:01.098774 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public_analytics.daily_stock_metrics" does not exist
  LINE 33:     FROM "airflow"."public_analytics"."daily_stock_metrics"
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m16:03:01.100920 [info ] [MainThread]: 
[0m16:03:01.102886 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
[0m16:03:01.105701 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9328516, "process_in_blocks": "0", "process_kernel_time": 0.481685, "process_mem_max_rss": "123504", "process_out_blocks": "0", "process_user_time": 4.977419}
[0m16:03:01.107938 [debug] [MainThread]: Command `dbt run` failed at 16:03:01.107706 after 2.94 seconds
[0m16:03:01.110334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf762e07a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf764af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbf729f9670>]}
[0m16:03:01.112275 [debug] [MainThread]: Flushing usage events
[0m16:03:02.460872 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:04:45.525393 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38adeac560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ae5bf320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ae2883b0>]}


============================== 16:04:45.541131 | 3e409423-fdf3-446b-9b34-30eabb223885 ==============================
[0m16:04:45.541131 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:04:45.544664 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:04:45.974113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38adca30b0>]}
[0m16:04:46.118523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38aea86bd0>]}
[0m16:04:46.122255 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:04:46.295294 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:04:47.055477 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:04:47.058343 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:04:47.161269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ae1e37d0>]}
[0m16:04:47.377778 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:04:47.396207 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:04:47.441404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ac9595b0>]}
[0m16:04:47.443721 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m16:04:47.445943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ac967650>]}
[0m16:04:47.451208 [info ] [MainThread]: 
[0m16:04:47.454125 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:04:47.457432 [info ] [MainThread]: 
[0m16:04:47.460014 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:04:47.470183 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:04:47.471695 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:04:47.473128 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:04:47.557221 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:04:47.558081 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:04:47.558867 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:04:47.560375 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:04:47.562004 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:04:47.563745 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:04:47.565561 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:04:47.567113 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:04:47.568833 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:04:47.581612 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.016 seconds
[0m16:04:47.582610 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.015 seconds
[0m16:04:47.586000 [debug] [ThreadPool]: On list_airflow: Close
[0m16:04:47.587144 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.018 seconds
[0m16:04:47.590653 [debug] [ThreadPool]: On list_airflow: Close
[0m16:04:47.594843 [debug] [ThreadPool]: On list_airflow: Close
[0m16:04:47.599146 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m16:04:47.600064 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m16:04:47.601791 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m16:04:47.603791 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m16:04:47.613195 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:04:47.617454 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:04:47.619132 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m16:04:47.620875 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m16:04:47.622351 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:04:47.623896 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:04:47.635322 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m16:04:47.636479 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m16:04:47.638130 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:04:47.639771 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:04:47.641460 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m16:04:47.643170 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m16:04:47.645681 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:04:47.647413 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:04:47.649808 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:04:47.652512 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:04:47.654381 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:04:47.656004 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:04:47.657764 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:04:47.659193 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:04:47.667443 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m16:04:47.669154 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m16:04:47.669980 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m16:04:47.672508 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m16:04:47.681316 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_staging)
[0m16:04:47.682807 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m16:04:47.684107 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m16:04:47.698376 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:04:47.703581 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:04:47.711056 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:04:47.714212 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:04:47.716955 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:04:47.719191 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:04:47.722522 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:04:47.725083 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:04:47.727426 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:04:47.747692 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m16:04:47.751400 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:04:47.756624 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:04:47.761482 [debug] [ThreadPool]: SQL status: BEGIN in 0.034 seconds
[0m16:04:47.771988 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:04:47.774942 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:04:47.768843 [debug] [ThreadPool]: SQL status: BEGIN in 0.043 seconds
[0m16:04:47.776466 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m16:04:47.779786 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:04:47.784690 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:04:47.785817 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m16:04:47.788145 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:04:47.790709 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:04:47.794058 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:04:47.803193 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:04:47.804502 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m16:04:47.811995 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:04:47.814674 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:04:47.831572 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:47.834325 [debug] [MainThread]: On master: BEGIN
[0m16:04:47.836696 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:04:47.849249 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m16:04:47.852450 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:47.855855 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:04:47.863949 [debug] [MainThread]: SQL status: SELECT 0 in 0.005 seconds
[0m16:04:47.870128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38abd34650>]}
[0m16:04:47.873256 [debug] [MainThread]: On master: ROLLBACK
[0m16:04:47.878462 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:47.882919 [debug] [MainThread]: On master: BEGIN
[0m16:04:47.885551 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:04:47.889739 [debug] [MainThread]: On master: COMMIT
[0m16:04:47.892471 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:47.894425 [debug] [MainThread]: On master: COMMIT
[0m16:04:47.896691 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:04:47.898890 [debug] [MainThread]: On master: Close
[0m16:04:47.912340 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m16:04:47.915614 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m16:04:47.917886 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m16:04:47.919518 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m16:04:47.937545 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m16:04:47.949067 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m16:04:48.024527 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.034621 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.036709 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m16:04:48.038824 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:04:48.051747 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m16:04:48.056035 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.058853 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m16:04:48.064276 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m16:04:48.078777 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.080606 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m16:04:48.082921 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.116161 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:04:48.118204 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.120697 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:04:48.126585 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:04:48.140294 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m16:04:48.150771 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:04:48.152763 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m16:04:48.155210 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m16:04:48.160535 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m16:04:48.164488 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ad5084a0>]}
[0m16:04:48.166650 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.24s]
[0m16:04:48.169004 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m16:04:48.172879 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m16:04:48.173870 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m16:04:48.175753 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m16:04:48.178111 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m16:04:48.179876 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m16:04:48.181996 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m16:04:48.183720 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m16:04:48.185699 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m16:04:48.192852 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m16:04:48.198865 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m16:04:48.210674 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m16:04:48.211893 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m16:04:48.283951 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m16:04:48.281429 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m16:04:48.296271 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:04:48.297375 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:04:48.298765 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m16:04:48.300522 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m16:04:48.301979 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:04:48.304233 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:04:48.316781 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m16:04:48.318518 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m16:04:48.320558 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:04:48.322941 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:04:48.325320 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m16:04:48.327789 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m16:04:48.349687 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.020 seconds
[0m16:04:48.363947 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:04:48.364891 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.034 seconds
[0m16:04:48.366663 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m16:04:48.375464 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:04:48.377855 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.379161 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m16:04:48.382610 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:04:48.385060 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.386675 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:04:48.390428 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:04:48.392420 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:04:48.394281 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:04:48.397429 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:04:48.414748 [debug] [Thread-3 (]: SQL status: COMMIT in 0.018 seconds
[0m16:04:48.426342 [debug] [Thread-4 (]: SQL status: COMMIT in 0.027 seconds
[0m16:04:48.431458 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m16:04:48.441234 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m16:04:48.447617 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:04:48.450113 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:04:48.452251 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m16:04:48.454732 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m16:04:48.457450 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:04:48.459585 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:04:48.463117 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m16:04:48.466887 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m16:04:48.468786 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9d41f10>]}
[0m16:04:48.471014 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ab923740>]}
[0m16:04:48.473243 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 959[0m in 0.29s]
[0m16:04:48.476222 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 959[0m in 0.29s]
[0m16:04:48.478866 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m16:04:48.481549 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m16:04:48.486705 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m16:04:48.487855 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m16:04:48.489170 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m16:04:48.490560 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m16:04:48.492273 [info ] [Thread-1 (]: 4 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m16:04:48.494731 [info ] [Thread-2 (]: 5 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m16:04:48.497063 [info ] [Thread-3 (]: 6 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m16:04:48.499457 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m16:04:48.501571 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.news_sentiment_analysis)
[0m16:04:48.504057 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_daily)
[0m16:04:48.506454 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_monthly)
[0m16:04:48.508629 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_weekly)
[0m16:04:48.510461 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m16:04:48.512352 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m16:04:48.514244 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m16:04:48.516142 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m16:04:48.523361 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.530019 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m16:04:48.536337 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m16:04:48.543228 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m16:04:48.552912 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m16:04:48.554904 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m16:04:48.556806 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m16:04:48.562634 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.563744 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m16:04:48.569356 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m16:04:48.575999 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m16:04:48.585408 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m16:04:48.592211 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.593724 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:04:48.595495 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m16:04:48.596888 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:04:48.598019 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:04:48.599673 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m16:04:48.601996 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:04:48.604532 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m16:04:48.607060 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m16:04:48.609232 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:04:48.612589 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:04:48.614545 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m16:04:48.623306 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m16:04:48.625552 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.628065 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m16:04:48.630580 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m16:04:48.632872 [debug] [Thread-3 (]: SQL status: BEGIN in 0.020 seconds
[0m16:04:48.634902 [debug] [Thread-4 (]: SQL status: BEGIN in 0.020 seconds
[0m16:04:48.637708 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:04:48.639894 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:04:48.642266 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:04:48.644500 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m16:04:48.646702 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m16:04:48.649420 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m16:04:48.650731 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.019 seconds
[0m16:04:48.661082 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.663326 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m16:04:48.665471 [debug] [Thread-2 (]: SQL status: SELECT 959 in 0.013 seconds
[0m16:04:48.666825 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.674087 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:04:48.674979 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.020 seconds
[0m16:04:48.675935 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.022 seconds
[0m16:04:48.678946 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:04:48.681091 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m16:04:48.688325 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:04:48.694995 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:04:48.696768 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.699513 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.700424 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m16:04:48.702274 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m16:04:48.704728 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:04:48.708388 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:04:48.710873 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.712523 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:04:48.715271 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:04:48.716619 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:04:48.719894 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:04:48.723602 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:04:48.725656 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:04:48.730943 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m16:04:48.732960 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:04:48.734700 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:04:48.738662 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:04:48.739667 [debug] [Thread-2 (]: SQL status: COMMIT in 0.003 seconds
[0m16:04:48.741345 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:04:48.743082 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:04:48.745106 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m16:04:48.750341 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m16:04:48.754748 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m16:04:48.756647 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m16:04:48.757761 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:04:48.759572 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:04:48.764876 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m16:04:48.771150 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m16:04:48.775313 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m16:04:48.777822 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m16:04:48.780684 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:04:48.783353 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:04:48.786373 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9d9ba40>]}
[0m16:04:48.789178 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:04:48.790682 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m16:04:48.792994 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m16:04:48.795927 [info ] [Thread-1 (]: 4 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 959[0m in 0.28s]
[0m16:04:48.800179 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m16:04:48.803258 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:04:48.805597 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:04:48.807411 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m16:04:48.809813 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9da7050>]}
[0m16:04:48.813327 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m16:04:48.817309 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m16:04:48.819754 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_macd
[0m16:04:48.822950 [info ] [Thread-2 (]: 5 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.31s]
[0m16:04:48.825710 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9dcc0e0>]}
[0m16:04:48.828030 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9dd7c80>]}
[0m16:04:48.830547 [info ] [Thread-1 (]: 8 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m16:04:48.833100 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m16:04:48.835620 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 0.32s]
[0m16:04:48.838827 [info ] [Thread-3 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 0.32s]
[0m16:04:48.841305 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.news_sentiment_analysis, now model.idx_stock.technical_indicators_macd)
[0m16:04:48.843713 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m16:04:48.846287 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m16:04:48.852076 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m16:04:48.854658 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m16:04:48.856958 [info ] [Thread-2 (]: 9 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m16:04:48.867207 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m16:04:48.868925 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_rsi)
[0m16:04:48.873083 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m16:04:48.880358 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.889667 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m16:04:48.891606 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m16:04:48.899320 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m16:04:48.906260 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.916594 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:04:48.918582 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.920330 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m16:04:48.922665 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m16:04:48.924638 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:04:48.926448 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:04:48.939008 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m16:04:48.940758 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m16:04:48.942272 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:04:48.944289 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.946212 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m16:04:48.948525 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m16:04:48.964060 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.012 seconds
[0m16:04:48.970735 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.971618 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.021 seconds
[0m16:04:48.973473 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m16:04:48.979332 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:04:48.981600 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:04:48.982897 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m16:04:48.986230 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:04:48.988775 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:04:48.990336 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:04:48.993286 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:04:48.995084 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:04:48.996665 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:04:48.999871 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:04:49.001026 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m16:04:49.007378 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m16:04:49.008279 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m16:04:49.010007 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:04:49.014878 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m16:04:49.016873 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m16:04:49.019082 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:04:49.021676 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:04:49.022913 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m16:04:49.026181 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m16:04:49.028220 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:04:49.030045 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a841c9b0>]}
[0m16:04:49.033172 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: Close
[0m16:04:49.035372 [info ] [Thread-2 (]: 9 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 0[0m in 0.16s]
[0m16:04:49.037877 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3e409423-fdf3-446b-9b34-30eabb223885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a9d83020>]}
[0m16:04:49.039956 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m16:04:49.041845 [info ] [Thread-1 (]: 8 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 959[0m in 0.20s]
[0m16:04:49.044899 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m16:04:49.048033 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:49.049438 [debug] [MainThread]: On master: BEGIN
[0m16:04:49.050748 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:04:49.060801 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m16:04:49.063320 [debug] [MainThread]: On master: COMMIT
[0m16:04:49.065008 [debug] [MainThread]: Using postgres connection "master"
[0m16:04:49.066466 [debug] [MainThread]: On master: COMMIT
[0m16:04:49.068377 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:04:49.070335 [debug] [MainThread]: On master: Close
[0m16:04:49.072480 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:04:49.074228 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m16:04:49.075730 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m16:04:49.077372 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m16:04:49.079011 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m16:04:49.080672 [info ] [MainThread]: 
[0m16:04:49.082272 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 1.62 seconds (1.62s).
[0m16:04:49.086347 [debug] [MainThread]: Command end result
[0m16:04:49.155048 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:04:49.163809 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:04:49.180472 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:04:49.182098 [info ] [MainThread]: 
[0m16:04:49.183731 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:04:49.185763 [info ] [MainThread]: 
[0m16:04:49.188331 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m16:04:49.190798 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.880832, "process_in_blocks": "0", "process_kernel_time": 0.593797, "process_mem_max_rss": "123360", "process_out_blocks": "0", "process_user_time": 6.838566}
[0m16:04:49.192922 [debug] [MainThread]: Command `dbt run` succeeded at 16:04:49.192720 after 3.88 seconds
[0m16:04:49.194625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38adf1ae70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38adc5b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38ae159b20>]}
[0m16:04:49.196251 [debug] [MainThread]: Flushing usage events
[0m16:04:50.777668 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:05:06.482115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05acfbcad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa975ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aae50680>]}


============================== 16:05:06.492922 | fc3b7428-cb70-4fbb-bfc3-bb97b820a5da ==============================
[0m16:05:06.492922 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:05:06.495093 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:05:06.832719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fc3b7428-cb70-4fbb-bfc3-bb97b820a5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa78dd60>]}
[0m16:05:06.932427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fc3b7428-cb70-4fbb-bfc3-bb97b820a5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa6596a0>]}
[0m16:05:06.934791 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:05:07.098729 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:05:07.602755 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:05:07.604697 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:05:07.672327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fc3b7428-cb70-4fbb-bfc3-bb97b820a5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9f740e0>]}
[0m16:05:07.837252 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:05:07.855352 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:05:07.913658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fc3b7428-cb70-4fbb-bfc3-bb97b820a5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a8fe1520>]}
[0m16:05:07.915608 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m16:05:07.917442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fc3b7428-cb70-4fbb-bfc3-bb97b820a5da', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9f8c110>]}
[0m16:05:07.921555 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m16:05:07.926034 [debug] [MainThread]: Command end result
[0m16:05:08.000007 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:05:08.015038 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:05:08.027279 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:05:08.030224 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.673759, "process_in_blocks": "0", "process_kernel_time": 0.337164, "process_mem_max_rss": "112528", "process_out_blocks": "0", "process_user_time": 4.006304}
[0m16:05:08.032488 [debug] [MainThread]: Command `dbt test` succeeded at 16:05:08.032234 after 1.68 seconds
[0m16:05:08.035107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05a9f28ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa6d7380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05aa6d7230>]}
[0m16:05:08.037139 [debug] [MainThread]: Flushing usage events
[0m16:05:09.181814 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:06:27.332737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b9c7d3a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b992cbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14ba03f950>]}


============================== 16:06:27.342849 | 86e486a2-a680-4ae0-bff1-2ee80ae296a7 ==============================
[0m16:06:27.342849 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:06:27.344780 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --select news_sentiment_analysis', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m16:06:27.710197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b9d5e4b0>]}
[0m16:06:27.845667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b9bf15e0>]}
[0m16:06:27.847982 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:06:28.024273 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:06:28.635879 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:06:28.638963 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:06:28.719181 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b93f84a0>]}
[0m16:06:28.912234 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:06:28.930439 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:06:28.971758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b7dbbe00>]}
[0m16:06:28.974152 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m16:06:28.976155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b7d9bbf0>]}
[0m16:06:28.980046 [info ] [MainThread]: 
[0m16:06:28.981929 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:06:28.983863 [info ] [MainThread]: 
[0m16:06:28.985999 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:06:28.990357 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:06:29.058470 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:06:29.060639 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:06:29.062470 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:06:29.075642 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.013 seconds
[0m16:06:29.079146 [debug] [ThreadPool]: On list_airflow: Close
[0m16:06:29.090882 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m16:06:29.092327 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:06:29.093713 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m16:06:29.104032 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:06:29.108940 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:06:29.113333 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:06:29.115330 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:06:29.117268 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:06:29.119311 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:06:29.121564 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:06:29.123695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:06:29.125546 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:06:29.139410 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m16:06:29.140523 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m16:06:29.142020 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:06:29.143243 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m16:06:29.144898 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:06:29.147056 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:06:29.149172 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:06:29.151004 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:06:29.154318 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:06:29.157815 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m16:06:29.161133 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:06:29.161984 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.003 seconds
[0m16:06:29.162697 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m16:06:29.164517 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:06:29.167631 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:06:29.170996 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:06:29.175494 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:06:29.177043 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:06:29.191424 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.193491 [debug] [MainThread]: On master: BEGIN
[0m16:06:29.196659 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:06:29.208570 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m16:06:29.210493 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.212442 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:06:29.224733 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m16:06:29.228135 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b795bc80>]}
[0m16:06:29.229874 [debug] [MainThread]: On master: ROLLBACK
[0m16:06:29.231768 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.233288 [debug] [MainThread]: On master: BEGIN
[0m16:06:29.235368 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:06:29.237375 [debug] [MainThread]: On master: COMMIT
[0m16:06:29.239461 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.241047 [debug] [MainThread]: On master: COMMIT
[0m16:06:29.242815 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:06:29.244365 [debug] [MainThread]: On master: Close
[0m16:06:29.252132 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m16:06:29.254619 [info ] [Thread-1 (]: 1 of 1 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m16:06:29.256956 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.news_sentiment_analysis)
[0m16:06:29.258580 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m16:06:29.274049 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.286439 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m16:06:29.356203 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.369050 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.370769 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m16:06:29.373046 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:06:29.383914 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m16:06:29.386420 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.388703 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m16:06:29.412900 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.022 seconds
[0m16:06:29.429909 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.432059 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m16:06:29.434491 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:06:29.441014 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.443146 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m16:06:29.445501 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:06:29.477810 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:06:29.479726 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.481525 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:06:29.488700 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:06:29.499548 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m16:06:29.510102 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:06:29.512052 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m16:06:29.520201 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.006 seconds
[0m16:06:29.525539 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m16:06:29.529170 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86e486a2-a680-4ae0-bff1-2ee80ae296a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14ba0a1d30>]}
[0m16:06:29.531443 [info ] [Thread-1 (]: 1 of 1 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 959[0m in 0.27s]
[0m16:06:29.533855 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m16:06:29.537961 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.539917 [debug] [MainThread]: On master: BEGIN
[0m16:06:29.541542 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:06:29.552079 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m16:06:29.554203 [debug] [MainThread]: On master: COMMIT
[0m16:06:29.556295 [debug] [MainThread]: Using postgres connection "master"
[0m16:06:29.557980 [debug] [MainThread]: On master: COMMIT
[0m16:06:29.559893 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:06:29.561475 [debug] [MainThread]: On master: Close
[0m16:06:29.563423 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:06:29.565026 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m16:06:29.566492 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m16:06:29.568136 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m16:06:29.569578 [info ] [MainThread]: 
[0m16:06:29.571661 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m16:06:29.574323 [debug] [MainThread]: Command end result
[0m16:06:29.651120 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:06:29.661235 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:06:29.678597 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:06:29.680315 [info ] [MainThread]: 
[0m16:06:29.682328 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:06:29.684154 [info ] [MainThread]: 
[0m16:06:29.685931 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:06:29.688981 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.4595058, "process_in_blocks": "0", "process_kernel_time": 0.512132, "process_mem_max_rss": "123268", "process_out_blocks": "0", "process_user_time": 4.177391}
[0m16:06:29.691228 [debug] [MainThread]: Command `dbt run` succeeded at 16:06:29.690976 after 2.46 seconds
[0m16:06:29.693180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14ba06f6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14b812e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14ba0a3740>]}
[0m16:06:29.694958 [debug] [MainThread]: Flushing usage events
[0m16:06:30.926423 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:41:59.661326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea821c680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea8854650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea9aa86e0>]}


============================== 17:41:59.672398 | b283e09d-5463-4267-8b3d-91c88560ee10 ==============================
[0m17:41:59.672398 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:41:59.674460 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m17:42:00.029696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea7780170>]}
[0m17:42:00.126214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea7510f50>]}
[0m17:42:00.128723 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:42:00.272393 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m17:42:00.838900 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:42:00.841018 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:42:00.915750 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea6795a90>]}
[0m17:42:01.072128 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m17:42:01.087722 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m17:42:01.131647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea5ba9490>]}
[0m17:42:01.133500 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m17:42:01.135274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea74bf0b0>]}
[0m17:42:01.139835 [info ] [MainThread]: 
[0m17:42:01.141665 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:42:01.143517 [info ] [MainThread]: 
[0m17:42:01.145583 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m17:42:01.155410 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m17:42:01.157667 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m17:42:01.158702 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m17:42:01.235863 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m17:42:01.236645 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m17:42:01.237289 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m17:42:01.238689 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m17:42:01.240531 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m17:42:01.242376 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m17:42:01.243893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:01.245685 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:01.247677 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:42:01.260238 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.015 seconds
[0m17:42:01.260976 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.017 seconds
[0m17:42:01.264591 [debug] [ThreadPool]: On list_airflow: Close
[0m17:42:01.265416 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.018 seconds
[0m17:42:01.268283 [debug] [ThreadPool]: On list_airflow: Close
[0m17:42:01.272799 [debug] [ThreadPool]: On list_airflow: Close
[0m17:42:01.279032 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m17:42:01.280378 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m17:42:01.281452 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m17:42:01.291746 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m17:42:01.295937 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m17:42:01.300130 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m17:42:01.301988 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m17:42:01.303758 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m17:42:01.305256 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m17:42:01.307055 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:01.308711 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:01.310171 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:42:01.323038 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m17:42:01.327354 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m17:42:01.326127 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m17:42:01.323888 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m17:42:01.329343 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m17:42:01.331247 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m17:42:01.333079 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m17:42:01.336122 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m17:42:01.338279 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m17:42:01.340384 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m17:42:01.344746 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m17:42:01.345714 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m17:42:01.346491 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m17:42:01.348380 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m17:42:01.351154 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m17:42:01.354673 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m17:42:01.358932 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m17:42:01.359616 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m17:42:01.373618 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:01.375565 [debug] [MainThread]: On master: BEGIN
[0m17:42:01.377309 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:42:01.388295 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m17:42:01.390339 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:01.392513 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m17:42:01.408776 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m17:42:01.412525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea5ba7200>]}
[0m17:42:01.414714 [debug] [MainThread]: On master: ROLLBACK
[0m17:42:01.416896 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:01.418652 [debug] [MainThread]: On master: BEGIN
[0m17:42:01.420844 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m17:42:01.422705 [debug] [MainThread]: On master: COMMIT
[0m17:42:01.424474 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:01.426287 [debug] [MainThread]: On master: COMMIT
[0m17:42:01.428319 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:42:01.430427 [debug] [MainThread]: On master: Close
[0m17:42:01.438407 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m17:42:01.440543 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m17:42:01.442564 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m17:42:01.444468 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m17:42:01.457564 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.471412 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m17:42:01.532123 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.543829 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.545691 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m17:42:01.547347 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:01.558258 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m17:42:01.560644 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.562677 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m17:42:01.570194 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m17:42:01.581798 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.583813 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m17:42:01.586705 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:01.592658 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.594610 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m17:42:01.597212 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:01.624991 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m17:42:01.627025 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.628971 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m17:42:01.637181 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m17:42:01.648564 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m17:42:01.657623 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m17:42:01.659645 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m17:42:01.669121 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.008 seconds
[0m17:42:01.674139 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m17:42:01.677708 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea9797290>]}
[0m17:42:01.680284 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.23s]
[0m17:42:01.682646 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m17:42:01.685490 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m17:42:01.686220 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m17:42:01.687848 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m17:42:01.689815 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m17:42:01.691670 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.daily_stock_metrics)
[0m17:42:01.693496 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m17:42:01.695349 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m17:42:01.697163 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m17:42:01.702631 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m17:42:01.707518 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m17:42:01.717681 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m17:42:01.718656 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m17:42:01.775760 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m17:42:01.772820 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m17:42:01.787700 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.788664 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.790052 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m17:42:01.791736 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m17:42:01.793565 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:01.795458 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m17:42:01.806360 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m17:42:01.808506 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m17:42:01.809658 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.811781 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.813833 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m17:42:01.815946 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m17:42:01.841148 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.023 seconds
[0m17:42:01.841954 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.023 seconds
[0m17:42:01.853590 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.861257 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.863236 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m17:42:01.865232 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m17:42:01.867758 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:01.869500 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:01.874478 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.881696 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.883462 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m17:42:01.885509 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m17:42:01.888010 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:01.889626 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m17:42:01.892439 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m17:42:01.896169 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m17:42:01.898530 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.900624 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.902524 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m17:42:01.904347 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m17:42:01.911343 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m17:42:01.916653 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m17:42:01.917449 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m17:42:01.922627 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m17:42:01.927911 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m17:42:01.930099 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m17:42:01.932363 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m17:42:01.935058 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m17:42:01.940669 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m17:42:01.944072 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m17:42:01.945208 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.008 seconds
[0m17:42:01.946860 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea4595f40>]}
[0m17:42:01.949908 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m17:42:01.952144 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 959[0m in 0.26s]
[0m17:42:01.954317 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea74bf7d0>]}
[0m17:42:01.956041 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m17:42:01.958283 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 959[0m in 0.26s]
[0m17:42:01.962075 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m17:42:01.965472 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m17:42:01.966264 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m17:42:01.967036 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m17:42:01.967907 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m17:42:01.969205 [info ] [Thread-1 (]: 4 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m17:42:01.971249 [info ] [Thread-2 (]: 5 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m17:42:01.973450 [info ] [Thread-3 (]: 6 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m17:42:01.975575 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m17:42:01.977671 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.news_sentiment_analysis)
[0m17:42:01.979739 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_daily)
[0m17:42:01.981623 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_monthly)
[0m17:42:01.983468 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_weekly)
[0m17:42:01.985277 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m17:42:01.986952 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m17:42:01.988659 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m17:42:01.990393 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m17:42:01.996909 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.003402 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m17:42:02.009618 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m17:42:02.016225 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m17:42:02.025550 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m17:42:02.026782 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m17:42:02.033413 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m17:42:02.034679 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m17:42:02.041481 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m17:42:02.040765 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.051325 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m17:42:02.057180 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m17:42:02.059629 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.063666 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m17:42:02.065442 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:02.068538 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.069790 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.071504 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m17:42:02.072977 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.074795 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m17:42:02.076538 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:02.078950 [debug] [Thread-4 (]: SQL status: BEGIN in 0.013 seconds
[0m17:42:02.080173 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m17:42:02.082188 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:42:02.085570 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.087423 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:42:02.091177 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m17:42:02.095030 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m17:42:02.097889 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.099967 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count
    FROM public.kontan_ticker_sentiment  -- Gunakan referensi langsung
),


stock_metrics AS (
    SELECT
        symbol,
        date,
        close,
        prev_close,
        (close - prev_close) / NULLIF(prev_close, 0) * 100 AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
)

SELECT
    s.symbol,
    c.name,
    s.date,
    s.close,
    s.percent_change,
    n.avg_sentiment,
    n.news_count,
    n.positive_count,
    n.negative_count,
    (n.positive_count::float / NULLIF(n.news_count, 0)) * 100 AS positive_percentage,
    
    -- Indikator korelasi sentimen-harga
    CASE
        WHEN n.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
        WHEN n.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
        WHEN n.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
        ELSE 'Neutral/No Strong Signal'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen
    CASE
        WHEN n.avg_sentiment > 0.4 AND n.news_count >= 3 THEN 'Strong Buy Signal'
        WHEN n.avg_sentiment > 0.2 AND n.news_count >= 2 THEN 'Buy Signal'
        WHEN n.avg_sentiment < -0.4 AND n.news_count >= 3 THEN 'Strong Sell Signal'
        WHEN n.avg_sentiment < -0.2 AND n.news_count >= 2 THEN 'Sell Signal'
        ELSE 'Hold/No Signal'
    END AS trading_signal
FROM stock_metrics s
LEFT JOIN news_sentiment n ON s.symbol = n.symbol AND s.date = n.date
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
WHERE s.date >= CURRENT_DATE - INTERVAL '30 day'
  );
  
[0m17:42:02.101896 [debug] [Thread-2 (]: SQL status: BEGIN in 0.020 seconds
[0m17:42:02.108647 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m17:42:02.112190 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.114894 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.117667 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m17:42:02.120123 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m17:42:02.131983 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.035 seconds
[0m17:42:02.138629 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.139703 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.036 seconds
[0m17:42:02.141813 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m17:42:02.148853 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.151514 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.152447 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m17:42:02.153457 [debug] [Thread-2 (]: SQL status: SELECT 959 in 0.030 seconds
[0m17:42:02.159148 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.161164 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.037 seconds
[0m17:42:02.162980 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.168743 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.170618 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m17:42:02.176953 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.183202 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.185388 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m17:42:02.187769 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m17:42:02.189075 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m17:42:02.191088 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m17:42:02.193496 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m17:42:02.196477 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m17:42:02.199598 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.201479 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.206736 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.208502 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.215144 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.219113 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m17:42:02.221628 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m17:42:02.223834 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m17:42:02.226025 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m17:42:02.228729 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.231476 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.234838 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.235712 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m17:42:02.239412 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m17:42:02.243205 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m17:42:02.244345 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m17:42:02.247601 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.249895 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.251649 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m17:42:02.256649 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m17:42:02.258723 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m17:42:02.261429 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m17:42:02.270751 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m17:42:02.273143 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m17:42:02.278292 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m17:42:02.280973 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m17:42:02.282036 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m17:42:02.284365 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m17:42:02.285938 [debug] [Thread-3 (]: SQL status: COMMIT in 0.009 seconds
[0m17:42:02.293964 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m17:42:02.302445 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m17:42:02.303728 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.007 seconds
[0m17:42:02.306003 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m17:42:02.307064 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.010 seconds
[0m17:42:02.309466 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m17:42:02.313488 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m17:42:02.315842 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m17:42:02.320254 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m17:42:02.322528 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m17:42:02.324943 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea4578ce0>]}
[0m17:42:02.329992 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea4579e50>]}
[0m17:42:02.335766 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.009 seconds
[0m17:42:02.334150 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 0.34s]
[0m17:42:02.339948 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.008 seconds
[0m17:42:02.339023 [info ] [Thread-1 (]: 4 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 959[0m in 0.35s]
[0m17:42:02.344177 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m17:42:02.346612 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m17:42:02.351022 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m17:42:02.353622 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m17:42:02.356169 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea457b770>]}
[0m17:42:02.357949 [debug] [Thread-4 (]: Began running node model.idx_stock.technical_indicators_macd
[0m17:42:02.360705 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea4578aa0>]}
[0m17:42:02.363143 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m17:42:02.366037 [info ] [Thread-2 (]: 5 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.38s]
[0m17:42:02.368578 [info ] [Thread-4 (]: 8 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m17:42:02.371573 [info ] [Thread-3 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 0.38s]
[0m17:42:02.373932 [info ] [Thread-1 (]: 9 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m17:42:02.377272 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m17:42:02.379930 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_weekly, now model.idx_stock.technical_indicators_macd)
[0m17:42:02.382872 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m17:42:02.385809 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.news_sentiment_analysis, now model.idx_stock.technical_indicators_rsi)
[0m17:42:02.389850 [debug] [Thread-4 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m17:42:02.394170 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m17:42:02.401637 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m17:42:02.410763 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.421278 [debug] [Thread-4 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m17:42:02.429931 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m17:42:02.429478 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m17:42:02.438249 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.450234 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.452794 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m17:42:02.454159 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.456086 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:42:02.458389 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m17:42:02.462284 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:42:02.471884 [debug] [Thread-4 (]: SQL status: BEGIN in 0.015 seconds
[0m17:42:02.474349 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.476407 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m17:42:02.478526 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m17:42:02.480969 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.484621 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m17:42:02.509935 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.027 seconds
[0m17:42:02.510926 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.024 seconds
[0m17:42:02.517535 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.523747 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.525530 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m17:42:02.527635 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m17:42:02.530508 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.532315 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m17:42:02.538799 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.545357 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.547461 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m17:42:02.549635 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m17:42:02.552299 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m17:42:02.554054 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m17:42:02.557522 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m17:42:02.561004 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m17:42:02.563049 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.564954 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.566855 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m17:42:02.568632 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m17:42:02.575775 [debug] [Thread-4 (]: SQL status: COMMIT in 0.005 seconds
[0m17:42:02.581655 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m17:42:02.582505 [debug] [Thread-1 (]: SQL status: COMMIT in 0.011 seconds
[0m17:42:02.584367 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m17:42:02.591232 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m17:42:02.593129 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m17:42:02.595946 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m17:42:02.599742 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m17:42:02.604992 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.007 seconds
[0m17:42:02.608523 [debug] [Thread-4 (]: On model.idx_stock.technical_indicators_macd: Close
[0m17:42:02.609510 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m17:42:02.611863 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea440bd70>]}
[0m17:42:02.615842 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m17:42:02.618334 [info ] [Thread-4 (]: 8 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 959[0m in 0.23s]
[0m17:42:02.620845 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b283e09d-5463-4267-8b3d-91c88560ee10', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea440a1e0>]}
[0m17:42:02.622832 [debug] [Thread-4 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m17:42:02.625113 [info ] [Thread-1 (]: 9 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 0[0m in 0.24s]
[0m17:42:02.628907 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m17:42:02.632727 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:02.634306 [debug] [MainThread]: On master: BEGIN
[0m17:42:02.635743 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:42:02.647298 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m17:42:02.649319 [debug] [MainThread]: On master: COMMIT
[0m17:42:02.651066 [debug] [MainThread]: Using postgres connection "master"
[0m17:42:02.652693 [debug] [MainThread]: On master: COMMIT
[0m17:42:02.654629 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m17:42:02.656393 [debug] [MainThread]: On master: Close
[0m17:42:02.658385 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:42:02.660492 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m17:42:02.662339 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m17:42:02.664215 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m17:42:02.665876 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m17:42:02.667661 [info ] [MainThread]: 
[0m17:42:02.669430 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 1.52 seconds (1.52s).
[0m17:42:02.673908 [debug] [MainThread]: Command end result
[0m17:42:02.741817 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m17:42:02.751543 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m17:42:02.769907 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m17:42:02.771704 [info ] [MainThread]: 
[0m17:42:02.773515 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:42:02.775212 [info ] [MainThread]: 
[0m17:42:02.777071 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m17:42:02.779967 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.2112308, "process_in_blocks": "0", "process_kernel_time": 0.749987, "process_mem_max_rss": "122332", "process_out_blocks": "0", "process_user_time": 4.449247}
[0m17:42:02.782250 [debug] [MainThread]: Command `dbt run` succeeded at 17:42:02.782024 after 3.21 seconds
[0m17:42:02.784097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea788aab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea671fa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ea47564b0>]}
[0m17:42:02.785938 [debug] [MainThread]: Flushing usage events
[0m17:42:04.429611 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:42:12.091684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25cbf4a270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25ca924c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25ca927aa0>]}


============================== 17:42:12.100780 | e0ae45d1-1bab-445b-972f-76fdb0f20a93 ==============================
[0m17:42:12.100780 [info ] [MainThread]: Running with dbt=1.9.4
[0m17:42:12.102983 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:42:12.401627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e0ae45d1-1bab-445b-972f-76fdb0f20a93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25caef5670>]}
[0m17:42:12.492467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e0ae45d1-1bab-445b-972f-76fdb0f20a93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25ca389190>]}
[0m17:42:12.494517 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m17:42:12.650108 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m17:42:13.069187 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:42:13.071095 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:42:13.134855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e0ae45d1-1bab-445b-972f-76fdb0f20a93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25c99d8f50>]}
[0m17:42:13.280199 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m17:42:13.292850 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m17:42:13.350592 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e0ae45d1-1bab-445b-972f-76fdb0f20a93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25c8dea270>]}
[0m17:42:13.352788 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m17:42:13.355081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e0ae45d1-1bab-445b-972f-76fdb0f20a93', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25c99d85c0>]}
[0m17:42:13.359606 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m17:42:13.364696 [debug] [MainThread]: Command end result
[0m17:42:13.431009 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m17:42:13.438676 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m17:42:13.449478 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m17:42:13.452176 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.453464, "process_in_blocks": "0", "process_kernel_time": 0.341315, "process_mem_max_rss": "112412", "process_out_blocks": "0", "process_user_time": 3.442413}
[0m17:42:13.454135 [debug] [MainThread]: Command `dbt test` succeeded at 17:42:13.453931 after 1.46 seconds
[0m17:42:13.455713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25ca5c4680>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25cb09b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25ca62a0f0>]}
[0m17:42:13.457436 [debug] [MainThread]: Flushing usage events
[0m17:42:14.555644 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:44:25.237875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d173a7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d1525e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d173b4d0>]}


============================== 19:44:25.247760 | 29c92170-70ec-41bc-b7f2-78b79253fceb ==============================
[0m19:44:25.247760 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:44:25.249812 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m19:44:25.596870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d111b050>]}
[0m19:44:25.689056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d17b9fa0>]}
[0m19:44:25.691663 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:44:25.831368 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:44:26.460719 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m19:44:26.462938 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/news_sentiment_analysis.sql
[0m19:44:27.077929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cf730dd0>]}
[0m19:44:27.280559 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:44:27.301118 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:44:27.394304 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cefacbc0>]}
[0m19:44:27.396539 [info ] [MainThread]: Found 9 models, 3 sources, 434 macros
[0m19:44:27.398707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cf730b00>]}
[0m19:44:27.403584 [info ] [MainThread]: 
[0m19:44:27.406018 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:44:27.408639 [info ] [MainThread]: 
[0m19:44:27.410877 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:44:27.419844 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:44:27.421166 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:44:27.422651 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:44:27.502717 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:44:27.503498 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:44:27.504328 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:44:27.505985 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:44:27.508357 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:44:27.510378 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:44:27.512123 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:44:27.513940 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:44:27.515705 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:44:27.529177 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m19:44:27.532730 [debug] [ThreadPool]: On list_airflow: Close
[0m19:44:27.533529 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.018 seconds
[0m19:44:27.534317 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.020 seconds
[0m19:44:27.539474 [debug] [ThreadPool]: On list_airflow: Close
[0m19:44:27.543275 [debug] [ThreadPool]: On list_airflow: Close
[0m19:44:27.547049 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m19:44:27.547927 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m19:44:27.548788 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m19:44:27.550277 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m19:44:27.552344 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m19:44:27.554346 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m19:44:27.564212 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m19:44:27.568333 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m19:44:27.573783 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m19:44:27.575960 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m19:44:27.577841 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m19:44:27.579594 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m19:44:27.581384 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.583058 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.584888 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.596533 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m19:44:27.603937 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m19:44:27.605090 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m19:44:27.606567 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m19:44:27.608942 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m19:44:27.610714 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m19:44:27.612539 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m19:44:27.614338 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m19:44:27.615994 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m19:44:27.618708 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m19:44:27.620108 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m19:44:27.621526 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m19:44:27.624001 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m19:44:27.626810 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m19:44:27.629285 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m19:44:27.631126 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m19:44:27.632862 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m19:44:27.634426 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m19:44:27.636073 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m19:44:27.637951 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m19:44:27.639805 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m19:44:27.647152 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m19:44:27.648835 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m19:44:27.652281 [debug] [ThreadPool]: SQL status: COMMIT in 0.008 seconds
[0m19:44:27.653012 [debug] [ThreadPool]: SQL status: COMMIT in 0.010 seconds
[0m19:44:27.654574 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m19:44:27.656789 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m19:44:27.663140 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m19:44:27.664262 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m19:44:27.665332 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m19:44:27.675958 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:44:27.680119 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:44:27.684438 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:44:27.686426 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m19:44:27.688193 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m19:44:27.690290 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m19:44:27.692207 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.693797 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.695636 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:44:27.708115 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m19:44:27.710231 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:44:27.711754 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m19:44:27.713511 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m19:44:27.714821 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m19:44:27.716405 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:44:27.719746 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:44:27.722258 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m19:44:27.723472 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m19:44:27.725373 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m19:44:27.730875 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m19:44:27.731952 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m19:44:27.734984 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m19:44:27.737959 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m19:44:27.739343 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m19:44:27.742733 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m19:44:27.745477 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m19:44:27.748753 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m19:44:27.761083 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:27.763167 [debug] [MainThread]: On master: BEGIN
[0m19:44:27.765039 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:44:27.777153 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m19:44:27.779231 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:27.781521 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:44:27.787976 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m19:44:27.792024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d2189ee0>]}
[0m19:44:27.794216 [debug] [MainThread]: On master: ROLLBACK
[0m19:44:27.796416 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:27.798303 [debug] [MainThread]: On master: BEGIN
[0m19:44:27.800672 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m19:44:27.802716 [debug] [MainThread]: On master: COMMIT
[0m19:44:27.804905 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:27.807094 [debug] [MainThread]: On master: COMMIT
[0m19:44:27.809273 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:44:27.811328 [debug] [MainThread]: On master: Close
[0m19:44:27.819583 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m19:44:27.822060 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m19:44:27.824417 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m19:44:27.826610 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m19:44:27.841293 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m19:44:27.853286 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m19:44:27.918742 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m19:44:27.933453 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:44:27.935181 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m19:44:27.936922 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:44:27.949035 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m19:44:27.951514 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:44:27.953611 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM "airflow"."public"."daily_stock_summary"
  );
[0m19:44:27.958731 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m19:44:27.972528 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:44:27.975029 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m19:44:27.977763 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:44:28.005579 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m19:44:28.007673 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:44:28.009689 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m19:44:28.020288 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m19:44:28.032407 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m19:44:28.043000 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:44:28.045119 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m19:44:28.047599 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m19:44:28.053159 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m19:44:28.057590 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d32fad20>]}
[0m19:44:28.060145 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.23s]
[0m19:44:28.062632 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m19:44:28.066047 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m19:44:28.067340 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m19:44:28.069448 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m19:44:28.071996 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m19:44:28.074490 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m19:44:28.076900 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m19:44:28.079030 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m19:44:28.081113 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m19:44:28.087950 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m19:44:28.093663 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m19:44:28.106131 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m19:44:28.107656 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m19:44:28.184600 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m19:44:28.189887 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m19:44:28.202136 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:44:28.203581 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:44:28.205352 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m19:44:28.207745 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m19:44:28.209571 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m19:44:28.211581 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m19:44:28.225655 [debug] [Thread-4 (]: SQL status: BEGIN in 0.016 seconds
[0m19:44:28.229887 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:44:28.228068 [debug] [Thread-3 (]: SQL status: BEGIN in 0.016 seconds
[0m19:44:28.232306 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m19:44:28.234441 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:44:28.238102 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

-- Metrik saham harian dengan perhitungan tambahan
SELECT
    s.symbol,
    s.name,
    s.date,
    s.open_price,
    s.high,
    s.low,
    s.close,
    s.prev_close,
    s.change,
    s.volume,
    s.value,
    s.frequency,
    s.foreign_buy,
    s.foreign_sell,
    (s.foreign_buy - s.foreign_sell) as net_foreign_flow,
    CASE 
        WHEN s.prev_close > 0 THEN ROUND((s.close - s.prev_close) / s.prev_close * 100, 2)
        ELSE 0
    END as percent_change,
    s.volume * s.close as market_cap_daily,
    s.index_individual,
    s.weight_for_index
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
  );
  
[0m19:44:28.250278 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.014 seconds
[0m19:44:28.263466 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.023 seconds
[0m19:44:28.264566 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:44:28.271935 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:44:28.273706 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m19:44:28.276029 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m19:44:28.278485 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m19:44:28.280764 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m19:44:28.283564 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m19:44:28.287246 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m19:44:28.289458 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:44:28.291785 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:44:28.293641 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m19:44:28.295719 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m19:44:28.300348 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m19:44:28.301975 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m19:44:28.309051 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m19:44:28.314313 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m19:44:28.320844 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:44:28.323625 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:44:28.325931 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m19:44:28.328269 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m19:44:28.331138 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m19:44:28.333052 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:28.336263 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m19:44:28.341177 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m19:44:28.344256 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9d7560>]}
[0m19:44:28.346451 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9e7170>]}
[0m19:44:28.348622 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 959[0m in 0.27s]
[0m19:44:28.351762 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 959[0m in 0.27s]
[0m19:44:28.355077 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m19:44:28.357774 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m19:44:28.360687 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_performance_daily
[0m19:44:28.361695 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m19:44:28.362745 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m19:44:28.363743 [debug] [Thread-3 (]: Began running node model.idx_stock.technical_indicators_macd
[0m19:44:28.366175 [info ] [Thread-1 (]: 4 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m19:44:28.368873 [info ] [Thread-2 (]: 5 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m19:44:28.371438 [info ] [Thread-4 (]: 6 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m19:44:28.374160 [info ] [Thread-3 (]: 7 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m19:44:28.376261 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.stock_performance_daily)
[0m19:44:28.378471 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_monthly)
[0m19:44:28.380394 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_weekly)
[0m19:44:28.382552 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_macd)
[0m19:44:28.384516 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m19:44:28.386711 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m19:44:28.388522 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m19:44:28.390504 [debug] [Thread-3 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m19:44:28.397790 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m19:44:28.406261 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m19:44:28.413131 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m19:44:28.420489 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m19:44:28.430112 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m19:44:28.433049 [debug] [Thread-3 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m19:44:28.440122 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_performance_daily
[0m19:44:28.444201 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m19:44:28.445634 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m19:44:28.456201 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m19:44:28.462724 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m19:44:28.471739 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m19:44:28.480242 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:44:28.482543 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:44:28.484883 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m19:44:28.486689 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:44:28.488121 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:44:28.490364 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m19:44:28.492793 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:44:28.495386 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m19:44:28.503356 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m19:44:28.500051 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:44:28.497717 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m19:44:28.509173 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m19:44:28.518960 [debug] [Thread-4 (]: SQL status: BEGIN in 0.015 seconds
[0m19:44:28.524939 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:44:28.524039 [debug] [Thread-2 (]: SQL status: BEGIN in 0.031 seconds
[0m19:44:28.529446 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:44:28.522223 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m19:44:28.527225 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m19:44:28.533279 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m19:44:28.535192 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m19:44:28.543069 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:44:28.536750 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:44:28.545598 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- EMA 12 = [Close - EMA(previous day)] × (2 ÷ (12 + 1)) + EMA(previous day)
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS simple_ma_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS simple_ma_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (simple_ma_12 - simple_ma_26) AS macd_line,
        AVG(simple_ma_12 - simple_ma_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE simple_ma_12 IS NOT NULL AND simple_ma_26 IS NOT NULL
)

SELECT
    m.symbol,
    c.name,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
JOIN "airflow"."public_core"."dim_companies" c ON m.symbol = c.symbol
WHERE m.signal_line IS NOT NULL
  );
  
[0m19:44:28.549105 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m19:44:28.560083 [debug] [Thread-2 (]: SQL status: SELECT 959 in 0.020 seconds
[0m19:44:28.561671 [debug] [Thread-4 (]: SQL status: SELECT 959 in 0.023 seconds
[0m19:44:28.569013 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:44:28.577294 [debug] [Thread-1 (]: SQL status: SELECT 959 in 0.019 seconds
[0m19:44:28.578200 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:44:28.579066 [debug] [Thread-3 (]: SQL status: SELECT 959 in 0.027 seconds
[0m19:44:28.581147 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m19:44:28.587554 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:44:28.589221 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m19:44:28.595931 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:44:28.597967 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:44:28.599218 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m19:44:28.601326 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m19:44:28.602587 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m19:44:28.605995 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m19:44:28.608347 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:44:28.611038 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m19:44:28.613695 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m19:44:28.614895 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:44:28.618065 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m19:44:28.619761 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:44:28.623039 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m19:44:28.624771 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m19:44:28.626469 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:44:28.628358 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m19:44:28.630211 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:44:28.633096 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m19:44:28.634849 [debug] [Thread-2 (]: SQL status: COMMIT in 0.003 seconds
[0m19:44:28.636741 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m19:44:28.637681 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m19:44:28.644329 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m19:44:28.645365 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m19:44:28.651521 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m19:44:28.652586 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m19:44:28.654496 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:44:28.659818 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m19:44:28.662077 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:44:28.667296 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m19:44:28.669194 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m19:44:28.671298 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:44:28.673161 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m19:44:28.675491 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:44:28.677813 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:28.679060 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m19:44:28.681227 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:28.682878 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m19:44:28.686319 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m19:44:28.688619 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:28.691787 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m19:44:28.693998 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:28.695755 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9959d0>]}
[0m19:44:28.699062 [debug] [Thread-1 (]: On model.idx_stock.stock_performance_daily: Close
[0m19:44:28.701109 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c6572bd0>]}
[0m19:44:28.704325 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_macd: Close
[0m19:44:28.706615 [info ] [Thread-2 (]: 5 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 959[0m in 0.32s]
[0m19:44:28.709391 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c651c410>]}
[0m19:44:28.711399 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 959[0m in 0.32s]
[0m19:44:28.713810 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9608c0>]}
[0m19:44:28.715771 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m19:44:28.717949 [info ] [Thread-1 (]: 4 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 959[0m in 0.33s]
[0m19:44:28.719740 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m19:44:28.721987 [info ] [Thread-3 (]: 7 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 959[0m in 0.33s]
[0m19:44:28.723842 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m19:44:28.725869 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_performance_daily
[0m19:44:28.727773 [debug] [Thread-4 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m19:44:28.729764 [debug] [Thread-3 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m19:44:28.731888 [info ] [Thread-2 (]: 8 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m19:44:28.735145 [info ] [Thread-4 (]: 9 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m19:44:28.738233 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.technical_indicators_rsi)
[0m19:44:28.740105 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_weekly, now model.idx_stock.news_sentiment_analysis)
[0m19:44:28.742006 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m19:44:28.743654 [debug] [Thread-4 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m19:44:28.753277 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.765503 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m19:44:28.780586 [debug] [Thread-4 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m19:44:28.862002 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m19:44:28.867825 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m19:44:28.874143 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.884653 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:44:28.886728 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m19:44:28.888042 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.890186 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m19:44:28.892609 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m19:44:28.896442 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:44:28.905599 [debug] [Thread-4 (]: SQL status: BEGIN in 0.015 seconds
[0m19:44:28.908121 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:44:28.910799 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m19:44:28.918720 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH detik_sentiment AS (
    -- Ambil data sentimen dari detik_ticker_sentiment
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        prev_close,
        -- Hitung persentase perubahan harga
        CASE
            WHEN prev_close IS NOT NULL AND prev_close != 0 THEN 
                (close - prev_close) / prev_close * 100
            ELSE NULL
        END AS percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Indikator kekuatan sentimen relatif terhadap berita
    CASE
        WHEN d.news_count >= 5 AND d.positive_percentage > 70 THEN 'Very Strong Positive'
        WHEN d.news_count >= 5 AND d.positive_percentage < 30 THEN 'Very Strong Negative'
        WHEN d.news_count >= 3 AND d.positive_percentage > 60 THEN 'Strong Positive'
        WHEN d.news_count >= 3 AND d.positive_percentage < 40 THEN 'Strong Negative'
        WHEN d.news_count >= 2 AND d.positive_percentage > 50 THEN 'Slightly Positive'
        WHEN d.news_count >= 2 AND d.positive_percentage < 50 THEN 'Slightly Negative'
        ELSE 'Neutral/Insufficient Data'
    END AS sentiment_strength,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN detik_sentiment d 
    ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
    ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
    -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
    (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
    -- Exclude data yang tidak memiliki salah satu dari dua input utama
    AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
    -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
    COALESCE(s.date, d.date) DESC, 
    COALESCE(s.symbol, d.symbol)
  );
  
[0m19:44:28.922003 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.925781 [debug] [Thread-4 (]: Postgres adapter: Postgres error: relation "public.detik_ticker_sentiment" does not exist
LINE 41:     FROM public.detik_ticker_sentiment
                  ^

[0m19:44:28.927565 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    c.name,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
JOIN "airflow"."public_core"."dim_companies" c ON r.symbol = c.symbol
  );
  
[0m19:44:28.941913 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: ROLLBACK
[0m19:44:28.947071 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m19:44:28.961311 [debug] [Thread-4 (]: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public.detik_ticker_sentiment" does not exist
  LINE 41:     FROM public.detik_ticker_sentiment
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m19:44:28.963261 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9de540>]}
[0m19:44:28.964165 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.019 seconds
[0m19:44:28.965941 [error] [Thread-4 (]: 9 of 9 ERROR creating sql table model public_analytics.news_sentiment_analysis . [[31mERROR[0m in 0.22s]
[0m19:44:28.973198 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.975190 [debug] [Thread-4 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m19:44:28.977090 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m19:44:28.979151 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.news_sentiment_analysis' to be skipped because of status 'error'.  Reason: Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public.detik_ticker_sentiment" does not exist
  LINE 41:     FROM public.detik_ticker_sentiment
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql.
[0m19:44:28.981604 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:44:28.986253 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m19:44:28.988235 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:44:28.989940 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m19:44:28.996740 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m19:44:29.002065 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m19:44:29.004444 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:44:29.006343 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m19:44:29.008641 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m19:44:29.012484 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m19:44:29.014852 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '29c92170-70ec-41bc-b7f2-78b79253fceb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55cc9df9e0>]}
[0m19:44:29.017059 [info ] [Thread-2 (]: 8 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 0[0m in 0.28s]
[0m19:44:29.020091 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m19:44:29.024902 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:29.026893 [debug] [MainThread]: On master: BEGIN
[0m19:44:29.028723 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:44:29.040721 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m19:44:29.043057 [debug] [MainThread]: On master: COMMIT
[0m19:44:29.044818 [debug] [MainThread]: Using postgres connection "master"
[0m19:44:29.046562 [debug] [MainThread]: On master: COMMIT
[0m19:44:29.048662 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:44:29.050411 [debug] [MainThread]: On master: Close
[0m19:44:29.052573 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:44:29.054188 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_daily' was properly closed.
[0m19:44:29.056092 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m19:44:29.057818 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m19:44:29.059523 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m19:44:29.061316 [info ] [MainThread]: 
[0m19:44:29.063101 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 1.65 seconds (1.65s).
[0m19:44:29.067693 [debug] [MainThread]: Command end result
[0m19:44:29.144241 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:44:29.153663 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:44:29.172897 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m19:44:29.174868 [info ] [MainThread]: 
[0m19:44:29.176750 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:44:29.178651 [info ] [MainThread]: 
[0m19:44:29.180832 [error] [MainThread]:   Database Error in model news_sentiment_analysis (models/marts/analytics/news_sentiment_analysis.sql)
  relation "public.detik_ticker_sentiment" does not exist
  LINE 41:     FROM public.detik_ticker_sentiment
                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/news_sentiment_analysis.sql
[0m19:44:29.182776 [info ] [MainThread]: 
[0m19:44:29.184819 [info ] [MainThread]: Done. PASS=8 WARN=0 ERROR=1 SKIP=0 TOTAL=9
[0m19:44:29.188046 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.094066, "process_in_blocks": "0", "process_kernel_time": 0.708002, "process_mem_max_rss": "131348", "process_out_blocks": "2360", "process_user_time": 5.369017}
[0m19:44:29.190296 [debug] [MainThread]: Command `dbt run` failed at 19:44:29.190077 after 4.10 seconds
[0m19:44:29.192259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d1e1c8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d17bb3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55d1e1f0e0>]}
[0m19:44:29.194215 [debug] [MainThread]: Flushing usage events
[0m19:44:30.644202 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:17:41.709763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6183a79eb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6183a79190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6183a79610>]}


============================== 21:17:41.728711 | 609e35fb-c949-4244-859d-f4994cdae10e ==============================
[0m21:17:41.728711 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:17:41.731447 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m21:17:42.232193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6184fe48f0>]}
[0m21:17:42.354329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6184517e90>]}
[0m21:17:42.357416 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:17:42.526731 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:17:42.708246 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m21:17:42.710551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61838f0350>]}
[0m21:17:45.655499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6181bdaf90>]}
[0m21:17:45.940681 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:17:45.959150 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:17:46.062710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61807916d0>]}
[0m21:17:46.065008 [info ] [MainThread]: Found 9 models, 5 sources, 434 macros
[0m21:17:46.067093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6180747c20>]}
[0m21:17:46.072185 [info ] [MainThread]: 
[0m21:17:46.074609 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:17:46.076607 [info ] [MainThread]: 
[0m21:17:46.078886 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:17:46.090343 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:17:46.091870 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:17:46.165449 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:17:46.166255 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:17:46.168210 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:17:46.170065 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:17:46.171861 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:17:46.173762 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:17:46.186984 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.013 seconds
[0m21:17:46.187836 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.016 seconds
[0m21:17:46.191197 [debug] [ThreadPool]: On list_airflow: Close
[0m21:17:46.194619 [debug] [ThreadPool]: On list_airflow: Close
[0m21:17:46.198631 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_public_analytics)
[0m21:17:46.201252 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_public_analytics"
"
[0m21:17:46.211710 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m21:17:46.213560 [debug] [ThreadPool]: On create_airflow_public_public_analytics: BEGIN
[0m21:17:46.215214 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:17:46.227365 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m21:17:46.229593 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m21:17:46.231619 [debug] [ThreadPool]: On create_airflow_public_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "create_airflow_public_public_analytics"} */
create schema if not exists "public_public_analytics"
[0m21:17:46.235168 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m21:17:46.238395 [debug] [ThreadPool]: On create_airflow_public_public_analytics: COMMIT
[0m21:17:46.240545 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m21:17:46.242502 [debug] [ThreadPool]: On create_airflow_public_public_analytics: COMMIT
[0m21:17:46.246296 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m21:17:46.248432 [debug] [ThreadPool]: On create_airflow_public_public_analytics: Close
[0m21:17:46.253548 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_public_analytics, now list_airflow_public)
[0m21:17:46.254970 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_public_analytics)
[0m21:17:46.267008 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m21:17:46.271539 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_public_analytics"
[0m21:17:46.273958 [debug] [ThreadPool]: On list_airflow_public: BEGIN
[0m21:17:46.275794 [debug] [ThreadPool]: On list_airflow_public_public_analytics: BEGIN
[0m21:17:46.277844 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:17:46.279751 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:17:46.292773 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m21:17:46.295141 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m21:17:46.296276 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m21:17:46.298359 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_public_analytics"
[0m21:17:46.300580 [debug] [ThreadPool]: On list_airflow_public: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow_public"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m21:17:46.302586 [debug] [ThreadPool]: On list_airflow_public_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow_public_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_public_analytics'
  
[0m21:17:46.310679 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m21:17:46.311557 [debug] [ThreadPool]: SQL status: SELECT 46 in 0.007 seconds
[0m21:17:46.314650 [debug] [ThreadPool]: On list_airflow_public_public_analytics: ROLLBACK
[0m21:17:46.319934 [debug] [ThreadPool]: On list_airflow_public: ROLLBACK
[0m21:17:46.322421 [debug] [ThreadPool]: On list_airflow_public_public_analytics: Close
[0m21:17:46.324615 [debug] [ThreadPool]: On list_airflow_public: Close
[0m21:17:46.349198 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:46.351094 [debug] [MainThread]: On master: BEGIN
[0m21:17:46.352867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:17:46.365609 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m21:17:46.367727 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:46.369729 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:17:46.376585 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m21:17:46.380168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61840485f0>]}
[0m21:17:46.382267 [debug] [MainThread]: On master: ROLLBACK
[0m21:17:46.384423 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:46.386100 [debug] [MainThread]: On master: BEGIN
[0m21:17:46.389090 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:17:46.391385 [debug] [MainThread]: On master: COMMIT
[0m21:17:46.393166 [debug] [MainThread]: Using postgres connection "master"
[0m21:17:46.394853 [debug] [MainThread]: On master: COMMIT
[0m21:17:46.396881 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:17:46.398801 [debug] [MainThread]: On master: Close
[0m21:17:46.409871 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m21:17:46.412050 [info ] [Thread-1 (]: 1 of 9 START sql view model public.stg_daily_stock_summary ..................... [RUN]
[0m21:17:46.414150 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public, now model.idx_stock.stg_daily_stock_summary)
[0m21:17:46.415921 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m21:17:46.432742 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.445642 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m21:17:46.517341 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.533546 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.536134 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m21:17:46.538470 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:17:46.552209 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:17:46.554839 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.557332 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m21:17:46.565107 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m21:17:46.578329 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.580544 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m21:17:46.584216 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:46.615893 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:17:46.618454 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.621156 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:17:46.631346 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m21:17:46.644872 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public"."stg_daily_stock_summary__dbt_backup"
[0m21:17:46.656180 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:17:46.658574 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public"."stg_daily_stock_summary__dbt_backup" cascade
[0m21:17:46.661214 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m21:17:46.667017 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m21:17:46.672146 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6185692ba0>]}
[0m21:17:46.674775 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public.stg_daily_stock_summary ................ [[32mCREATE VIEW[0m in 0.26s]
[0m21:17:46.677407 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m21:17:46.680742 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m21:17:46.681797 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m21:17:46.682737 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m21:17:46.684005 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m21:17:46.685745 [info ] [Thread-3 (]: 2 of 9 START sql table model public_public_analytics.daily_stock_metrics ....... [RUN]
[0m21:17:46.688369 [info ] [Thread-4 (]: 3 of 9 START sql table model public.dim_companies .............................. [RUN]
[0m21:17:46.690802 [info ] [Thread-2 (]: 4 of 9 START sql table model public_public_analytics.technical_indicators_macd . [RUN]
[0m21:17:46.693310 [info ] [Thread-1 (]: 5 of 9 START sql table model public_public_analytics.technical_indicators_rsi .. [RUN]
[0m21:17:46.695707 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.idx_stock.daily_stock_metrics'
[0m21:17:46.698176 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m21:17:46.700516 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_public_analytics, now model.idx_stock.technical_indicators_macd)
[0m21:17:46.702871 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m21:17:46.704879 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m21:17:46.707141 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m21:17:46.709197 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m21:17:46.711423 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m21:17:46.718509 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m21:17:46.724788 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m21:17:46.731824 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m21:17:46.739174 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m21:17:46.749405 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m21:17:46.750942 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m21:17:46.758690 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m21:17:46.768943 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m21:17:46.807931 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m21:17:46.813782 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m21:17:46.820659 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m21:17:46.829598 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m21:17:46.840877 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:17:46.844633 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:17:46.848268 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m21:17:46.850519 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:46.852440 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:17:46.854721 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m21:17:46.857216 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m21:17:46.860148 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m21:17:46.862827 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m21:17:46.865448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:17:46.869142 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:17:46.871187 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:17:46.887714 [debug] [Thread-3 (]: SQL status: BEGIN in 0.030 seconds
[0m21:17:46.892932 [debug] [Thread-2 (]: SQL status: BEGIN in 0.022 seconds
[0m21:17:46.894482 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:17:46.896323 [debug] [Thread-1 (]: SQL status: BEGIN in 0.030 seconds
[0m21:17:46.898023 [debug] [Thread-4 (]: SQL status: BEGIN in 0.029 seconds
[0m21:17:46.900446 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:17:46.902747 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public"."stg_daily_stock_summary"
  );
  
[0m21:17:46.905555 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:17:46.908272 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:46.910621 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m21:17:46.914502 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m21:17:46.917535 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m21:17:51.366327 [debug] [Thread-4 (]: SQL status: SELECT 963 in 4.445 seconds
[0m21:17:51.397420 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:51.402538 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public"."dim_companies" rename to "dim_companies__dbt_backup"
[0m21:17:51.407072 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:51.416878 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:51.423019 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m21:17:51.427424 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:51.443777 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:17:51.447108 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:51.458895 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:17:51.499269 [debug] [Thread-4 (]: SQL status: COMMIT in 0.035 seconds
[0m21:17:51.512815 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public"."dim_companies__dbt_backup"
[0m21:17:51.527066 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:17:51.530353 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public"."dim_companies__dbt_backup" cascade
[0m21:17:51.548152 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.015 seconds
[0m21:17:51.555793 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m21:17:51.559772 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61804a8830>]}
[0m21:17:51.564669 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public.dim_companies ......................... [[32mSELECT 963[0m in 4.86s]
[0m21:17:51.577831 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m21:17:51.580834 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m21:17:51.583500 [info ] [Thread-4 (]: 6 of 9 START sql table model public_public_analytics.stock_performance_daily ... [RUN]
[0m21:17:51.587946 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m21:17:51.590572 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m21:17:51.604771 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m21:17:51.626102 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m21:17:51.640016 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m21:17:51.658321 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:17:51.661120 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m21:17:51.664106 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m21:17:51.689311 [debug] [Thread-4 (]: SQL status: BEGIN in 0.025 seconds
[0m21:17:51.692548 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:17:51.695646 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m21:17:51.897185 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.197 seconds
[0m21:17:51.934201 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:17:51.943695 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m21:17:51.955262 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:51.966449 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:17:51.973230 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:17:51.977155 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:17:51.994846 [debug] [Thread-4 (]: SQL status: COMMIT in 0.013 seconds
[0m21:17:52.016726 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_daily__dbt_backup"
[0m21:17:52.025990 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:17:52.030946 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m21:17:52.037852 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:17:52.045906 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m21:17:52.052840 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61804d65a0>]}
[0m21:17:52.057311 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_public_analytics.stock_performance_daily  [[32mSELECT 960[0m in 0.46s]
[0m21:17:52.065589 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m21:17:52.070950 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m21:17:52.074547 [info ] [Thread-4 (]: 7 of 9 START sql table model public_public_analytics.stock_performance_monthly . [RUN]
[0m21:17:52.079187 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m21:17:52.083692 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m21:17:52.098000 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m21:17:52.115631 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m21:17:52.137585 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m21:17:52.159214 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:17:52.161782 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m21:17:52.164147 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m21:17:52.186973 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m21:17:52.189937 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:17:52.192560 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m21:17:53.944416 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 7.031 seconds
[0m21:17:53.954564 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:17:53.956672 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m21:17:53.959404 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:17:53.963175 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:17:53.965060 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:17:53.967952 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:17:53.973664 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m21:17:53.979724 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_public_analytics"."daily_stock_metrics__dbt_backup"
[0m21:17:53.981942 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:17:53.984150 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m21:17:53.987477 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:17:53.992458 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m21:17:53.996813 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f618047fad0>]}
[0m21:17:54.008707 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_public_analytics.daily_stock_metrics .. [[32mSELECT 701021[0m in 7.30s]
[0m21:17:54.011604 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m21:17:54.013456 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m21:17:54.015797 [info ] [Thread-3 (]: 8 of 9 START sql table model public_public_analytics.stock_performance_weekly .. [RUN]
[0m21:17:54.020252 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m21:17:54.022871 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m21:17:54.030944 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m21:17:54.047629 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m21:17:54.061363 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m21:17:54.076518 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:17:54.079996 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m21:17:54.083211 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:17:54.103369 [debug] [Thread-3 (]: SQL status: BEGIN in 0.020 seconds
[0m21:17:54.107413 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:17:54.110723 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m21:17:59.069938 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 12.150 seconds
[0m21:17:59.079818 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:17:59.081921 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m21:17:59.084561 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:59.088186 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m21:17:59.090325 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:17:59.091974 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m21:17:59.102026 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m21:17:59.108488 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_public_analytics"."technical_indicators_macd__dbt_backup"
[0m21:17:59.110870 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:17:59.114315 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m21:17:59.117319 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:17:59.122684 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m21:17:59.125165 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6180479610>]}
[0m21:17:59.131604 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_public_analytics.technical_indicators_macd  [[32mSELECT 701021[0m in 12.42s]
[0m21:17:59.139736 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m21:17:59.142048 [debug] [Thread-2 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m21:17:59.144884 [info ] [Thread-2 (]: 9 of 9 START sql table model public_public_analytics.news_sentiment_analysis ... [RUN]
[0m21:17:59.147478 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.technical_indicators_macd, now model.idx_stock.news_sentiment_analysis)
[0m21:17:59.149400 [debug] [Thread-2 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m21:17:59.158276 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.171895 [debug] [Thread-2 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m21:17:59.184530 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.199174 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.201129 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m21:17:59.202938 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:17:59.219685 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m21:17:59.222181 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.224894 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m21:17:59.716954 [debug] [Thread-4 (]: SQL status: SELECT 960 in 7.522 seconds
[0m21:17:59.724788 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:17:59.726798 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m21:17:59.729487 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:17:59.734702 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:17:59.736625 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:17:59.738421 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:17:59.741926 [debug] [Thread-4 (]: SQL status: COMMIT in 0.002 seconds
[0m21:17:59.748353 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_monthly__dbt_backup"
[0m21:17:59.750491 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:17:59.752285 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m21:17:59.754391 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:17:59.757982 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m21:17:59.760065 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6180304260>]}
[0m21:17:59.769509 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_public_analytics.stock_performance_monthly  [[32mSELECT 960[0m in 7.68s]
[0m21:17:59.771639 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m21:17:59.853569 [debug] [Thread-2 (]: SQL status: SELECT 20138 in 0.625 seconds
[0m21:17:59.861495 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.863891 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m21:17:59.886322 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.020 seconds
[0m21:17:59.890594 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m21:17:59.892609 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.894337 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m21:17:59.905666 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m21:17:59.912909 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_backup"
[0m21:17:59.915805 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:17:59.917879 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m21:17:59.920334 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:17:59.924382 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m21:17:59.926834 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61805c7fb0>]}
[0m21:17:59.930215 [info ] [Thread-2 (]: 9 of 9 OK created sql table model public_public_analytics.news_sentiment_analysis  [[32mSELECT 20138[0m in 0.78s]
[0m21:17:59.933802 [debug] [Thread-2 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m21:18:01.282559 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 14.362 seconds
[0m21:18:01.289940 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:18:01.291883 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m21:18:01.295317 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:01.298906 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m21:18:01.300514 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:18:01.302110 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m21:18:01.309557 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:18:01.316079 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_backup"
[0m21:18:01.318624 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:18:01.320502 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m21:18:01.322902 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:18:01.326952 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m21:18:01.329568 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61804987a0>]}
[0m21:18:01.331957 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_public_analytics.technical_indicators_rsi  [[32mSELECT 700058[0m in 14.63s]
[0m21:18:01.334244 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m21:18:01.424788 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.311 seconds
[0m21:18:01.432082 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:18:01.434185 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m21:18:01.436721 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:18:01.440327 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:18:01.442289 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:18:01.444555 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:18:01.448981 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m21:18:01.454537 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_weekly__dbt_backup"
[0m21:18:01.456938 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:18:01.459022 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m21:18:01.461713 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:18:01.465683 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m21:18:01.467968 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '609e35fb-c949-4244-859d-f4994cdae10e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6180445eb0>]}
[0m21:18:01.470426 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_public_analytics.stock_performance_weekly  [[32mSELECT 960[0m in 7.45s]
[0m21:18:01.472916 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m21:18:01.477509 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.479839 [debug] [MainThread]: On master: BEGIN
[0m21:18:01.481679 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:18:01.493399 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m21:18:01.496103 [debug] [MainThread]: On master: COMMIT
[0m21:18:01.497957 [debug] [MainThread]: Using postgres connection "master"
[0m21:18:01.499839 [debug] [MainThread]: On master: COMMIT
[0m21:18:01.502246 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:18:01.504334 [debug] [MainThread]: On master: Close
[0m21:18:01.506549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:18:01.508421 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m21:18:01.510329 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m21:18:01.512439 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m21:18:01.514343 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m21:18:01.516411 [info ] [MainThread]: 
[0m21:18:01.518426 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 15.44 seconds (15.44s).
[0m21:18:01.523248 [debug] [MainThread]: Command end result
[0m21:18:01.602163 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:18:01.612402 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:18:01.632128 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:18:01.634025 [info ] [MainThread]: 
[0m21:18:01.636124 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:18:01.638031 [info ] [MainThread]: 
[0m21:18:01.640032 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m21:18:01.643324 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 20.081053, "process_in_blocks": "28688", "process_kernel_time": 0.854484, "process_mem_max_rss": "127304", "process_out_blocks": "2360", "process_user_time": 8.414155}
[0m21:18:01.645938 [debug] [MainThread]: Command `dbt run` succeeded at 21:18:01.645662 after 20.08 seconds
[0m21:18:01.648047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6183cefe90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61838f1340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f61838f2810>]}
[0m21:18:01.649978 [debug] [MainThread]: Flushing usage events
[0m21:18:03.262264 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:18:17.760472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c28430ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c2655dee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c267abf50>]}


============================== 21:18:17.771310 | 8d2b40de-3c2f-4270-ad20-c9f17e6e7083 ==============================
[0m21:18:17.771310 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:18:17.774321 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:18:18.133714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d2b40de-3c2f-4270-ad20-c9f17e6e7083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c262edfd0>]}
[0m21:18:18.243932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d2b40de-3c2f-4270-ad20-c9f17e6e7083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c26938920>]}
[0m21:18:18.246741 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:18:18.402328 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:18:18.872589 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:18:18.874291 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:18:18.941845 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d2b40de-3c2f-4270-ad20-c9f17e6e7083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c257d91c0>]}
[0m21:18:19.098954 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:18:19.112760 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:18:19.172299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d2b40de-3c2f-4270-ad20-c9f17e6e7083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c247dd700>]}
[0m21:18:19.174217 [info ] [MainThread]: Found 9 models, 5 sources, 434 macros
[0m21:18:19.176098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d2b40de-3c2f-4270-ad20-c9f17e6e7083', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c24bcbfe0>]}
[0m21:18:19.181239 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m21:18:19.185850 [debug] [MainThread]: Command end result
[0m21:18:19.254286 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:18:19.262633 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:18:19.275812 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:18:19.279076 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.6136012, "process_in_blocks": "1120", "process_kernel_time": 0.248881, "process_mem_max_rss": "112296", "process_out_blocks": "0", "process_user_time": 3.972151}
[0m21:18:19.281590 [debug] [MainThread]: Command `dbt test` succeeded at 21:18:19.281301 after 1.62 seconds
[0m21:18:19.283705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c2655dc70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c24b7ecc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c26f1fb00>]}
[0m21:18:19.285697 [debug] [MainThread]: Flushing usage events
[0m21:18:20.377023 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:10:06.340634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f044156e9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0440f5a300>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0441366cc0>]}


============================== 22:10:06.354352 | e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64 ==============================
[0m22:10:06.354352 [info ] [MainThread]: Running with dbt=1.9.4
[0m22:10:06.356902 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m22:10:07.031660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043fd21c10>]}
[0m22:10:07.210268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04422c9400>]}
[0m22:10:07.214742 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:10:07.482367 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m22:10:08.146509 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:10:08.148146 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:10:08.222830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04415497f0>]}
[0m22:10:08.489117 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:10:08.531334 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:10:08.703465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043f1cb200>]}
[0m22:10:08.706972 [info ] [MainThread]: Found 9 models, 5 sources, 434 macros
[0m22:10:08.710308 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043f1cfc80>]}
[0m22:10:08.718715 [info ] [MainThread]: 
[0m22:10:08.721428 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:10:08.724991 [info ] [MainThread]: 
[0m22:10:08.728452 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:10:08.749810 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:10:08.752378 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:10:08.916729 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:10:08.918272 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:10:08.920222 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:10:08.923054 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:10:08.926044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:08.928460 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:10:08.954989 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.029 seconds
[0m22:10:08.956419 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.028 seconds
[0m22:10:08.962421 [debug] [ThreadPool]: On list_airflow: Close
[0m22:10:08.968880 [debug] [ThreadPool]: On list_airflow: Close
[0m22:10:08.977489 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_public_analytics)
[0m22:10:08.980420 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_public_analytics"
"
[0m22:10:08.996328 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m22:10:08.998272 [debug] [ThreadPool]: On create_airflow_public_public_analytics: BEGIN
[0m22:10:09.000238 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:10:09.018545 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m22:10:09.024587 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m22:10:09.028888 [debug] [ThreadPool]: On create_airflow_public_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "create_airflow_public_public_analytics"} */
create schema if not exists "public_public_analytics"
[0m22:10:09.032863 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m22:10:09.037149 [debug] [ThreadPool]: On create_airflow_public_public_analytics: COMMIT
[0m22:10:09.039606 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_public_analytics"
[0m22:10:09.043351 [debug] [ThreadPool]: On create_airflow_public_public_analytics: COMMIT
[0m22:10:09.049815 [debug] [ThreadPool]: SQL status: COMMIT in 0.004 seconds
[0m22:10:09.051945 [debug] [ThreadPool]: On create_airflow_public_public_analytics: Close
[0m22:10:09.059438 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_public_analytics, now list_airflow_public_public_analytics)
[0m22:10:09.061279 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public)
[0m22:10:09.079241 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_public_analytics"
[0m22:10:09.085829 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m22:10:09.088086 [debug] [ThreadPool]: On list_airflow_public_public_analytics: BEGIN
[0m22:10:09.091814 [debug] [ThreadPool]: On list_airflow_public: BEGIN
[0m22:10:09.094544 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:10:09.096819 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:10:09.117132 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m22:10:09.119515 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m22:10:09.122108 [debug] [ThreadPool]: Using postgres connection "list_airflow_public"
[0m22:10:09.124516 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_public_analytics"
[0m22:10:09.127571 [debug] [ThreadPool]: On list_airflow_public: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow_public"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public'
  
[0m22:10:09.130386 [debug] [ThreadPool]: On list_airflow_public_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "list_airflow_public_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_public_analytics'
  
[0m22:10:09.140038 [debug] [ThreadPool]: SQL status: SELECT 46 in 0.007 seconds
[0m22:10:09.141632 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m22:10:09.149575 [debug] [ThreadPool]: On list_airflow_public: ROLLBACK
[0m22:10:09.154818 [debug] [ThreadPool]: On list_airflow_public_public_analytics: ROLLBACK
[0m22:10:09.157442 [debug] [ThreadPool]: On list_airflow_public: Close
[0m22:10:09.159923 [debug] [ThreadPool]: On list_airflow_public_public_analytics: Close
[0m22:10:09.208176 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:09.210830 [debug] [MainThread]: On master: BEGIN
[0m22:10:09.212999 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:10:09.229558 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m22:10:09.232438 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:09.234848 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:10:09.243804 [debug] [MainThread]: SQL status: SELECT 0 in 0.007 seconds
[0m22:10:09.248059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043fd82480>]}
[0m22:10:09.250337 [debug] [MainThread]: On master: ROLLBACK
[0m22:10:09.252842 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:09.254929 [debug] [MainThread]: On master: BEGIN
[0m22:10:09.258996 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:10:09.261853 [debug] [MainThread]: On master: COMMIT
[0m22:10:09.264441 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:09.266863 [debug] [MainThread]: On master: COMMIT
[0m22:10:09.269973 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:10:09.272632 [debug] [MainThread]: On master: Close
[0m22:10:09.295341 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m22:10:09.299475 [info ] [Thread-1 (]: 1 of 9 START sql view model public.stg_daily_stock_summary ..................... [RUN]
[0m22:10:09.302942 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m22:10:09.306274 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m22:10:09.333075 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.348480 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m22:10:09.481670 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.497436 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.500344 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m22:10:09.503162 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:10:09.522396 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m22:10:09.525573 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.528108 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m22:10:09.540629 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m22:10:09.556993 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.559508 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m22:10:09.562567 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:09.601205 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m22:10:09.603295 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.605671 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m22:10:09.613810 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m22:10:09.629517 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public"."stg_daily_stock_summary__dbt_backup"
[0m22:10:09.645783 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m22:10:09.647889 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public"."stg_daily_stock_summary__dbt_backup" cascade
[0m22:10:09.650266 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m22:10:09.656988 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m22:10:09.662480 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04413323f0>]}
[0m22:10:09.665382 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public.stg_daily_stock_summary ................ [[32mCREATE VIEW[0m in 0.36s]
[0m22:10:09.667901 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m22:10:09.671796 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m22:10:09.673162 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m22:10:09.674815 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m22:10:09.675994 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m22:10:09.677674 [info ] [Thread-3 (]: 2 of 9 START sql table model public_public_analytics.daily_stock_metrics ....... [RUN]
[0m22:10:09.680243 [info ] [Thread-4 (]: 3 of 9 START sql table model public.dim_companies .............................. [RUN]
[0m22:10:09.682317 [info ] [Thread-2 (]: 4 of 9 START sql table model public_public_analytics.technical_indicators_macd . [RUN]
[0m22:10:09.684603 [info ] [Thread-1 (]: 5 of 9 START sql table model public_public_analytics.technical_indicators_rsi .. [RUN]
[0m22:10:09.687207 [debug] [Thread-3 (]: Acquiring new postgres connection 'model.idx_stock.daily_stock_metrics'
[0m22:10:09.689697 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m22:10:09.692599 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public, now model.idx_stock.technical_indicators_macd)
[0m22:10:09.694891 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m22:10:09.696961 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m22:10:09.699057 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m22:10:09.701216 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m22:10:09.703216 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m22:10:09.714205 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m22:10:09.720911 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m22:10:09.730466 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m22:10:09.740062 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m22:10:09.751193 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m22:10:09.753228 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m22:10:09.754938 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m22:10:09.762851 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m22:10:09.865753 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m22:10:09.887053 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m22:10:09.891720 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m22:10:09.901134 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m22:10:09.913814 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:10:09.915362 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:09.917457 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:10:09.919134 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m22:10:09.922069 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:10:09.923975 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m22:10:09.928354 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m22:10:09.931092 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:10:09.933805 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m22:10:09.936410 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:10:09.938940 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:10:09.945304 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:10:09.965959 [debug] [Thread-1 (]: SQL status: BEGIN in 0.035 seconds
[0m22:10:09.970061 [debug] [Thread-4 (]: SQL status: BEGIN in 0.033 seconds
[0m22:10:09.972286 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:10:09.979667 [debug] [Thread-2 (]: SQL status: BEGIN in 0.034 seconds
[0m22:10:09.982906 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:09.985467 [debug] [Thread-3 (]: SQL status: BEGIN in 0.046 seconds
[0m22:10:09.989137 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m22:10:09.994377 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:10:09.997725 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m22:10:10.000428 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:10:10.005063 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m22:10:10.010325 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public"."stg_daily_stock_summary"
  );
  
[0m22:10:15.781079 [debug] [Thread-4 (]: SQL status: SELECT 963 in 5.772 seconds
[0m22:10:15.801051 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:15.803995 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public"."dim_companies" rename to "dim_companies__dbt_backup"
[0m22:10:15.807165 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:15.821605 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:15.824010 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m22:10:15.826705 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:15.839213 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m22:10:15.841210 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:15.844112 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m22:10:15.853931 [debug] [Thread-4 (]: SQL status: COMMIT in 0.007 seconds
[0m22:10:15.861502 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public"."dim_companies__dbt_backup"
[0m22:10:15.868666 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m22:10:15.870857 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public"."dim_companies__dbt_backup" cascade
[0m22:10:15.883050 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.010 seconds
[0m22:10:15.887740 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m22:10:15.889990 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043c71f6b0>]}
[0m22:10:15.892268 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public.dim_companies ......................... [[32mSELECT 963[0m in 6.20s]
[0m22:10:15.906202 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m22:10:15.908795 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m22:10:15.910813 [info ] [Thread-4 (]: 6 of 9 START sql table model public_public_analytics.stock_performance_daily ... [RUN]
[0m22:10:15.913395 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m22:10:15.915112 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m22:10:15.924807 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m22:10:15.937022 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m22:10:15.945061 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m22:10:15.958193 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:10:15.962046 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m22:10:15.964507 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:10:15.978683 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m22:10:15.980911 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:10:15.982942 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m22:10:16.151883 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.167 seconds
[0m22:10:16.160109 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:10:16.162135 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m22:10:16.164718 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:16.169578 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m22:10:16.171732 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:10:16.173458 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m22:10:16.193385 [debug] [Thread-4 (]: SQL status: COMMIT in 0.018 seconds
[0m22:10:16.199298 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_daily__dbt_backup"
[0m22:10:16.202756 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m22:10:16.205380 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m22:10:16.207584 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:16.211516 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m22:10:16.214065 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043d060500>]}
[0m22:10:16.216800 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_public_analytics.stock_performance_daily  [[32mSELECT 960[0m in 0.30s]
[0m22:10:16.220760 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m22:10:16.222887 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m22:10:16.225447 [info ] [Thread-4 (]: 7 of 9 START sql table model public_public_analytics.stock_performance_monthly . [RUN]
[0m22:10:16.228457 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m22:10:16.230264 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m22:10:16.239483 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m22:10:16.254375 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m22:10:16.265585 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m22:10:16.279183 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:10:16.281650 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m22:10:16.283390 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:10:16.297558 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m22:10:16.300103 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:10:16.303552 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m22:10:17.771539 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 7.757 seconds
[0m22:10:17.783284 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:10:17.786266 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m22:10:17.788957 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:17.792999 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m22:10:17.796358 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:10:17.798322 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m22:10:17.822837 [debug] [Thread-3 (]: SQL status: COMMIT in 0.022 seconds
[0m22:10:17.831127 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_public_analytics"."daily_stock_metrics__dbt_backup"
[0m22:10:17.834877 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m22:10:17.838192 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m22:10:17.840783 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:17.845867 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m22:10:17.848485 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043d0da690>]}
[0m22:10:17.852390 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_public_analytics.daily_stock_metrics .. [[32mSELECT 701021[0m in 8.16s]
[0m22:10:17.856247 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m22:10:17.858515 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m22:10:17.861443 [info ] [Thread-3 (]: 8 of 9 START sql table model public_public_analytics.stock_performance_weekly .. [RUN]
[0m22:10:17.864537 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m22:10:17.867374 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m22:10:17.880070 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m22:10:17.911806 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m22:10:17.927731 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m22:10:17.946000 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:10:17.948899 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m22:10:17.953734 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:10:17.976130 [debug] [Thread-3 (]: SQL status: BEGIN in 0.022 seconds
[0m22:10:17.978790 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:10:17.981303 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m22:10:21.937605 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 11.924 seconds
[0m22:10:21.945299 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:10:21.947727 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m22:10:21.950739 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:21.955027 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m22:10:21.956924 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:10:21.958670 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m22:10:21.966461 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m22:10:21.972926 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_public_analytics"."technical_indicators_macd__dbt_backup"
[0m22:10:21.975371 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m22:10:21.977413 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m22:10:21.979643 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:21.984302 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m22:10:21.986804 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043c730770>]}
[0m22:10:21.996672 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_public_analytics.technical_indicators_macd  [[32mSELECT 701021[0m in 12.29s]
[0m22:10:21.999845 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m22:10:22.002142 [debug] [Thread-2 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m22:10:22.004187 [info ] [Thread-2 (]: 9 of 9 START sql table model public_public_analytics.news_sentiment_analysis ... [RUN]
[0m22:10:22.006850 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.technical_indicators_macd, now model.idx_stock.news_sentiment_analysis)
[0m22:10:22.008710 [debug] [Thread-2 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m22:10:22.018135 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m22:10:22.031241 [debug] [Thread-2 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m22:10:22.044071 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m22:10:22.067757 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m22:10:22.070360 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m22:10:22.072740 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:10:22.090778 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m22:10:22.094346 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m22:10:22.098427 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m22:10:23.000738 [debug] [Thread-2 (]: SQL status: SELECT 20138 in 0.897 seconds
[0m22:10:23.010346 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m22:10:23.012550 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m22:10:23.016217 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:23.020909 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m22:10:23.023107 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m22:10:23.025073 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m22:10:23.037842 [debug] [Thread-2 (]: SQL status: COMMIT in 0.011 seconds
[0m22:10:23.043702 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_backup"
[0m22:10:23.047310 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m22:10:23.050243 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m22:10:23.053021 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:23.058043 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m22:10:23.061185 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043d1ace00>]}
[0m22:10:23.068054 [info ] [Thread-2 (]: 9 of 9 OK created sql table model public_public_analytics.news_sentiment_analysis  [[32mSELECT 20138[0m in 1.05s]
[0m22:10:23.072237 [debug] [Thread-2 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m22:10:23.317610 [debug] [Thread-4 (]: SQL status: SELECT 960 in 7.012 seconds
[0m22:10:23.325083 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:10:23.327210 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m22:10:23.330529 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:23.334939 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m22:10:23.337221 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:10:23.339166 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m22:10:23.347147 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m22:10:23.353147 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_monthly__dbt_backup"
[0m22:10:23.355825 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m22:10:23.357774 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m22:10:23.360335 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:23.365645 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m22:10:23.368610 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043c7961b0>]}
[0m22:10:23.371024 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_public_analytics.stock_performance_monthly  [[32mSELECT 960[0m in 7.14s]
[0m22:10:23.374459 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m22:10:24.766834 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 14.763 seconds
[0m22:10:24.774153 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:10:24.776118 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m22:10:24.778954 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:24.782608 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m22:10:24.784318 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:10:24.785956 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m22:10:24.793918 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m22:10:24.801675 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_backup"
[0m22:10:24.803995 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m22:10:24.805834 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m22:10:24.808103 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:24.812361 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m22:10:24.815022 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043c7c47a0>]}
[0m22:10:24.817392 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_public_analytics.technical_indicators_rsi  [[32mSELECT 700058[0m in 15.12s]
[0m22:10:24.819910 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m22:10:25.092795 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.109 seconds
[0m22:10:25.099459 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:10:25.101398 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m22:10:25.103915 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:10:25.106836 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m22:10:25.108868 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:10:25.110696 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m22:10:25.119677 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m22:10:25.124824 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_public_analytics"."stock_performance_weekly__dbt_backup"
[0m22:10:25.127000 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m22:10:25.129443 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "dev", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m22:10:25.131943 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m22:10:25.135411 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m22:10:25.137535 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e39f45d0-5b83-4eb6-8ac2-b3b0ee1a9f64', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043c757080>]}
[0m22:10:25.139921 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_public_analytics.stock_performance_weekly  [[32mSELECT 960[0m in 7.27s]
[0m22:10:25.142210 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m22:10:25.146946 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.148958 [debug] [MainThread]: On master: BEGIN
[0m22:10:25.150709 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:10:25.161957 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m22:10:25.164365 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.166278 [debug] [MainThread]: Using postgres connection "master"
[0m22:10:25.167893 [debug] [MainThread]: On master: COMMIT
[0m22:10:25.169977 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:10:25.171802 [debug] [MainThread]: On master: Close
[0m22:10:25.173896 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:10:25.175391 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m22:10:25.177233 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m22:10:25.179479 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m22:10:25.181419 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m22:10:25.183345 [info ] [MainThread]: 
[0m22:10:25.185347 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 16.46 seconds (16.46s).
[0m22:10:25.190274 [debug] [MainThread]: Command end result
[0m22:10:25.262200 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:10:25.271158 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:10:25.290632 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m22:10:25.292250 [info ] [MainThread]: 
[0m22:10:25.294772 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:10:25.296918 [info ] [MainThread]: 
[0m22:10:25.298901 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m22:10:25.301896 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 19.11621, "process_in_blocks": "0", "process_kernel_time": 0.709411, "process_mem_max_rss": "126484", "process_out_blocks": "2360", "process_user_time": 6.699995}
[0m22:10:25.304388 [debug] [MainThread]: Command `dbt run` succeeded at 22:10:25.304112 after 19.12 seconds
[0m22:10:25.306434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f043fd51310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f04408671a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0440867200>]}
[0m22:10:25.308273 [debug] [MainThread]: Flushing usage events
[0m22:10:26.927728 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:10:37.316772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea46dd700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea513df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea4b962a0>]}


============================== 22:10:37.332037 | ec4b8b1c-add1-4e64-b990-71baf83a1659 ==============================
[0m22:10:37.332037 [info ] [MainThread]: Running with dbt=1.9.4
[0m22:10:37.333904 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m22:10:37.646729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ec4b8b1c-add1-4e64-b990-71baf83a1659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea4fc0aa0>]}
[0m22:10:37.747109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ec4b8b1c-add1-4e64-b990-71baf83a1659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea46d7500>]}
[0m22:10:37.749442 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:10:37.911269 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m22:10:38.381358 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:10:38.383366 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:10:38.445662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ec4b8b1c-add1-4e64-b990-71baf83a1659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea449d0a0>]}
[0m22:10:38.599682 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:10:38.614638 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:10:38.687456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ec4b8b1c-add1-4e64-b990-71baf83a1659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea29e5520>]}
[0m22:10:38.689818 [info ] [MainThread]: Found 9 models, 5 sources, 434 macros
[0m22:10:38.692184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ec4b8b1c-add1-4e64-b990-71baf83a1659', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea39b3ce0>]}
[0m22:10:38.696489 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m22:10:38.701201 [debug] [MainThread]: Command end result
[0m22:10:38.771698 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:10:38.780755 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:10:38.792737 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m22:10:38.795435 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 1.5809855, "process_in_blocks": "0", "process_kernel_time": 0.382522, "process_mem_max_rss": "112064", "process_out_blocks": "0", "process_user_time": 4.469469}
[0m22:10:38.797635 [debug] [MainThread]: Command `dbt test` succeeded at 22:10:38.797415 after 1.58 seconds
[0m22:10:38.799752 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea5e5f740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea2db6f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea2db6fc0>]}
[0m22:10:38.801778 [debug] [MainThread]: Flushing usage events
[0m22:10:39.884314 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:33:14.555162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49526b8a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951f01f70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951f01b20>]}


============================== 23:33:14.566428 | 79e6bd4b-fb0d-4118-a3fc-cb8818158931 ==============================
[0m23:33:14.566428 [info ] [MainThread]: Running with dbt=1.9.4
[0m23:33:14.568974 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m23:33:14.586066 [error] [MainThread]: Encountered an error:
Runtime Error
  Could not find profile named 'idx_stock'
[0m23:33:14.594136 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.22315297, "process_in_blocks": "0", "process_kernel_time": 0.408059, "process_mem_max_rss": "100028", "process_out_blocks": "1056", "process_user_time": 2.945994}
[0m23:33:14.596629 [debug] [MainThread]: Command `dbt run` failed at 23:33:14.596376 after 0.23 seconds
[0m23:33:14.598689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951f01040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951dd6750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4951f6c4a0>]}
[0m23:33:14.600851 [debug] [MainThread]: Flushing usage events
[0m23:33:16.005069 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:35:07.504100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f429638ae40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42971e65a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f429638ba70>]}


============================== 23:35:07.517066 | 341a2d76-84a1-4eeb-bcf7-65e5992e1e54 ==============================
[0m23:35:07.517066 [info ] [MainThread]: Running with dbt=1.9.4
[0m23:35:07.519247 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:35:07.984751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4296248500>]}
[0m23:35:08.092408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4296026780>]}
[0m23:35:08.095049 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:35:08.256557 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m23:35:08.487146 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m23:35:08.489353 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m23:35:08.491443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4295cb3950>]}
[0m23:35:11.514491 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4295d4e390>]}
[0m23:35:11.751383 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:35:11.764840 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:35:11.807202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f429351cc20>]}
[0m23:35:11.809008 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m23:35:11.810826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '341a2d76-84a1-4eeb-bcf7-65e5992e1e54', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42957b5d00>]}
[0m23:35:11.815667 [info ] [MainThread]: 
[0m23:35:11.817426 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m23:35:11.819033 [info ] [MainThread]: 
[0m23:35:11.821112 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:35:11.831176 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:35:11.832799 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:35:11.834013 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:35:11.910435 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:35:11.911252 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:35:11.912038 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:35:11.913662 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.915367 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.917148 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.918758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:11.920146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:11.921745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:35:11.924291 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m23:35:11.925728 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m23:35:11.927745 [debug] [ThreadPool]: Postgres adapter: Got a retryable error when attempting to open a postgres connection.
1 attempts remaining. Retrying in 0 seconds.
Error:
connection to server at "localhost" (::1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?

[0m23:35:11.929710 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.931529 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.933154 [debug] [ThreadPool]: Postgres adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:35:11.934381 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.936018 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.937698 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.939318 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m23:35:11.940921 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m23:35:11.942677 [debug] [ThreadPool]: Postgres adapter: Error running SQL: macro list_schemas
[0m23:35:11.944156 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.945612 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.947447 [debug] [ThreadPool]: Postgres adapter: Rolling back transaction.
[0m23:35:11.949115 [debug] [ThreadPool]: On list_airflow: No close available on handle
[0m23:35:11.950696 [debug] [ThreadPool]: On list_airflow: No close available on handle
[0m23:35:11.952300 [debug] [ThreadPool]: On list_airflow: No close available on handle
[0m23:35:11.956606 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:35:11.957942 [debug] [MainThread]: Connection 'list_airflow' was properly closed.
[0m23:35:11.959138 [debug] [MainThread]: Connection 'list_airflow' was properly closed.
[0m23:35:11.960381 [debug] [MainThread]: Connection 'list_airflow' was properly closed.
[0m23:35:11.961927 [info ] [MainThread]: 
[0m23:35:11.963827 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m23:35:11.965942 [error] [MainThread]: Encountered an error:
Database Error
  connection to server at "localhost" (::1), port 5432 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
  	Is the server running on that host and accepting TCP/IP connections?
  
[0m23:35:11.968755 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.609791, "process_in_blocks": "0", "process_kernel_time": 0.560796, "process_mem_max_rss": "122196", "process_out_blocks": "0", "process_user_time": 7.670901}
[0m23:35:11.970796 [debug] [MainThread]: Command `dbt run` failed at 23:35:11.970568 after 4.61 seconds
[0m23:35:11.972473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4295c74ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f42939afef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4296248500>]}
[0m23:35:11.974094 [debug] [MainThread]: Flushing usage events
[0m23:35:13.186707 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:36:40.743185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524a224a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52481f3890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52481f0d10>]}


============================== 23:36:40.752149 | b6ec71c0-47d8-4110-9947-3d483629dd65 ==============================
[0m23:36:40.752149 [info ] [MainThread]: Running with dbt=1.9.4
[0m23:36:40.754039 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:36:41.058317 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5247c38c80>]}
[0m23:36:41.153236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524829a3c0>]}
[0m23:36:41.155556 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:36:41.285037 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m23:36:41.487840 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m23:36:41.489855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5246d9f7a0>]}
[0m23:36:43.930847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5245d03320>]}
[0m23:36:44.131502 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:36:44.148096 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:36:44.186329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52465c4080>]}
[0m23:36:44.188395 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m23:36:44.190485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524b749d60>]}
[0m23:36:44.194972 [info ] [MainThread]: 
[0m23:36:44.196764 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m23:36:44.198538 [info ] [MainThread]: 
[0m23:36:44.200495 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:36:44.209181 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:36:44.211488 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:36:44.212732 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:36:44.274055 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:36:44.275203 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:36:44.276026 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:36:44.277620 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:36:44.283305 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:36:44.284975 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:36:44.286645 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:36:44.288722 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:36:44.291224 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:36:44.303430 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m23:36:44.306749 [debug] [ThreadPool]: On list_airflow: Close
[0m23:36:44.308327 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.019 seconds
[0m23:36:44.309052 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.018 seconds
[0m23:36:44.313776 [debug] [ThreadPool]: On list_airflow: Close
[0m23:36:44.316749 [debug] [ThreadPool]: On list_airflow: Close
[0m23:36:44.321221 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m23:36:44.322518 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m23:36:44.323828 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m23:36:44.326051 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m23:36:44.328306 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m23:36:44.330415 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m23:36:44.339529 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m23:36:44.344270 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m23:36:44.348627 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m23:36:44.350553 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m23:36:44.352403 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m23:36:44.354131 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m23:36:44.356072 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.358312 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.360010 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.370818 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m23:36:44.372801 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m23:36:44.374701 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m23:36:44.376368 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m23:36:44.377770 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m23:36:44.379659 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m23:36:44.381335 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m23:36:44.384214 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m23:36:44.385044 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m23:36:44.386347 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m23:36:44.388851 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m23:36:44.390999 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m23:36:44.393373 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m23:36:44.394884 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m23:36:44.396589 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m23:36:44.398960 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m23:36:44.400617 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m23:36:44.402212 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m23:36:44.403977 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m23:36:44.405721 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m23:36:44.409665 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m23:36:44.410696 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m23:36:44.413800 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m23:36:44.414550 [debug] [ThreadPool]: SQL status: COMMIT in 0.003 seconds
[0m23:36:44.415298 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m23:36:44.417443 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m23:36:44.419148 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m23:36:44.425554 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_analytics)
[0m23:36:44.426662 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_core)
[0m23:36:44.427897 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m23:36:44.450156 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:36:44.455411 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:36:44.462461 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:36:44.464702 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m23:36:44.466609 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m23:36:44.468887 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m23:36:44.470830 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.473170 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.475612 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:36:44.493246 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m23:36:44.496791 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:36:44.498758 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m23:36:44.500212 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m23:36:44.501263 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m23:36:44.503480 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:36:44.505299 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:36:44.508819 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m23:36:44.511032 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m23:36:44.512685 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m23:36:44.518304 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m23:36:44.519700 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m23:36:44.520536 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m23:36:44.522423 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m23:36:44.525993 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m23:36:44.529258 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m23:36:44.532496 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m23:36:44.534038 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m23:36:44.547745 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:44.549394 [debug] [MainThread]: On master: BEGIN
[0m23:36:44.551445 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:36:44.564228 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m23:36:44.566500 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:44.568714 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:36:44.576601 [debug] [MainThread]: SQL status: SELECT 0 in 0.006 seconds
[0m23:36:44.580226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5246545d30>]}
[0m23:36:44.581977 [debug] [MainThread]: On master: ROLLBACK
[0m23:36:44.583646 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:44.585195 [debug] [MainThread]: On master: BEGIN
[0m23:36:44.587618 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:36:44.591056 [debug] [MainThread]: On master: COMMIT
[0m23:36:44.592994 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:44.594824 [debug] [MainThread]: On master: COMMIT
[0m23:36:44.596894 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:36:44.598726 [debug] [MainThread]: On master: Close
[0m23:36:44.609013 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m23:36:44.610912 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m23:36:44.612723 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m23:36:44.614264 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m23:36:44.629965 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.640342 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m23:36:44.717748 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.730262 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.731932 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m23:36:44.733665 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:36:44.745829 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m23:36:44.748247 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.750498 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m23:36:44.757933 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m23:36:44.770691 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.773011 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m23:36:44.776327 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:44.805990 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m23:36:44.808889 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.810995 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m23:36:44.819167 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m23:36:44.831700 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m23:36:44.842243 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m23:36:44.844465 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m23:36:44.847144 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m23:36:44.852377 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m23:36:44.857050 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5249e44b60>]}
[0m23:36:44.859790 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.24s]
[0m23:36:44.862192 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m23:36:44.865446 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m23:36:44.866378 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m23:36:44.867286 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m23:36:44.868193 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m23:36:44.869735 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m23:36:44.872194 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m23:36:44.875078 [info ] [Thread-2 (]: 4 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m23:36:44.877788 [info ] [Thread-1 (]: 5 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m23:36:44.880024 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m23:36:44.882244 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m23:36:44.883852 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.technical_indicators_macd)
[0m23:36:44.885780 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m23:36:44.887556 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m23:36:44.889753 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m23:36:44.891779 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m23:36:44.893739 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m23:36:44.899824 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m23:36:44.908028 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m23:36:44.914197 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m23:36:44.921094 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m23:36:44.932132 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m23:36:44.933805 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m23:36:44.935049 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m23:36:44.947652 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m23:36:44.993038 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m23:36:45.006755 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m23:36:45.004389 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m23:36:45.013501 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m23:36:45.024948 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m23:36:45.026390 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m23:36:45.028717 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m23:36:45.030245 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m23:36:45.031635 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m23:36:45.033667 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m23:36:45.036100 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m23:36:45.038445 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:36:45.041104 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m23:36:45.043188 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:36:45.045398 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:36:45.049046 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:36:45.058002 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m23:36:45.061590 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m23:36:45.063169 [debug] [Thread-3 (]: SQL status: BEGIN in 0.020 seconds
[0m23:36:45.065199 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m23:36:45.067714 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m23:36:45.069173 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m23:36:45.071473 [debug] [Thread-2 (]: SQL status: BEGIN in 0.022 seconds
[0m23:36:45.074897 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m23:36:45.077573 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m23:36:45.080091 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m23:36:45.085661 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m23:36:45.082215 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m23:36:49.619786 [debug] [Thread-4 (]: SQL status: SELECT 963 in 4.531 seconds
[0m23:36:49.635464 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m23:36:49.638228 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m23:36:49.641000 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:49.644639 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m23:36:49.646386 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m23:36:49.648099 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m23:36:49.661058 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m23:36:49.670066 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m23:36:49.676764 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m23:36:49.678667 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m23:36:49.680761 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:49.684510 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m23:36:49.687202 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5244697890>]}
[0m23:36:49.689530 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 4.80s]
[0m23:36:49.692331 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m23:36:49.694385 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m23:36:49.696247 [info ] [Thread-4 (]: 6 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m23:36:49.698819 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m23:36:49.700559 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m23:36:49.712030 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m23:36:49.726231 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m23:36:49.733998 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m23:36:49.746619 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m23:36:49.749558 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m23:36:49.752403 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:36:49.786304 [debug] [Thread-4 (]: SQL status: BEGIN in 0.034 seconds
[0m23:36:49.790402 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m23:36:49.792648 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m23:36:49.988758 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.194 seconds
[0m23:36:49.998681 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m23:36:50.000895 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m23:36:50.003876 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:50.007646 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m23:36:50.009467 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m23:36:50.011316 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m23:36:50.018287 [debug] [Thread-4 (]: SQL status: COMMIT in 0.005 seconds
[0m23:36:50.027208 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m23:36:50.030306 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m23:36:50.032923 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m23:36:50.036560 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m23:36:50.041077 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m23:36:50.043134 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52447dfad0>]}
[0m23:36:50.046217 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.34s]
[0m23:36:50.048963 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m23:36:50.050830 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m23:36:50.053382 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m23:36:50.055620 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m23:36:50.057499 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m23:36:50.065283 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m23:36:50.078945 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m23:36:50.090252 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m23:36:50.105203 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m23:36:50.107468 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m23:36:50.109388 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:36:50.126691 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m23:36:50.128859 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m23:36:50.130853 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m23:36:50.972911 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 5.888 seconds
[0m23:36:50.982742 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m23:36:50.985937 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m23:36:50.989670 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:50.996205 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m23:36:50.998498 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m23:36:51.002517 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m23:36:51.011326 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m23:36:51.020115 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m23:36:51.023597 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m23:36:51.026335 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m23:36:51.033161 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:51.039709 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m23:36:51.043592 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5245d033b0>]}
[0m23:36:51.058192 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701021[0m in 6.16s]
[0m23:36:51.062818 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m23:36:51.064967 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m23:36:51.067495 [info ] [Thread-3 (]: 8 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m23:36:51.071417 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m23:36:51.074277 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m23:36:51.083853 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m23:36:51.100612 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m23:36:51.110389 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m23:36:51.124869 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m23:36:51.127450 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m23:36:51.130038 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:36:51.144504 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m23:36:51.147086 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m23:36:51.149464 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m23:36:56.678927 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 11.591 seconds
[0m23:36:56.687315 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m23:36:56.698945 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m23:36:56.702026 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:56.707854 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m23:36:56.709837 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m23:36:56.711556 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m23:36:56.721993 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m23:36:56.731484 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m23:36:56.734130 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m23:36:56.751517 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m23:36:56.766218 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:56.770150 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m23:36:56.772202 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52446adf10>]}
[0m23:36:56.774538 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701021[0m in 11.89s]
[0m23:36:56.778383 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m23:36:56.782140 [debug] [Thread-2 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m23:36:56.784828 [info ] [Thread-2 (]: 9 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m23:36:56.787685 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.technical_indicators_macd, now model.idx_stock.news_sentiment_analysis)
[0m23:36:56.793340 [debug] [Thread-2 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m23:36:56.806057 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m23:36:56.820022 [debug] [Thread-2 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m23:36:56.827394 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m23:36:56.850629 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m23:36:56.853411 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m23:36:56.855426 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:36:56.878411 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m23:36:56.881624 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m23:36:56.884834 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m23:36:57.138714 [debug] [Thread-4 (]: SQL status: SELECT 960 in 7.006 seconds
[0m23:36:57.146551 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m23:36:57.151016 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m23:36:57.154555 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:57.158081 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m23:36:57.159741 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m23:36:57.161279 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m23:36:57.169486 [debug] [Thread-4 (]: SQL status: COMMIT in 0.007 seconds
[0m23:36:57.176168 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m23:36:57.178427 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m23:36:57.180630 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m23:36:57.183228 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:57.187205 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m23:36:57.189344 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524466c200>]}
[0m23:36:57.198714 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 7.13s]
[0m23:36:57.201053 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m23:36:57.484061 [debug] [Thread-2 (]: SQL status: SELECT 20138 in 0.596 seconds
[0m23:36:57.494293 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m23:36:57.497138 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m23:36:57.500218 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:57.505974 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m23:36:57.539641 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m23:36:57.541805 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m23:36:57.548113 [debug] [Thread-2 (]: SQL status: COMMIT in 0.004 seconds
[0m23:36:57.553957 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m23:36:57.555935 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m23:36:57.557950 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m23:36:57.559962 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:57.564183 [debug] [Thread-2 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m23:36:57.566706 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524466d820>]}
[0m23:36:57.568938 [info ] [Thread-2 (]: 9 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 20138[0m in 0.78s]
[0m23:36:57.571895 [debug] [Thread-2 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m23:36:58.840286 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.688 seconds
[0m23:36:58.847845 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m23:36:58.850074 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m23:36:58.852530 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:58.856212 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m23:36:58.858199 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m23:36:58.860080 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m23:36:58.866062 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m23:36:58.871923 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m23:36:58.874486 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m23:36:58.876658 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m23:36:58.879410 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m23:36:58.883582 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m23:36:58.886111 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524454bf50>]}
[0m23:36:58.888936 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 7.81s]
[0m23:36:58.891877 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m23:36:58.990794 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 13.917 seconds
[0m23:36:58.998083 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m23:36:59.000283 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m23:36:59.002895 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:36:59.006514 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m23:36:59.008709 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m23:36:59.010812 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m23:36:59.018039 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m23:36:59.023429 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m23:36:59.025752 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m23:36:59.027641 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m23:36:59.030569 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m23:36:59.034267 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m23:36:59.036468 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b6ec71c0-47d8-4110-9947-3d483629dd65', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5246d03cb0>]}
[0m23:36:59.038814 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 700058[0m in 14.15s]
[0m23:36:59.041190 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m23:36:59.045861 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.047977 [debug] [MainThread]: On master: BEGIN
[0m23:36:59.049794 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:36:59.060950 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m23:36:59.063570 [debug] [MainThread]: On master: COMMIT
[0m23:36:59.065356 [debug] [MainThread]: Using postgres connection "master"
[0m23:36:59.067093 [debug] [MainThread]: On master: COMMIT
[0m23:36:59.069092 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:36:59.070838 [debug] [MainThread]: On master: Close
[0m23:36:59.072677 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:36:59.074440 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m23:36:59.076149 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m23:36:59.078107 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m23:36:59.082809 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m23:36:59.085071 [info ] [MainThread]: 
[0m23:36:59.087035 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 14.88 seconds (14.88s).
[0m23:36:59.091512 [debug] [MainThread]: Command end result
[0m23:36:59.169441 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:36:59.180272 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:36:59.199384 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m23:36:59.201158 [info ] [MainThread]: 
[0m23:36:59.203193 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:36:59.205522 [info ] [MainThread]: 
[0m23:36:59.207416 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m23:36:59.210203 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.570522, "process_in_blocks": "0", "process_kernel_time": 0.361378, "process_mem_max_rss": "128156", "process_out_blocks": "0", "process_user_time": 6.846119}
[0m23:36:59.212921 [debug] [MainThread]: Command `dbt run` succeeded at 23:36:59.212659 after 18.57 seconds
[0m23:36:59.214924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5247e6b4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f52446f83b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f524891fa70>]}
[0m23:36:59.216701 [debug] [MainThread]: Flushing usage events
[0m23:37:00.672245 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:37:09.434106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90046e8590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f900311cb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9001b49790>]}


============================== 23:37:09.443815 | 38fa4ba7-fc8f-4457-a43f-5cb48e32efa8 ==============================
[0m23:37:09.443815 [info ] [MainThread]: Running with dbt=1.9.4
[0m23:37:09.445910 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m23:37:09.760434 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9000bc4c20>]}
[0m23:37:09.859741 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f900216e3f0>]}
[0m23:37:09.862271 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:37:10.012031 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m23:37:10.777363 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:37:10.780939 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:37:10.913492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f900150fe30>]}
[0m23:37:11.125227 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:37:11.147598 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:37:11.213530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ffed00da0>]}
[0m23:37:11.216076 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m23:37:11.219055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90001cca70>]}
[0m23:37:11.224114 [info ] [MainThread]: 
[0m23:37:11.226240 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m23:37:11.228080 [info ] [MainThread]: 
[0m23:37:11.230393 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:37:11.241258 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m23:37:11.242602 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m23:37:11.243922 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m23:37:11.317183 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:37:11.318644 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:37:11.319460 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:37:11.321088 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m23:37:11.322938 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m23:37:11.324515 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m23:37:11.326223 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:11.327723 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:11.329285 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:11.345114 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m23:37:11.346375 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m23:37:11.348447 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m23:37:11.349440 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:37:11.351381 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:37:11.353765 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:37:11.355720 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m23:37:11.357666 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m23:37:11.359570 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m23:37:11.365777 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m23:37:11.366942 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m23:37:11.368157 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m23:37:11.371422 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m23:37:11.374552 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m23:37:11.377705 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m23:37:11.379941 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m23:37:11.381675 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m23:37:11.383455 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m23:37:11.399607 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.401812 [debug] [MainThread]: On master: BEGIN
[0m23:37:11.403867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:37:11.414743 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m23:37:11.417359 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.420292 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:37:11.436774 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m23:37:11.440359 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '38fa4ba7-fc8f-4457-a43f-5cb48e32efa8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9001791760>]}
[0m23:37:11.442403 [debug] [MainThread]: On master: ROLLBACK
[0m23:37:11.444533 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.446383 [debug] [MainThread]: On master: BEGIN
[0m23:37:11.448742 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:37:11.451835 [debug] [MainThread]: On master: COMMIT
[0m23:37:11.453852 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.455586 [debug] [MainThread]: On master: COMMIT
[0m23:37:11.457489 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:37:11.459205 [debug] [MainThread]: On master: Close
[0m23:37:11.468829 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m23:37:11.469730 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m23:37:11.471470 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m23:37:11.473610 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m23:37:11.475693 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m23:37:11.477709 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m23:37:11.479470 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m23:37:11.481316 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m23:37:11.523598 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m23:37:11.519964 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m23:37:11.533416 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m23:37:11.541948 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m23:37:11.570073 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m23:37:11.569298 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m23:37:11.579095 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m23:37:11.581085 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m23:37:11.582254 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m23:37:11.583974 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:37:11.586921 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m23:37:11.590487 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:37:11.598994 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m23:37:11.601648 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m23:37:11.604076 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m23:37:11.606053 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m23:37:11.608192 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m23:37:11.611438 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m23:37:11.612375 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m23:37:11.620300 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.006 seconds
[0m23:37:11.622727 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m23:37:11.626330 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m23:37:11.628595 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m23:37:11.630453 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m23:37:11.632551 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.15s]
[0m23:37:11.635178 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m23:37:11.638077 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m23:37:11.640377 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m23:37:11.645261 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.647090 [debug] [MainThread]: On master: BEGIN
[0m23:37:11.648876 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:37:11.660119 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m23:37:11.662643 [debug] [MainThread]: On master: COMMIT
[0m23:37:11.672464 [debug] [MainThread]: Using postgres connection "master"
[0m23:37:11.674429 [debug] [MainThread]: On master: COMMIT
[0m23:37:11.676793 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m23:37:11.678642 [debug] [MainThread]: On master: Close
[0m23:37:11.680988 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:37:11.683002 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m23:37:11.685914 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m23:37:11.688350 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m23:37:11.690527 [info ] [MainThread]: 
[0m23:37:11.692699 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m23:37:11.696104 [debug] [MainThread]: Command end result
[0m23:37:11.804212 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:37:11.811778 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:37:11.863309 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m23:37:11.865706 [info ] [MainThread]: 
[0m23:37:11.870237 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:37:11.872857 [info ] [MainThread]: 
[0m23:37:11.875144 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m23:37:11.878405 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.5437975, "process_in_blocks": "0", "process_kernel_time": 0.408112, "process_mem_max_rss": "121808", "process_out_blocks": "0", "process_user_time": 4.568867}
[0m23:37:11.881111 [debug] [MainThread]: Command `dbt test` succeeded at 23:37:11.880590 after 2.55 seconds
[0m23:37:11.883415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ffcc9cce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8ffcc9c9e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9001768260>]}
[0m23:37:11.885634 [debug] [MainThread]: Flushing usage events
[0m23:37:13.075290 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:47:23.892488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5389260c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5389b8f380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5389263620>]}


============================== 00:47:23.903543 | f288b79d-9c16-44c4-aae2-4689b76cdf2c ==============================
[0m00:47:23.903543 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:47:23.905973 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:47:24.326916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538898dbb0>]}
[0m00:47:24.644707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53886f1790>]}
[0m00:47:24.647654 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:47:24.887154 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:47:25.749262 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:47:25.751066 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:47:25.870350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53891a7350>]}
[0m00:47:26.109855 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:47:26.125784 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:47:26.223360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5386f21520>]}
[0m00:47:26.225714 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m00:47:26.227662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53889a0bc0>]}
[0m00:47:26.232918 [info ] [MainThread]: 
[0m00:47:26.234946 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:47:26.236865 [info ] [MainThread]: 
[0m00:47:26.239632 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:47:26.249507 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:47:26.250912 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:47:26.252203 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:47:26.338666 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:47:26.339915 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:47:26.340865 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:47:26.342437 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:47:26.344599 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:47:26.346359 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:47:26.348242 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:26.350056 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:26.351746 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:47:26.369546 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.021 seconds
[0m00:47:26.371502 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.021 seconds
[0m00:47:26.374652 [debug] [ThreadPool]: On list_airflow: Close
[0m00:47:26.376094 [debug] [ThreadPool]: SQL status: SELECT 11 in 0.024 seconds
[0m00:47:26.380254 [debug] [ThreadPool]: On list_airflow: Close
[0m00:47:26.385688 [debug] [ThreadPool]: On list_airflow: Close
[0m00:47:26.393987 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m00:47:26.395333 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m00:47:26.396530 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m00:47:26.408806 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:47:26.413257 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:47:26.418374 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:47:26.420522 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m00:47:26.424410 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m00:47:26.427323 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m00:47:26.429092 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:26.430846 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:26.432408 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:47:26.447756 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m00:47:26.449993 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m00:47:26.451203 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:47:26.453093 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m00:47:26.454367 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:47:26.457005 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m00:47:26.460213 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:47:26.462488 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m00:47:26.466445 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m00:47:26.472229 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.007 seconds
[0m00:47:26.477005 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m00:47:26.477913 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m00:47:26.478875 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m00:47:26.481531 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m00:47:26.485278 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m00:47:26.490952 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m00:47:26.497908 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m00:47:26.500057 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m00:47:26.521150 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:26.525035 [debug] [MainThread]: On master: BEGIN
[0m00:47:26.526930 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:47:26.541710 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m00:47:26.543572 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:26.545775 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:47:26.561084 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m00:47:26.564879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53896d5f70>]}
[0m00:47:26.567601 [debug] [MainThread]: On master: ROLLBACK
[0m00:47:26.569565 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:26.571632 [debug] [MainThread]: On master: BEGIN
[0m00:47:26.575125 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:47:26.577813 [debug] [MainThread]: On master: COMMIT
[0m00:47:26.580348 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:26.582424 [debug] [MainThread]: On master: COMMIT
[0m00:47:26.585085 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:26.587489 [debug] [MainThread]: On master: Close
[0m00:47:26.600564 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m00:47:26.602912 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m00:47:26.605394 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m00:47:26.607307 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m00:47:26.627982 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.642498 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m00:47:26.756695 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.778541 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.781989 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m00:47:26.784822 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:47:26.812654 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m00:47:26.816593 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.819443 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m00:47:26.833814 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.011 seconds
[0m00:47:26.858990 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.862016 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m00:47:26.866601 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:26.882092 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.885206 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m00:47:26.889717 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:26.961912 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m00:47:26.966477 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:26.969215 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m00:47:26.984603 [debug] [Thread-1 (]: SQL status: COMMIT in 0.012 seconds
[0m00:47:27.019397 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m00:47:27.042533 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m00:47:27.044536 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m00:47:27.052496 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m00:47:27.060144 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m00:47:27.066199 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538a8526c0>]}
[0m00:47:27.068824 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.46s]
[0m00:47:27.071939 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m00:47:27.076624 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m00:47:27.077820 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m00:47:27.078882 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m00:47:27.080152 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m00:47:27.081855 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m00:47:27.083968 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m00:47:27.086300 [info ] [Thread-2 (]: 4 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m00:47:27.088626 [info ] [Thread-1 (]: 5 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m00:47:27.092424 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m00:47:27.094825 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m00:47:27.096918 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.technical_indicators_macd)
[0m00:47:27.098989 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m00:47:27.101037 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m00:47:27.103069 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m00:47:27.106147 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m00:47:27.109333 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m00:47:27.117727 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m00:47:27.126679 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m00:47:27.134300 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m00:47:27.144479 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m00:47:27.155899 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m00:47:27.158062 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m00:47:27.160159 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m00:47:27.162116 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m00:47:27.282210 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m00:47:27.291374 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m00:47:27.295775 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m00:47:27.303640 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m00:47:27.317034 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:27.318590 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:27.319660 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:27.323042 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m00:47:27.324823 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:27.326575 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m00:47:27.328915 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m00:47:27.331028 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:47:27.332815 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m00:47:27.334270 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m00:47:27.335932 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:47:27.341131 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:47:27.357169 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m00:47:27.359223 [debug] [Thread-4 (]: SQL status: BEGIN in 0.025 seconds
[0m00:47:27.361641 [debug] [Thread-2 (]: SQL status: BEGIN in 0.025 seconds
[0m00:47:27.363198 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:27.365502 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:27.367218 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m00:47:27.368548 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:27.370876 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m00:47:27.374919 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m00:47:27.377665 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:27.380447 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m00:47:27.386289 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m00:47:34.501445 [debug] [Thread-4 (]: SQL status: SELECT 963 in 7.117 seconds
[0m00:47:34.523735 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:34.527083 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m00:47:34.581173 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.051 seconds
[0m00:47:34.593119 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:34.598369 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m00:47:34.602128 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:34.606503 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m00:47:34.608389 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:34.611487 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m00:47:34.625233 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m00:47:34.634350 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m00:47:34.642441 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m00:47:34.644699 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m00:47:34.664672 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.018 seconds
[0m00:47:34.671631 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m00:47:34.675018 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53863f4530>]}
[0m00:47:34.684149 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 7.58s]
[0m00:47:34.687279 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m00:47:34.689787 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m00:47:34.691814 [info ] [Thread-4 (]: 6 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m00:47:34.694347 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m00:47:34.696558 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m00:47:34.706980 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m00:47:34.725054 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m00:47:34.737533 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m00:47:34.752892 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:34.754899 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m00:47:34.756861 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m00:47:34.775227 [debug] [Thread-4 (]: SQL status: BEGIN in 0.018 seconds
[0m00:47:34.777824 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:34.779779 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m00:47:34.956493 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.174 seconds
[0m00:47:34.964060 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:34.966417 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m00:47:34.969563 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:34.977244 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:34.979419 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m00:47:34.982143 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:34.987968 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m00:47:34.990282 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:34.992033 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m00:47:35.035672 [debug] [Thread-4 (]: SQL status: COMMIT in 0.042 seconds
[0m00:47:35.044585 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m00:47:35.046958 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m00:47:35.049258 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m00:47:35.058826 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.007 seconds
[0m00:47:35.062183 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m00:47:35.063860 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53886e8410>]}
[0m00:47:35.066062 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.37s]
[0m00:47:35.071249 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m00:47:35.073526 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m00:47:35.075726 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m00:47:35.077764 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m00:47:35.079661 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m00:47:35.089607 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m00:47:35.105165 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m00:47:35.113674 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m00:47:35.128221 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:35.130438 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m00:47:35.134324 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m00:47:35.146132 [debug] [Thread-4 (]: SQL status: BEGIN in 0.012 seconds
[0m00:47:35.147909 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:35.151781 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m00:47:38.335037 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 10.945 seconds
[0m00:47:38.371195 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:38.373687 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m00:47:38.378377 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m00:47:38.394862 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:38.407265 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m00:47:38.440296 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.030 seconds
[0m00:47:38.447951 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m00:47:38.450298 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:38.452335 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m00:47:38.465754 [debug] [Thread-3 (]: SQL status: COMMIT in 0.008 seconds
[0m00:47:38.471797 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m00:47:38.474028 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m00:47:38.475813 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m00:47:38.684566 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.206 seconds
[0m00:47:38.690436 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m00:47:38.692581 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5384780290>]}
[0m00:47:38.695234 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701021[0m in 11.60s]
[0m00:47:38.699099 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m00:47:38.721368 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m00:47:38.737667 [info ] [Thread-3 (]: 8 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m00:47:38.755854 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m00:47:38.765614 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m00:47:38.785775 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m00:47:38.837894 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m00:47:38.863254 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m00:47:38.876123 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:38.880757 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m00:47:38.888698 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:47:38.950593 [debug] [Thread-3 (]: SQL status: BEGIN in 0.062 seconds
[0m00:47:38.964671 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:38.967430 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m00:47:43.401712 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.249 seconds
[0m00:47:43.413916 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:43.421167 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m00:47:43.427551 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:43.450202 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:43.467310 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m00:47:43.470352 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:43.478379 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m00:47:43.481267 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:43.484347 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m00:47:43.510789 [debug] [Thread-4 (]: SQL status: COMMIT in 0.023 seconds
[0m00:47:43.520118 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m00:47:43.522803 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m00:47:43.526055 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m00:47:43.543517 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.015 seconds
[0m00:47:43.548845 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m00:47:43.551949 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5384781040>]}
[0m00:47:43.562180 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 8.47s]
[0m00:47:43.566303 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m00:47:43.568821 [debug] [Thread-4 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m00:47:43.572578 [info ] [Thread-4 (]: 9 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m00:47:43.577534 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m00:47:43.580591 [debug] [Thread-4 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m00:47:43.594090 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m00:47:43.607990 [debug] [Thread-4 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m00:47:43.617934 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m00:47:43.632947 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:43.634892 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m00:47:43.636740 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m00:47:43.656031 [debug] [Thread-4 (]: SQL status: BEGIN in 0.019 seconds
[0m00:47:43.658544 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:43.661394 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m00:47:44.378121 [debug] [Thread-4 (]: SQL status: SELECT 20138 in 0.714 seconds
[0m00:47:44.388776 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:44.391184 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m00:47:44.393829 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:44.401666 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:44.403520 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m00:47:44.405799 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:47:44.410140 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m00:47:44.411826 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:44.413374 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m00:47:44.428672 [debug] [Thread-4 (]: SQL status: COMMIT in 0.014 seconds
[0m00:47:44.434992 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m00:47:44.437755 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m00:47:44.440210 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m00:47:44.454547 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.012 seconds
[0m00:47:44.459383 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m00:47:44.461699 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53847fb7a0>]}
[0m00:47:44.470801 [info ] [Thread-4 (]: 9 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 20138[0m in 0.88s]
[0m00:47:44.474087 [debug] [Thread-4 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m00:47:45.180461 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 17.792 seconds
[0m00:47:45.187383 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:45.189891 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m00:47:45.193429 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:45.200782 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:45.202848 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m00:47:45.206013 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m00:47:45.211285 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m00:47:45.213368 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:45.215075 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m00:47:45.246618 [debug] [Thread-2 (]: SQL status: COMMIT in 0.030 seconds
[0m00:47:45.252757 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m00:47:45.255099 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m00:47:45.257394 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m00:47:45.306443 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.047 seconds
[0m00:47:45.311048 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m00:47:45.313289 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5384622a20>]}
[0m00:47:45.316352 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701021[0m in 18.22s]
[0m00:47:45.321000 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m00:47:46.755636 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.774 seconds
[0m00:47:46.763173 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:46.765259 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m00:47:46.767860 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:46.774965 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:46.776859 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m00:47:46.779173 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:46.782603 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m00:47:46.784719 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:46.786396 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m00:47:46.793452 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m00:47:46.798867 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m00:47:46.800973 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m00:47:46.802768 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m00:47:46.808163 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m00:47:46.811880 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m00:47:46.814221 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53847e6d80>]}
[0m00:47:46.817226 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 8.06s]
[0m00:47:46.820705 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m00:47:46.979238 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 19.597 seconds
[0m00:47:46.985569 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:46.987193 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m00:47:46.989860 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:46.995632 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:46.997334 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m00:47:46.999421 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:47:47.002449 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m00:47:47.004054 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:47.006195 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m00:47:47.014119 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m00:47:47.019028 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m00:47:47.021233 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m00:47:47.023323 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m00:47:47.043906 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.019 seconds
[0m00:47:47.047245 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m00:47:47.050543 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f288b79d-9c16-44c4-aae2-4689b76cdf2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5384614500>]}
[0m00:47:47.052710 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 700058[0m in 19.95s]
[0m00:47:47.055164 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m00:47:47.059094 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.061187 [debug] [MainThread]: On master: BEGIN
[0m00:47:47.062991 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:47:47.074356 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m00:47:47.076330 [debug] [MainThread]: On master: COMMIT
[0m00:47:47.078053 [debug] [MainThread]: Using postgres connection "master"
[0m00:47:47.079860 [debug] [MainThread]: On master: COMMIT
[0m00:47:47.082018 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:47:47.083845 [debug] [MainThread]: On master: Close
[0m00:47:47.085842 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:47:47.087672 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m00:47:47.090306 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m00:47:47.092129 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m00:47:47.093856 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m00:47:47.095773 [info ] [MainThread]: 
[0m00:47:47.097605 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 20.86 seconds (20.86s).
[0m00:47:47.102145 [debug] [MainThread]: Command end result
[0m00:47:47.176072 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:47:47.185371 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:47:47.202688 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:47:47.205024 [info ] [MainThread]: 
[0m00:47:47.207381 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:47:47.209102 [info ] [MainThread]: 
[0m00:47:47.217439 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m00:47:47.220273 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 23.459152, "process_in_blocks": "0", "process_kernel_time": 0.88859, "process_mem_max_rss": "125212", "process_out_blocks": "2360", "process_user_time": 6.866378}
[0m00:47:47.222849 [debug] [MainThread]: Command `dbt run` succeeded at 00:47:47.222596 after 23.46 seconds
[0m00:47:47.224696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538c2ef170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538a3bc6e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f538477c110>]}
[0m00:47:47.226541 [debug] [MainThread]: Flushing usage events
[0m00:47:49.295306 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:48:03.189758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a55fa750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a5b11040>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a6149dc0>]}


============================== 00:48:03.202029 | 41e08a90-efc0-4f74-9ce5-00c619f0d861 ==============================
[0m00:48:03.202029 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:48:03.204169 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m00:48:03.603442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a3e2e7b0>]}
[0m00:48:03.707442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a5948770>]}
[0m00:48:03.710406 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:48:03.872317 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:48:04.475332 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:48:04.477385 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:48:04.564271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a39928d0>]}
[0m00:48:04.753566 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:48:04.770187 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:48:04.829053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a1fe4980>]}
[0m00:48:04.831565 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m00:48:04.834107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a2fd1ee0>]}
[0m00:48:04.841283 [info ] [MainThread]: 
[0m00:48:04.844273 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:48:04.846888 [info ] [MainThread]: 
[0m00:48:04.849171 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:48:04.859659 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m00:48:04.861088 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m00:48:04.863949 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m00:48:04.944873 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:48:04.945744 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:48:04.946507 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:48:04.960429 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m00:48:04.962657 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m00:48:04.964630 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m00:48:04.966311 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:48:04.967876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:48:04.969686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:48:04.983253 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m00:48:04.984050 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m00:48:04.985408 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m00:48:04.986160 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:48:04.987898 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:48:04.989792 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:48:04.991844 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m00:48:04.993904 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m00:48:04.995888 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m00:48:05.002079 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m00:48:05.002827 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m00:48:05.003596 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m00:48:05.006169 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m00:48:05.010495 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m00:48:05.013823 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m00:48:05.015917 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m00:48:05.017791 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m00:48:05.019639 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m00:48:05.035298 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.037125 [debug] [MainThread]: On master: BEGIN
[0m00:48:05.038814 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:48:05.049983 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m00:48:05.051846 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.053858 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:48:05.067499 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m00:48:05.071562 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41e08a90-efc0-4f74-9ce5-00c619f0d861', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a2fd1b20>]}
[0m00:48:05.073813 [debug] [MainThread]: On master: ROLLBACK
[0m00:48:05.076605 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.078535 [debug] [MainThread]: On master: BEGIN
[0m00:48:05.080957 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m00:48:05.082710 [debug] [MainThread]: On master: COMMIT
[0m00:48:05.084370 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.086100 [debug] [MainThread]: On master: COMMIT
[0m00:48:05.088507 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:48:05.090552 [debug] [MainThread]: On master: Close
[0m00:48:05.098841 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:48:05.099736 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:48:05.101407 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m00:48:05.103400 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m00:48:05.105605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m00:48:05.107720 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m00:48:05.109956 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:48:05.111845 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:48:05.150761 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:48:05.151731 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:48:05.162237 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:48:05.170728 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:48:05.197501 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:48:05.200308 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:48:05.210987 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:48:05.213217 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m00:48:05.214209 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:48:05.215766 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:48:05.217594 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m00:48:05.220974 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:48:05.230693 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m00:48:05.232583 [debug] [Thread-2 (]: SQL status: BEGIN in 0.012 seconds
[0m00:48:05.233413 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m00:48:05.235254 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m00:48:05.237332 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m00:48:05.239490 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m00:48:05.243225 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m00:48:05.251359 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.007 seconds
[0m00:48:05.252227 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m00:48:05.255627 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m00:48:05.258248 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m00:48:05.260404 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m00:48:05.262452 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m00:48:05.264740 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.16s]
[0m00:48:05.267027 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m00:48:05.269260 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m00:48:05.275037 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.277039 [debug] [MainThread]: On master: BEGIN
[0m00:48:05.278681 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:48:05.289823 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m00:48:05.292390 [debug] [MainThread]: On master: COMMIT
[0m00:48:05.294300 [debug] [MainThread]: Using postgres connection "master"
[0m00:48:05.296059 [debug] [MainThread]: On master: COMMIT
[0m00:48:05.298088 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m00:48:05.299821 [debug] [MainThread]: On master: Close
[0m00:48:05.302407 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:48:05.304397 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m00:48:05.306150 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m00:48:05.308071 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m00:48:05.310061 [info ] [MainThread]: 
[0m00:48:05.311912 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.46 seconds (0.46s).
[0m00:48:05.314623 [debug] [MainThread]: Command end result
[0m00:48:05.390931 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:48:05.400835 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:48:05.419554 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:48:05.421402 [info ] [MainThread]: 
[0m00:48:05.423628 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:48:05.426330 [info ] [MainThread]: 
[0m00:48:05.428411 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m00:48:05.431073 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.3643076, "process_in_blocks": "0", "process_kernel_time": 0.36254, "process_mem_max_rss": "123028", "process_out_blocks": "0", "process_user_time": 4.35048}
[0m00:48:05.433489 [debug] [MainThread]: Command `dbt test` succeeded at 00:48:05.433265 after 2.37 seconds
[0m00:48:05.435360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a3f961b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a23b9bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5a392edb0>]}
[0m00:48:05.437181 [debug] [MainThread]: Flushing usage events
[0m00:48:06.914182 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:02:09.608941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bdfa7fb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00be6c2ae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bdfa5460>]}


============================== 15:02:09.622858 | 33a12f8a-d86e-4091-84cb-ff9e8a220e41 ==============================
[0m15:02:09.622858 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:02:09.624944 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m15:02:10.168278 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00be574320>]}
[0m15:02:10.284688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bd983f80>]}
[0m15:02:10.288633 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:02:10.463720 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:02:11.149407 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:02:11.151288 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:02:11.238448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bcfe9340>]}
[0m15:02:11.442467 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:02:11.458496 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:02:11.512293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bcf59ac0>]}
[0m15:02:11.515536 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m15:02:11.518093 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bdc6c320>]}
[0m15:02:11.523155 [info ] [MainThread]: 
[0m15:02:11.525333 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:02:11.527249 [info ] [MainThread]: 
[0m15:02:11.529319 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:02:11.539812 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:02:11.541040 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:02:11.542326 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m15:02:11.624196 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:02:11.625031 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:02:11.625729 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m15:02:11.627395 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:02:11.629547 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:02:11.632307 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m15:02:11.634913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:11.636951 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:11.638657 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:11.651972 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m15:02:11.653974 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.015 seconds
[0m15:02:11.656188 [debug] [ThreadPool]: On list_airflow: Close
[0m15:02:11.656981 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.020 seconds
[0m15:02:11.659976 [debug] [ThreadPool]: On list_airflow: Close
[0m15:02:11.665203 [debug] [ThreadPool]: On list_airflow: Close
[0m15:02:11.669060 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m15:02:11.670165 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m15:02:11.671033 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m15:02:11.673027 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m15:02:11.675399 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m15:02:11.677676 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m15:02:11.687445 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m15:02:11.691868 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m15:02:11.696552 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:02:11.698714 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m15:02:11.700708 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m15:02:11.702498 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m15:02:11.704494 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.706314 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.708030 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.721047 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m15:02:11.723361 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m15:02:11.725021 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m15:02:11.726419 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m15:02:11.727609 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m15:02:11.730226 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:02:11.731148 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m15:02:11.732657 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m15:02:11.734587 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m15:02:11.737676 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m15:02:11.739496 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m15:02:11.742162 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m15:02:11.743442 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m15:02:11.746212 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m15:02:11.747963 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:02:11.749969 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m15:02:11.752545 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m15:02:11.754476 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m15:02:11.757439 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m15:02:11.759403 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m15:02:11.760981 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m15:02:11.761768 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m15:02:11.764842 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m15:02:11.768885 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m15:02:11.770657 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m15:02:11.773330 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m15:02:11.775097 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m15:02:11.780029 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m15:02:11.781282 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m15:02:11.782430 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m15:02:11.792503 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:02:11.797376 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:02:11.801828 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:02:11.803783 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:02:11.805673 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:02:11.807547 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:02:11.809384 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.811252 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.813501 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:02:11.825533 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m15:02:11.827498 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m15:02:11.829883 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m15:02:11.830643 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:02:11.832429 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:02:11.834388 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:02:11.836434 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:02:11.838353 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:02:11.840398 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:02:11.847374 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m15:02:11.848184 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m15:02:11.848855 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m15:02:11.851661 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:02:11.854867 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:02:11.858098 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:02:11.860298 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:02:11.861679 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:02:11.863203 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:02:11.877011 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:11.879152 [debug] [MainThread]: On master: BEGIN
[0m15:02:11.880942 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:02:11.892336 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m15:02:11.894578 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:11.896978 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:02:11.903363 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m15:02:11.907008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bcfc0350>]}
[0m15:02:11.909058 [debug] [MainThread]: On master: ROLLBACK
[0m15:02:11.911253 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:11.913771 [debug] [MainThread]: On master: BEGIN
[0m15:02:11.916263 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:02:11.918286 [debug] [MainThread]: On master: COMMIT
[0m15:02:11.920095 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:11.921825 [debug] [MainThread]: On master: COMMIT
[0m15:02:11.923857 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:02:11.925615 [debug] [MainThread]: On master: Close
[0m15:02:11.939149 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m15:02:11.941477 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m15:02:11.943578 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m15:02:11.945375 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m15:02:11.958890 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m15:02:11.973457 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m15:02:12.036529 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.051271 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.053288 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m15:02:12.054918 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:02:12.067037 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m15:02:12.069446 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.071505 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m15:02:12.080414 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m15:02:12.094772 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.097403 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m15:02:12.101404 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:12.135939 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m15:02:12.142980 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.145588 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m15:02:12.155524 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m15:02:12.171165 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m15:02:12.182804 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m15:02:12.185200 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m15:02:12.187788 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m15:02:12.193370 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m15:02:12.198890 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bfc32a20>]}
[0m15:02:12.201567 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.25s]
[0m15:02:12.203915 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m15:02:12.206949 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m15:02:12.208008 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m15:02:12.208829 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m15:02:12.209694 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m15:02:12.211061 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m15:02:12.212995 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m15:02:12.215131 [info ] [Thread-2 (]: 4 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m15:02:12.217327 [info ] [Thread-1 (]: 5 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m15:02:12.219386 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.daily_stock_metrics)
[0m15:02:12.221259 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m15:02:12.223019 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.technical_indicators_macd)
[0m15:02:12.224810 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m15:02:12.226672 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m15:02:12.228431 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m15:02:12.230696 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m15:02:12.233047 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m15:02:12.239888 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m15:02:12.245872 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m15:02:12.253522 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m15:02:12.259816 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m15:02:12.270652 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m15:02:12.271957 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m15:02:12.273545 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m15:02:12.275014 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m15:02:12.347858 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m15:02:12.350490 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m15:02:12.355838 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m15:02:12.362658 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m15:02:12.374411 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m15:02:12.376268 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m15:02:12.378199 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m15:02:12.380220 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m15:02:12.381719 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m15:02:12.384085 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m15:02:12.386595 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m15:02:12.389022 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:02:12.391360 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m15:02:12.393876 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:02:12.396113 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m15:02:12.399863 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:02:12.409494 [debug] [Thread-2 (]: SQL status: BEGIN in 0.020 seconds
[0m15:02:12.412978 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m15:02:12.415066 [debug] [Thread-4 (]: SQL status: BEGIN in 0.021 seconds
[0m15:02:12.416719 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m15:02:12.418867 [debug] [Thread-3 (]: SQL status: BEGIN in 0.023 seconds
[0m15:02:12.420437 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m15:02:12.421928 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m15:02:12.425600 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m15:02:12.427999 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m15:02:12.430143 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m15:02:12.432562 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m15:02:12.435122 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m15:02:17.104216 [debug] [Thread-4 (]: SQL status: SELECT 963 in 4.667 seconds
[0m15:02:17.125508 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m15:02:17.127545 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m15:02:17.130009 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:17.133759 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m15:02:17.135483 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m15:02:17.137281 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m15:02:17.172192 [debug] [Thread-4 (]: SQL status: COMMIT in 0.033 seconds
[0m15:02:17.181315 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m15:02:17.188227 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m15:02:17.190330 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m15:02:17.193558 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:02:17.197877 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m15:02:17.200457 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bc7decc0>]}
[0m15:02:17.202916 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 4.98s]
[0m15:02:17.205628 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m15:02:17.209014 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m15:02:17.211166 [info ] [Thread-4 (]: 6 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m15:02:17.213310 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m15:02:17.215373 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m15:02:17.224025 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m15:02:17.238025 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m15:02:17.249115 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m15:02:17.263039 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m15:02:17.264926 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m15:02:17.266981 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:02:17.284320 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m15:02:17.287861 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m15:02:17.290535 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m15:02:17.547214 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.254 seconds
[0m15:02:17.555996 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m15:02:17.558433 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m15:02:17.562144 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:17.566329 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m15:02:17.570895 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m15:02:17.574588 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m15:02:17.618748 [debug] [Thread-4 (]: SQL status: COMMIT in 0.041 seconds
[0m15:02:17.627361 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m15:02:17.630220 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m15:02:17.632893 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m15:02:17.635230 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m15:02:17.638886 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m15:02:17.641147 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b8113b30>]}
[0m15:02:17.644908 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.43s]
[0m15:02:17.648932 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m15:02:17.650799 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m15:02:17.652952 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m15:02:17.654983 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m15:02:17.656684 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m15:02:17.668760 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m15:02:17.702869 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m15:02:17.716219 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m15:02:17.733789 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m15:02:17.736232 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m15:02:17.738571 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:02:17.755350 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m15:02:17.758389 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m15:02:17.761446 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m15:02:18.295617 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 5.857 seconds
[0m15:02:18.304254 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m15:02:18.306763 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m15:02:18.312067 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:18.320054 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m15:02:18.323013 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m15:02:18.326204 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m15:02:18.337855 [debug] [Thread-3 (]: SQL status: COMMIT in 0.008 seconds
[0m15:02:18.346791 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m15:02:18.350223 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m15:02:18.352739 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m15:02:18.355955 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m15:02:18.361574 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m15:02:18.364384 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b9bd0890>]}
[0m15:02:18.368232 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701021[0m in 6.14s]
[0m15:02:18.372963 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m15:02:18.376990 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m15:02:18.380588 [info ] [Thread-3 (]: 8 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m15:02:18.383546 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m15:02:18.386330 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m15:02:18.400361 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m15:02:18.420507 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m15:02:18.434075 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m15:02:18.454768 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m15:02:18.458535 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m15:02:18.462428 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m15:02:18.488813 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m15:02:18.495997 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m15:02:18.500536 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m15:02:24.954365 [debug] [Thread-4 (]: SQL status: SELECT 960 in 7.190 seconds
[0m15:02:24.964170 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m15:02:24.965324 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 12.541 seconds
[0m15:02:24.967389 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m15:02:24.984052 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m15:02:24.987732 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:24.989717 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m15:02:24.994516 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m15:02:24.997710 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:24.999195 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m15:02:25.005656 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m15:02:25.009343 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m15:02:25.012474 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m15:02:25.016645 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m15:02:25.018469 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m15:02:25.028490 [debug] [Thread-2 (]: SQL status: COMMIT in 0.007 seconds
[0m15:02:25.027344 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m15:02:25.037507 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m15:02:25.040464 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m15:02:25.043612 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m15:02:25.046486 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m15:02:25.048975 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m15:02:25.052414 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:02:25.054865 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:02:25.059524 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m15:02:25.065292 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m15:02:25.068845 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b9a7f290>]}
[0m15:02:25.072058 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b9b99fa0>]}
[0m15:02:25.075289 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 7.41s]
[0m15:02:25.079046 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701021[0m in 12.85s]
[0m15:02:25.082867 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m15:02:25.086957 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m15:02:25.090497 [debug] [Thread-4 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m15:02:25.095314 [info ] [Thread-4 (]: 9 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m15:02:25.098436 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m15:02:25.101912 [debug] [Thread-4 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m15:02:25.111381 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.127475 [debug] [Thread-4 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m15:02:25.138858 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.153353 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.155942 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m15:02:25.158311 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:02:25.172497 [debug] [Thread-4 (]: SQL status: BEGIN in 0.014 seconds
[0m15:02:25.175491 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.178892 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m15:02:25.876443 [debug] [Thread-4 (]: SQL status: SELECT 19277 in 0.694 seconds
[0m15:02:25.885987 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.888977 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m15:02:25.892381 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:25.897723 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m15:02:25.900369 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.903131 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m15:02:25.915363 [debug] [Thread-4 (]: SQL status: COMMIT in 0.009 seconds
[0m15:02:25.923897 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m15:02:25.927688 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m15:02:25.930079 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m15:02:25.933509 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:02:25.938787 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m15:02:25.941645 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b9bf78c0>]}
[0m15:02:25.945229 [info ] [Thread-4 (]: 9 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 19277[0m in 0.84s]
[0m15:02:25.948723 [debug] [Thread-4 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m15:02:26.236387 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.732 seconds
[0m15:02:26.244560 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m15:02:26.247021 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m15:02:26.250183 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:26.254935 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m15:02:26.256870 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m15:02:26.258929 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m15:02:26.305106 [debug] [Thread-3 (]: SQL status: COMMIT in 0.044 seconds
[0m15:02:26.311142 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m15:02:26.314264 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m15:02:26.317684 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m15:02:26.321129 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m15:02:26.326210 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m15:02:26.334029 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00b9ad3590>]}
[0m15:02:26.336907 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 7.95s]
[0m15:02:26.339446 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m15:02:27.364972 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 14.925 seconds
[0m15:02:27.372331 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m15:02:27.374863 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m15:02:27.377982 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m15:02:27.382021 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m15:02:27.384712 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m15:02:27.386864 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m15:02:27.422362 [debug] [Thread-1 (]: SQL status: COMMIT in 0.033 seconds
[0m15:02:27.428209 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m15:02:27.430738 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m15:02:27.433112 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m15:02:27.435986 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m15:02:27.440017 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m15:02:27.442551 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '33a12f8a-d86e-4091-84cb-ff9e8a220e41', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bbfe4fb0>]}
[0m15:02:27.445180 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 700058[0m in 15.22s]
[0m15:02:27.447763 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m15:02:27.452826 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:27.455080 [debug] [MainThread]: On master: BEGIN
[0m15:02:27.457204 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:02:27.470154 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m15:02:27.472863 [debug] [MainThread]: On master: COMMIT
[0m15:02:27.474893 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:27.477071 [debug] [MainThread]: On master: COMMIT
[0m15:02:27.480045 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:02:27.482342 [debug] [MainThread]: On master: Close
[0m15:02:27.484971 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:02:27.486906 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m15:02:27.488881 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m15:02:27.490858 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m15:02:27.492868 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m15:02:27.495070 [info ] [MainThread]: 
[0m15:02:27.497232 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 15.97 seconds (15.97s).
[0m15:02:27.502497 [debug] [MainThread]: Command end result
[0m15:02:27.597495 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:02:27.607760 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:02:27.629698 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:02:27.631777 [info ] [MainThread]: 
[0m15:02:27.634490 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:02:27.636613 [info ] [MainThread]: 
[0m15:02:27.638823 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m15:02:27.642161 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.17107, "process_in_blocks": "29136", "process_kernel_time": 0.745158, "process_mem_max_rss": "125272", "process_out_blocks": "1056", "process_user_time": 6.051893}
[0m15:02:27.644708 [debug] [MainThread]: Command `dbt run` succeeded at 15:02:27.644441 after 18.17 seconds
[0m15:02:27.646697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00c16670e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bf74c6e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f00bd9b49b0>]}
[0m15:02:27.648814 [debug] [MainThread]: Flushing usage events
[0m15:02:29.479537 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:02:39.237080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab96540ef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab961bc140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab96986630>]}


============================== 15:02:39.247485 | c25897dd-43ff-40a6-a59e-f2ae0943f80b ==============================
[0m15:02:39.247485 [info ] [MainThread]: Running with dbt=1.9.4
[0m15:02:39.249508 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m15:02:39.593303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab96123ce0>]}
[0m15:02:39.708405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab9737eae0>]}
[0m15:02:39.710617 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m15:02:39.897257 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m15:02:40.550079 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:02:40.552657 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:02:40.661213 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab95397fb0>]}
[0m15:02:40.892798 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:02:40.909932 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:02:40.977891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab93f092b0>]}
[0m15:02:40.980147 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m15:02:40.982433 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab95e3c5f0>]}
[0m15:02:40.987493 [info ] [MainThread]: 
[0m15:02:40.989953 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:02:40.992070 [info ] [MainThread]: 
[0m15:02:40.994470 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m15:02:41.004792 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m15:02:41.006656 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m15:02:41.008273 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m15:02:41.095002 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:02:41.095891 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:02:41.096687 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:02:41.098395 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m15:02:41.100489 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m15:02:41.102592 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m15:02:41.104797 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:41.107108 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:41.109173 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:02:41.122690 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m15:02:41.124752 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m15:02:41.126876 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m15:02:41.128103 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m15:02:41.130139 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m15:02:41.132122 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m15:02:41.134367 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m15:02:41.136521 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m15:02:41.140176 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m15:02:41.141747 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m15:02:41.146550 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m15:02:41.147400 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m15:02:41.148209 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m15:02:41.150251 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m15:02:41.153875 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m15:02:41.157816 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m15:02:41.162518 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m15:02:41.164667 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m15:02:41.180311 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.182595 [debug] [MainThread]: On master: BEGIN
[0m15:02:41.184669 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:02:41.196750 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m15:02:41.199332 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.201731 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m15:02:41.219048 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m15:02:41.223401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c25897dd-43ff-40a6-a59e-f2ae0943f80b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab94321fa0>]}
[0m15:02:41.225700 [debug] [MainThread]: On master: ROLLBACK
[0m15:02:41.228109 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.230068 [debug] [MainThread]: On master: BEGIN
[0m15:02:41.232694 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m15:02:41.234857 [debug] [MainThread]: On master: COMMIT
[0m15:02:41.236873 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.238860 [debug] [MainThread]: On master: COMMIT
[0m15:02:41.241311 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:02:41.243196 [debug] [MainThread]: On master: Close
[0m15:02:41.251975 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m15:02:41.252973 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m15:02:41.254810 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m15:02:41.256912 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m15:02:41.259101 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m15:02:41.261128 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m15:02:41.263138 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m15:02:41.265083 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m15:02:41.303961 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m15:02:41.307957 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m15:02:41.317746 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m15:02:41.319117 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m15:02:41.352417 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m15:02:41.353448 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m15:02:41.364799 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m15:02:41.366371 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m15:02:41.367824 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m15:02:41.370119 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m15:02:41.372357 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:02:41.374612 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:02:41.386560 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m15:02:41.389023 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m15:02:41.390825 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m15:02:41.393135 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m15:02:41.395239 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m15:02:41.397335 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m15:02:41.401283 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m15:02:41.402448 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m15:02:41.410759 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m15:02:41.414445 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m15:02:41.417025 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m15:02:41.418929 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m15:02:41.420845 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.16s]
[0m15:02:41.423470 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m15:02:41.425862 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m15:02:41.428304 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m15:02:41.434034 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.435788 [debug] [MainThread]: On master: BEGIN
[0m15:02:41.437623 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:02:41.449456 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m15:02:41.451563 [debug] [MainThread]: On master: COMMIT
[0m15:02:41.453812 [debug] [MainThread]: Using postgres connection "master"
[0m15:02:41.456617 [debug] [MainThread]: On master: COMMIT
[0m15:02:41.458888 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m15:02:41.460597 [debug] [MainThread]: On master: Close
[0m15:02:41.462644 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:02:41.464453 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m15:02:41.466236 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m15:02:41.467980 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m15:02:41.469885 [info ] [MainThread]: 
[0m15:02:41.472025 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.48 seconds (0.48s).
[0m15:02:41.474979 [debug] [MainThread]: Command end result
[0m15:02:41.551435 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m15:02:41.561056 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m15:02:41.580713 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m15:02:41.582788 [info ] [MainThread]: 
[0m15:02:41.584820 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:02:41.586923 [info ] [MainThread]: 
[0m15:02:41.589485 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m15:02:41.592359 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.482387, "process_in_blocks": "1120", "process_kernel_time": 0.371231, "process_mem_max_rss": "122188", "process_out_blocks": "0", "process_user_time": 4.962774}
[0m15:02:41.594832 [debug] [MainThread]: Command `dbt test` succeeded at 15:02:41.594589 after 2.49 seconds
[0m15:02:41.596773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab961266f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab9612e1e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fab96984710>]}
[0m15:02:41.598609 [debug] [MainThread]: Flushing usage events
[0m15:02:42.685783 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:38:26.417107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0fae7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0529e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d06dab40>]}


============================== 16:38:26.429519 | 78ca5764-790f-4cef-b3e3-358b9c80345e ==============================
[0m16:38:26.429519 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:38:26.431651 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:38:26.888530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d03d66f0>]}
[0m16:38:27.014533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d08ed280>]}
[0m16:38:27.017360 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:38:27.213482 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:38:27.799167 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:38:27.801433 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:38:27.934302 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d02b6bd0>]}
[0m16:38:28.150254 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:38:28.167084 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:38:28.244173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2ceb21700>]}
[0m16:38:28.246973 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m16:38:28.249481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d033a0f0>]}
[0m16:38:28.254391 [info ] [MainThread]: 
[0m16:38:28.256663 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:38:28.258751 [info ] [MainThread]: 
[0m16:38:28.261126 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:38:28.270857 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:38:28.272084 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:38:28.273165 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:38:28.351279 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:38:28.352077 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:38:28.352802 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:38:28.354460 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:38:28.356353 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:38:28.358281 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:38:28.360051 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:38:28.361950 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:38:28.364208 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:38:28.376904 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.017 seconds
[0m16:38:28.377666 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.016 seconds
[0m16:38:28.378517 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.014 seconds
[0m16:38:28.381965 [debug] [ThreadPool]: On list_airflow: Close
[0m16:38:28.385376 [debug] [ThreadPool]: On list_airflow: Close
[0m16:38:28.388571 [debug] [ThreadPool]: On list_airflow: Close
[0m16:38:28.394176 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m16:38:28.395482 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m16:38:28.396939 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m16:38:28.398863 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m16:38:28.401088 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m16:38:28.403134 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m16:38:28.413331 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:38:28.418067 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:38:28.426693 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:38:28.428539 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m16:38:28.431266 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m16:38:28.433152 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m16:38:28.434970 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.436597 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.438356 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.450922 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m16:38:28.452790 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:38:28.454492 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m16:38:28.455303 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m16:38:28.456638 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m16:38:28.457823 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:38:28.460712 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:38:28.461435 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:38:28.463463 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m16:38:28.466486 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m16:38:28.468632 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m16:38:28.471263 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:38:28.471990 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:38:28.474392 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:38:28.476539 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:38:28.478328 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m16:38:28.481239 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:38:28.483308 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:38:28.486340 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:38:28.488139 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:38:28.489956 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:38:28.494356 [debug] [ThreadPool]: SQL status: COMMIT in 0.009 seconds
[0m16:38:28.496189 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m16:38:28.498998 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m16:38:28.499708 [debug] [ThreadPool]: SQL status: COMMIT in 0.008 seconds
[0m16:38:28.501137 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m16:38:28.502946 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m16:38:28.509342 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_analytics)
[0m16:38:28.510621 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_staging)
[0m16:38:28.511979 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_core)
[0m16:38:28.522238 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:38:28.526538 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:38:28.531063 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:38:28.533104 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:38:28.535104 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:38:28.536963 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:38:28.538608 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.540532 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.542545 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:38:28.555077 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m16:38:28.556475 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m16:38:28.557802 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:38:28.559512 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:38:28.560814 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:38:28.562891 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:38:28.564954 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:38:28.566957 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:38:28.570259 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:38:28.572930 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m16:38:28.577530 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:38:28.578387 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m16:38:28.579343 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m16:38:28.580995 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:38:28.584037 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:38:28.587602 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:38:28.591572 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:38:28.593925 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:38:28.607614 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:28.609662 [debug] [MainThread]: On master: BEGIN
[0m16:38:28.611369 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:38:28.622623 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m16:38:28.624648 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:28.626926 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:38:28.633369 [debug] [MainThread]: SQL status: SELECT 0 in 0.004 seconds
[0m16:38:28.637818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cf7343e0>]}
[0m16:38:28.640162 [debug] [MainThread]: On master: ROLLBACK
[0m16:38:28.642613 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:28.644663 [debug] [MainThread]: On master: BEGIN
[0m16:38:28.647487 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:38:28.649619 [debug] [MainThread]: On master: COMMIT
[0m16:38:28.651626 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:28.653552 [debug] [MainThread]: On master: COMMIT
[0m16:38:28.655838 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:38:28.657961 [debug] [MainThread]: On master: Close
[0m16:38:28.669927 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m16:38:28.672448 [info ] [Thread-1 (]: 1 of 9 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m16:38:28.674895 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_daily_stock_summary)
[0m16:38:28.677563 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m16:38:28.692558 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.707384 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m16:38:28.784554 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.798250 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.800301 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m16:38:28.802123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:38:28.814331 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m16:38:28.816414 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.818514 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m16:38:28.827510 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m16:38:28.858171 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.862266 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m16:38:28.865356 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:28.900511 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:38:28.902401 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.904255 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:38:28.911233 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:38:28.924000 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m16:38:28.934747 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:38:28.936828 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m16:38:28.939186 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m16:38:28.944755 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m16:38:28.948997 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d252b9b0>]}
[0m16:38:28.951388 [info ] [Thread-1 (]: 1 of 9 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.27s]
[0m16:38:28.953858 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m16:38:28.957169 [debug] [Thread-3 (]: Began running node model.idx_stock.daily_stock_metrics
[0m16:38:28.958213 [debug] [Thread-4 (]: Began running node model.idx_stock.dim_companies
[0m16:38:28.959192 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m16:38:28.960251 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m16:38:28.961851 [info ] [Thread-3 (]: 2 of 9 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m16:38:28.964058 [info ] [Thread-4 (]: 3 of 9 START sql table model public_core.dim_companies ......................... [RUN]
[0m16:38:28.966732 [info ] [Thread-2 (]: 4 of 9 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m16:38:28.968743 [info ] [Thread-1 (]: 5 of 9 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m16:38:28.971009 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m16:38:28.973193 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.dim_companies'
[0m16:38:28.975305 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.technical_indicators_macd)
[0m16:38:28.977636 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_rsi)
[0m16:38:28.979671 [debug] [Thread-3 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m16:38:28.981616 [debug] [Thread-4 (]: Began compiling node model.idx_stock.dim_companies
[0m16:38:28.983753 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m16:38:28.985729 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m16:38:28.993537 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m16:38:28.999488 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m16:38:29.006786 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m16:38:29.014615 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m16:38:29.025962 [debug] [Thread-3 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m16:38:29.027735 [debug] [Thread-4 (]: Began executing node model.idx_stock.dim_companies
[0m16:38:29.028942 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m16:38:29.036907 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m16:38:29.107964 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m16:38:29.117185 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m16:38:29.123073 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m16:38:29.129837 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m16:38:29.141515 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:38:29.144288 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:38:29.145760 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:38:29.146783 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m16:38:29.147741 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:38:29.150067 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m16:38:29.152376 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: BEGIN
[0m16:38:29.154676 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:38:29.157379 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m16:38:29.159621 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:38:29.161875 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:38:29.165633 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:38:29.177220 [debug] [Thread-3 (]: SQL status: BEGIN in 0.022 seconds
[0m16:38:29.179222 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:38:29.181534 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m16:38:29.184358 [debug] [Thread-4 (]: SQL status: BEGIN in 0.022 seconds
[0m16:38:29.185328 [debug] [Thread-1 (]: SQL status: BEGIN in 0.026 seconds
[0m16:38:29.187250 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m16:38:29.189659 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:38:29.191953 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:38:29.194211 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:38:29.196565 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m16:38:29.199004 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m16:38:29.201796 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m16:38:33.753062 [debug] [Thread-4 (]: SQL status: SELECT 963 in 4.545 seconds
[0m16:38:33.790905 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:38:33.794337 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m16:38:33.799193 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:33.808748 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:38:33.812582 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:38:33.815577 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:38:33.830163 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m16:38:33.841551 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m16:38:33.856417 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:38:33.859714 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m16:38:33.865416 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:38:33.873522 [debug] [Thread-4 (]: On model.idx_stock.dim_companies: Close
[0m16:38:33.878198 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc213920>]}
[0m16:38:33.883399 [info ] [Thread-4 (]: 3 of 9 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 4.90s]
[0m16:38:33.896407 [debug] [Thread-4 (]: Finished running node model.idx_stock.dim_companies
[0m16:38:33.902244 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m16:38:33.908027 [info ] [Thread-4 (]: 6 of 9 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m16:38:33.914451 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.stock_performance_daily)
[0m16:38:33.919451 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m16:38:33.938670 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m16:38:33.960162 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m16:38:33.976236 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m16:38:34.000266 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:38:34.003969 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m16:38:34.007211 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m16:38:34.031088 [debug] [Thread-4 (]: SQL status: BEGIN in 0.024 seconds
[0m16:38:34.034508 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:38:34.038314 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m16:38:34.245124 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.201 seconds
[0m16:38:34.262388 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:38:34.268138 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m16:38:34.274795 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m16:38:34.283258 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:38:34.287371 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:38:34.291442 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:38:34.307089 [debug] [Thread-4 (]: SQL status: COMMIT in 0.012 seconds
[0m16:38:34.326939 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m16:38:34.331970 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:38:34.337057 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m16:38:34.342878 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:38:34.353860 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m16:38:34.361192 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc27be90>]}
[0m16:38:34.365461 [info ] [Thread-4 (]: 6 of 9 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.45s]
[0m16:38:34.374316 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m16:38:34.383074 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m16:38:34.390503 [info ] [Thread-4 (]: 7 of 9 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m16:38:34.394053 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_monthly)
[0m16:38:34.397781 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m16:38:34.419846 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m16:38:34.454998 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m16:38:34.483370 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m16:38:34.514597 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:38:34.521512 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m16:38:34.525715 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m16:38:34.565064 [debug] [Thread-4 (]: SQL status: BEGIN in 0.039 seconds
[0m16:38:34.569858 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:38:34.577064 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m16:38:36.051215 [debug] [Thread-3 (]: SQL status: SELECT 701021 in 6.864 seconds
[0m16:38:36.059669 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:38:36.061740 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m16:38:36.064266 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:36.070282 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:38:36.072735 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:38:36.074712 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:38:36.081310 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m16:38:36.090546 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m16:38:36.093144 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:38:36.095289 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m16:38:36.098136 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:38:36.103340 [debug] [Thread-3 (]: On model.idx_stock.daily_stock_metrics: Close
[0m16:38:36.105789 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc250080>]}
[0m16:38:36.108353 [info ] [Thread-3 (]: 2 of 9 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701021[0m in 7.13s]
[0m16:38:36.110825 [debug] [Thread-3 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m16:38:36.112848 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_weekly
[0m16:38:36.115626 [info ] [Thread-3 (]: 8 of 9 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m16:38:36.119016 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_weekly)
[0m16:38:36.121285 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m16:38:36.129768 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m16:38:36.146273 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m16:38:36.155931 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m16:38:36.172112 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:38:36.174420 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m16:38:36.176561 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:38:36.193281 [debug] [Thread-3 (]: SQL status: BEGIN in 0.017 seconds
[0m16:38:36.195549 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:38:36.198198 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m16:38:42.967206 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.389 seconds
[0m16:38:42.974702 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:38:42.976538 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m16:38:42.979109 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:42.982859 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:38:42.984727 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:38:42.986453 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:38:42.998031 [debug] [Thread-4 (]: SQL status: COMMIT in 0.010 seconds
[0m16:38:43.004354 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m16:38:43.006541 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:38:43.008201 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m16:38:43.010773 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:38:43.018881 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m16:38:43.021114 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc2aa690>]}
[0m16:38:43.023620 [info ] [Thread-4 (]: 7 of 9 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 8.63s]
[0m16:38:43.026300 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m16:38:43.028281 [debug] [Thread-4 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m16:38:43.030426 [info ] [Thread-4 (]: 9 of 9 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m16:38:43.032313 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m16:38:43.034066 [debug] [Thread-4 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m16:38:43.042500 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.054069 [debug] [Thread-4 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m16:38:43.066047 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.078998 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.081773 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m16:38:43.083867 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m16:38:43.102886 [debug] [Thread-4 (]: SQL status: BEGIN in 0.019 seconds
[0m16:38:43.105518 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.108369 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m16:38:43.354530 [debug] [Thread-2 (]: SQL status: SELECT 701021 in 14.148 seconds
[0m16:38:43.365400 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:38:43.367975 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m16:38:43.371393 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:43.375758 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:38:43.377884 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:38:43.380060 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:38:43.420817 [debug] [Thread-2 (]: SQL status: COMMIT in 0.039 seconds
[0m16:38:43.428029 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m16:38:43.431060 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:38:43.433465 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m16:38:43.436504 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:38:43.440715 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m16:38:43.443388 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc2e3ce0>]}
[0m16:38:43.446296 [info ] [Thread-2 (]: 4 of 9 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701021[0m in 14.47s]
[0m16:38:43.449230 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m16:38:43.676844 [debug] [Thread-4 (]: SQL status: SELECT 19276 in 0.566 seconds
[0m16:38:43.684511 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.686752 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m16:38:43.689220 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:43.692729 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:38:43.694927 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.696968 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:38:43.710677 [debug] [Thread-4 (]: SQL status: COMMIT in 0.011 seconds
[0m16:38:43.716818 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m16:38:43.719687 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:38:43.722295 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m16:38:43.726025 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:38:43.731855 [debug] [Thread-4 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m16:38:43.735018 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d252b9b0>]}
[0m16:38:43.738784 [info ] [Thread-4 (]: 9 of 9 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 19276[0m in 0.70s]
[0m16:38:43.743235 [debug] [Thread-4 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m16:38:44.644691 [debug] [Thread-3 (]: SQL status: SELECT 960 in 8.446 seconds
[0m16:38:44.652828 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:38:44.654946 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m16:38:44.657673 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:44.661436 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:38:44.663543 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:38:44.666187 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:38:44.713202 [debug] [Thread-3 (]: SQL status: COMMIT in 0.044 seconds
[0m16:38:44.719357 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m16:38:44.721928 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:38:44.723926 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m16:38:44.726093 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:38:44.731622 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_weekly: Close
[0m16:38:44.734448 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc250200>]}
[0m16:38:44.737098 [info ] [Thread-3 (]: 8 of 9 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 8.62s]
[0m16:38:44.739669 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m16:38:45.616366 [debug] [Thread-1 (]: SQL status: SELECT 700058 in 16.412 seconds
[0m16:38:45.623575 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:38:45.625982 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m16:38:45.628653 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:38:45.632172 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:38:45.634096 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:38:45.636056 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:38:45.672866 [debug] [Thread-1 (]: SQL status: COMMIT in 0.035 seconds
[0m16:38:45.678348 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m16:38:45.680539 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:38:45.682415 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m16:38:45.684779 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:38:45.688427 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m16:38:45.691142 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '78ca5764-790f-4cef-b3e3-358b9c80345e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2cc2ad820>]}
[0m16:38:45.693739 [info ] [Thread-1 (]: 5 of 9 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 700058[0m in 16.71s]
[0m16:38:45.696064 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m16:38:45.700631 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:45.702774 [debug] [MainThread]: On master: BEGIN
[0m16:38:45.704958 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:38:45.717329 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m16:38:45.719477 [debug] [MainThread]: On master: COMMIT
[0m16:38:45.721578 [debug] [MainThread]: Using postgres connection "master"
[0m16:38:45.723543 [debug] [MainThread]: On master: COMMIT
[0m16:38:45.725890 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:38:45.727894 [debug] [MainThread]: On master: Close
[0m16:38:45.730207 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:38:45.732360 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m16:38:45.734371 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m16:38:45.736369 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m16:38:45.738462 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m16:38:45.740795 [info ] [MainThread]: 
[0m16:38:45.743423 [info ] [MainThread]: Finished running 8 table models, 1 view model in 0 hours 0 minutes and 17.48 seconds (17.48s).
[0m16:38:45.749099 [debug] [MainThread]: Command end result
[0m16:38:45.842702 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:38:45.853536 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:38:45.876827 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:38:45.878754 [info ] [MainThread]: 
[0m16:38:45.880777 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:38:45.882832 [info ] [MainThread]: 
[0m16:38:45.884822 [info ] [MainThread]: Done. PASS=9 WARN=0 ERROR=0 SKIP=0 TOTAL=9
[0m16:38:45.888042 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 19.564266, "process_in_blocks": "0", "process_kernel_time": 0.439791, "process_mem_max_rss": "124932", "process_out_blocks": "2360", "process_user_time": 5.807241}
[0m16:38:45.890734 [debug] [MainThread]: Command `dbt run` succeeded at 16:38:45.890285 after 19.57 seconds
[0m16:38:45.893656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0e456a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d15f6240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff2d0b46480>]}
[0m16:38:45.896026 [debug] [MainThread]: Flushing usage events
[0m16:38:47.370500 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:39:05.277155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929db254f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929dc31340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929dcb5160>]}


============================== 16:39:05.296685 | f07e102a-513a-403b-a276-d1f38e339820 ==============================
[0m16:39:05.296685 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:39:05.299013 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:39:05.723054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929d6b5f40>]}
[0m16:39:05.836223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929d97fef0>]}
[0m16:39:05.838850 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:39:06.017206 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:39:06.572693 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:39:06.574796 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:39:06.735610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929c99a990>]}
[0m16:39:07.091321 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:39:07.117290 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:39:07.268594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929c9e8140>]}
[0m16:39:07.279674 [info ] [MainThread]: Found 9 models, 2 data tests, 5 sources, 434 macros
[0m16:39:07.285370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929b9ec9b0>]}
[0m16:39:07.292833 [info ] [MainThread]: 
[0m16:39:07.297648 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:39:07.300830 [info ] [MainThread]: 
[0m16:39:07.303482 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:39:07.321944 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m16:39:07.324753 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:39:07.326578 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m16:39:07.442078 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:39:07.443044 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:39:07.444051 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:39:07.446110 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:39:07.448440 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:39:07.450662 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:39:07.452545 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:07.454860 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:07.456964 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:39:07.472911 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m16:39:07.473964 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m16:39:07.475626 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m16:39:07.476697 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:39:07.479482 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:39:07.481902 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:39:07.484205 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:39:07.486762 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:39:07.489284 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:39:07.498620 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.007 seconds
[0m16:39:07.499789 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m16:39:07.500859 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.007 seconds
[0m16:39:07.504606 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:39:07.508744 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:39:07.513522 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:39:07.516364 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:39:07.518661 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:39:07.520912 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:39:07.541039 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.543527 [debug] [MainThread]: On master: BEGIN
[0m16:39:07.546030 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:39:07.558400 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m16:39:07.560845 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.563495 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:39:07.578872 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m16:39:07.582762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f07e102a-513a-403b-a276-d1f38e339820', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929b527c20>]}
[0m16:39:07.584969 [debug] [MainThread]: On master: ROLLBACK
[0m16:39:07.587239 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.589211 [debug] [MainThread]: On master: BEGIN
[0m16:39:07.591672 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:39:07.593895 [debug] [MainThread]: On master: COMMIT
[0m16:39:07.596426 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.598314 [debug] [MainThread]: On master: COMMIT
[0m16:39:07.600551 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:39:07.602413 [debug] [MainThread]: On master: Close
[0m16:39:07.614656 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:39:07.615646 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:39:07.617543 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m16:39:07.619712 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m16:39:07.622095 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m16:39:07.624202 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m16:39:07.626459 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:39:07.629226 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:39:07.667904 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:39:07.669686 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:39:07.680930 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:39:07.682047 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:39:07.716593 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:39:07.715638 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:39:07.726742 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:39:07.728948 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:39:07.730394 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m16:39:07.732342 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m16:39:07.734263 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:39:07.736217 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:39:07.748160 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m16:39:07.749745 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m16:39:07.750704 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:39:07.752844 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:39:07.754922 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m16:39:07.756956 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m16:39:07.760226 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m16:39:07.768505 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.007 seconds
[0m16:39:07.768101 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m16:39:07.772366 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m16:39:07.774701 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m16:39:07.776771 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m16:39:07.779381 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m16:39:07.781814 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.16s]
[0m16:39:07.784116 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:39:07.786554 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:39:07.792268 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.794231 [debug] [MainThread]: On master: BEGIN
[0m16:39:07.797003 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:39:07.810185 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m16:39:07.812880 [debug] [MainThread]: On master: COMMIT
[0m16:39:07.815743 [debug] [MainThread]: Using postgres connection "master"
[0m16:39:07.817865 [debug] [MainThread]: On master: COMMIT
[0m16:39:07.820402 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:39:07.822912 [debug] [MainThread]: On master: Close
[0m16:39:07.825805 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:39:07.827998 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m16:39:07.830325 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m16:39:07.832812 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m16:39:07.835053 [info ] [MainThread]: 
[0m16:39:07.837171 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.53 seconds (0.53s).
[0m16:39:07.840119 [debug] [MainThread]: Command end result
[0m16:39:07.932186 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:39:07.942587 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:39:07.965413 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:39:07.967751 [info ] [MainThread]: 
[0m16:39:07.970291 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:39:07.972429 [info ] [MainThread]: 
[0m16:39:07.974557 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:39:07.978479 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.9097497, "process_in_blocks": "872", "process_kernel_time": 0.390908, "process_mem_max_rss": "125612", "process_out_blocks": "0", "process_user_time": 5.492762}
[0m16:39:07.981430 [debug] [MainThread]: Command `dbt test` succeeded at 16:39:07.981152 after 2.91 seconds
[0m16:39:07.983589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929d9e4bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f929d9e5820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92998b19a0>]}
[0m16:39:07.985731 [debug] [MainThread]: Flushing usage events
[0m16:39:09.061258 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:37:21.861709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d11040740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d10ffd460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d1206ca70>]}


============================== 18:37:21.882537 | 3425e79a-9e0e-46c8-94ae-8006aa25b82f ==============================
[0m18:37:21.882537 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:37:21.884787 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m18:37:22.559883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3425e79a-9e0e-46c8-94ae-8006aa25b82f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d1278ee10>]}
[0m18:37:22.711601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3425e79a-9e0e-46c8-94ae-8006aa25b82f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d107b9310>]}
[0m18:37:22.715438 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:37:22.924509 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m18:37:23.598936 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 0 files changed.
[0m18:37:23.601242 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m18:37:23.603210 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m18:37:23.605057 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m18:37:23.606901 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/staging/stg_stock_predictions.sql
[0m18:37:23.951194 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stock_prediction_dashboard' (models/marts/analytics/stock_prediction_dashboard.sql) depends on a node named 'fct_daily_stock_metrics' which was not found
[0m18:37:23.954056 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1974802, "process_in_blocks": "4304", "process_kernel_time": 0.774392, "process_mem_max_rss": "114076", "process_out_blocks": "1912", "process_user_time": 4.993839}
[0m18:37:23.956049 [debug] [MainThread]: Command `dbt run` failed at 18:37:23.955878 after 2.20 seconds
[0m18:37:23.957825 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d109efd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d0eb7eb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2d110e8aa0>]}
[0m18:37:23.959572 [debug] [MainThread]: Flushing usage events
[0m18:37:25.298972 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:42:33.095913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59528843b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5952d5eae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5952d5e990>]}


============================== 18:42:33.113533 | 754d8f75-0b5a-4273-9a10-cb90cf55241f ==============================
[0m18:42:33.113533 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:42:33.116303 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m18:42:33.618807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '754d8f75-0b5a-4273-9a10-cb90cf55241f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59525bb8c0>]}
[0m18:42:33.759226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '754d8f75-0b5a-4273-9a10-cb90cf55241f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5952d28110>]}
[0m18:42:33.762774 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:42:34.155215 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m18:42:35.083363 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 5 files added, 0 files changed.
[0m18:42:35.087560 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m18:42:35.089908 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m18:42:35.092554 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_daily_stock_metrics.sql
[0m18:42:35.094758 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m18:42:35.097240 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/staging/stg_stock_predictions.sql
[0m18:42:35.890152 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stock_prediction_dashboard' (models/marts/analytics/stock_prediction_dashboard.sql) depends on a node named 'news_sentiment_metrics' which was not found
[0m18:42:35.895387 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9361804, "process_in_blocks": "0", "process_kernel_time": 0.41268, "process_mem_max_rss": "114116", "process_out_blocks": "0", "process_user_time": 4.932031}
[0m18:42:35.900653 [debug] [MainThread]: Command `dbt run` failed at 18:42:35.899910 after 2.94 seconds
[0m18:42:35.904383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5952cf8920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5951f59e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f595077b800>]}
[0m18:42:35.907302 [debug] [MainThread]: Flushing usage events
[0m18:42:37.406467 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:07:24.272303 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27eb531430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ed509250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ebf9d340>]}


============================== 20:07:24.293100 | 032dfa52-59dc-4174-b174-bdfcb82bf02a ==============================
[0m20:07:24.293100 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:07:24.294747 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging', 'send_anonymous_usage_stats': 'True'}
[0m20:07:24.664256 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '032dfa52-59dc-4174-b174-bdfcb82bf02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ea937b00>]}
[0m20:07:24.780329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '032dfa52-59dc-4174-b174-bdfcb82bf02a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ec96bce0>]}
[0m20:07:24.782803 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:07:24.953931 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:07:25.480633 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 5 files added, 0 files changed.
[0m20:07:25.482240 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m20:07:25.483508 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m20:07:25.484689 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/staging/stg_stock_predictions.sql
[0m20:07:25.485981 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_daily_stock_metrics.sql
[0m20:07:25.487502 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m20:07:25.843875 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stock_prediction_dashboard' (models/marts/analytics/stock_prediction_dashboard.sql) depends on a node named 'news_sentiment_metrics' which was not found
[0m20:07:25.846424 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.7257935, "process_in_blocks": "40", "process_kernel_time": 0.519297, "process_mem_max_rss": "116336", "process_out_blocks": "1912", "process_user_time": 4.134013}
[0m20:07:25.848357 [debug] [MainThread]: Command `dbt run` failed at 20:07:25.848184 after 1.73 seconds
[0m20:07:25.850052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ef06f200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ed0dc530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27ea51f6b0>]}
[0m20:07:25.852116 [debug] [MainThread]: Flushing usage events
[0m20:07:27.219259 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:13:51.473803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a04f0f2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a04ec6d20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a06f53d10>]}


============================== 20:13:51.486142 | e3497641-465f-4beb-b842-094d06f5d73f ==============================
[0m20:13:51.486142 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:13:51.488382 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:13:51.803310 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e3497641-465f-4beb-b842-094d06f5d73f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a04b5e810>]}
[0m20:13:51.901130 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e3497641-465f-4beb-b842-094d06f5d73f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a04bc4ce0>]}
[0m20:13:51.903657 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:13:52.062960 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:13:52.815295 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 5 files added, 0 files changed.
[0m20:13:52.817526 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/staging/stg_stock_predictions.sql
[0m20:13:52.819866 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m20:13:52.822248 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/core/fct_daily_stock_metrics.sql
[0m20:13:52.824097 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m20:13:52.825990 [debug] [MainThread]: Partial parsing: added file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m20:13:53.376505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e3497641-465f-4beb-b842-094d06f5d73f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a033d92b0>]}
[0m20:13:53.571091 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:13:53.586619 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:13:53.658353 [error] [MainThread]: Encountered an error:
Found a cycle: model.idx_stock.stg_stock_predictions
[0m20:13:53.662963 [error] [MainThread]: Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 153, in wrapper
    result, success = func(*args, **kwargs)
                      ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 103, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 235, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 264, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 311, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/requires.py", line 328, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/cli/main.py", line 578, in run
    results = task.run()
              ^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 574, in run
    self._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/compile.py", line 133, in _runtime_initialize
    super()._runtime_initialize()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/runnable.py", line 170, in _runtime_initialize
    self.compile_manifest()
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/task/base.py", line 134, in compile_manifest
    self.graph = self.compiler.compile(self.manifest)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/compilation.py", line 475, in compile
    linker.link_graph(manifest)
  File "/home/airflow/.local/lib/python3.12/site-packages/dbt/compilation.py", line 195, in link_graph
    raise RuntimeError("Found a cycle: {}".format(cycle))
RuntimeError: Found a cycle: model.idx_stock.stg_stock_predictions

[0m20:13:53.666015 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.294005, "process_in_blocks": "16", "process_kernel_time": 0.360323, "process_mem_max_rss": "117544", "process_out_blocks": "448", "process_user_time": 4.403953}
[0m20:13:53.668463 [debug] [MainThread]: Command `dbt run` failed at 20:13:53.668228 after 2.30 seconds
[0m20:13:53.671165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a04c2c350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a02b578c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1a02f4c770>]}
[0m20:13:53.673130 [debug] [MainThread]: Flushing usage events
[0m20:13:55.064600 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:18:42.305706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc438fc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc3920380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc3c64710>]}


============================== 20:18:42.320028 | 17f742d6-7aa9-4a9c-8b84-3ca1826e03ee ==============================
[0m20:18:42.320028 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:18:42.322061 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging', 'send_anonymous_usage_stats': 'True'}
[0m20:18:42.763136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '17f742d6-7aa9-4a9c-8b84-3ca1826e03ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc3cecda0>]}
[0m20:18:42.881641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '17f742d6-7aa9-4a9c-8b84-3ca1826e03ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc3d9bce0>]}
[0m20:18:42.884454 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:18:43.081397 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:18:43.716579 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m20:18:43.718897 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m20:18:43.720951 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m20:18:44.286655 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stock_prediction_dashboard' (models/marts/analytics/stock_prediction_dashboard.sql) depends on a node named 'news_sentiment_metrics' which was not found
[0m20:18:44.291249 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.0945435, "process_in_blocks": "0", "process_kernel_time": 0.418559, "process_mem_max_rss": "114052", "process_out_blocks": "0", "process_user_time": 4.215491}
[0m20:18:44.294726 [debug] [MainThread]: Command `dbt run` failed at 20:18:44.294265 after 2.10 seconds
[0m20:18:44.298691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc438fc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc2d07b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dc43303e0>]}
[0m20:18:44.302215 [debug] [MainThread]: Flushing usage events
[0m20:18:45.736336 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:19:54.160932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bcb7d54c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc9da6480>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bcb710d40>]}


============================== 20:19:54.174072 | ce9396bb-6e77-4ae6-8d7d-f5b57506a17b ==============================
[0m20:19:54.174072 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:19:54.176798 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:19:54.560000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc9251a30>]}
[0m20:19:54.674140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc91d6d80>]}
[0m20:19:54.676930 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:19:54.821870 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:19:55.646169 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m20:19:55.648669 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m20:19:56.264098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc9192b40>]}
[0m20:19:56.515906 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:19:56.536449 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:19:56.591544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc7fe1610>]}
[0m20:19:56.593993 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:19:56.596296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc874f6b0>]}
[0m20:19:56.601368 [info ] [MainThread]: 
[0m20:19:56.604184 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:19:56.606778 [info ] [MainThread]: 
[0m20:19:56.609137 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:19:56.618176 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:19:56.729122 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:19:56.731419 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:19:56.733695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:19:56.749217 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.015 seconds
[0m20:19:56.753433 [debug] [ThreadPool]: On list_airflow: Close
[0m20:19:56.757022 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m20:19:56.759343 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m20:19:56.771766 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m20:19:56.774672 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m20:19:56.776768 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:19:56.791663 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:19:56.793722 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m20:19:56.795706 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m20:19:56.799154 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m20:19:56.802796 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m20:19:56.805228 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m20:19:56.807504 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m20:19:56.814850 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m20:19:56.816963 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m20:19:56.823647 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m20:19:56.825271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m20:19:56.826804 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m20:19:56.842044 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:19:56.846865 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:19:56.852232 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:19:56.855107 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:19:56.857308 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:19:56.859417 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:19:56.861741 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:19:56.863913 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:19:56.866096 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:19:56.881632 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m20:19:56.883744 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:19:56.886081 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m20:19:56.887587 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:19:56.890069 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m20:19:56.891724 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:19:56.895307 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:19:56.897431 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:19:56.899567 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:19:56.903673 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.009 seconds
[0m20:19:56.908168 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:19:56.909336 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m20:19:56.910737 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m20:19:56.911874 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:19:56.915381 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:19:56.919225 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:19:56.923818 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:19:56.926323 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:19:56.944123 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:56.946632 [debug] [MainThread]: On master: BEGIN
[0m20:19:56.948476 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:19:56.963340 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m20:19:56.965899 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:56.968028 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:19:56.976739 [debug] [MainThread]: SQL status: SELECT 0 in 0.006 seconds
[0m20:19:56.980935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc6f2c080>]}
[0m20:19:56.982892 [debug] [MainThread]: On master: ROLLBACK
[0m20:19:56.984869 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:56.986786 [debug] [MainThread]: On master: BEGIN
[0m20:19:56.989693 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:19:56.991601 [debug] [MainThread]: On master: COMMIT
[0m20:19:56.993704 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:56.996202 [debug] [MainThread]: On master: COMMIT
[0m20:19:56.998671 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:19:57.000512 [debug] [MainThread]: On master: Close
[0m20:19:57.013395 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m20:19:57.014540 [debug] [Thread-2 (]: Began running node model.idx_stock.stg_stock_predictions
[0m20:19:57.016621 [info ] [Thread-1 (]: 1 of 2 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m20:19:57.018611 [info ] [Thread-2 (]: 2 of 2 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m20:19:57.020864 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m20:19:57.023533 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m20:19:57.025564 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m20:19:57.027629 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m20:19:57.046837 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.052840 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m20:19:57.063999 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m20:19:57.065705 [debug] [Thread-2 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m20:19:57.234550 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m20:19:57.236220 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.245699 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m20:19:57.248691 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m20:19:57.250291 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.252221 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:19:57.259647 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m20:19:57.263326 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:19:57.276178 [debug] [Thread-2 (]: SQL status: BEGIN in 0.024 seconds
[0m20:19:57.278359 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m20:19:57.280317 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m20:19:57.281562 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m20:19:57.284240 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.288743 [debug] [Thread-2 (]: Postgres adapter: Postgres error: relation "stock_predictions" does not exist
LINE 17: FROM stock_predictions
              ^

[0m20:19:57.290356 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m20:19:57.292773 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: ROLLBACK
[0m20:19:57.296631 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: Close
[0m20:19:57.303084 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m20:19:57.318027 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.323220 [debug] [Thread-2 (]: Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql
[0m20:19:57.324920 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m20:19:57.329556 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc9d18050>]}
[0m20:19:57.332334 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:19:57.333740 [error] [Thread-2 (]: 2 of 2 ERROR creating sql view model public_staging.stg_stock_predictions ...... [[31mERROR[0m in 0.30s]
[0m20:19:57.354413 [debug] [Thread-2 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m20:19:57.370558 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:19:57.372944 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stg_stock_predictions' to be skipped because of status 'error'.  Reason: Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql.
[0m20:19:57.375724 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.380693 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:19:57.386775 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m20:19:57.401425 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m20:19:57.414533 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:19:57.416967 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m20:19:57.419982 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m20:19:57.426222 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m20:19:57.428959 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ce9396bb-6e77-4ae6-8d7d-f5b57506a17b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bcb400920>]}
[0m20:19:57.431400 [info ] [Thread-1 (]: 1 of 2 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.41s]
[0m20:19:57.434127 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m20:19:57.439473 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:57.441704 [debug] [MainThread]: On master: BEGIN
[0m20:19:57.443762 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:19:57.456477 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m20:19:57.458388 [debug] [MainThread]: On master: COMMIT
[0m20:19:57.460268 [debug] [MainThread]: Using postgres connection "master"
[0m20:19:57.462029 [debug] [MainThread]: On master: COMMIT
[0m20:19:57.464059 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:19:57.466042 [debug] [MainThread]: On master: Close
[0m20:19:57.468677 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:19:57.470915 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m20:19:57.473009 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m20:19:57.474781 [debug] [MainThread]: Connection 'model.idx_stock.stg_stock_predictions' was properly closed.
[0m20:19:57.477002 [info ] [MainThread]: 
[0m20:19:57.478995 [info ] [MainThread]: Finished running 2 view models in 0 hours 0 minutes and 0.87 seconds (0.87s).
[0m20:19:57.481887 [debug] [MainThread]: Command end result
[0m20:19:57.575896 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:19:57.590252 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:19:57.618264 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:19:57.621129 [info ] [MainThread]: 
[0m20:19:57.624249 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:19:57.626948 [info ] [MainThread]: 
[0m20:19:57.629662 [error] [MainThread]:   Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql
[0m20:19:57.632245 [info ] [MainThread]: 
[0m20:19:57.635490 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
[0m20:19:57.640574 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.586119, "process_in_blocks": "1456", "process_kernel_time": 0.307096, "process_mem_max_rss": "128280", "process_out_blocks": "0", "process_user_time": 5.159217}
[0m20:19:57.643897 [debug] [MainThread]: Command `dbt run` failed at 20:19:57.643586 after 3.59 seconds
[0m20:19:57.646709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bcacda3f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc734e5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5bc734f590>]}
[0m20:19:57.649659 [debug] [MainThread]: Flushing usage events
[0m20:19:59.019271 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:42:21.769397 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2adaca5130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2adc49c230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2adaca6960>]}


============================== 20:42:21.782134 | c2658a5d-a94a-4078-a205-547d8b3383f3 ==============================
[0m20:42:21.782134 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:42:21.784322 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m20:42:22.115163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad9fa0500>]}
[0m20:42:22.211999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad950abd0>]}
[0m20:42:22.214495 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:42:22.355300 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:42:22.966037 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:42:22.968312 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:42:23.056293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad9540f50>]}
[0m20:42:23.245239 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:42:23.261231 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:42:23.302688 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad8536f90>]}
[0m20:42:23.304802 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:42:23.306817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad9ede060>]}
[0m20:42:23.311965 [info ] [MainThread]: 
[0m20:42:23.314043 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:42:23.316414 [info ] [MainThread]: 
[0m20:42:23.318647 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:42:23.328074 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:42:23.329271 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:42:23.330374 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:42:23.402172 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:42:23.402948 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:42:23.403634 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:42:23.405241 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:42:23.409874 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:42:23.412155 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:42:23.414267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:42:23.416750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:42:23.418695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:42:23.432010 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.018 seconds
[0m20:42:23.435476 [debug] [ThreadPool]: On list_airflow: Close
[0m20:42:23.436271 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.020 seconds
[0m20:42:23.436956 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.018 seconds
[0m20:42:23.441421 [debug] [ThreadPool]: On list_airflow: Close
[0m20:42:23.445085 [debug] [ThreadPool]: On list_airflow: Close
[0m20:42:23.449303 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m20:42:23.450287 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m20:42:23.452332 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m20:42:23.454482 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m20:42:23.464013 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m20:42:23.468571 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m20:42:23.470659 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m20:42:23.472549 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m20:42:23.474352 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:42:23.476360 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:42:23.488069 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m20:42:23.489625 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m20:42:23.490358 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m20:42:23.492181 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m20:42:23.494044 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m20:42:23.495930 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m20:42:23.498690 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m20:42:23.500211 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m20:42:23.502261 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m20:42:23.504746 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m20:42:23.506569 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m20:42:23.508222 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m20:42:23.509984 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m20:42:23.511570 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m20:42:23.518753 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m20:42:23.520407 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m20:42:23.523882 [debug] [ThreadPool]: SQL status: COMMIT in 0.010 seconds
[0m20:42:23.525563 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m20:42:23.530459 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m20:42:23.531838 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_core)
[0m20:42:23.533463 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m20:42:23.543232 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:42:23.549530 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:42:23.554173 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:42:23.556326 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:42:23.558109 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:42:23.560197 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:42:23.562600 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:42:23.564959 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:42:23.567037 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:42:23.579578 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m20:42:23.581581 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:42:23.583906 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:42:23.585435 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m20:42:23.586861 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m20:42:23.589129 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:42:23.591329 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:42:23.592313 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m20:42:23.594123 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:42:23.596412 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:42:23.600668 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:42:23.605729 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:42:23.606626 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m20:42:23.611429 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:42:23.612238 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m20:42:23.614360 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:42:23.618587 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:42:23.622922 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:42:23.637576 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:23.639433 [debug] [MainThread]: On master: BEGIN
[0m20:42:23.641214 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:42:23.656980 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m20:42:23.660272 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:23.663090 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:42:23.681109 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m20:42:23.687486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad8da8b30>]}
[0m20:42:23.690663 [debug] [MainThread]: On master: ROLLBACK
[0m20:42:23.693323 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:23.695585 [debug] [MainThread]: On master: BEGIN
[0m20:42:23.699917 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:42:23.703173 [debug] [MainThread]: On master: COMMIT
[0m20:42:23.705365 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:23.706842 [debug] [MainThread]: On master: COMMIT
[0m20:42:23.708475 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:42:23.710222 [debug] [MainThread]: On master: Close
[0m20:42:23.723260 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m20:42:23.724877 [debug] [Thread-2 (]: Began running node model.idx_stock.stg_stock_predictions
[0m20:42:23.726952 [info ] [Thread-1 (]: 1 of 14 START sql view model public_staging.stg_daily_stock_summary ............ [RUN]
[0m20:42:23.729480 [info ] [Thread-2 (]: 2 of 14 START sql view model public_staging.stg_stock_predictions .............. [RUN]
[0m20:42:23.733540 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m20:42:23.735662 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m20:42:23.737409 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m20:42:23.739056 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m20:42:23.755864 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.761423 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m20:42:23.771351 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m20:42:23.772875 [debug] [Thread-2 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m20:42:23.889754 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m20:42:23.890762 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.901392 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m20:42:23.902636 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.904962 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m20:42:23.906888 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m20:42:23.908676 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:42:23.910530 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:42:23.923137 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m20:42:23.924847 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:42:23.926169 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m20:42:23.927992 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.930091 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m20:42:23.932438 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m20:42:23.935966 [debug] [Thread-2 (]: Postgres adapter: Postgres error: relation "stock_predictions" does not exist
LINE 17: FROM stock_predictions
              ^

[0m20:42:23.938285 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: ROLLBACK
[0m20:42:23.940864 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: Close
[0m20:42:23.941741 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m20:42:23.956942 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.960901 [debug] [Thread-2 (]: Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql
[0m20:42:23.962422 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m20:42:23.967785 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad85e4110>]}
[0m20:42:23.970274 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:23.972052 [error] [Thread-2 (]: 2 of 14 ERROR creating sql view model public_staging.stg_stock_predictions ..... [[31mERROR[0m in 0.23s]
[0m20:42:23.978728 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:23.981723 [debug] [Thread-2 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m20:42:23.984290 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m20:42:23.986794 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stg_stock_predictions' to be skipped because of status 'error'.  Reason: Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql.
[0m20:42:23.989593 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:24.022587 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:42:24.024717 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:24.026720 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:42:24.035355 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m20:42:24.049693 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m20:42:24.059785 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:42:24.062005 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m20:42:24.072308 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.008 seconds
[0m20:42:24.077547 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m20:42:24.079925 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad476b830>]}
[0m20:42:24.082592 [info ] [Thread-1 (]: 1 of 14 OK created sql view model public_staging.stg_daily_stock_summary ....... [[32mCREATE VIEW[0m in 0.35s]
[0m20:42:24.084938 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m20:42:24.087884 [debug] [Thread-4 (]: Began running node model.idx_stock.daily_stock_metrics
[0m20:42:24.088702 [debug] [Thread-3 (]: Began running node model.idx_stock.dim_companies
[0m20:42:24.089485 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m20:42:24.090321 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_macd
[0m20:42:24.091653 [info ] [Thread-4 (]: 3 of 14 START sql table model public_analytics.daily_stock_metrics ............. [RUN]
[0m20:42:24.093635 [info ] [Thread-3 (]: 4 of 14 START sql table model public_core.dim_companies ........................ [RUN]
[0m20:42:24.096039 [info ] [Thread-2 (]: 5 of 14 START sql table model public_core.fct_daily_stock_metrics .............. [RUN]
[0m20:42:24.098622 [info ] [Thread-1 (]: 6 of 14 START sql table model public_analytics.technical_indicators_macd ....... [RUN]
[0m20:42:24.100880 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.daily_stock_metrics'
[0m20:42:24.102941 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.dim_companies)
[0m20:42:24.104760 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.fct_daily_stock_metrics)
[0m20:42:24.106798 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_macd)
[0m20:42:24.108576 [debug] [Thread-4 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m20:42:24.110384 [debug] [Thread-3 (]: Began compiling node model.idx_stock.dim_companies
[0m20:42:24.112190 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m20:42:24.114345 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m20:42:24.120987 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m20:42:24.126764 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m20:42:24.133491 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:24.139450 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m20:42:24.149537 [debug] [Thread-4 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m20:42:24.152005 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m20:42:24.174688 [debug] [Thread-3 (]: Began executing node model.idx_stock.dim_companies
[0m20:42:24.199757 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m20:42:24.200612 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m20:42:24.211460 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m20:42:24.213864 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m20:42:24.221691 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:24.230823 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:42:24.233001 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:42:24.234905 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m20:42:24.236295 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:42:24.237437 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:24.239235 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: BEGIN
[0m20:42:24.241076 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:42:24.243625 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m20:42:24.245913 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m20:42:24.248219 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:42:24.252009 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:42:24.253998 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:42:24.261140 [debug] [Thread-4 (]: SQL status: BEGIN in 0.020 seconds
[0m20:42:24.262810 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:42:24.264691 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m20:42:24.268303 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m20:42:24.269860 [debug] [Thread-3 (]: SQL status: BEGIN in 0.022 seconds
[0m20:42:24.270824 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m20:42:24.271688 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:24.273937 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:42:24.276120 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:42:24.278270 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m20:42:24.280812 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m20:42:24.283613 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m20:42:29.588075 [debug] [Thread-3 (]: SQL status: SELECT 963 in 5.301 seconds
[0m20:42:29.607000 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:42:29.608990 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m20:42:29.612438 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:29.616576 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: COMMIT
[0m20:42:29.618426 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:42:29.620126 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: COMMIT
[0m20:42:29.663547 [debug] [Thread-3 (]: SQL status: COMMIT in 0.042 seconds
[0m20:42:29.669971 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m20:42:29.678378 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:42:29.680717 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m20:42:29.683534 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:42:29.687247 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: Close
[0m20:42:29.689802 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad47c5a30>]}
[0m20:42:29.692706 [info ] [Thread-3 (]: 4 of 14 OK created sql table model public_core.dim_companies ................... [[32mSELECT 963[0m in 5.59s]
[0m20:42:29.696353 [debug] [Thread-3 (]: Finished running node model.idx_stock.dim_companies
[0m20:42:29.698562 [debug] [Thread-3 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m20:42:29.700911 [info ] [Thread-3 (]: 7 of 14 START sql table model public_analytics.technical_indicators_rsi ........ [RUN]
[0m20:42:29.703240 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_rsi)
[0m20:42:29.705550 [debug] [Thread-3 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m20:42:29.713887 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m20:42:29.727850 [debug] [Thread-3 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m20:42:29.735733 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m20:42:29.750797 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:42:29.752622 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m20:42:29.754326 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:42:29.772705 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m20:42:29.774444 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:42:29.776714 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m20:42:33.879777 [debug] [Thread-4 (]: SQL status: SELECT 701981 in 9.613 seconds
[0m20:42:33.887163 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:42:33.888453 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 9.602 seconds
[0m20:42:33.890598 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m20:42:33.899483 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:33.902264 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:33.903943 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m20:42:33.907835 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m20:42:33.910577 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:42:33.912144 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m20:42:34.073485 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.164 seconds
[0m20:42:34.077996 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m20:42:34.080438 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:34.082507 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m20:42:34.083480 [debug] [Thread-4 (]: SQL status: COMMIT in 0.170 seconds
[0m20:42:34.090622 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m20:42:34.091589 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m20:42:34.093727 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:42:34.099446 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m20:42:34.101597 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m20:42:34.104079 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:42:34.106792 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:42:34.108527 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m20:42:34.112185 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: Close
[0m20:42:34.115640 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:42:34.118529 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad47d7c50>]}
[0m20:42:34.124072 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m20:42:34.127062 [info ] [Thread-4 (]: 3 of 14 OK created sql table model public_analytics.daily_stock_metrics ........ [[32mSELECT 701981[0m in 10.02s]
[0m20:42:34.129605 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad47c3c20>]}
[0m20:42:34.132141 [debug] [Thread-4 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m20:42:34.134647 [info ] [Thread-2 (]: 5 of 14 OK created sql table model public_core.fct_daily_stock_metrics ......... [[32mSELECT 701981[0m in 10.02s]
[0m20:42:34.136917 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_daily
[0m20:42:34.139640 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m20:42:34.141896 [info ] [Thread-4 (]: 8 of 14 START sql table model public_analytics.stock_performance_daily ......... [RUN]
[0m20:42:34.144383 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_monthly
[0m20:42:34.146588 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_daily)
[0m20:42:34.148821 [info ] [Thread-2 (]: 9 of 14 START sql table model public_analytics.stock_performance_monthly ....... [RUN]
[0m20:42:34.151038 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m20:42:34.153149 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.fct_daily_stock_metrics, now model.idx_stock.stock_performance_monthly)
[0m20:42:34.161001 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m20:42:34.162777 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m20:42:34.172893 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m20:42:34.180542 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_daily
[0m20:42:34.190474 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m20:42:34.191664 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m20:42:34.198587 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m20:42:34.209992 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:42:34.211657 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:42:34.214001 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m20:42:34.216098 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m20:42:34.218275 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:42:34.220228 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:42:34.249394 [debug] [Thread-2 (]: SQL status: BEGIN in 0.031 seconds
[0m20:42:34.250398 [debug] [Thread-4 (]: SQL status: BEGIN in 0.030 seconds
[0m20:42:34.252072 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:42:34.254123 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:42:34.256735 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m20:42:34.260212 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m20:42:35.008997 [debug] [Thread-4 (]: SQL status: SELECT 960 in 0.745 seconds
[0m20:42:35.019810 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:42:35.022902 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m20:42:35.027508 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:35.031476 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m20:42:35.033614 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:42:35.035992 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m20:42:35.044650 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m20:42:35.051099 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m20:42:35.053621 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:42:35.056221 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m20:42:35.059466 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:42:35.063205 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_daily: Close
[0m20:42:35.065450 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad47e2c90>]}
[0m20:42:35.067990 [info ] [Thread-4 (]: 8 of 14 OK created sql table model public_analytics.stock_performance_daily .... [[32mSELECT 960[0m in 0.92s]
[0m20:42:35.070625 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_daily
[0m20:42:35.073497 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m20:42:35.076393 [info ] [Thread-4 (]: 10 of 14 START sql table model public_analytics.stock_performance_weekly ....... [RUN]
[0m20:42:35.078480 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_weekly)
[0m20:42:35.080389 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m20:42:35.089275 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m20:42:35.107827 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m20:42:35.115844 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m20:42:35.131194 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:42:35.133930 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m20:42:35.135946 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m20:42:35.151184 [debug] [Thread-4 (]: SQL status: BEGIN in 0.015 seconds
[0m20:42:35.152951 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:42:35.155871 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m20:42:41.431108 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 17.147 seconds
[0m20:42:41.442208 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:42:41.444723 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m20:42:41.449564 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:41.455495 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m20:42:41.457874 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:42:41.459981 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m20:42:41.476348 [debug] [Thread-1 (]: SQL status: COMMIT in 0.014 seconds
[0m20:42:41.485096 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m20:42:41.488296 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:42:41.490862 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m20:42:41.493670 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:42:41.499914 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: Close
[0m20:42:41.502716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad47ac140>]}
[0m20:42:41.506304 [info ] [Thread-1 (]: 6 of 14 OK created sql table model public_analytics.technical_indicators_macd .. [[32mSELECT 701981[0m in 17.40s]
[0m20:42:41.510468 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m20:42:41.513690 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m20:42:41.517638 [info ] [Thread-1 (]: 11 of 14 START sql table model public_analytics.news_sentiment_analysis ........ [RUN]
[0m20:42:41.520164 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.technical_indicators_macd, now model.idx_stock.news_sentiment_analysis)
[0m20:42:41.522415 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m20:42:41.533619 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.551432 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m20:42:41.561670 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.581194 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.584411 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m20:42:41.587123 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:42:41.610202 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m20:42:41.612909 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.616958 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m20:42:41.966606 [debug] [Thread-1 (]: SQL status: SELECT 20140 in 0.346 seconds
[0m20:42:41.973255 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.975039 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m20:42:41.977335 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:41.982383 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m20:42:41.984429 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:42:41.986063 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m20:42:42.035127 [debug] [Thread-1 (]: SQL status: COMMIT in 0.047 seconds
[0m20:42:42.046070 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m20:42:42.050496 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:42:42.052997 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m20:42:42.056203 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:42:42.060888 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m20:42:42.063827 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad464e390>]}
[0m20:42:42.067414 [info ] [Thread-1 (]: 11 of 14 OK created sql table model public_analytics.news_sentiment_analysis ... [[32mSELECT 20140[0m in 0.54s]
[0m20:42:42.070693 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m20:42:42.073264 [debug] [Thread-1 (]: Began running node model.idx_stock.fct_stock_predictions
[0m20:42:42.075790 [info ] [Thread-1 (]: 12 of 14 SKIP relation public_core.fct_stock_predictions ....................... [[33mSKIP[0m]
[0m20:42:42.078118 [debug] [Thread-1 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m20:42:42.081595 [debug] [Thread-1 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m20:42:42.084150 [info ] [Thread-1 (]: 13 of 14 SKIP relation public_analytics.lstm_performance_metrics ............... [[33mSKIP[0m]
[0m20:42:42.087748 [debug] [Thread-1 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m20:42:43.360569 [debug] [Thread-2 (]: SQL status: SELECT 960 in 9.102 seconds
[0m20:42:43.368272 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:42:43.370406 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m20:42:43.373028 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:43.379176 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m20:42:43.381928 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:42:43.384200 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m20:42:43.426257 [debug] [Thread-2 (]: SQL status: COMMIT in 0.040 seconds
[0m20:42:43.435865 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m20:42:43.440232 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:42:43.443093 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m20:42:43.446815 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m20:42:43.452633 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_monthly: Close
[0m20:42:43.455741 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad81b3290>]}
[0m20:42:43.459874 [info ] [Thread-2 (]: 9 of 14 OK created sql table model public_analytics.stock_performance_monthly .. [[32mSELECT 960[0m in 9.30s]
[0m20:42:43.464802 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m20:42:44.585500 [debug] [Thread-4 (]: SQL status: SELECT 960 in 9.431 seconds
[0m20:42:44.593045 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:42:44.595689 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m20:42:44.598625 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:44.602482 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m20:42:44.604712 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:42:44.606808 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m20:42:44.652283 [debug] [Thread-4 (]: SQL status: COMMIT in 0.043 seconds
[0m20:42:44.657991 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m20:42:44.660610 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:42:44.662717 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m20:42:44.665208 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:42:44.668757 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m20:42:44.670915 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad81c0410>]}
[0m20:42:44.673609 [info ] [Thread-4 (]: 10 of 14 OK created sql table model public_analytics.stock_performance_weekly .. [[32mSELECT 960[0m in 9.59s]
[0m20:42:44.677136 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m20:42:45.265880 [debug] [Thread-3 (]: SQL status: SELECT 701018 in 15.491 seconds
[0m20:42:45.272432 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:42:45.274465 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m20:42:45.277385 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:42:45.281630 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m20:42:45.283997 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:42:45.285920 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m20:42:45.296072 [debug] [Thread-3 (]: SQL status: COMMIT in 0.008 seconds
[0m20:42:45.301678 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m20:42:45.304084 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:42:45.306000 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m20:42:45.308520 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m20:42:45.312232 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m20:42:45.314651 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c2658a5d-a94a-4078-a205-547d8b3383f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ad60c7c80>]}
[0m20:42:45.317209 [info ] [Thread-3 (]: 7 of 14 OK created sql table model public_analytics.technical_indicators_rsi ... [[32mSELECT 701018[0m in 15.61s]
[0m20:42:45.319771 [debug] [Thread-3 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m20:42:45.322704 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m20:42:45.325240 [info ] [Thread-1 (]: 14 of 14 SKIP relation public_analytics.stock_prediction_dashboard ............. [[33mSKIP[0m]
[0m20:42:45.327353 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m20:42:45.332342 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:45.334431 [debug] [MainThread]: On master: BEGIN
[0m20:42:45.336345 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:42:45.352622 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m20:42:45.354798 [debug] [MainThread]: On master: COMMIT
[0m20:42:45.356785 [debug] [MainThread]: Using postgres connection "master"
[0m20:42:45.358760 [debug] [MainThread]: On master: COMMIT
[0m20:42:45.361118 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:42:45.363201 [debug] [MainThread]: On master: Close
[0m20:42:45.365291 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:42:45.367234 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_monthly' was properly closed.
[0m20:42:45.369121 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m20:42:45.371017 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m20:42:45.372804 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m20:42:45.374797 [info ] [MainThread]: 
[0m20:42:45.376790 [info ] [MainThread]: Finished running 12 table models, 2 view models in 0 hours 0 minutes and 22.06 seconds (22.06s).
[0m20:42:45.382364 [debug] [MainThread]: Command end result
[0m20:42:45.533537 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:42:45.544304 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:42:45.565542 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:42:45.567536 [info ] [MainThread]: 
[0m20:42:45.569502 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m20:42:45.571418 [info ] [MainThread]: 
[0m20:42:45.573509 [error] [MainThread]:   Database Error in model stg_stock_predictions (models/staging/stg_stock_predictions.sql)
  relation "stock_predictions" does not exist
  LINE 17: FROM stock_predictions
                ^
  compiled code at target/run/idx_stock/models/staging/stg_stock_predictions.sql
[0m20:42:45.575331 [info ] [MainThread]: 
[0m20:42:45.577292 [info ] [MainThread]: Done. PASS=10 WARN=0 ERROR=1 SKIP=3 TOTAL=14
[0m20:42:45.579907 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 23.913399, "process_in_blocks": "0", "process_kernel_time": 0.491675, "process_mem_max_rss": "126680", "process_out_blocks": "0", "process_user_time": 5.207746}
[0m20:42:45.582074 [debug] [MainThread]: Command `dbt run` failed at 20:42:45.581857 after 23.92 seconds
[0m20:42:45.584004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2adc80d4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2ada0d6db0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2adaf6be30>]}
[0m20:42:45.586041 [debug] [MainThread]: Flushing usage events
[0m20:42:47.184132 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:51:45.885533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815e3b8aa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81602b4890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815e005be0>]}


============================== 20:51:45.898323 | 618ac83f-929d-4a89-9ec6-afccb871c4c7 ==============================
[0m20:51:45.898323 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:51:45.900341 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m20:51:46.221076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815d3370e0>]}
[0m20:51:46.316006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815e233770>]}
[0m20:51:46.318521 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:51:46.473194 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:51:47.230163 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:51:47.232971 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:51:47.370641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815cf28680>]}
[0m20:51:47.623844 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:51:47.641761 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:51:47.689054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815c32e780>]}
[0m20:51:47.691408 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:51:47.693479 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815c3030e0>]}
[0m20:51:47.698096 [info ] [MainThread]: 
[0m20:51:47.700528 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:51:47.703191 [info ] [MainThread]: 
[0m20:51:47.705518 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:51:47.709812 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:51:47.778560 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:51:47.780702 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:51:47.782738 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:51:47.796833 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.014 seconds
[0m20:51:47.800032 [debug] [ThreadPool]: On list_airflow: Close
[0m20:51:47.811639 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m20:51:47.814204 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m20:51:47.815636 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m20:51:47.826596 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:51:47.830951 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:51:47.836188 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:51:47.838393 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:51:47.840118 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:51:47.842012 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:51:47.843844 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:51:47.845358 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:51:47.847415 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:51:47.860302 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m20:51:47.862011 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m20:51:47.863447 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:51:47.864364 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m20:51:47.865935 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:51:47.868090 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:51:47.870545 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:51:47.872568 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:51:47.875648 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:51:47.880590 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m20:51:47.881303 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m20:51:47.882238 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m20:51:47.885554 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:51:47.889389 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:51:47.892854 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:51:47.895288 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:51:47.897186 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:51:47.899049 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:51:47.916161 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:47.918433 [debug] [MainThread]: On master: BEGIN
[0m20:51:47.920625 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:51:47.932170 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:51:47.934438 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:47.937009 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:51:47.957692 [debug] [MainThread]: SQL status: SELECT 1 in 0.018 seconds
[0m20:51:47.961442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815dd9e8a0>]}
[0m20:51:47.963391 [debug] [MainThread]: On master: ROLLBACK
[0m20:51:47.965413 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:47.967219 [debug] [MainThread]: On master: BEGIN
[0m20:51:47.970212 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:51:47.972065 [debug] [MainThread]: On master: COMMIT
[0m20:51:47.974012 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:47.975785 [debug] [MainThread]: On master: COMMIT
[0m20:51:47.977886 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:51:47.979564 [debug] [MainThread]: On master: Close
[0m20:51:47.988895 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m20:51:47.991185 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m20:51:47.993179 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m20:51:47.995093 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m20:51:48.010613 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.025249 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m20:51:48.092411 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.108334 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.109979 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m20:51:48.111454 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:51:48.124698 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m20:51:48.126765 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.128950 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m20:51:48.137708 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m20:51:48.148990 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.151193 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m20:51:48.154614 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:51:48.160734 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.162711 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m20:51:48.165516 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:51:48.196350 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:51:48.198595 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.200499 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m20:51:48.205317 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m20:51:48.216691 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m20:51:48.226854 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m20:51:48.228961 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m20:51:48.238034 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m20:51:48.242821 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m20:51:48.246401 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '618ac83f-929d-4a89-9ec6-afccb871c4c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815aff3da0>]}
[0m20:51:48.248929 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.25s]
[0m20:51:48.251451 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m20:51:48.255627 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:48.257495 [debug] [MainThread]: On master: BEGIN
[0m20:51:48.259219 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:51:48.270563 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m20:51:48.272567 [debug] [MainThread]: On master: COMMIT
[0m20:51:48.274396 [debug] [MainThread]: Using postgres connection "master"
[0m20:51:48.276155 [debug] [MainThread]: On master: COMMIT
[0m20:51:48.278132 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:51:48.279911 [debug] [MainThread]: On master: Close
[0m20:51:48.281892 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:51:48.283497 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m20:51:48.285797 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m20:51:48.287664 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m20:51:48.289469 [info ] [MainThread]: 
[0m20:51:48.291288 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.58 seconds (0.58s).
[0m20:51:48.293647 [debug] [MainThread]: Command end result
[0m20:51:48.373907 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:51:48.383694 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:51:48.402941 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:51:48.404871 [info ] [MainThread]: 
[0m20:51:48.406725 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:51:48.408632 [info ] [MainThread]: 
[0m20:51:48.410372 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m20:51:48.413135 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.6202922, "process_in_blocks": "200", "process_kernel_time": 0.355593, "process_mem_max_rss": "121768", "process_out_blocks": "0", "process_user_time": 4.653193}
[0m20:51:48.415649 [debug] [MainThread]: Command `dbt run` succeeded at 20:51:48.415436 after 2.62 seconds
[0m20:51:48.417698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815e631dc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815de5d550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f815c342660>]}
[0m20:51:48.420061 [debug] [MainThread]: Flushing usage events
[0m20:51:50.175911 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:51:58.795838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc6d40d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc6439ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc63bebd0>]}


============================== 20:51:58.807953 | b39b7dc4-0c95-414b-865a-e3ace66c8bd4 ==============================
[0m20:51:58.807953 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:51:58.810124 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'send_anonymous_usage_stats': 'True'}
[0m20:51:59.141903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc5edd280>]}
[0m20:51:59.255663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc5edf410>]}
[0m20:51:59.258374 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:51:59.439865 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:52:00.133559 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:52:00.135434 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:52:00.228870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc53aabd0>]}
[0m20:52:00.431780 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:52:00.448323 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:52:00.491830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc4b28bf0>]}
[0m20:52:00.494603 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:52:00.496721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc53aacc0>]}
[0m20:52:00.501139 [info ] [MainThread]: 
[0m20:52:00.503132 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:52:00.504979 [info ] [MainThread]: 
[0m20:52:00.506902 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:52:00.516228 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:52:00.579158 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:52:00.581153 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:52:00.583030 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:00.595804 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.013 seconds
[0m20:52:00.599135 [debug] [ThreadPool]: On list_airflow: Close
[0m20:52:00.604208 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m20:52:00.605460 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m20:52:00.606743 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m20:52:00.617358 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:52:00.621558 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:52:00.626946 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:52:00.629042 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:52:00.630972 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:52:00.632704 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:52:00.634434 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:52:00.636240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:00.638042 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:00.650080 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m20:52:00.651610 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:52:00.652356 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:52:00.653802 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m20:52:00.655060 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:52:00.657148 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:52:00.659793 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:52:00.661798 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:52:00.664588 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:52:00.667238 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m20:52:00.670472 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:52:00.671231 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m20:52:00.672159 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m20:52:00.674059 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:52:00.677937 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:52:00.681141 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:52:00.687655 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:52:00.689186 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:52:00.704678 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:00.706744 [debug] [MainThread]: On master: BEGIN
[0m20:52:00.708505 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:52:00.723274 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m20:52:00.725334 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:00.728275 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:52:00.743177 [debug] [MainThread]: SQL status: SELECT 1 in 0.012 seconds
[0m20:52:00.747255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc4bd0770>]}
[0m20:52:00.749304 [debug] [MainThread]: On master: ROLLBACK
[0m20:52:00.751419 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:00.753314 [debug] [MainThread]: On master: BEGIN
[0m20:52:00.755854 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:52:00.758458 [debug] [MainThread]: On master: COMMIT
[0m20:52:00.760584 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:00.762593 [debug] [MainThread]: On master: COMMIT
[0m20:52:00.764879 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:52:00.766828 [debug] [MainThread]: On master: Close
[0m20:52:00.775677 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m20:52:00.776944 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m20:52:00.779349 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m20:52:00.782111 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m20:52:00.784157 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.dim_companies)
[0m20:52:00.786218 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_daily_stock_metrics)
[0m20:52:00.788181 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m20:52:00.790277 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m20:52:00.805876 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m20:52:00.817406 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:00.827469 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m20:52:00.836407 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m20:52:00.981935 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:00.985332 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m20:52:00.994767 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:00.996582 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:00.998431 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m20:52:01.000648 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m20:52:01.002654 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:52:01.004753 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:52:01.021913 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m20:52:01.024157 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:01.026723 [debug] [Thread-2 (]: SQL status: BEGIN in 0.024 seconds
[0m20:52:01.028199 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m20:52:01.030806 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:01.035011 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m20:52:05.782720 [debug] [Thread-1 (]: SQL status: SELECT 963 in 4.748 seconds
[0m20:52:05.819479 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:05.822108 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m20:52:05.824740 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:05.831845 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:05.834234 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m20:52:05.836919 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:05.876664 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m20:52:05.879082 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:05.880989 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m20:52:05.904211 [debug] [Thread-1 (]: SQL status: COMMIT in 0.021 seconds
[0m20:52:05.920002 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m20:52:05.931841 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m20:52:05.933767 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m20:52:05.943819 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.008 seconds
[0m20:52:05.951379 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m20:52:05.958478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc83571a0>]}
[0m20:52:05.962977 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 5.17s]
[0m20:52:05.965993 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m20:52:06.537092 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 5.499 seconds
[0m20:52:06.544606 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:06.546884 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics" rename to "fct_daily_stock_metrics__dbt_backup"
[0m20:52:06.549767 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:06.557415 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:06.559802 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m20:52:06.562541 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:52:06.566593 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m20:52:06.568773 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:06.571131 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m20:52:06.578890 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m20:52:06.587702 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m20:52:06.590248 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m20:52:06.592124 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m20:52:06.623123 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.029 seconds
[0m20:52:06.626967 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m20:52:06.629100 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b39b7dc4-0c95-414b-865a-e3ace66c8bd4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc31c8ad0>]}
[0m20:52:06.631362 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 5.84s]
[0m20:52:06.634010 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m20:52:06.640200 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:06.642069 [debug] [MainThread]: On master: BEGIN
[0m20:52:06.643812 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:52:06.660305 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m20:52:06.662612 [debug] [MainThread]: On master: COMMIT
[0m20:52:06.664539 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:06.666766 [debug] [MainThread]: On master: COMMIT
[0m20:52:06.669145 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:52:06.671789 [debug] [MainThread]: On master: Close
[0m20:52:06.675096 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:52:06.677906 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m20:52:06.679924 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m20:52:06.681942 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m20:52:06.684431 [info ] [MainThread]: 
[0m20:52:06.686998 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 6.18 seconds (6.18s).
[0m20:52:06.690396 [debug] [MainThread]: Command end result
[0m20:52:06.779608 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:52:06.793646 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:52:06.812972 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:52:06.815065 [info ] [MainThread]: 
[0m20:52:06.817752 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:52:06.820463 [info ] [MainThread]: 
[0m20:52:06.823271 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:52:06.827131 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.130703, "process_in_blocks": "0", "process_kernel_time": 0.381966, "process_mem_max_rss": "121516", "process_out_blocks": "0", "process_user_time": 4.664012}
[0m20:52:06.829676 [debug] [MainThread]: Command `dbt run` succeeded at 20:52:06.829419 after 8.13 seconds
[0m20:52:06.831798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc64a03b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc63c3560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6bc63c18b0>]}
[0m20:52:06.833876 [debug] [MainThread]: Flushing usage events
[0m20:52:08.132897 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:52:17.024627 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5843c44350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5843ba1a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5843ec77d0>]}


============================== 20:52:17.040349 | f966fe10-13c2-4ef6-a813-de537763663b ==============================
[0m20:52:17.040349 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:52:17.042886 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m20:52:17.429443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f584390d250>]}
[0m20:52:17.550503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5843f5ce30>]}
[0m20:52:17.558859 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:52:17.727753 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:52:18.280843 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:52:18.282780 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:52:18.368974 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5842bec290>]}
[0m20:52:18.553981 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:52:18.569010 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:52:18.608255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5841fe64e0>]}
[0m20:52:18.610458 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:52:18.612363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5842b8deb0>]}
[0m20:52:18.616950 [info ] [MainThread]: 
[0m20:52:18.618863 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:52:18.620788 [info ] [MainThread]: 
[0m20:52:18.622930 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:52:18.632638 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m20:52:18.695758 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m20:52:18.697516 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m20:52:18.699086 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:18.713950 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.015 seconds
[0m20:52:18.717108 [debug] [ThreadPool]: On list_airflow: Close
[0m20:52:18.721878 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m20:52:18.723023 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m20:52:18.725303 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m20:52:18.734982 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:52:18.738749 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:52:18.743768 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:52:18.746009 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:52:18.747653 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:52:18.749352 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:52:18.750765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m20:52:18.752293 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:18.753838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:52:18.765449 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m20:52:18.767258 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:52:18.768923 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:52:18.770908 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m20:52:18.771724 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m20:52:18.773230 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:52:18.775072 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m20:52:18.775975 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:52:18.778052 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:52:18.781431 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:52:18.783315 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:52:18.786455 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:52:18.789451 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m20:52:18.791994 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m20:52:18.794636 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:52:18.798382 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:52:18.800255 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:52:18.801783 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:52:18.816702 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:18.818408 [debug] [MainThread]: On master: BEGIN
[0m20:52:18.820254 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:52:18.832380 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:52:18.834404 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:18.837232 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:52:18.850172 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m20:52:18.854234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5840b71490>]}
[0m20:52:18.856313 [debug] [MainThread]: On master: ROLLBACK
[0m20:52:18.858645 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:18.860960 [debug] [MainThread]: On master: BEGIN
[0m20:52:18.863868 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:52:18.865767 [debug] [MainThread]: On master: COMMIT
[0m20:52:18.867660 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:18.869988 [debug] [MainThread]: On master: COMMIT
[0m20:52:18.872389 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:52:18.874274 [debug] [MainThread]: On master: Close
[0m20:52:18.883263 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m20:52:18.884367 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m20:52:18.885385 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m20:52:18.886350 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m20:52:18.887929 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m20:52:18.890638 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m20:52:18.893491 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m20:52:18.896468 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m20:52:18.898751 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m20:52:18.900892 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_daily)
[0m20:52:18.902884 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m20:52:18.904959 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m20:52:18.906926 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m20:52:18.908930 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m20:52:18.911608 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m20:52:18.913748 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m20:52:18.930278 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m20:52:18.936543 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m20:52:18.943631 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m20:52:18.950825 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m20:52:18.961879 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m20:52:18.963955 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m20:52:18.976148 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m20:52:18.987326 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m20:52:19.067529 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m20:52:19.072858 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m20:52:19.079778 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m20:52:19.085559 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m20:52:19.097262 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.098481 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:19.100334 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m20:52:19.101799 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:19.103870 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:19.105176 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m20:52:19.111900 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:52:19.116044 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m20:52:19.122146 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m20:52:19.128505 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m20:52:19.140160 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:52:19.147023 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:52:19.153195 [debug] [Thread-2 (]: SQL status: BEGIN in 0.041 seconds
[0m20:52:19.158107 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.161198 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m20:52:19.166058 [debug] [Thread-4 (]: SQL status: BEGIN in 0.038 seconds
[0m20:52:19.168986 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:19.171498 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m20:52:19.180599 [debug] [Thread-3 (]: SQL status: BEGIN in 0.040 seconds
[0m20:52:19.181611 [debug] [Thread-1 (]: SQL status: BEGIN in 0.035 seconds
[0m20:52:19.183440 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:19.185462 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:19.188012 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m20:52:19.190823 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m20:52:19.560090 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.397 seconds
[0m20:52:19.587185 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.589812 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m20:52:19.593470 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:19.606917 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.609465 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m20:52:19.612154 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:19.668041 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m20:52:19.671115 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.673327 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m20:52:19.683901 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m20:52:19.699006 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m20:52:19.712277 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m20:52:19.715089 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m20:52:19.725723 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.008 seconds
[0m20:52:19.737214 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m20:52:19.746480 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5845a8a060>]}
[0m20:52:19.750890 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.84s]
[0m20:52:19.754599 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m20:52:19.758395 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m20:52:19.762003 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m20:52:19.765165 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m20:52:19.767696 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m20:52:19.779891 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m20:52:19.799382 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m20:52:19.814135 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m20:52:19.833123 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:19.835841 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m20:52:19.838393 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:52:19.856767 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m20:52:19.860336 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:19.863789 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m20:52:25.417352 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 6.223 seconds
[0m20:52:25.428855 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:25.432076 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m20:52:25.438675 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:25.461493 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:25.464854 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m20:52:25.470346 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m20:52:25.484611 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m20:52:25.488119 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:25.499620 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m20:52:25.513959 [debug] [Thread-1 (]: SQL status: COMMIT in 0.011 seconds
[0m20:52:25.533150 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m20:52:25.536556 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m20:52:25.550018 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m20:52:25.594871 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.042 seconds
[0m20:52:25.601281 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m20:52:25.612459 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5842bb73e0>]}
[0m20:52:25.615963 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 6.71s]
[0m20:52:25.619757 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m20:52:25.623111 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m20:52:25.626679 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m20:52:25.629511 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m20:52:25.631900 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m20:52:25.643135 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m20:52:25.659744 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m20:52:25.668535 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m20:52:25.684811 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:25.687757 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m20:52:25.689988 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:52:25.703841 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m20:52:25.706746 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:25.709156 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m20:52:26.633975 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.440 seconds
[0m20:52:26.644781 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:26.647032 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m20:52:26.649499 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:26.660846 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:26.664359 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m20:52:26.666987 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:26.673574 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m20:52:26.680458 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:26.683230 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m20:52:26.691151 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m20:52:26.698030 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m20:52:26.700378 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m20:52:26.703599 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m20:52:26.710916 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m20:52:26.716253 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m20:52:26.719456 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58397009b0>]}
[0m20:52:26.722781 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 7.82s]
[0m20:52:26.726124 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m20:52:26.728624 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m20:52:26.731293 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m20:52:26.733988 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m20:52:26.736734 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m20:52:26.746220 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m20:52:26.762195 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m20:52:26.772363 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m20:52:26.790489 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:26.793262 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m20:52:26.795933 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m20:52:26.815271 [debug] [Thread-3 (]: SQL status: BEGIN in 0.019 seconds
[0m20:52:26.817756 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:26.821126 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m20:52:27.397489 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.223 seconds
[0m20:52:27.409484 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:27.412267 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m20:52:27.416676 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:27.430649 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:27.433306 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m20:52:27.437309 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:27.443064 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m20:52:27.445810 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:27.448731 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m20:52:27.466347 [debug] [Thread-4 (]: SQL status: COMMIT in 0.013 seconds
[0m20:52:27.474616 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m20:52:27.477735 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m20:52:27.480943 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m20:52:27.493621 [debug] [Thread-3 (]: SQL status: SELECT 20140 in 0.669 seconds
[0m20:52:27.496715 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.012 seconds
[0m20:52:27.509808 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:27.514688 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m20:52:27.517740 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m20:52:27.521834 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58409cb6b0>]}
[0m20:52:27.525581 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:27.527184 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 8.62s]
[0m20:52:27.534782 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:27.537350 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m20:52:27.539523 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m20:52:27.543129 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:27.546974 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m20:52:27.549192 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:27.551029 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m20:52:27.557344 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m20:52:27.563249 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m20:52:27.565689 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m20:52:27.567486 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m20:52:27.574073 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m20:52:27.578112 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m20:52:27.580528 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5840953bf0>]}
[0m20:52:27.583276 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 20140[0m in 0.85s]
[0m20:52:27.586243 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m20:52:30.623514 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 10.757 seconds
[0m20:52:30.630354 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:30.632335 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m20:52:30.635312 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:30.641940 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:30.643993 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m20:52:30.646366 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m20:52:30.650227 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m20:52:30.652647 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:30.654546 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m20:52:30.664328 [debug] [Thread-2 (]: SQL status: COMMIT in 0.008 seconds
[0m20:52:30.672636 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m20:52:30.675117 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m20:52:30.677404 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m20:52:30.694430 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.015 seconds
[0m20:52:30.698088 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m20:52:30.700601 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58397802c0>]}
[0m20:52:30.703353 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 10.94s]
[0m20:52:30.705795 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m20:52:36.249273 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 10.537 seconds
[0m20:52:36.263106 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:36.266098 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m20:52:36.269409 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:36.276676 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:36.279416 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m20:52:36.282591 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m20:52:36.286731 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m20:52:36.289026 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:36.291275 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m20:52:36.302374 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m20:52:36.308654 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m20:52:36.311395 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m20:52:36.314049 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m20:52:36.330542 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.014 seconds
[0m20:52:36.334759 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m20:52:36.337742 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f966fe10-13c2-4ef6-a813-de537763663b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5840a7c470>]}
[0m20:52:36.340808 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 10.71s]
[0m20:52:36.343931 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m20:52:36.349977 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:36.352124 [debug] [MainThread]: On master: BEGIN
[0m20:52:36.354077 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:52:36.367554 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m20:52:36.369697 [debug] [MainThread]: On master: COMMIT
[0m20:52:36.371682 [debug] [MainThread]: Using postgres connection "master"
[0m20:52:36.373594 [debug] [MainThread]: On master: COMMIT
[0m20:52:36.376102 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:52:36.378106 [debug] [MainThread]: On master: Close
[0m20:52:36.381165 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:52:36.383283 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m20:52:36.385294 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m20:52:36.387250 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m20:52:36.389109 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m20:52:36.391319 [info ] [MainThread]: 
[0m20:52:36.393357 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 17.77 seconds (17.77s).
[0m20:52:36.398846 [debug] [MainThread]: Command end result
[0m20:52:36.490579 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:52:36.503383 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:52:36.525247 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:52:36.527341 [info ] [MainThread]: 
[0m20:52:36.529872 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:52:36.532144 [info ] [MainThread]: 
[0m20:52:36.534407 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m20:52:36.537926 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 19.638136, "process_in_blocks": "8", "process_kernel_time": 0.476933, "process_mem_max_rss": "122128", "process_out_blocks": "0", "process_user_time": 5.355562}
[0m20:52:36.540781 [debug] [MainThread]: Command `dbt run` succeeded at 20:52:36.540528 after 19.64 seconds
[0m20:52:36.543063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5843c44350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5840b71340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58445ae720>]}
[0m20:52:36.545320 [debug] [MainThread]: Flushing usage events
[0m20:52:37.862664 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m20:53:03.947374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1fd617f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1de47380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1dc1b590>]}


============================== 20:53:03.972396 | cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe ==============================
[0m20:53:03.972396 [info ] [MainThread]: Running with dbt=1.9.4
[0m20:53:03.976050 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m20:53:04.513947 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1d787ec0>]}
[0m20:53:04.635488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1dd6be30>]}
[0m20:53:04.638296 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m20:53:04.797624 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m20:53:05.356879 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:53:05.358708 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:53:05.453910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1cdf6d80>]}
[0m20:53:05.700661 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:53:05.715982 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:53:05.823478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1b94d7c0>]}
[0m20:53:05.826118 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m20:53:05.828725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1b92ef30>]}
[0m20:53:05.836981 [info ] [MainThread]: 
[0m20:53:05.839141 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m20:53:05.840970 [info ] [MainThread]: 
[0m20:53:05.843257 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m20:53:05.855156 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m20:53:05.856681 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m20:53:05.858071 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m20:53:05.945212 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:53:05.946215 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:53:05.947081 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:53:05.948791 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m20:53:05.950689 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m20:53:05.953025 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m20:53:05.955444 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:53:05.957485 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:53:05.959677 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:53:05.975671 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m20:53:05.976601 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m20:53:05.978318 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m20:53:05.979434 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m20:53:05.981250 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m20:53:05.983745 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m20:53:05.986008 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m20:53:05.988113 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m20:53:05.990301 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m20:53:05.997598 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m20:53:05.998861 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m20:53:05.999746 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m20:53:06.003362 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m20:53:06.007175 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m20:53:06.010959 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m20:53:06.013304 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m20:53:06.015064 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m20:53:06.016895 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m20:53:06.035296 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.037636 [debug] [MainThread]: On master: BEGIN
[0m20:53:06.040360 [debug] [MainThread]: Opening a new connection, currently in state init
[0m20:53:06.052815 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:53:06.055274 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.057975 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m20:53:06.071457 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m20:53:06.075747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb6230b3-39cb-4bb2-91d9-c11e1d7bcdbe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1d7866c0>]}
[0m20:53:06.078459 [debug] [MainThread]: On master: ROLLBACK
[0m20:53:06.081127 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.083369 [debug] [MainThread]: On master: BEGIN
[0m20:53:06.086204 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m20:53:06.088598 [debug] [MainThread]: On master: COMMIT
[0m20:53:06.090784 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.092812 [debug] [MainThread]: On master: COMMIT
[0m20:53:06.095142 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:53:06.097197 [debug] [MainThread]: On master: Close
[0m20:53:06.107884 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m20:53:06.108963 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m20:53:06.110974 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m20:53:06.113131 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m20:53:06.115445 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m20:53:06.117880 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m20:53:06.120682 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m20:53:06.124882 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m20:53:06.173875 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m20:53:06.179882 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m20:53:06.190183 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m20:53:06.198363 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m20:53:06.233842 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m20:53:06.251002 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m20:53:06.259325 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m20:53:06.261458 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m20:53:06.262740 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m20:53:06.264558 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m20:53:06.266654 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m20:53:06.270348 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m20:53:06.279738 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m20:53:06.281838 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m20:53:06.283593 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m20:53:06.284998 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m20:53:06.287333 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m20:53:06.291095 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m20:53:06.292054 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m20:53:06.300897 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.007 seconds
[0m20:53:06.303100 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m20:53:06.307309 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m20:53:06.309751 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m20:53:06.311610 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m20:53:06.313695 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.20s]
[0m20:53:06.315981 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.20s]
[0m20:53:06.318974 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m20:53:06.321756 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m20:53:06.327969 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.329967 [debug] [MainThread]: On master: BEGIN
[0m20:53:06.331781 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m20:53:06.344197 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m20:53:06.346311 [debug] [MainThread]: On master: COMMIT
[0m20:53:06.348247 [debug] [MainThread]: Using postgres connection "master"
[0m20:53:06.350229 [debug] [MainThread]: On master: COMMIT
[0m20:53:06.352641 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m20:53:06.354775 [debug] [MainThread]: On master: Close
[0m20:53:06.357030 [debug] [MainThread]: Connection 'master' was properly closed.
[0m20:53:06.359089 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m20:53:06.362210 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m20:53:06.364420 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m20:53:06.366266 [info ] [MainThread]: 
[0m20:53:06.368157 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.52 seconds (0.52s).
[0m20:53:06.370922 [debug] [MainThread]: Command end result
[0m20:53:06.454759 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m20:53:06.464722 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m20:53:06.484260 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m20:53:06.486262 [info ] [MainThread]: 
[0m20:53:06.488528 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:53:06.490543 [info ] [MainThread]: 
[0m20:53:06.492549 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m20:53:06.495717 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.6935015, "process_in_blocks": "1016", "process_kernel_time": 0.371837, "process_mem_max_rss": "123788", "process_out_blocks": "0", "process_user_time": 5.225829}
[0m20:53:06.498137 [debug] [MainThread]: Command `dbt test` succeeded at 20:53:06.497893 after 2.70 seconds
[0m20:53:06.500244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1e07e870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1e4593a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1b1f97b0e0>]}
[0m20:53:06.502440 [debug] [MainThread]: Flushing usage events
[0m20:53:08.035085 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:22:45.782033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41dacc6ab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41dbb99250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da511430>]}


============================== 21:22:45.801485 | 9c5ef15a-d969-415e-82fe-7cba87c57f99 ==============================
[0m21:22:45.801485 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:22:45.804536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt', 'send_anonymous_usage_stats': 'True'}
[0m21:22:46.252544 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da0edf10>]}
[0m21:22:46.369968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da1c9280>]}
[0m21:22:46.372511 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:22:46.532237 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:22:47.177801 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:22:47.179942 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:22:47.276447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d93e74d0>]}
[0m21:22:47.481409 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:22:47.508813 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:22:47.553583 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d831b5c0>]}
[0m21:22:47.555861 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m21:22:47.558095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d87f6000>]}
[0m21:22:47.565021 [info ] [MainThread]: 
[0m21:22:47.567699 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:22:47.569729 [info ] [MainThread]: 
[0m21:22:47.571965 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:22:47.584322 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:22:47.586057 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:22:47.587653 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:22:47.674632 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:22:47.675963 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:22:47.676747 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:22:47.678456 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:22:47.680523 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:22:47.682547 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:22:47.684423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:22:47.686595 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:22:47.688465 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:22:47.704906 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m21:22:47.705781 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.021 seconds
[0m21:22:47.706496 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m21:22:47.710128 [debug] [ThreadPool]: On list_airflow: Close
[0m21:22:47.713419 [debug] [ThreadPool]: On list_airflow: Close
[0m21:22:47.716574 [debug] [ThreadPool]: On list_airflow: Close
[0m21:22:47.724944 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m21:22:47.726565 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m21:22:47.727793 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m21:22:47.737810 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:22:47.742352 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:22:47.747190 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:22:47.749174 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m21:22:47.751002 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m21:22:47.752930 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m21:22:47.754621 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:22:47.756482 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:22:47.758290 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:22:47.770749 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m21:22:47.772101 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m21:22:47.773340 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:22:47.774794 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m21:22:47.776151 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:22:47.778246 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m21:22:47.780162 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:22:47.781936 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m21:22:47.785189 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m21:22:47.788993 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m21:22:47.793891 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m21:22:47.794660 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m21:22:47.795375 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.007 seconds
[0m21:22:47.797192 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m21:22:47.799839 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m21:22:47.802921 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m21:22:47.808803 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m21:22:47.810929 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m21:22:47.825122 [debug] [MainThread]: Using postgres connection "master"
[0m21:22:47.827569 [debug] [MainThread]: On master: BEGIN
[0m21:22:47.829346 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:22:47.840871 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m21:22:47.843628 [debug] [MainThread]: Using postgres connection "master"
[0m21:22:47.845619 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:22:47.856478 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m21:22:47.860381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d8b9d280>]}
[0m21:22:47.862349 [debug] [MainThread]: On master: ROLLBACK
[0m21:22:47.864326 [debug] [MainThread]: Using postgres connection "master"
[0m21:22:47.865990 [debug] [MainThread]: On master: BEGIN
[0m21:22:47.869121 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:22:47.870905 [debug] [MainThread]: On master: COMMIT
[0m21:22:47.872610 [debug] [MainThread]: Using postgres connection "master"
[0m21:22:47.874230 [debug] [MainThread]: On master: COMMIT
[0m21:22:47.876945 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:22:47.878620 [debug] [MainThread]: On master: Close
[0m21:22:47.885827 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m21:22:47.886579 [debug] [Thread-2 (]: Began running node model.idx_stock.stg_stock_predictions
[0m21:22:47.888264 [info ] [Thread-1 (]: 1 of 14 START sql view model public_staging.stg_daily_stock_summary ............ [RUN]
[0m21:22:47.890223 [info ] [Thread-2 (]: 2 of 14 START sql view model public_staging.stg_stock_predictions .............. [RUN]
[0m21:22:47.892924 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m21:22:47.894975 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m21:22:47.896705 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m21:22:47.898404 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m21:22:47.911780 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m21:22:47.915994 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m21:22:47.922967 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m21:22:47.924419 [debug] [Thread-2 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m21:22:48.006723 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m21:22:48.012497 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.021106 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:22:48.022435 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.024410 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m21:22:48.027340 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m21:22:48.029517 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:22:48.031502 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:22:48.048120 [debug] [Thread-2 (]: SQL status: BEGIN in 0.019 seconds
[0m21:22:48.050241 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m21:22:48.051140 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:22:48.053069 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.055087 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m21:22:48.057056 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m21:22:48.064177 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m21:22:48.074167 [debug] [Thread-2 (]: SQL status: CREATE VIEW in 0.014 seconds
[0m21:22:48.078004 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.084004 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:22:48.085988 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m21:22:48.088062 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m21:22:48.091102 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:48.092850 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:48.098097 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.127755 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m21:22:48.148094 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m21:22:48.149274 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m21:22:48.151298 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:22:48.159195 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:22:48.161355 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m21:22:48.163382 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.166287 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m21:22:48.171255 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m21:22:48.181342 [debug] [Thread-1 (]: SQL status: COMMIT in 0.013 seconds
[0m21:22:48.187193 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m21:22:48.192907 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m21:22:48.203798 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:22:48.205882 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m21:22:48.208176 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m21:22:48.210524 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m21:22:48.213011 [debug] [Thread-2 (]: SQL status: DROP VIEW in 0.000 seconds
[0m21:22:48.218347 [debug] [Thread-2 (]: On model.idx_stock.stg_stock_predictions: Close
[0m21:22:48.220186 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m21:22:48.223161 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41dac38980>]}
[0m21:22:48.226754 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m21:22:48.229009 [info ] [Thread-2 (]: 2 of 14 OK created sql view model public_staging.stg_stock_predictions ......... [[32mCREATE VIEW[0m in 0.33s]
[0m21:22:48.231588 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d61cf800>]}
[0m21:22:48.233320 [debug] [Thread-2 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m21:22:48.235754 [info ] [Thread-1 (]: 1 of 14 OK created sql view model public_staging.stg_daily_stock_summary ....... [[32mCREATE VIEW[0m in 0.34s]
[0m21:22:48.239127 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m21:22:48.242834 [debug] [Thread-4 (]: Began running node model.idx_stock.daily_stock_metrics
[0m21:22:48.243825 [debug] [Thread-3 (]: Began running node model.idx_stock.dim_companies
[0m21:22:48.244702 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m21:22:48.245681 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_macd
[0m21:22:48.247219 [info ] [Thread-4 (]: 3 of 14 START sql table model public_analytics.daily_stock_metrics ............. [RUN]
[0m21:22:48.249168 [info ] [Thread-3 (]: 4 of 14 START sql table model public_core.dim_companies ........................ [RUN]
[0m21:22:48.251473 [info ] [Thread-2 (]: 5 of 14 START sql table model public_core.fct_daily_stock_metrics .............. [RUN]
[0m21:22:48.253777 [info ] [Thread-1 (]: 6 of 14 START sql table model public_analytics.technical_indicators_macd ....... [RUN]
[0m21:22:48.256032 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.daily_stock_metrics'
[0m21:22:48.258179 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.dim_companies)
[0m21:22:48.260476 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.fct_daily_stock_metrics)
[0m21:22:48.262433 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_daily_stock_summary, now model.idx_stock.technical_indicators_macd)
[0m21:22:48.264289 [debug] [Thread-4 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m21:22:48.265922 [debug] [Thread-3 (]: Began compiling node model.idx_stock.dim_companies
[0m21:22:48.267742 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m21:22:48.269557 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m21:22:48.276495 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m21:22:48.281925 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m21:22:48.288353 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:48.295291 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m21:22:48.306698 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m21:22:48.309022 [debug] [Thread-4 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m21:22:48.310050 [debug] [Thread-3 (]: Began executing node model.idx_stock.dim_companies
[0m21:22:48.316956 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m21:22:48.369806 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:48.366253 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m21:22:48.377236 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m21:22:48.383536 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m21:22:48.395683 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:48.396833 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:48.398144 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:48.399897 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m21:22:48.401787 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:22:48.402688 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m21:22:48.404912 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: BEGIN
[0m21:22:48.407000 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:22:48.409554 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m21:22:48.411715 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m21:22:48.413752 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:22:48.417138 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:22:48.428105 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m21:22:48.430078 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:48.431643 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m21:22:48.432516 [debug] [Thread-4 (]: SQL status: BEGIN in 0.021 seconds
[0m21:22:48.435396 [debug] [Thread-1 (]: SQL status: BEGIN in 0.016 seconds
[0m21:22:48.436464 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m21:22:48.438738 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:48.440880 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:48.443354 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:22:48.446698 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m21:22:48.448990 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m21:22:48.451462 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m21:22:52.790098 [debug] [Thread-3 (]: SQL status: SELECT 963 in 4.336 seconds
[0m21:22:52.810693 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:52.813240 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m21:22:52.816099 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:52.825383 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:52.827985 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m21:22:52.831131 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:52.836882 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:22:52.840390 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:52.843158 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: COMMIT
[0m21:22:52.858432 [debug] [Thread-3 (]: SQL status: COMMIT in 0.013 seconds
[0m21:22:52.865183 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m21:22:52.873658 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m21:22:52.876071 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m21:22:52.885647 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m21:22:52.890729 [debug] [Thread-3 (]: On model.idx_stock.dim_companies: Close
[0m21:22:52.893242 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41b7f21a00>]}
[0m21:22:52.895620 [info ] [Thread-3 (]: 4 of 14 OK created sql table model public_core.dim_companies ................... [[32mSELECT 963[0m in 4.64s]
[0m21:22:52.898993 [debug] [Thread-3 (]: Finished running node model.idx_stock.dim_companies
[0m21:22:52.902089 [debug] [Thread-3 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m21:22:52.906009 [info ] [Thread-3 (]: 7 of 14 START sql table model public_analytics.technical_indicators_rsi ........ [RUN]
[0m21:22:52.908375 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.dim_companies, now model.idx_stock.technical_indicators_rsi)
[0m21:22:52.910258 [debug] [Thread-3 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m21:22:52.918128 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m21:22:52.932994 [debug] [Thread-3 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m21:22:52.942749 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m21:22:52.958060 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:22:52.960573 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m21:22:52.963037 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:22:52.978201 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m21:22:52.980205 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:22:52.982346 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m21:22:55.034784 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 6.589 seconds
[0m21:22:55.048030 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:55.050924 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics" rename to "fct_daily_stock_metrics__dbt_backup"
[0m21:22:55.064540 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.011 seconds
[0m21:22:55.077680 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:55.080627 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m21:22:55.083694 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:55.088603 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m21:22:55.091149 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:55.093669 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m21:22:55.100542 [debug] [Thread-2 (]: SQL status: COMMIT in 0.004 seconds
[0m21:22:55.112854 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m21:22:55.114324 [debug] [Thread-4 (]: SQL status: SELECT 701981 in 6.659 seconds
[0m21:22:55.116538 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m21:22:55.126461 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:55.140102 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m21:22:55.142461 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m21:22:55.146416 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:55.158045 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:55.160125 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m21:22:55.162836 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:55.167798 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:22:55.170792 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:55.173309 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m21:22:55.178480 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m21:22:55.188264 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.044 seconds
[0m21:22:55.187025 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m21:22:55.192444 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m21:22:55.194895 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m21:22:55.197346 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d6187e60>]}
[0m21:22:55.199433 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m21:22:55.203246 [info ] [Thread-2 (]: 5 of 14 OK created sql table model public_core.fct_daily_stock_metrics ......... [[32mSELECT 701981[0m in 6.94s]
[0m21:22:55.207562 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m21:22:55.209787 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m21:22:55.212378 [info ] [Thread-2 (]: 8 of 14 START sql table model public_analytics.stock_performance_daily ......... [RUN]
[0m21:22:55.214610 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.fct_daily_stock_metrics, now model.idx_stock.stock_performance_daily)
[0m21:22:55.217013 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m21:22:55.231945 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m21:22:55.238414 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.032 seconds
[0m21:22:55.244334 [debug] [Thread-4 (]: On model.idx_stock.daily_stock_metrics: Close
[0m21:22:55.247637 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41b7f93740>]}
[0m21:22:55.249017 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m21:22:55.251516 [info ] [Thread-4 (]: 3 of 14 OK created sql table model public_analytics.daily_stock_metrics ........ [[32mSELECT 701981[0m in 6.99s]
[0m21:22:55.261786 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m21:22:55.264159 [debug] [Thread-4 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m21:22:55.267787 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_monthly
[0m21:22:55.271214 [info ] [Thread-4 (]: 9 of 14 START sql table model public_analytics.stock_performance_monthly ....... [RUN]
[0m21:22:55.273897 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.stock_performance_monthly)
[0m21:22:55.276517 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m21:22:55.286160 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.287590 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m21:22:55.289343 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m21:22:55.292666 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:22:55.305073 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m21:22:55.313280 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m21:22:55.314472 [debug] [Thread-2 (]: SQL status: BEGIN in 0.022 seconds
[0m21:22:55.318569 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.321501 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m21:22:55.330948 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:22:55.333440 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m21:22:55.336598 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m21:22:55.359108 [debug] [Thread-4 (]: SQL status: BEGIN in 0.023 seconds
[0m21:22:55.361677 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:22:55.364805 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m21:22:55.796532 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.473 seconds
[0m21:22:55.805748 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.807902 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m21:22:55.810316 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:55.817923 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.821301 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m21:22:55.824217 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:22:55.828348 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:22:55.830387 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.832578 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m21:22:55.839561 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m21:22:55.845614 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m21:22:55.847894 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m21:22:55.849686 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m21:22:55.856360 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:22:55.861657 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m21:22:55.864499 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d61e19d0>]}
[0m21:22:55.867565 [info ] [Thread-2 (]: 8 of 14 OK created sql table model public_analytics.stock_performance_daily .... [[32mSELECT 960[0m in 0.65s]
[0m21:22:55.871947 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m21:22:55.874587 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_weekly
[0m21:22:55.877358 [info ] [Thread-2 (]: 10 of 14 START sql table model public_analytics.stock_performance_weekly ....... [RUN]
[0m21:22:55.879947 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.stock_performance_weekly)
[0m21:22:55.882713 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m21:22:55.894910 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m21:22:55.910916 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m21:22:55.920325 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m21:22:55.935791 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:22:55.938025 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m21:22:55.939750 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:22:55.953862 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m21:22:55.956009 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:22:55.958163 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m21:23:00.810012 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 12.353 seconds
[0m21:23:00.819261 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:23:00.821285 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m21:23:00.823794 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:00.830835 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:23:00.833479 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m21:23:00.836117 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:00.842152 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m21:23:00.844027 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:23:00.845671 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m21:23:00.851756 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:23:00.859889 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m21:23:00.862907 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m21:23:00.866164 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m21:23:00.886425 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.018 seconds
[0m21:23:00.890430 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_macd: Close
[0m21:23:00.892734 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d61cc920>]}
[0m21:23:00.895515 [info ] [Thread-1 (]: 6 of 14 OK created sql table model public_analytics.technical_indicators_macd .. [[32mSELECT 701981[0m in 12.63s]
[0m21:23:00.899306 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m21:23:00.901823 [debug] [Thread-1 (]: Began running node model.idx_stock.fct_stock_predictions
[0m21:23:00.904087 [info ] [Thread-1 (]: 11 of 14 START sql table model public_core.fct_stock_predictions ............... [RUN]
[0m21:23:00.906174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.technical_indicators_macd, now model.idx_stock.fct_stock_predictions)
[0m21:23:00.907958 [debug] [Thread-1 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m21:23:00.917635 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m21:23:00.934153 [debug] [Thread-1 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m21:23:00.942024 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m21:23:00.960374 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:23:00.962707 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m21:23:00.965291 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:23:00.985818 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m21:23:00.988043 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:23:00.990183 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/core/fct_stock_predictions.sql


WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m21:23:01.289916 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.297 seconds
[0m21:23:01.299261 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:23:01.301666 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m21:23:01.304425 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:01.308417 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m21:23:01.310837 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:23:01.313713 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m21:23:01.320674 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m21:23:01.328110 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m21:23:01.331053 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:23:01.334259 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m21:23:01.336877 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m21:23:01.341289 [debug] [Thread-1 (]: On model.idx_stock.fct_stock_predictions: Close
[0m21:23:01.344357 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d8326d20>]}
[0m21:23:01.346772 [info ] [Thread-1 (]: 11 of 14 OK created sql table model public_core.fct_stock_predictions .......... [[32mSELECT 1[0m in 0.44s]
[0m21:23:01.351119 [debug] [Thread-1 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m21:23:01.353480 [debug] [Thread-1 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m21:23:01.356169 [info ] [Thread-1 (]: 12 of 14 START sql table model public_analytics.news_sentiment_analysis ........ [RUN]
[0m21:23:01.358724 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.fct_stock_predictions, now model.idx_stock.news_sentiment_analysis)
[0m21:23:01.361076 [debug] [Thread-1 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m21:23:01.372669 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m21:23:01.390299 [debug] [Thread-1 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m21:23:01.399849 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m21:23:01.414961 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:01.417355 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m21:23:01.419021 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:23:01.434551 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m21:23:01.437170 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:01.439902 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m21:23:02.085437 [debug] [Thread-1 (]: SQL status: SELECT 20140 in 0.643 seconds
[0m21:23:02.093078 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:02.095282 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m21:23:02.098380 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:02.105823 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:02.107548 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m21:23:02.110062 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:02.114668 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m21:23:02.116697 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:02.118519 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m21:23:02.128809 [debug] [Thread-4 (]: SQL status: SELECT 960 in 6.761 seconds
[0m21:23:02.136812 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:23:02.137896 [debug] [Thread-1 (]: SQL status: COMMIT in 0.018 seconds
[0m21:23:02.139505 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m21:23:02.148883 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m21:23:02.152082 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:02.153686 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m21:23:02.231170 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:23:02.233307 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m21:23:02.235365 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m21:23:02.238868 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:02.242869 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:23:02.244046 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m21:23:02.245818 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:23:02.250319 [debug] [Thread-1 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m21:23:02.252524 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m21:23:02.254884 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da3f6f00>]}
[0m21:23:02.258574 [info ] [Thread-1 (]: 12 of 14 OK created sql table model public_analytics.news_sentiment_analysis ... [[32mSELECT 20140[0m in 0.90s]
[0m21:23:02.260063 [debug] [Thread-4 (]: SQL status: COMMIT in 0.003 seconds
[0m21:23:02.262152 [debug] [Thread-1 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m21:23:02.268742 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m21:23:02.270883 [debug] [Thread-1 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m21:23:02.273641 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m21:23:02.276950 [info ] [Thread-1 (]: 13 of 14 START sql table model public_analytics.lstm_performance_metrics ....... [RUN]
[0m21:23:02.278970 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m21:23:02.281782 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.news_sentiment_analysis, now model.idx_stock.lstm_performance_metrics)
[0m21:23:02.285178 [debug] [Thread-1 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m21:23:02.293412 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.009 seconds
[0m21:23:02.294575 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.298808 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_monthly: Close
[0m21:23:02.302572 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41b7f93a70>]}
[0m21:23:02.304992 [info ] [Thread-4 (]: 9 of 14 OK created sql table model public_analytics.stock_performance_monthly .. [[32mSELECT 960[0m in 7.03s]
[0m21:23:02.308027 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m21:23:02.315136 [debug] [Thread-1 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m21:23:02.322963 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.339195 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.341554 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m21:23:02.343763 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:23:02.358167 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m21:23:02.360439 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.363192 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m21:23:02.375764 [debug] [Thread-1 (]: SQL status: SELECT 0 in 0.009 seconds
[0m21:23:02.384032 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.385988 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m21:23:02.388197 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:23:02.391688 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m21:23:02.393735 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.395775 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m21:23:02.402876 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m21:23:02.408706 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m21:23:02.411407 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:23:02.413699 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m21:23:02.416401 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:23:02.420297 [debug] [Thread-1 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m21:23:02.422519 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da2402c0>]}
[0m21:23:02.425216 [info ] [Thread-1 (]: 13 of 14 OK created sql table model public_analytics.lstm_performance_metrics .. [[32mSELECT 0[0m in 0.14s]
[0m21:23:02.427631 [debug] [Thread-1 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m21:23:03.032394 [debug] [Thread-2 (]: SQL status: SELECT 960 in 7.072 seconds
[0m21:23:03.039268 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:23:03.041281 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m21:23:03.043882 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:03.052844 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:23:03.055113 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m21:23:03.057827 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:03.062066 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:23:03.064690 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:23:03.066767 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m21:23:03.074761 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m21:23:03.081466 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m21:23:03.084176 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m21:23:03.086354 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m21:23:03.092152 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.004 seconds
[0m21:23:03.096568 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_weekly: Close
[0m21:23:03.099401 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d93e7020>]}
[0m21:23:03.101703 [info ] [Thread-2 (]: 10 of 14 OK created sql table model public_analytics.stock_performance_weekly .. [[32mSELECT 960[0m in 7.22s]
[0m21:23:03.104232 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m21:23:05.179378 [debug] [Thread-3 (]: SQL status: SELECT 701018 in 12.195 seconds
[0m21:23:05.185806 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:23:05.187833 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m21:23:05.190296 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:23:05.196330 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:23:05.198329 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m21:23:05.200659 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:23:05.203897 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m21:23:05.205789 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:23:05.207620 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m21:23:05.229565 [debug] [Thread-3 (]: SQL status: COMMIT in 0.020 seconds
[0m21:23:05.234435 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m21:23:05.236461 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m21:23:05.238205 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m21:23:05.254308 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.014 seconds
[0m21:23:05.257707 [debug] [Thread-3 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m21:23:05.259989 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d83d58b0>]}
[0m21:23:05.262434 [info ] [Thread-3 (]: 7 of 14 OK created sql table model public_analytics.technical_indicators_rsi ... [[32mSELECT 701018[0m in 12.35s]
[0m21:23:05.264984 [debug] [Thread-3 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m21:23:05.267461 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m21:23:05.269438 [info ] [Thread-4 (]: 14 of 14 START sql table model public_analytics.stock_prediction_dashboard ..... [RUN]
[0m21:23:05.271247 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.stock_prediction_dashboard)
[0m21:23:05.272919 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m21:23:05.282489 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m21:23:05.297423 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m21:23:05.303634 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m21:23:05.317381 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:23:05.319031 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m21:23:05.320444 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m21:23:05.331417 [debug] [Thread-4 (]: SQL status: BEGIN in 0.011 seconds
[0m21:23:05.333424 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:23:05.335408 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/stock_prediction_dashboard.sql


WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal as news_trading_signal,
        ld.predicted_close,
        ld.prediction_direction as lstm_direction
    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 days'
)

SELECT * FROM combined_data
  );
  
[0m21:23:09.452774 [debug] [Thread-4 (]: SQL status: SELECT 53599 in 4.115 seconds
[0m21:23:09.459631 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:23:09.461573 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m21:23:09.464007 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:23:09.467212 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m21:23:09.469236 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:23:09.471026 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m21:23:09.478594 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m21:23:09.483337 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m21:23:09.485482 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:23:09.487277 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m21:23:09.489461 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m21:23:09.493223 [debug] [Thread-4 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m21:23:09.495422 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9c5ef15a-d969-415e-82fe-7cba87c57f99', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41d61ad040>]}
[0m21:23:09.497660 [info ] [Thread-4 (]: 14 of 14 OK created sql table model public_analytics.stock_prediction_dashboard  [[32mSELECT 53599[0m in 4.22s]
[0m21:23:09.499812 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m21:23:09.503579 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:09.505306 [debug] [MainThread]: On master: BEGIN
[0m21:23:09.506834 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:23:09.518015 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m21:23:09.519774 [debug] [MainThread]: On master: COMMIT
[0m21:23:09.521362 [debug] [MainThread]: Using postgres connection "master"
[0m21:23:09.522971 [debug] [MainThread]: On master: COMMIT
[0m21:23:09.524913 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:23:09.526987 [debug] [MainThread]: On master: Close
[0m21:23:09.528849 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:23:09.530428 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m21:23:09.531938 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m21:23:09.533366 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m21:23:09.534566 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m21:23:09.536158 [info ] [MainThread]: 
[0m21:23:09.537831 [info ] [MainThread]: Finished running 12 table models, 2 view models in 0 hours 0 minutes and 21.96 seconds (21.96s).
[0m21:23:09.544561 [debug] [MainThread]: Command end result
[0m21:23:09.617028 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:23:09.626660 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:23:09.643381 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:23:09.645011 [info ] [MainThread]: 
[0m21:23:09.646789 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:23:09.648389 [info ] [MainThread]: 
[0m21:23:09.650061 [info ] [MainThread]: Done. PASS=14 WARN=0 ERROR=0 SKIP=0 TOTAL=14
[0m21:23:09.652724 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 24.027304, "process_in_blocks": "24", "process_kernel_time": 0.352969, "process_mem_max_rss": "122828", "process_out_blocks": "0", "process_user_time": 5.74836}
[0m21:23:09.655017 [debug] [MainThread]: Command `dbt run` succeeded at 21:23:09.654794 after 24.03 seconds
[0m21:23:09.656689 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da645a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41dac3abd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f41da80a180>]}
[0m21:23:09.658631 [debug] [MainThread]: Flushing usage events
[0m21:23:11.201366 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m21:25:54.648850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdceb8b0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdceb166720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcead309e0>]}


============================== 21:25:54.662746 | 92843268-553a-438c-bb47-eb67e7170355 ==============================
[0m21:25:54.662746 [info ] [MainThread]: Running with dbt=1.9.4
[0m21:25:54.664765 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m21:25:55.052246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce9f4faa0>]}
[0m21:25:55.170571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdceaa05c10>]}
[0m21:25:55.173858 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m21:25:55.344730 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m21:25:56.149434 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m21:25:56.151775 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m21:25:56.248603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce9f8fd10>]}
[0m21:25:56.451302 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:25:56.467801 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:25:56.509031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce8f19f70>]}
[0m21:25:56.511666 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m21:25:56.513715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce9feb8c0>]}
[0m21:25:56.519976 [info ] [MainThread]: 
[0m21:25:56.522974 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m21:25:56.525553 [info ] [MainThread]: 
[0m21:25:56.527838 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m21:25:56.537896 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:25:56.539554 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:25:56.540874 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m21:25:56.619726 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:25:56.620736 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:25:56.621713 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m21:25:56.623371 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:25:56.625158 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:25:56.626915 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m21:25:56.628608 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:56.630245 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:56.631858 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m21:25:56.645960 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m21:25:56.647064 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m21:25:56.654700 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.023 seconds
[0m21:25:56.656012 [debug] [ThreadPool]: On list_airflow: Close
[0m21:25:56.659035 [debug] [ThreadPool]: On list_airflow: Close
[0m21:25:56.662328 [debug] [ThreadPool]: On list_airflow: Close
[0m21:25:56.670590 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m21:25:56.672381 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m21:25:56.673682 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m21:25:56.683648 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:25:56.688152 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:25:56.694001 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:25:56.696009 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m21:25:56.697717 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m21:25:56.699312 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m21:25:56.701050 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:56.702671 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:56.704556 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m21:25:56.716727 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m21:25:56.718186 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m21:25:56.719561 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m21:25:56.721087 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m21:25:56.722252 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m21:25:56.723857 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m21:25:56.726801 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m21:25:56.728721 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m21:25:56.729637 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m21:25:56.731240 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m21:25:56.736122 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m21:25:56.737612 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m21:25:56.740825 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m21:25:56.743864 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m21:25:56.744693 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m21:25:56.749789 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m21:25:56.753137 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m21:25:56.757903 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m21:25:56.769377 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:56.771825 [debug] [MainThread]: On master: BEGIN
[0m21:25:56.773774 [debug] [MainThread]: Opening a new connection, currently in state init
[0m21:25:56.784891 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m21:25:56.787059 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:56.789910 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m21:25:56.801149 [debug] [MainThread]: SQL status: SELECT 2 in 0.009 seconds
[0m21:25:56.805551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce6bdb0e0>]}
[0m21:25:56.807755 [debug] [MainThread]: On master: ROLLBACK
[0m21:25:56.809947 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:56.811768 [debug] [MainThread]: On master: BEGIN
[0m21:25:56.814134 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m21:25:56.815989 [debug] [MainThread]: On master: COMMIT
[0m21:25:56.817769 [debug] [MainThread]: Using postgres connection "master"
[0m21:25:56.819579 [debug] [MainThread]: On master: COMMIT
[0m21:25:56.822552 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:25:56.824393 [debug] [MainThread]: On master: Close
[0m21:25:56.831980 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m21:25:56.834175 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m21:25:56.836307 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m21:25:56.838811 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m21:25:56.851606 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m21:25:56.865864 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m21:25:56.927688 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m21:25:56.940519 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:56.941941 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m21:25:56.943343 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:56.953372 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m21:25:56.955651 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:56.957317 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m21:25:56.961023 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m21:25:56.972865 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:56.974782 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m21:25:56.977089 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:25:56.982831 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:56.984206 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m21:25:56.986412 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:57.020100 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m21:25:57.022907 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:57.024687 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m21:25:57.034370 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m21:25:57.052035 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m21:25:57.062140 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m21:25:57.064276 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m21:25:57.072743 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m21:25:57.077690 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m21:25:57.081229 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcecb62cf0>]}
[0m21:25:57.083399 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.24s]
[0m21:25:57.085493 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m21:25:57.088563 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m21:25:57.090677 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m21:25:57.092471 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m21:25:57.094173 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m21:25:57.100318 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m21:25:57.118791 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m21:25:57.158996 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m21:25:57.174181 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.175946 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m21:25:57.177659 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m21:25:57.188902 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m21:25:57.191032 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.193080 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/core/fct_stock_predictions.sql


WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m21:25:57.683243 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.488 seconds
[0m21:25:57.695734 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.697857 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m21:25:57.700555 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:25:57.707423 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.709404 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m21:25:57.711841 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:25:57.715191 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m21:25:57.717373 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.719625 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m21:25:57.728631 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m21:25:57.733395 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m21:25:57.739667 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m21:25:57.741828 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m21:25:57.750668 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m21:25:57.754723 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m21:25:57.757162 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce6aecfe0>]}
[0m21:25:57.759497 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.66s]
[0m21:25:57.761987 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m21:25:57.764785 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m21:25:57.765635 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m21:25:57.767539 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m21:25:57.770083 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m21:25:57.772725 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m21:25:57.774557 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m21:25:57.776448 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m21:25:57.778106 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m21:25:57.784099 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.791695 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m21:25:57.800844 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m21:25:57.801995 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m21:25:57.808319 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.814760 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m21:25:57.824976 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.826854 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:25:57.827604 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m21:25:57.829207 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m21:25:57.830690 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m21:25:57.832248 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m21:25:57.843132 [debug] [Thread-2 (]: SQL status: BEGIN in 0.012 seconds
[0m21:25:57.844429 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m21:25:57.845687 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.847524 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:25:57.849721 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m21:25:57.852038 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/stock_prediction_dashboard.sql


WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal as news_trading_signal,
        ld.predicted_close,
        ld.prediction_direction as lstm_direction
    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 days'
)

SELECT * FROM combined_data
  );
  
[0m21:25:57.868679 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.014 seconds
[0m21:25:57.875458 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.877593 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m21:25:57.880029 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:25:57.886133 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.888594 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m21:25:57.891054 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m21:25:57.894360 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m21:25:57.896308 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.898132 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m21:25:57.904911 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m21:25:57.909778 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m21:25:57.911856 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m21:25:57.913683 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m21:25:57.921645 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.006 seconds
[0m21:25:57.925338 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m21:25:57.927436 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce87c9a30>]}
[0m21:25:57.929640 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.15s]
[0m21:25:57.931986 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m21:26:01.669461 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 3.814 seconds
[0m21:26:01.678908 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:26:01.681187 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m21:26:01.684200 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:26:01.690950 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:26:01.693180 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m21:26:01.695912 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m21:26:01.700252 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m21:26:01.702751 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:26:01.704795 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m21:26:01.709144 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m21:26:01.714969 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m21:26:01.717924 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m21:26:01.720160 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m21:26:01.727662 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m21:26:01.731517 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m21:26:01.734246 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92843268-553a-438c-bb47-eb67e7170355', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce48fe540>]}
[0m21:26:01.737012 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 3.96s]
[0m21:26:01.739714 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m21:26:01.744055 [debug] [MainThread]: Using postgres connection "master"
[0m21:26:01.746185 [debug] [MainThread]: On master: BEGIN
[0m21:26:01.748102 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m21:26:01.760036 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m21:26:01.762194 [debug] [MainThread]: On master: COMMIT
[0m21:26:01.764275 [debug] [MainThread]: Using postgres connection "master"
[0m21:26:01.766241 [debug] [MainThread]: On master: COMMIT
[0m21:26:01.769106 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m21:26:01.771145 [debug] [MainThread]: On master: Close
[0m21:26:01.773304 [debug] [MainThread]: Connection 'master' was properly closed.
[0m21:26:01.775252 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m21:26:01.777138 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m21:26:01.779082 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m21:26:01.781129 [info ] [MainThread]: 
[0m21:26:01.783407 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.25 seconds (5.25s).
[0m21:26:01.787395 [debug] [MainThread]: Command end result
[0m21:26:01.870768 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m21:26:01.882721 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m21:26:01.902617 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m21:26:01.904771 [info ] [MainThread]: 
[0m21:26:01.906897 [info ] [MainThread]: [32mCompleted successfully[0m
[0m21:26:01.908881 [info ] [MainThread]: 
[0m21:26:01.910788 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m21:26:01.913726 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.371415, "process_in_blocks": "0", "process_kernel_time": 0.408189, "process_mem_max_rss": "123560", "process_out_blocks": "0", "process_user_time": 4.549814}
[0m21:26:01.916408 [debug] [MainThread]: Command `dbt run` succeeded at 21:26:01.916075 after 7.37 seconds
[0m21:26:01.918605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdceac92ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce492bb60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdce87be120>]}
[0m21:26:01.920604 [debug] [MainThread]: Flushing usage events
[0m21:26:03.144592 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m22:46:38.984465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722d2c12b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722b5e89e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722b763d70>]}


============================== 22:46:38.998975 | fd409d31-79ec-4620-a817-2dab075e6408 ==============================
[0m22:46:38.998975 [info ] [MainThread]: Running with dbt=1.9.4
[0m22:46:39.000991 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m22:46:39.351889 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722a34faa0>]}
[0m22:46:39.516844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722b6ee810>]}
[0m22:46:39.519900 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m22:46:39.789491 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m22:46:40.573470 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m22:46:40.575719 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m22:46:40.706432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722a34ff80>]}
[0m22:46:41.026909 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:46:41.049367 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:46:41.116436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722931a300>]}
[0m22:46:41.118985 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m22:46:41.121470 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722a3c0350>]}
[0m22:46:41.130295 [info ] [MainThread]: 
[0m22:46:41.133952 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:46:41.136684 [info ] [MainThread]: 
[0m22:46:41.139310 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m22:46:41.155886 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:46:41.160582 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:46:41.162390 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m22:46:41.293225 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:46:41.294439 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:46:41.295383 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m22:46:41.297123 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:46:41.299194 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:46:41.301256 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m22:46:41.303265 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:41.305249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:41.307271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:46:41.327088 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.022 seconds
[0m22:46:41.331770 [debug] [ThreadPool]: On list_airflow: Close
[0m22:46:41.332877 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.030 seconds
[0m22:46:41.336146 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.029 seconds
[0m22:46:41.339498 [debug] [ThreadPool]: On list_airflow: Close
[0m22:46:41.345720 [debug] [ThreadPool]: On list_airflow: Close
[0m22:46:41.356700 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m22:46:41.358600 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m22:46:41.360529 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m22:46:41.374714 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:46:41.381623 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:46:41.387163 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:46:41.389844 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m22:46:41.392282 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m22:46:41.395553 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m22:46:41.397744 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:46:41.399948 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:46:41.402477 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:46:41.421203 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m22:46:41.423931 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m22:46:41.426523 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m22:46:41.428982 [debug] [ThreadPool]: SQL status: BEGIN in 0.029 seconds
[0m22:46:41.431024 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m22:46:41.433304 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m22:46:41.435766 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m22:46:41.438045 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.007 seconds
[0m22:46:41.439454 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m22:46:41.442016 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m22:46:41.446763 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m22:46:41.451151 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m22:46:41.459390 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.011 seconds
[0m22:46:41.460797 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.011 seconds
[0m22:46:41.464469 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m22:46:41.468144 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m22:46:41.470216 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m22:46:41.472308 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m22:46:41.493797 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:41.496075 [debug] [MainThread]: On master: BEGIN
[0m22:46:41.498069 [debug] [MainThread]: Opening a new connection, currently in state init
[0m22:46:41.514995 [debug] [MainThread]: SQL status: BEGIN in 0.017 seconds
[0m22:46:41.517379 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:41.520452 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m22:46:41.550421 [debug] [MainThread]: SQL status: SELECT 2 in 0.027 seconds
[0m22:46:41.555403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722b126360>]}
[0m22:46:41.558184 [debug] [MainThread]: On master: ROLLBACK
[0m22:46:41.562084 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:41.565263 [debug] [MainThread]: On master: BEGIN
[0m22:46:41.569271 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m22:46:41.580135 [debug] [MainThread]: On master: COMMIT
[0m22:46:41.586242 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:41.589753 [debug] [MainThread]: On master: COMMIT
[0m22:46:41.593566 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:46:41.596668 [debug] [MainThread]: On master: Close
[0m22:46:41.610349 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m22:46:41.613410 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m22:46:41.616428 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m22:46:41.619008 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m22:46:41.638848 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m22:46:41.653497 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m22:46:41.744081 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m22:46:41.758111 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.760446 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m22:46:41.762445 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:46:41.775926 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m22:46:41.778323 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.780771 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m22:46:41.787526 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m22:46:41.802291 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.804968 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m22:46:41.808708 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:41.816568 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.819018 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m22:46:41.822011 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:41.857635 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m22:46:41.860489 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.862624 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m22:46:41.868993 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m22:46:41.883163 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m22:46:41.895908 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m22:46:41.898075 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m22:46:41.908049 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.008 seconds
[0m22:46:41.914474 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m22:46:41.919058 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722d323800>]}
[0m22:46:41.921778 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.30s]
[0m22:46:41.924798 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m22:46:41.928559 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m22:46:41.930969 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m22:46:41.933182 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m22:46:41.935218 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m22:46:41.943181 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m22:46:41.958484 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m22:46:42.004026 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m22:46:42.021859 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:42.023619 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m22:46:42.025855 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:46:42.038599 [debug] [Thread-3 (]: SQL status: BEGIN in 0.013 seconds
[0m22:46:42.041719 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:42.044851 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/core/fct_stock_predictions.sql


WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m22:46:43.650131 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.603 seconds
[0m22:46:43.668498 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:43.670818 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m22:46:43.674100 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:43.681726 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:43.684175 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m22:46:43.687292 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:43.692933 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m22:46:43.695233 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:43.697946 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m22:46:43.704809 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m22:46:43.712250 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m22:46:43.720136 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m22:46:43.722133 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m22:46:43.731259 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m22:46:43.736478 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m22:46:43.739193 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72281a4830>]}
[0m22:46:43.742188 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 1.81s]
[0m22:46:43.744873 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m22:46:43.748333 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m22:46:43.749528 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m22:46:43.751531 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m22:46:43.753964 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m22:46:43.755950 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m22:46:43.758432 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m22:46:43.760377 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m22:46:43.762754 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m22:46:43.770872 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.780231 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m22:46:43.788755 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m22:46:43.797560 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m22:46:43.798389 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.805919 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m22:46:43.816411 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.818554 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m22:46:43.819860 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:43.821723 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:46:43.824108 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m22:46:43.828225 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:46:43.837861 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m22:46:43.840509 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.842527 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m22:46:43.844322 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m22:46:43.846922 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:43.850803 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/stock_prediction_dashboard.sql


WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal as news_trading_signal,
        ld.predicted_close,
        ld.prediction_direction as lstm_direction
    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 days'
)

SELECT * FROM combined_data
  );
  
[0m22:46:43.864987 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.016 seconds
[0m22:46:43.873108 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.875560 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m22:46:43.878208 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:43.884956 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.887116 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m22:46:43.890187 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:43.894582 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m22:46:43.896269 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.897758 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m22:46:43.903834 [debug] [Thread-2 (]: SQL status: COMMIT in 0.004 seconds
[0m22:46:43.910569 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m22:46:43.913164 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m22:46:43.915286 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m22:46:43.922313 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.005 seconds
[0m22:46:43.926589 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m22:46:43.928844 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7220f13e60>]}
[0m22:46:43.931326 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.17s]
[0m22:46:43.933675 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m22:46:48.861762 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 5.007 seconds
[0m22:46:48.873605 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:48.875925 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m22:46:48.878923 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:48.885919 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:48.888706 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m22:46:48.891717 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m22:46:48.898352 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m22:46:48.900660 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:48.902924 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m22:46:48.937141 [debug] [Thread-1 (]: SQL status: COMMIT in 0.032 seconds
[0m22:46:48.942786 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m22:46:48.945079 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m22:46:48.947089 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m22:46:48.959502 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.010 seconds
[0m22:46:48.963406 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m22:46:48.966438 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd409d31-79ec-4620-a817-2dab075e6408', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7220f03cb0>]}
[0m22:46:48.969592 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 5.21s]
[0m22:46:48.972540 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m22:46:48.977549 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:48.979617 [debug] [MainThread]: On master: BEGIN
[0m22:46:48.981533 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:46:48.994230 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m22:46:48.996370 [debug] [MainThread]: On master: COMMIT
[0m22:46:48.998344 [debug] [MainThread]: Using postgres connection "master"
[0m22:46:49.000404 [debug] [MainThread]: On master: COMMIT
[0m22:46:49.002837 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m22:46:49.005057 [debug] [MainThread]: On master: Close
[0m22:46:49.007254 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:46:49.009246 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m22:46:49.011067 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m22:46:49.012904 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m22:46:49.014951 [info ] [MainThread]: 
[0m22:46:49.017045 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 7.88 seconds (7.88s).
[0m22:46:49.021682 [debug] [MainThread]: Command end result
[0m22:46:49.125169 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m22:46:49.137124 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m22:46:49.159054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m22:46:49.161352 [info ] [MainThread]: 
[0m22:46:49.163791 [info ] [MainThread]: [32mCompleted successfully[0m
[0m22:46:49.166047 [info ] [MainThread]: 
[0m22:46:49.168186 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m22:46:49.172436 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.294228, "process_in_blocks": "0", "process_kernel_time": 0.558858, "process_mem_max_rss": "121976", "process_out_blocks": "0", "process_user_time": 5.149482}
[0m22:46:49.175059 [debug] [MainThread]: Command `dbt run` succeeded at 22:46:49.174764 after 10.30 seconds
[0m22:46:49.177503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722bab48f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722bc96b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f722811f380>]}
[0m22:46:49.179527 [debug] [MainThread]: Flushing usage events
[0m22:46:50.429157 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m23:39:00.408808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b3a79580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b3845640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b3845490>]}


============================== 23:39:00.444899 | 43e64141-6930-4b64-ac94-12f1a3dd25d8 ==============================
[0m23:39:00.444899 [info ] [MainThread]: Running with dbt=1.9.4
[0m23:39:00.449908 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m23:39:01.482128 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b2aa2180>]}
[0m23:39:01.828753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b2a69fd0>]}
[0m23:39:01.835386 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m23:39:02.273110 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m23:39:04.092016 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:39:04.094948 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:39:04.289528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b2b5e090>]}
[0m23:39:04.727573 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:39:04.776898 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:39:04.872711 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b2b5dfa0>]}
[0m23:39:04.876443 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m23:39:04.879844 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b1b02780>]}
[0m23:39:04.891549 [info ] [MainThread]: 
[0m23:39:04.895000 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m23:39:04.897975 [info ] [MainThread]: 
[0m23:39:04.901689 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m23:39:04.918098 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:39:04.920955 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:39:04.923636 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m23:39:05.076051 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:39:05.077857 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:39:05.079387 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m23:39:05.082689 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:39:05.086669 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:39:05.090427 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m23:39:05.094594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:39:05.098553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:39:05.103610 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:39:05.136850 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.038 seconds
[0m23:39:05.147012 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.043 seconds
[0m23:39:05.148840 [debug] [ThreadPool]: On list_airflow: Close
[0m23:39:05.150864 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.056 seconds
[0m23:39:05.157606 [debug] [ThreadPool]: On list_airflow: Close
[0m23:39:05.169408 [debug] [ThreadPool]: On list_airflow: Close
[0m23:39:05.184993 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m23:39:05.187626 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m23:39:05.191212 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m23:39:05.223970 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:39:05.217241 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:39:05.235399 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:39:05.238419 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m23:39:05.242405 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m23:39:05.246454 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m23:39:05.250922 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:39:05.254816 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:39:05.258659 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:39:05.289903 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m23:39:05.294091 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m23:39:05.296679 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m23:39:05.300512 [debug] [ThreadPool]: SQL status: BEGIN in 0.042 seconds
[0m23:39:05.303383 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m23:39:05.307450 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m23:39:05.311674 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m23:39:05.316091 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m23:39:05.323035 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m23:39:05.334432 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.014 seconds
[0m23:39:05.336881 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.010 seconds
[0m23:39:05.338738 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.010 seconds
[0m23:39:05.344748 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m23:39:05.353866 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m23:39:05.360395 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m23:39:05.365257 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m23:39:05.369424 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m23:39:05.373165 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m23:39:05.417164 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:05.421135 [debug] [MainThread]: On master: BEGIN
[0m23:39:05.424821 [debug] [MainThread]: Opening a new connection, currently in state init
[0m23:39:05.451974 [debug] [MainThread]: SQL status: BEGIN in 0.027 seconds
[0m23:39:05.456631 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:05.461207 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m23:39:05.502877 [debug] [MainThread]: SQL status: SELECT 2 in 0.037 seconds
[0m23:39:05.510374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b322a540>]}
[0m23:39:05.515251 [debug] [MainThread]: On master: ROLLBACK
[0m23:39:05.520900 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:05.524892 [debug] [MainThread]: On master: BEGIN
[0m23:39:05.529773 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m23:39:05.533964 [debug] [MainThread]: On master: COMMIT
[0m23:39:05.538030 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:05.541785 [debug] [MainThread]: On master: COMMIT
[0m23:39:05.546172 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:39:05.550787 [debug] [MainThread]: On master: Close
[0m23:39:05.569598 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m23:39:05.574334 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m23:39:05.578450 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m23:39:05.582889 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m23:39:05.619896 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m23:39:05.652905 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m23:39:05.784752 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m23:39:05.808222 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:05.811492 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m23:39:05.815820 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:39:05.840893 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m23:39:05.845191 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:05.849106 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m23:39:05.863113 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.010 seconds
[0m23:39:05.887886 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:05.891861 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m23:39:05.897209 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:05.909705 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:05.913838 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m23:39:05.919618 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m23:39:05.983122 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m23:39:05.987259 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:05.990959 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m23:39:06.002777 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m23:39:06.026233 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m23:39:06.047101 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m23:39:06.051315 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m23:39:06.066379 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.011 seconds
[0m23:39:06.083963 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m23:39:06.097644 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b548bd70>]}
[0m23:39:06.103951 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.51s]
[0m23:39:06.109445 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m23:39:06.118076 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m23:39:06.123447 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m23:39:06.129099 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m23:39:06.134943 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m23:39:06.158104 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m23:39:06.204025 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m23:39:06.316311 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m23:39:06.358430 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:06.363463 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m23:39:06.368975 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:39:06.399174 [debug] [Thread-3 (]: SQL status: BEGIN in 0.030 seconds
[0m23:39:06.405005 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:06.411148 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/core/fct_stock_predictions.sql


WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m23:39:09.498377 [debug] [Thread-3 (]: SQL status: SELECT 1 in 3.082 seconds
[0m23:39:09.524492 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:09.529262 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m23:39:09.538005 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:09.567674 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:09.574197 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m23:39:09.583461 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:09.598374 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m23:39:09.605322 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:09.612970 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m23:39:09.631800 [debug] [Thread-3 (]: SQL status: COMMIT in 0.011 seconds
[0m23:39:09.655775 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m23:39:09.683605 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m23:39:09.690564 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m23:39:09.710335 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.013 seconds
[0m23:39:09.726108 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m23:39:09.734131 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b03f0f20>]}
[0m23:39:09.742513 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 3.60s]
[0m23:39:09.754177 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m23:39:09.772768 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m23:39:09.767889 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m23:39:09.785217 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m23:39:09.793902 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m23:39:09.802660 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m23:39:09.809857 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.lstm_performance_metrics)
[0m23:39:09.819184 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m23:39:09.827111 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m23:39:09.884220 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m23:39:09.903014 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m23:39:09.940104 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m23:39:09.948822 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m23:39:09.976727 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.002188 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m23:39:10.042096 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.050911 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m23:39:10.055191 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:10.063890 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:39:10.073191 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m23:39:10.086803 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:39:10.125462 [debug] [Thread-2 (]: SQL status: BEGIN in 0.062 seconds
[0m23:39:10.133837 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.148915 [debug] [Thread-1 (]: SQL status: BEGIN in 0.062 seconds
[0m23:39:10.144423 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m23:39:10.158019 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:10.172499 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/stock_prediction_dashboard.sql


WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal as news_trading_signal,
        ld.predicted_close,
        ld.prediction_direction as lstm_direction
    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 days'
)

SELECT * FROM combined_data
  );
  
[0m23:39:10.207932 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.041 seconds
[0m23:39:10.243027 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.253485 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m23:39:10.264357 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m23:39:10.296704 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.304894 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m23:39:10.316259 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:10.333374 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m23:39:10.344679 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.353048 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m23:39:10.371170 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m23:39:10.398026 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m23:39:10.409648 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m23:39:10.417737 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m23:39:10.449890 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.020 seconds
[0m23:39:10.465707 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m23:39:10.470774 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b03889b0>]}
[0m23:39:10.476060 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.66s]
[0m23:39:10.480516 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m23:39:16.149053 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 5.965 seconds
[0m23:39:16.176744 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:16.183791 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m23:39:16.192291 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:16.214796 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:16.228874 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m23:39:16.238459 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m23:39:16.253141 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m23:39:16.261003 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:16.267269 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m23:39:16.280207 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m23:39:16.298593 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m23:39:16.306342 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m23:39:16.312690 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m23:39:16.364142 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.045 seconds
[0m23:39:16.378415 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m23:39:16.388070 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43e64141-6930-4b64-ac94-12f1a3dd25d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b021f5f0>]}
[0m23:39:16.396885 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 6.59s]
[0m23:39:16.407016 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m23:39:16.424347 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:16.431896 [debug] [MainThread]: On master: BEGIN
[0m23:39:16.439051 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:39:16.494493 [debug] [MainThread]: SQL status: BEGIN in 0.055 seconds
[0m23:39:16.502271 [debug] [MainThread]: On master: COMMIT
[0m23:39:16.510743 [debug] [MainThread]: Using postgres connection "master"
[0m23:39:16.517864 [debug] [MainThread]: On master: COMMIT
[0m23:39:16.526747 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m23:39:16.534048 [debug] [MainThread]: On master: Close
[0m23:39:16.542585 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:39:16.549884 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m23:39:16.559028 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m23:39:16.566477 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m23:39:16.574498 [info ] [MainThread]: 
[0m23:39:16.582140 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 11.67 seconds (11.67s).
[0m23:39:16.596285 [debug] [MainThread]: Command end result
[0m23:39:16.917242 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m23:39:16.954306 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m23:39:17.026751 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m23:39:17.034328 [info ] [MainThread]: 
[0m23:39:17.043550 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:39:17.052189 [info ] [MainThread]: 
[0m23:39:17.061997 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m23:39:17.074479 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 16.978498, "process_in_blocks": "0", "process_kernel_time": 1.531166, "process_mem_max_rss": "121444", "process_out_blocks": "0", "process_user_time": 13.154109}
[0m23:39:17.082901 [debug] [MainThread]: Command `dbt run` succeeded at 23:39:17.082127 after 16.99 seconds
[0m23:39:17.091833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b35ec620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b3c42ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8b3db9bb0>]}
[0m23:39:17.098907 [debug] [MainThread]: Flushing usage events
[0m23:39:18.860473 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:10:17.426871 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb1190f530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb116e90a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11e0cbc0>]}


============================== 00:10:17.453919 | 816afb30-d748-4c17-9075-53a0a736653b ==============================
[0m00:10:17.453919 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:10:17.458552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m00:10:18.166348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb111ac080>]}
[0m00:10:18.357623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb10a9bd40>]}
[0m00:10:18.361614 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:10:18.703238 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:10:20.584286 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:10:20.586692 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:10:20.730374 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb10b2f860>]}
[0m00:10:21.096249 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:10:21.133366 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:10:21.233039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0fb34050>]}
[0m00:10:21.237176 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m00:10:21.241371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0fb0a9c0>]}
[0m00:10:21.252111 [info ] [MainThread]: 
[0m00:10:21.256156 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m00:10:21.259885 [info ] [MainThread]: 
[0m00:10:21.262981 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m00:10:21.282267 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:10:21.284802 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:10:21.287416 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m00:10:21.438393 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:10:21.440716 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:10:21.442352 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m00:10:21.445334 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:10:21.448886 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:10:21.452618 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m00:10:21.457205 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:10:21.461164 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:10:21.464488 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:10:21.495385 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.031 seconds
[0m00:10:21.502415 [debug] [ThreadPool]: On list_airflow: Close
[0m00:10:21.503985 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.047 seconds
[0m00:10:21.506142 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.045 seconds
[0m00:10:21.514640 [debug] [ThreadPool]: On list_airflow: Close
[0m00:10:21.521318 [debug] [ThreadPool]: On list_airflow: Close
[0m00:10:21.534320 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m00:10:21.536560 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m00:10:21.539153 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m00:10:21.563156 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:10:21.570056 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:10:21.579693 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:10:21.583447 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m00:10:21.587576 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m00:10:21.593147 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m00:10:21.597268 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:10:21.601347 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:10:21.605956 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m00:10:21.635224 [debug] [ThreadPool]: SQL status: BEGIN in 0.038 seconds
[0m00:10:21.640787 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m00:10:21.643516 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m00:10:21.647174 [debug] [ThreadPool]: SQL status: BEGIN in 0.041 seconds
[0m00:10:21.649644 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m00:10:21.653581 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m00:10:21.658998 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m00:10:21.663438 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m00:10:21.670586 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m00:10:21.679844 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.012 seconds
[0m00:10:21.690016 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.014 seconds
[0m00:10:21.687673 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m00:10:21.692703 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.014 seconds
[0m00:10:21.699457 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m00:10:21.704512 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m00:10:21.712839 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m00:10:21.716917 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m00:10:21.728056 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m00:10:21.770897 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:21.776144 [debug] [MainThread]: On master: BEGIN
[0m00:10:21.780080 [debug] [MainThread]: Opening a new connection, currently in state init
[0m00:10:21.806775 [debug] [MainThread]: SQL status: BEGIN in 0.026 seconds
[0m00:10:21.811047 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:21.816141 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m00:10:21.845353 [debug] [MainThread]: SQL status: SELECT 2 in 0.024 seconds
[0m00:10:21.854137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb11270ce0>]}
[0m00:10:21.859569 [debug] [MainThread]: On master: ROLLBACK
[0m00:10:21.864637 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:21.868725 [debug] [MainThread]: On master: BEGIN
[0m00:10:21.874868 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m00:10:21.879537 [debug] [MainThread]: On master: COMMIT
[0m00:10:21.883634 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:21.887797 [debug] [MainThread]: On master: COMMIT
[0m00:10:21.893933 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:10:21.898119 [debug] [MainThread]: On master: Close
[0m00:10:21.921317 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m00:10:21.927133 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m00:10:21.931791 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m00:10:21.936193 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m00:10:21.976871 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m00:10:22.024777 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m00:10:22.291290 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m00:10:22.342393 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.347065 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m00:10:22.350343 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:10:22.373899 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m00:10:22.377090 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.380281 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    

SELECT 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
FROM stock_predictions
  );
[0m00:10:22.391039 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m00:10:22.418170 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.421772 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m00:10:22.426754 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:22.437730 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.444650 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m00:10:22.449653 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:22.505964 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m00:10:22.509218 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.512378 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m00:10:22.522506 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m00:10:22.547513 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m00:10:22.568137 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m00:10:22.572187 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m00:10:22.584489 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.008 seconds
[0m00:10:22.596007 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m00:10:22.603761 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb134619a0>]}
[0m00:10:22.609029 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.67s]
[0m00:10:22.614175 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m00:10:22.620686 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m00:10:22.626056 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m00:10:22.630576 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m00:10:22.634214 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m00:10:22.649346 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m00:10:22.681349 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m00:10:22.779787 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m00:10:22.813970 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:22.817952 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m00:10:22.822209 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m00:10:22.845921 [debug] [Thread-3 (]: SQL status: BEGIN in 0.024 seconds
[0m00:10:22.849766 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:22.854318 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/core/fct_stock_predictions.sql


WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m00:10:24.362404 [debug] [Thread-3 (]: SQL status: SELECT 2 in 1.503 seconds
[0m00:10:24.390695 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:24.393825 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m00:10:24.397425 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:24.411550 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:24.419372 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m00:10:24.425398 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:24.432822 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m00:10:24.435930 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:24.441380 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m00:10:24.449895 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m00:10:24.461969 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m00:10:24.473451 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m00:10:24.475917 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m00:10:24.493841 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m00:10:24.499614 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m00:10:24.509349 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0d3f6090>]}
[0m00:10:24.512385 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 2[0m in 1.88s]
[0m00:10:24.515675 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m00:10:24.518624 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m00:10:24.520873 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m00:10:24.523402 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m00:10:24.525662 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m00:10:24.527587 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m00:10:24.529669 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m00:10:24.531742 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m00:10:24.533710 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m00:10:24.542666 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.553220 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m00:10:24.562396 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m00:10:24.564271 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m00:10:24.574914 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.585423 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m00:10:24.597919 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.600232 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:24.603313 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m00:10:24.606540 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m00:10:24.609288 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m00:10:24.612020 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m00:10:24.630544 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m00:10:24.633184 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m00:10:24.634545 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.637697 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:24.641374 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m00:10:24.645398 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/stock_prediction_dashboard.sql


WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal as news_trading_signal,
        ld.predicted_close,
        ld.prediction_direction as lstm_direction
    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 days'
)

SELECT * FROM combined_data
  );
  
[0m00:10:24.666077 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.017 seconds
[0m00:10:24.676819 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.680022 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m00:10:24.683664 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:24.694091 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.696836 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m00:10:24.700218 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:24.707692 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m00:10:24.711395 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.714307 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m00:10:24.722701 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m00:10:24.731574 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m00:10:24.735069 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m00:10:24.739256 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m00:10:24.751906 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.007 seconds
[0m00:10:24.758701 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m00:10:24.762441 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0d392180>]}
[0m00:10:24.767102 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.23s]
[0m00:10:24.771987 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m00:10:29.953637 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 5.301 seconds
[0m00:10:29.979721 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:29.984835 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m00:10:29.991243 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m00:10:30.008063 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:30.012824 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m00:10:30.019378 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m00:10:30.038296 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m00:10:30.043774 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:30.048402 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m00:10:30.086527 [debug] [Thread-1 (]: SQL status: COMMIT in 0.032 seconds
[0m00:10:30.098046 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m00:10:30.103605 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m00:10:30.107303 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m00:10:30.121598 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.011 seconds
[0m00:10:30.128750 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m00:10:30.134474 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '816afb30-d748-4c17-9075-53a0a736653b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0c255ac0>]}
[0m00:10:30.140434 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 5.60s]
[0m00:10:30.145790 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m00:10:30.156300 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:30.160002 [debug] [MainThread]: On master: BEGIN
[0m00:10:30.163552 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m00:10:30.188730 [debug] [MainThread]: SQL status: BEGIN in 0.025 seconds
[0m00:10:30.192429 [debug] [MainThread]: On master: COMMIT
[0m00:10:30.196138 [debug] [MainThread]: Using postgres connection "master"
[0m00:10:30.199782 [debug] [MainThread]: On master: COMMIT
[0m00:10:30.204342 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m00:10:30.207878 [debug] [MainThread]: On master: Close
[0m00:10:30.212298 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:10:30.216113 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m00:10:30.219968 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m00:10:30.223371 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m00:10:30.227116 [info ] [MainThread]: 
[0m00:10:30.231052 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 8.96 seconds (8.96s).
[0m00:10:30.241089 [debug] [MainThread]: Command end result
[0m00:10:30.461624 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:10:30.493990 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:10:30.586710 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:10:30.593467 [info ] [MainThread]: 
[0m00:10:30.606348 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:10:30.609844 [info ] [MainThread]: 
[0m00:10:30.624181 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m00:10:30.629147 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 13.605951, "process_in_blocks": "0", "process_kernel_time": 0.86061, "process_mem_max_rss": "123184", "process_out_blocks": "0", "process_user_time": 9.89207}
[0m00:10:30.634352 [debug] [MainThread]: Command `dbt run` succeeded at 00:10:30.633598 after 13.61 seconds
[0m00:10:30.638306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb1190f530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb103fd790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbb0effca70>]}
[0m00:10:30.641722 [debug] [MainThread]: Flushing usage events
[0m00:10:32.280902 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:12:03.540211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9491a2930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9491a1a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc949566db0>]}


============================== 00:12:03.562790 | 0fd4fe7c-5e32-4979-95c3-72e6814740ee ==============================
[0m00:12:03.562790 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:12:03.565255 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select tag:stock_predictions tag:BMRI', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:12:04.096904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0fd4fe7c-5e32-4979-95c3-72e6814740ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9491113a0>]}
[0m00:12:04.233980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0fd4fe7c-5e32-4979-95c3-72e6814740ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9491113d0>]}
[0m00:12:04.238373 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:12:04.443696 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:12:05.779270 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:12:05.781503 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:12:05.926701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0fd4fe7c-5e32-4979-95c3-72e6814740ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94852bf20>]}
[0m00:12:06.272965 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:06.294567 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:06.418594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0fd4fe7c-5e32-4979-95c3-72e6814740ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc948560830>]}
[0m00:12:06.421842 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m00:12:06.424582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fd4fe7c-5e32-4979-95c3-72e6814740ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9491a2180>]}
[0m00:12:06.427918 [warn ] [MainThread]: The selection criterion 'tag:stock_predictions' does not match any enabled nodes
[0m00:12:06.430850 [warn ] [MainThread]: The selection criterion 'tag:BMRI' does not match any enabled nodes
[0m00:12:06.436687 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m00:12:06.441963 [debug] [MainThread]: Command end result
[0m00:12:06.542090 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:06.552750 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:06.569583 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:12:06.573564 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.2098913, "process_in_blocks": "34400", "process_kernel_time": 0.611107, "process_mem_max_rss": "112908", "process_out_blocks": "2360", "process_user_time": 5.499968}
[0m00:12:06.576734 [debug] [MainThread]: Command `dbt run` succeeded at 00:12:06.576299 after 3.21 seconds
[0m00:12:06.579445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc949111370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc94951c560>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc9492f6360>]}
[0m00:12:06.582918 [debug] [MainThread]: Flushing usage events
[0m00:12:07.840226 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:12:28.569493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6587242180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65895f8710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65874542f0>]}


============================== 00:12:28.582299 | 39e5f7df-1921-40cc-92c5-355ef4241fe4 ==============================
[0m00:12:28.582299 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:12:28.584678 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select tag:stock_predictions tag:BNGA', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:12:28.986872 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '39e5f7df-1921-40cc-92c5-355ef4241fe4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65891672c0>]}
[0m00:12:29.111725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '39e5f7df-1921-40cc-92c5-355ef4241fe4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65873ee120>]}
[0m00:12:29.114174 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:12:29.296548 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:12:29.921841 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:12:29.923746 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:12:30.009049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '39e5f7df-1921-40cc-92c5-355ef4241fe4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65863ebbc0>]}
[0m00:12:30.192983 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:30.208216 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:30.248633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '39e5f7df-1921-40cc-92c5-355ef4241fe4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6585f33260>]}
[0m00:12:30.250759 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m00:12:30.253054 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '39e5f7df-1921-40cc-92c5-355ef4241fe4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65853313a0>]}
[0m00:12:30.255327 [warn ] [MainThread]: The selection criterion 'tag:stock_predictions' does not match any enabled nodes
[0m00:12:30.257535 [warn ] [MainThread]: The selection criterion 'tag:BNGA' does not match any enabled nodes
[0m00:12:30.260678 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m00:12:30.265053 [debug] [MainThread]: Command end result
[0m00:12:30.338515 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:30.347492 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:30.360157 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:12:30.363098 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.8931217, "process_in_blocks": "0", "process_kernel_time": 0.26019, "process_mem_max_rss": "111904", "process_out_blocks": "0", "process_user_time": 3.992926}
[0m00:12:30.365448 [debug] [MainThread]: Command `dbt run` succeeded at 00:12:30.365217 after 1.90 seconds
[0m00:12:30.367625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f65895f8710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6587284e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6586303080>]}
[0m00:12:30.369754 [debug] [MainThread]: Flushing usage events
[0m00:12:31.486132 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:12:51.075193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae50abe00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae72b1c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae50a9d30>]}


============================== 00:12:51.100479 | 088a4c49-e414-4b5b-86d3-7200ab8d504f ==============================
[0m00:12:51.100479 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:12:51.104344 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select tag:stock_predictions tag:TLKM', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:12:51.698249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '088a4c49-e414-4b5b-86d3-7200ab8d504f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae72b1c40>]}
[0m00:12:51.877220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '088a4c49-e414-4b5b-86d3-7200ab8d504f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae616a390>]}
[0m00:12:51.881060 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:12:52.527019 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:12:53.786451 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:12:53.788950 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:12:53.917444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '088a4c49-e414-4b5b-86d3-7200ab8d504f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae59c9e20>]}
[0m00:12:54.188812 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:54.213318 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:54.267775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '088a4c49-e414-4b5b-86d3-7200ab8d504f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae333b050>]}
[0m00:12:54.270490 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m00:12:54.273045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '088a4c49-e414-4b5b-86d3-7200ab8d504f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae43bbb00>]}
[0m00:12:54.276635 [warn ] [MainThread]: The selection criterion 'tag:stock_predictions' does not match any enabled nodes
[0m00:12:54.279819 [warn ] [MainThread]: The selection criterion 'tag:TLKM' does not match any enabled nodes
[0m00:12:54.284585 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m00:12:54.290002 [debug] [MainThread]: Command end result
[0m00:12:54.405774 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:12:54.417098 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:12:54.439283 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:12:54.443338 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.5438228, "process_in_blocks": "0", "process_kernel_time": 0.638159, "process_mem_max_rss": "111772", "process_out_blocks": "0", "process_user_time": 6.391566}
[0m00:12:54.446555 [debug] [MainThread]: Command `dbt run` succeeded at 00:12:54.446132 after 3.55 seconds
[0m00:12:54.449552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae594bf80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae592a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ae592b650>]}
[0m00:12:54.452562 [debug] [MainThread]: Flushing usage events
[0m00:12:55.557416 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:13:19.678232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a540a2930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5622c380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a540a2b70>]}


============================== 00:13:19.697277 | 28a042e3-0844-4bab-9a10-86f300a4adc5 ==============================
[0m00:13:19.697277 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:13:19.700968 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select tag:stock_predictions tag:BBRI', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m00:13:20.177489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '28a042e3-0844-4bab-9a10-86f300a4adc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a53b985c0>]}
[0m00:13:20.290316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '28a042e3-0844-4bab-9a10-86f300a4adc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a53d0fb90>]}
[0m00:13:20.293051 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:13:20.518475 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:13:21.264431 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:13:21.266492 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:13:21.358575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28a042e3-0844-4bab-9a10-86f300a4adc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a53c17e30>]}
[0m00:13:21.558044 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:13:21.575196 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:13:21.616361 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28a042e3-0844-4bab-9a10-86f300a4adc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a5253fbc0>]}
[0m00:13:21.618171 [info ] [MainThread]: Found 14 models, 2 data tests, 5 sources, 434 macros
[0m00:13:21.620301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28a042e3-0844-4bab-9a10-86f300a4adc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a52d97200>]}
[0m00:13:21.622973 [warn ] [MainThread]: The selection criterion 'tag:stock_predictions' does not match any enabled nodes
[0m00:13:21.625096 [warn ] [MainThread]: The selection criterion 'tag:BBRI' does not match any enabled nodes
[0m00:13:21.628255 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m00:13:21.632464 [debug] [MainThread]: Command end result
[0m00:13:21.700087 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m00:13:21.708478 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m00:13:21.719233 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m00:13:21.722088 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.2268844, "process_in_blocks": "0", "process_kernel_time": 0.441649, "process_mem_max_rss": "111932", "process_out_blocks": "0", "process_user_time": 4.455757}
[0m00:13:21.723998 [debug] [MainThread]: Command `dbt run` succeeded at 00:13:21.723797 after 2.23 seconds
[0m00:13:21.725939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a547d1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a547d31a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a53de0680>]}
[0m00:13:21.727722 [debug] [MainThread]: Flushing usage events
[0m00:13:23.112704 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m00:32:06.347747 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dce3cc3b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dce308b30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcc430920>]}


============================== 00:32:06.362687 | 104ffe13-94e5-499f-87e8-2357ff5c50bc ==============================
[0m00:32:06.362687 [info ] [MainThread]: Running with dbt=1.9.4
[0m00:32:06.364926 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select tag:stock_predictions tag:BNGA', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m00:32:06.748758 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '104ffe13-94e5-499f-87e8-2357ff5c50bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcb36aea0>]}
[0m00:32:06.859957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '104ffe13-94e5-499f-87e8-2357ff5c50bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcbd42c90>]}
[0m00:32:06.862472 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m00:32:07.039590 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m00:32:07.778990 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m00:32:07.782095 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m00:32:07.784402 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m00:32:07.786814 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m00:32:07.789104 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m00:32:07.792167 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m00:32:08.546785 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m00:32:08.549961 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.3416402, "process_in_blocks": "416", "process_kernel_time": 0.351165, "process_mem_max_rss": "116004", "process_out_blocks": "0", "process_user_time": 5.879513}
[0m00:32:08.552349 [debug] [MainThread]: Command `dbt run` failed at 00:32:08.552138 after 2.34 seconds
[0m00:32:08.554345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcbfee570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dcbd40ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8dca72c1a0>]}
[0m00:32:08.556672 [debug] [MainThread]: Flushing usage events
[0m00:32:09.859711 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:51:47.801597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bda200b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bd0ba720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bd0bb7d0>]}


============================== 02:51:47.821503 | 11480836-9ef6-4025-8c42-fa6264a2f6bf ==============================
[0m02:51:47.821503 [info ] [MainThread]: Running with dbt=1.9.4
[0m02:51:47.825424 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'send_anonymous_usage_stats': 'True'}
[0m02:51:48.464894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '11480836-9ef6-4025-8c42-fa6264a2f6bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bcc8eba0>]}
[0m02:51:48.609227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '11480836-9ef6-4025-8c42-fa6264a2f6bf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bd99dc70>]}
[0m02:51:48.613296 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m02:51:48.860050 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m02:51:50.088746 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m02:51:50.093656 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m02:51:50.096083 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m02:51:50.098169 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m02:51:50.100120 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m02:51:50.102282 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m02:51:50.972348 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m02:51:50.976164 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.4292686, "process_in_blocks": "26992", "process_kernel_time": 0.511923, "process_mem_max_rss": "116292", "process_out_blocks": "1056", "process_user_time": 6.17319}
[0m02:51:50.978541 [debug] [MainThread]: Command `dbt run` failed at 02:51:50.978301 after 3.43 seconds
[0m02:51:50.980605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bcfbecc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bbf76a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f25bbfe8350>]}
[0m02:51:50.982663 [debug] [MainThread]: Flushing usage events
[0m02:51:52.575777 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:53:55.403543 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151eddcf20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151f150980>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151cef2e40>]}


============================== 02:53:55.417857 | aa4ed809-f8e5-46ef-ab6f-15fccee39172 ==============================
[0m02:53:55.417857 [info ] [MainThread]: Running with dbt=1.9.4
[0m02:53:55.419916 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions lstm_performance_metrics', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:53:55.738426 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa4ed809-f8e5-46ef-ab6f-15fccee39172', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151ca2ba40>]}
[0m02:53:55.834846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aa4ed809-f8e5-46ef-ab6f-15fccee39172', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151db7ae70>]}
[0m02:53:55.837297 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m02:53:55.986176 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m02:53:56.634650 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m02:53:56.637596 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m02:53:56.639879 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m02:53:56.642642 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m02:53:56.644901 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m02:53:56.646981 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m02:53:57.705682 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m02:53:57.712515 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4079125, "process_in_blocks": "0", "process_kernel_time": 0.3385, "process_mem_max_rss": "116000", "process_out_blocks": "0", "process_user_time": 4.43037}
[0m02:53:57.716001 [debug] [MainThread]: Command `dbt run` failed at 02:53:57.715525 after 2.41 seconds
[0m02:53:57.719712 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151eddcf20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151b9e6690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f151c5702c0>]}
[0m02:53:57.723200 [debug] [MainThread]: Flushing usage events
[0m02:53:59.042507 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m02:55:36.971927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd2a348c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd1b1be00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd1d15790>]}


============================== 02:55:36.985721 | 2b54b402-33be-480d-94ec-f05366c2b31f ==============================
[0m02:55:36.985721 [info ] [MainThread]: Running with dbt=1.9.4
[0m02:55:36.987969 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions model_performance_metrics', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m02:55:37.360597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2b54b402-33be-480d-94ec-f05366c2b31f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd17b83b0>]}
[0m02:55:37.476185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2b54b402-33be-480d-94ec-f05366c2b31f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd2236ed0>]}
[0m02:55:37.478843 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m02:55:37.634088 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m02:55:38.350372 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m02:55:38.353175 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m02:55:38.355380 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m02:55:38.357883 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m02:55:38.360384 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m02:55:38.362614 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m02:55:38.998084 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m02:55:39.000795 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.1411066, "process_in_blocks": "0", "process_kernel_time": 0.228323, "process_mem_max_rss": "116188", "process_out_blocks": "0", "process_user_time": 4.407642}
[0m02:55:39.002899 [debug] [MainThread]: Command `dbt run` failed at 02:55:39.002692 after 2.14 seconds
[0m02:55:39.004805 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd1a7e7b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbccfb8aa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcd03feb10>]}
[0m02:55:39.006890 [debug] [MainThread]: Flushing usage events
[0m02:55:40.247527 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:00:23.567462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8efb59100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8edd88590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8edcc5e80>]}


============================== 03:00:23.580173 | b720ba2e-f761-4319-ad1a-aa5b9299b6c7 ==============================
[0m03:00:23.580173 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:00:23.582149 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics model_performance_metrics stock_prediction_dashboard', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:00:23.893442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b720ba2e-f761-4319-ad1a-aa5b9299b6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8ecf3c740>]}
[0m03:00:23.993414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b720ba2e-f761-4319-ad1a-aa5b9299b6c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8ee1d5640>]}
[0m03:00:23.995653 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:00:24.132397 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:00:24.769336 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:00:24.772107 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:00:24.774064 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:00:24.775983 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:00:24.777814 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:00:24.779740 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:00:25.356288 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m03:00:25.358969 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.8880486, "process_in_blocks": "0", "process_kernel_time": 0.172158, "process_mem_max_rss": "115980", "process_out_blocks": "0", "process_user_time": 4.101418}
[0m03:00:25.361073 [debug] [MainThread]: Command `dbt run` failed at 03:00:25.360889 after 1.89 seconds
[0m03:00:25.363077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8ee2dc530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8ebf06990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8ebf069c0>]}
[0m03:00:25.365006 [debug] [MainThread]: Flushing usage events
[0m03:00:26.662112 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:02:36.490107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd086d21e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd086d21190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd086d22c90>]}


============================== 03:02:36.504356 | 560caf15-2015-4d38-8bf6-70987801b727 ==============================
[0m03:02:36.504356 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:02:36.506723 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics model_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m03:02:36.900831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '560caf15-2015-4d38-8bf6-70987801b727', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd086660110>]}
[0m03:02:37.057478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '560caf15-2015-4d38-8bf6-70987801b727', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd085db0860>]}
[0m03:02:37.059978 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:02:37.239782 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:02:38.001080 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:02:38.005023 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:02:38.007951 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:02:38.010484 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:02:38.013391 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:02:38.015640 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:02:38.962402 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:02:38.965926 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.6080194, "process_in_blocks": "0", "process_kernel_time": 0.441009, "process_mem_max_rss": "116052", "process_out_blocks": "0", "process_user_time": 6.09395}
[0m03:02:38.968706 [debug] [MainThread]: Command `dbt run` failed at 03:02:38.968472 after 2.61 seconds
[0m03:02:38.971091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd086e66a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd085d0e240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd0849481a0>]}
[0m03:02:38.973368 [debug] [MainThread]: Flushing usage events
[0m03:02:40.244896 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:07:48.364423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7137505a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71376b38f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71375050a0>]}


============================== 03:07:48.375874 | a5ca7fc6-52ed-4706-9a1e-f944654c65e5 ==============================
[0m03:07:48.375874 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:07:48.377290 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions model_performance_metrics', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:07:48.687471 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a5ca7fc6-52ed-4706-9a1e-f944654c65e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f713613bd10>]}
[0m03:07:48.879659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a5ca7fc6-52ed-4706-9a1e-f944654c65e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71375c6a20>]}
[0m03:07:48.884030 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:07:49.134752 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:07:49.978505 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:07:49.981896 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:07:49.984551 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:07:49.987173 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:07:49.989811 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:07:49.991962 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:07:50.814693 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m03:07:50.818262 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.5808876, "process_in_blocks": "0", "process_kernel_time": 0.241, "process_mem_max_rss": "118328", "process_out_blocks": "0", "process_user_time": 4.508722}
[0m03:07:50.820722 [debug] [MainThread]: Command `dbt run` failed at 03:07:50.820417 after 2.58 seconds
[0m03:07:50.824056 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f713ab83170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7134d22d80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7134d13ec0>]}
[0m03:07:50.828527 [debug] [MainThread]: Flushing usage events
[0m03:07:52.113189 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:08:29.140414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660a455b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660a456090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660a457dd0>]}


============================== 03:08:29.153551 | 45f4481e-4494-4798-9bc0-d271f8ada5fd ==============================
[0m03:08:29.153551 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:08:29.155956 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions model_performance_metrics', 'send_anonymous_usage_stats': 'True'}
[0m03:08:29.489372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '45f4481e-4494-4798-9bc0-d271f8ada5fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6609f61b50>]}
[0m03:08:29.606047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '45f4481e-4494-4798-9bc0-d271f8ada5fd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660bc7fce0>]}
[0m03:08:29.609159 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:08:29.905280 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:08:30.687877 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:08:30.690941 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:08:30.693156 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:08:30.695589 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:08:30.698309 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:08:30.700575 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:08:31.472661 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.lstm_performance_metrics' (models/marts/analytics/lstm_performance_metrics.sql) depends on a source named 'public.model_performance_metrics' which was not found
[0m03:08:31.475801 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.4435728, "process_in_blocks": "0", "process_kernel_time": 0.407638, "process_mem_max_rss": "116188", "process_out_blocks": "0", "process_user_time": 5.408669}
[0m03:08:31.478314 [debug] [MainThread]: Command `dbt run` failed at 03:08:31.478004 after 2.45 seconds
[0m03:08:31.481372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660de8b1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f660bf4c590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6608bba5a0>]}
[0m03:08:31.483453 [debug] [MainThread]: Flushing usage events
[0m03:08:32.589568 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:22:52.851788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea454b260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea454a900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea454a060>]}


============================== 03:22:52.871228 | a73c2d91-b1a4-4cfb-ab05-dfaf180c8cab ==============================
[0m03:22:52.871228 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:22:52.873536 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions model_performance_metrics', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:22:53.368165 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a73c2d91-b1a4-4cfb-ab05-dfaf180c8cab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea41bcda0>]}
[0m03:22:53.495198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a73c2d91-b1a4-4cfb-ab05-dfaf180c8cab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea47f2c30>]}
[0m03:22:53.498632 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:22:53.677619 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:22:54.356189 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:22:54.359015 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:22:54.361182 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:22:54.363194 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:22:54.365247 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:22:54.367270 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:22:55.115750 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:22:55.118582 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.378439, "process_in_blocks": "27424", "process_kernel_time": 0.386877, "process_mem_max_rss": "116436", "process_out_blocks": "1912", "process_user_time": 4.870685}
[0m03:22:55.120809 [debug] [MainThread]: Command `dbt run` failed at 03:22:55.120577 after 2.38 seconds
[0m03:22:55.122588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea4e26b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea2337740>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7ea41bd310>]}
[0m03:22:55.124404 [debug] [MainThread]: Flushing usage events
[0m03:22:56.347383 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:24:03.579349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec70a29a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec70a2b230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec70a2b260>]}


============================== 03:24:03.592813 | cc0109e3-835c-47e7-a7d3-0b9ae052a372 ==============================
[0m03:24:03.592813 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:24:03.594943 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:24:03.950437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cc0109e3-835c-47e7-a7d3-0b9ae052a372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec6fcdaae0>]}
[0m03:24:04.052179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cc0109e3-835c-47e7-a7d3-0b9ae052a372', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec6fe5e0f0>]}
[0m03:24:04.054796 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:24:04.241732 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:24:04.930072 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:24:04.933184 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:24:04.935285 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:24:04.937365 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:24:04.939988 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:24:04.942004 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:24:05.672466 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:24:05.675622 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.196153, "process_in_blocks": "0", "process_kernel_time": 0.280103, "process_mem_max_rss": "116168", "process_out_blocks": "0", "process_user_time": 4.421626}
[0m03:24:05.677793 [debug] [MainThread]: Command `dbt run` failed at 03:24:05.677595 after 2.20 seconds
[0m03:24:05.679853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec7115c410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec6e340ce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fec6e3759d0>]}
[0m03:24:05.681778 [debug] [MainThread]: Flushing usage events
[0m03:24:06.849319 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:27:30.183641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecbeca9c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecde6b500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecbecaa50>]}


============================== 03:27:30.196641 | 4a80f0c8-bcab-4053-abca-5c7852b4316e ==============================
[0m03:27:30.196641 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:27:30.198529 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude staging.stg_stock_predictions', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:27:30.506449 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '4a80f0c8-bcab-4053-abca-5c7852b4316e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecc014920>]}
[0m03:27:30.606194 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '4a80f0c8-bcab-4053-abca-5c7852b4316e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecc559a90>]}
[0m03:27:30.608689 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:27:30.750744 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:27:31.466781 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:27:31.470196 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:27:31.472612 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:27:31.474590 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:27:31.476442 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:27:31.478332 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:27:32.106769 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:27:32.111256 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.0193043, "process_in_blocks": "0", "process_kernel_time": 0.338146, "process_mem_max_rss": "116032", "process_out_blocks": "0", "process_user_time": 4.226828}
[0m03:27:32.113603 [debug] [MainThread]: Command `dbt run` failed at 03:27:32.113419 after 2.02 seconds
[0m03:27:32.115399 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ecc49f1a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ec9b19ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ec9b1bf20>]}
[0m03:27:32.117243 [debug] [MainThread]: Flushing usage events
[0m03:27:33.574232 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:33:31.519262 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00f202f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a0184cb30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a0184f9b0>]}


============================== 03:33:31.533787 | e92ef91b-2906-40d3-8027-b3ed80a2db84 ==============================
[0m03:33:31.533787 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:33:31.535908 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:33:31.971406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e92ef91b-2906-40d3-8027-b3ed80a2db84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00d00ad0>]}
[0m03:33:32.105009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e92ef91b-2906-40d3-8027-b3ed80a2db84', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a018e36b0>]}
[0m03:33:32.107933 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:33:32.304392 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:33:33.119607 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:33:33.123281 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:33:33.126503 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:33:33.129559 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:33:33.133167 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:33:33.137208 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:33:34.302064 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:33:34.307207 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.9047532, "process_in_blocks": "0", "process_kernel_time": 0.460613, "process_mem_max_rss": "116328", "process_out_blocks": "1912", "process_user_time": 6.178229}
[0m03:33:34.309790 [debug] [MainThread]: Command `dbt run` failed at 03:33:34.309518 after 2.91 seconds
[0m03:33:34.311826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9a00f202f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99fefa07a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f99ffb3cf20>]}
[0m03:33:34.313848 [debug] [MainThread]: Flushing usage events
[0m03:33:35.482671 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:34:05.431153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a0c12840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a125ee40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a2c7cbc0>]}


============================== 03:34:05.446705 | c4e8e336-5bcc-44ba-944e-ae68827a0f00 ==============================
[0m03:34:05.446705 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:34:05.448806 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:34:05.771608 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'c4e8e336-5bcc-44ba-944e-ae68827a0f00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a138c1a0>]}
[0m03:34:05.871473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'c4e8e336-5bcc-44ba-944e-ae68827a0f00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a1b7a810>]}
[0m03:34:05.873933 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:34:06.020120 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:34:06.674701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:34:06.677736 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:34:06.679654 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:34:06.681612 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:34:06.683650 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:34:06.685343 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:34:07.312540 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:34:07.315289 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.9794071, "process_in_blocks": "0", "process_kernel_time": 0.231361, "process_mem_max_rss": "116412", "process_out_blocks": "0", "process_user_time": 4.586986}
[0m03:34:07.317671 [debug] [MainThread]: Command `dbt run` failed at 03:34:07.317390 after 1.98 seconds
[0m03:34:07.320203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38a0ab7470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389f558c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f389e9972f0>]}
[0m03:34:07.321902 [debug] [MainThread]: Flushing usage events
[0m03:34:08.402794 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:39:25.868529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b7a77fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b7a74bc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b78a0c20>]}


============================== 03:39:25.888717 | 654b349c-1356-48ec-b9a2-487a8d6990dd ==============================
[0m03:39:25.888717 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:39:25.891767 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:39:26.474621 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '654b349c-1356-48ec-b9a2-487a8d6990dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b7554050>]}
[0m03:39:26.696234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '654b349c-1356-48ec-b9a2-487a8d6990dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b770d850>]}
[0m03:39:26.699138 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:39:26.931029 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:39:27.938156 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 5 files changed.
[0m03:39:27.943461 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:39:27.945964 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:39:27.948394 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:39:27.950529 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:39:27.952529 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:39:28.814375 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.idx_stock.stg_stock_predictions' (models/staging/stg_stock_predictions.sql) depends on a source named 'public.stock_predictions' which was not found
[0m03:39:28.817415 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0851288, "process_in_blocks": "0", "process_kernel_time": 0.508335, "process_mem_max_rss": "118288", "process_out_blocks": "0", "process_user_time": 6.787772}
[0m03:39:28.819791 [debug] [MainThread]: Command `dbt run` failed at 03:39:28.819562 after 3.09 seconds
[0m03:39:28.822077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71bb28b200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b5f43a40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f71b89c0950>]}
[0m03:39:28.824530 [debug] [MainThread]: Flushing usage events
[0m03:39:30.271846 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:47:56.245883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91ac545490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aaa133e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aaa11430>]}


============================== 03:47:56.258924 | 2f7dd42a-98aa-4a56-a571-a411e70e90dd ==============================
[0m03:47:56.258924 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:47:56.260959 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:47:56.595360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aa533f80>]}
[0m03:47:56.698594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aa73f9e0>]}
[0m03:47:56.701176 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:47:56.844610 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:47:57.525385 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 6 files changed.
[0m03:47:57.528300 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/schema.yml
[0m03:47:57.530462 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/src_raw.yml
[0m03:47:57.532598 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m03:47:57.534669 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m03:47:57.536910 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/staging/stg_stock_predictions.sql
[0m03:47:57.539070 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m03:47:58.448539 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91a892d490>]}
[0m03:47:58.631213 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:47:58.648777 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:47:58.739074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91a6f1afc0>]}
[0m03:47:58.741422 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:47:58.743406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91a8db3170>]}
[0m03:47:58.747749 [info ] [MainThread]: 
[0m03:47:58.749858 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:47:58.751825 [info ] [MainThread]: 
[0m03:47:58.754156 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:47:58.757511 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:47:58.835983 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:47:58.838089 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:47:58.840127 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:58.853235 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.013 seconds
[0m03:47:58.856822 [debug] [ThreadPool]: On list_airflow: Close
[0m03:47:58.859360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m03:47:58.861493 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m03:47:58.870538 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:47:58.872507 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m03:47:58.874211 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:47:58.884618 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m03:47:58.886712 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:47:58.888848 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m03:47:58.894964 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.004 seconds
[0m03:47:58.897495 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m03:47:58.898987 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:47:58.900561 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m03:47:58.904330 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m03:47:58.906145 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m03:47:58.915692 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_analytics)
[0m03:47:58.916820 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:47:58.918079 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m03:47:58.928425 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:47:58.932242 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:47:58.937093 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:47:58.939290 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:47:58.940824 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:47:58.942553 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:47:58.944294 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:47:58.945720 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:58.947363 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:58.958553 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:47:58.960220 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:47:58.961697 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:47:58.962426 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m03:47:58.964279 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:47:58.966220 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:47:58.968097 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:47:58.969784 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:47:58.973348 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:47:58.976848 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:47:58.980071 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:47:58.980846 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m03:47:58.981514 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:47:58.983193 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:47:58.985925 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:47:58.989641 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:47:58.993152 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:47:58.994921 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:47:59.006359 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.008324 [debug] [MainThread]: On master: BEGIN
[0m03:47:59.009962 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:47:59.021346 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:47:59.023425 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.025585 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:47:59.034883 [debug] [MainThread]: SQL status: SELECT 0 in 0.007 seconds
[0m03:47:59.038753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aa3d6cf0>]}
[0m03:47:59.040795 [debug] [MainThread]: On master: ROLLBACK
[0m03:47:59.042934 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.044634 [debug] [MainThread]: On master: BEGIN
[0m03:47:59.046902 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:47:59.048579 [debug] [MainThread]: On master: COMMIT
[0m03:47:59.050384 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.051890 [debug] [MainThread]: On master: COMMIT
[0m03:47:59.054002 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:47:59.055957 [debug] [MainThread]: On master: Close
[0m03:47:59.065657 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m03:47:59.067705 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m03:47:59.069679 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m03:47:59.071760 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m03:47:59.085234 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.100474 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m03:47:59.161280 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.174442 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.176208 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m03:47:59.177989 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:47:59.189622 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m03:47:59.191599 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.193530 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m03:47:59.213880 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.018 seconds
[0m03:47:59.226163 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.228352 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m03:47:59.231033 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:47:59.256931 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m03:47:59.258865 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.260617 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m03:47:59.264326 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m03:47:59.275303 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m03:47:59.284388 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:47:59.286396 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m03:47:59.289105 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m03:47:59.293800 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m03:47:59.298614 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f7dd42a-98aa-4a56-a571-a411e70e90dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91ac5ab530>]}
[0m03:47:59.300983 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.23s]
[0m03:47:59.303189 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m03:47:59.307128 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.308574 [debug] [MainThread]: On master: BEGIN
[0m03:47:59.309917 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:47:59.320994 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:47:59.323074 [debug] [MainThread]: On master: COMMIT
[0m03:47:59.324697 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:59.326347 [debug] [MainThread]: On master: COMMIT
[0m03:47:59.328250 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:47:59.329968 [debug] [MainThread]: On master: Close
[0m03:47:59.331737 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:47:59.333462 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m03:47:59.335123 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m03:47:59.336805 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m03:47:59.338799 [info ] [MainThread]: 
[0m03:47:59.340541 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.59 seconds (0.59s).
[0m03:47:59.342840 [debug] [MainThread]: Command end result
[0m03:47:59.415673 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:47:59.424283 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:47:59.440064 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:47:59.441661 [info ] [MainThread]: 
[0m03:47:59.443699 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:47:59.445532 [info ] [MainThread]: 
[0m03:47:59.447338 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m03:47:59.449913 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.3002367, "process_in_blocks": "3000", "process_kernel_time": 0.390473, "process_mem_max_rss": "132108", "process_out_blocks": "448", "process_user_time": 5.386533}
[0m03:47:59.452163 [debug] [MainThread]: Command `dbt run` succeeded at 03:47:59.451946 after 3.30 seconds
[0m03:47:59.454305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91aa7d7da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91a646fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91a63e3ce0>]}
[0m03:47:59.456123 [debug] [MainThread]: Flushing usage events
[0m03:48:00.615603 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:10.251540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d2296f8c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d241fb860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d22eb5100>]}


============================== 03:48:10.270280 | 02e25bff-254b-4a5c-879b-b26758f656a5 ==============================
[0m03:48:10.270280 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:48:10.273049 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'send_anonymous_usage_stats': 'True'}
[0m03:48:10.781910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d224e2030>]}
[0m03:48:11.058552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d2305ee70>]}
[0m03:48:11.061818 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:48:11.326117 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:48:12.152139 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:48:12.154029 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:48:12.289400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d21728290>]}
[0m03:48:12.585961 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:48:12.605565 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:48:12.676111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d20b40500>]}
[0m03:48:12.678510 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:48:12.680853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d20b0bd40>]}
[0m03:48:12.686546 [info ] [MainThread]: 
[0m03:48:12.688967 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:48:12.691191 [info ] [MainThread]: 
[0m03:48:12.694406 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:48:12.705645 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:48:12.780410 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:48:12.782505 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:48:12.784438 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:12.798700 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.014 seconds
[0m03:48:12.802373 [debug] [ThreadPool]: On list_airflow: Close
[0m03:48:12.805367 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m03:48:12.808644 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m03:48:12.819267 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:48:12.821428 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m03:48:12.823435 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:12.835511 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m03:48:12.837714 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:48:12.839766 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m03:48:12.842506 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m03:48:12.845595 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m03:48:12.847576 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:48:12.849476 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m03:48:12.858110 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m03:48:12.860801 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m03:48:12.866278 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_staging)
[0m03:48:12.867815 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:48:12.870030 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:48:12.881036 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:48:12.887313 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:48:12.892634 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:48:12.894940 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:48:12.897119 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:48:12.899278 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:48:12.901361 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:12.903257 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:12.905266 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:12.918191 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m03:48:12.920068 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:48:12.921667 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:48:12.922720 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m03:48:12.924259 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:48:12.926886 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:48:12.929011 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:48:12.932612 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:48:12.934777 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:48:12.935918 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m03:48:12.942180 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:48:12.943036 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:48:12.943802 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:48:12.945801 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:48:12.948968 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:48:12.952502 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:48:12.956694 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:48:12.958959 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:48:12.972175 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:12.974448 [debug] [MainThread]: On master: BEGIN
[0m03:48:12.976762 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:48:12.989365 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m03:48:12.991882 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:12.994366 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:48:13.010411 [debug] [MainThread]: SQL status: SELECT 1 in 0.014 seconds
[0m03:48:13.014649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d24338e30>]}
[0m03:48:13.017012 [debug] [MainThread]: On master: ROLLBACK
[0m03:48:13.019248 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:13.021017 [debug] [MainThread]: On master: BEGIN
[0m03:48:13.023396 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:48:13.026041 [debug] [MainThread]: On master: COMMIT
[0m03:48:13.028161 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:13.030210 [debug] [MainThread]: On master: COMMIT
[0m03:48:13.032629 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:48:13.034734 [debug] [MainThread]: On master: Close
[0m03:48:13.044316 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m03:48:13.045518 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m03:48:13.047634 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m03:48:13.050241 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m03:48:13.052494 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.dim_companies)
[0m03:48:13.054876 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_daily_stock_metrics)
[0m03:48:13.057000 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m03:48:13.059851 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m03:48:13.091970 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m03:48:13.093033 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:13.102819 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m03:48:13.111428 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m03:48:13.296662 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:13.293081 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m03:48:13.305814 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:13.308189 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:48:13.309710 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m03:48:13.311674 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m03:48:13.313526 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:48:13.315464 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:13.329548 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m03:48:13.331379 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:13.333248 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m03:48:13.335335 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m03:48:13.337458 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:48:13.339653 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m03:48:17.084780 [debug] [Thread-1 (]: SQL status: SELECT 963 in 3.743 seconds
[0m03:48:17.104291 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:48:17.107006 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m03:48:17.113761 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.004 seconds
[0m03:48:17.143507 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m03:48:17.145633 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:48:17.147622 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m03:48:17.155500 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m03:48:17.170147 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m03:48:17.180447 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:48:17.182902 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m03:48:17.185397 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:48:17.191362 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m03:48:17.195496 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d247df500>]}
[0m03:48:17.197891 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 4.14s]
[0m03:48:17.200337 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m03:48:17.380984 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 4.045 seconds
[0m03:48:17.387373 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:17.389684 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m03:48:17.392093 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:17.395367 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m03:48:17.397239 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:17.398997 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m03:48:17.407510 [debug] [Thread-2 (]: SQL status: COMMIT in 0.007 seconds
[0m03:48:17.412891 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m03:48:17.415067 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:48:17.416836 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m03:48:17.418935 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:48:17.422361 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m03:48:17.424547 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02e25bff-254b-4a5c-879b-b26758f656a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1f69fe60>]}
[0m03:48:17.426801 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 4.37s]
[0m03:48:17.429195 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m03:48:17.432969 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:17.434744 [debug] [MainThread]: On master: BEGIN
[0m03:48:17.436465 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:48:17.447175 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:48:17.449141 [debug] [MainThread]: On master: COMMIT
[0m03:48:17.451137 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:17.452907 [debug] [MainThread]: On master: COMMIT
[0m03:48:17.455279 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:48:17.457214 [debug] [MainThread]: On master: Close
[0m03:48:17.459193 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:48:17.460983 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m03:48:17.462655 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m03:48:17.464264 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m03:48:17.465873 [info ] [MainThread]: 
[0m03:48:17.467613 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 4.77 seconds (4.77s).
[0m03:48:17.470333 [debug] [MainThread]: Command end result
[0m03:48:17.549747 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:48:17.558982 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:48:17.574876 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:48:17.576620 [info ] [MainThread]: 
[0m03:48:17.578337 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:48:17.579876 [info ] [MainThread]: 
[0m03:48:17.581491 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m03:48:17.584007 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.4828963, "process_in_blocks": "0", "process_kernel_time": 0.396834, "process_mem_max_rss": "121576", "process_out_blocks": "0", "process_user_time": 6.38903}
[0m03:48:17.586267 [debug] [MainThread]: Command `dbt run` succeeded at 03:48:17.586035 after 7.49 seconds
[0m03:48:17.588266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d22997d40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d21b95880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d22550890>]}
[0m03:48:17.590230 [debug] [MainThread]: Flushing usage events
[0m03:48:18.664222 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:48:27.309565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6c0c5f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6c5f48f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6c667ad0>]}


============================== 03:48:27.320945 | 73bf245c-a7b9-4a50-a20a-01c02a6cd94d ==============================
[0m03:48:27.320945 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:48:27.323059 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:48:27.637623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6e02f920>]}
[0m03:48:27.730853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6cc96330>]}
[0m03:48:27.732846 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:48:27.869023 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:48:28.418374 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:48:28.420020 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:48:28.503111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6b595910>]}
[0m03:48:28.681397 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:48:28.695246 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:48:28.732226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6a537d70>]}
[0m03:48:28.734306 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:48:28.736325 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6c032de0>]}
[0m03:48:28.743321 [info ] [MainThread]: 
[0m03:48:28.745228 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:48:28.746891 [info ] [MainThread]: 
[0m03:48:28.748924 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:48:28.757366 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:48:28.816792 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:48:28.818760 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:48:28.820558 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:28.832601 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.012 seconds
[0m03:48:28.835733 [debug] [ThreadPool]: On list_airflow: Close
[0m03:48:28.837992 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m03:48:28.839865 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m03:48:28.848516 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:48:28.849974 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m03:48:28.851380 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:28.861692 [debug] [ThreadPool]: SQL status: BEGIN in 0.010 seconds
[0m03:48:28.863443 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:48:28.865101 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m03:48:28.867290 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m03:48:28.869781 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m03:48:28.871390 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:48:28.873018 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m03:48:28.880252 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m03:48:28.882063 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m03:48:28.887069 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m03:48:28.888513 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:48:28.890881 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:48:28.902117 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:48:28.906018 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:48:28.910647 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:48:28.912504 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:48:28.914296 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:48:28.916078 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:48:28.917758 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:48:28.919435 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:28.921062 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:48:28.931916 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:48:28.933289 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:48:28.934574 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:48:28.935401 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:48:28.936844 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:48:28.938945 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:48:28.940717 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:48:28.942535 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:48:28.945516 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:48:28.948055 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m03:48:28.951158 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:48:28.951898 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m03:48:28.952607 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m03:48:28.953991 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:48:28.956962 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:48:28.960266 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:48:28.963904 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:48:28.965616 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:48:28.977111 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:28.979005 [debug] [MainThread]: On master: BEGIN
[0m03:48:28.980711 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:48:28.991367 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:48:28.993354 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:28.995424 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:48:29.006096 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m03:48:29.009577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d69d93800>]}
[0m03:48:29.011656 [debug] [MainThread]: On master: ROLLBACK
[0m03:48:29.013637 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:29.015423 [debug] [MainThread]: On master: BEGIN
[0m03:48:29.017592 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:48:29.019296 [debug] [MainThread]: On master: COMMIT
[0m03:48:29.020851 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:29.022460 [debug] [MainThread]: On master: COMMIT
[0m03:48:29.024230 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:48:29.025858 [debug] [MainThread]: On master: Close
[0m03:48:29.032936 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m03:48:29.033778 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m03:48:29.034555 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m03:48:29.035400 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m03:48:29.037051 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m03:48:29.039336 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m03:48:29.041593 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m03:48:29.043884 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m03:48:29.046259 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.daily_stock_metrics)
[0m03:48:29.048005 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_daily)
[0m03:48:29.049777 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_monthly)
[0m03:48:29.051695 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m03:48:29.053328 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m03:48:29.054800 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m03:48:29.056598 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m03:48:29.058330 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m03:48:29.071258 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m03:48:29.077039 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m03:48:29.083116 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m03:48:29.089706 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m03:48:29.099585 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m03:48:29.101155 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m03:48:29.108207 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m03:48:29.109152 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m03:48:29.202268 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m03:48:29.205747 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m03:48:29.206735 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m03:48:29.212263 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m03:48:29.222134 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:48:29.223915 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:48:29.225239 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m03:48:29.226954 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:48:29.228359 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:48:29.235094 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m03:48:29.237403 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:48:29.239606 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m03:48:29.241514 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m03:48:29.243498 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:29.246966 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:48:29.248833 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:48:29.255551 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m03:48:29.257293 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:48:29.258659 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m03:48:29.261908 [debug] [Thread-3 (]: SQL status: BEGIN in 0.015 seconds
[0m03:48:29.263162 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m03:48:29.265188 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:48:29.266117 [debug] [Thread-4 (]: SQL status: BEGIN in 0.017 seconds
[0m03:48:29.268802 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:48:29.271133 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m03:48:29.273431 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:48:29.275404 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m03:48:29.279616 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m03:48:29.490534 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.230 seconds
[0m03:48:29.512934 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:48:29.515768 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m03:48:29.519246 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:29.561275 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m03:48:29.563589 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:48:29.565466 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m03:48:29.579853 [debug] [Thread-2 (]: SQL status: COMMIT in 0.012 seconds
[0m03:48:29.598541 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m03:48:29.612352 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:48:29.614499 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m03:48:29.616942 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:48:29.622589 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m03:48:29.628411 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d69062480>]}
[0m03:48:29.631909 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.58s]
[0m03:48:29.635718 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m03:48:29.638775 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m03:48:29.642006 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m03:48:29.644881 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m03:48:29.647591 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m03:48:29.656070 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m03:48:29.668756 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m03:48:29.677012 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m03:48:29.693543 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:48:29.696548 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m03:48:29.699194 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:48:29.715167 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m03:48:29.717466 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:48:29.719523 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m03:48:35.474264 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 6.192 seconds
[0m03:48:35.481811 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:48:35.483794 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m03:48:35.487898 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:35.491787 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m03:48:35.493662 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:48:35.495430 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m03:48:35.506068 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m03:48:35.512459 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m03:48:35.514728 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:48:35.516788 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m03:48:35.519721 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:48:35.523760 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m03:48:35.526484 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6c44bb60>]}
[0m03:48:35.529924 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 6.48s]
[0m03:48:35.532490 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m03:48:35.534575 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m03:48:35.538238 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m03:48:35.541418 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m03:48:35.545560 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m03:48:35.559293 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m03:48:35.577812 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m03:48:35.588358 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m03:48:35.607412 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:48:35.610808 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m03:48:35.613941 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:48:35.634485 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m03:48:35.637425 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:48:35.640664 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m03:48:36.643624 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.366 seconds
[0m03:48:36.655236 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:48:36.657955 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m03:48:36.661432 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:36.667262 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m03:48:36.670033 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:48:36.672553 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m03:48:36.678934 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m03:48:36.688037 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m03:48:36.691649 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:48:36.694807 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m03:48:36.698156 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:48:36.704478 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m03:48:36.707865 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d687362a0>]}
[0m03:48:36.711432 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 7.66s]
[0m03:48:36.714923 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m03:48:36.718999 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m03:48:36.722337 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m03:48:36.726073 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m03:48:36.728989 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m03:48:36.746576 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m03:48:36.765530 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m03:48:36.782501 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m03:48:36.804313 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:48:36.807191 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m03:48:36.813061 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:48:36.838650 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m03:48:36.841565 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:48:36.845420 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m03:48:37.358739 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.077 seconds
[0m03:48:37.370065 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:48:37.373298 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m03:48:37.376772 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:37.381678 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m03:48:37.384838 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:48:37.387184 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m03:48:37.395728 [debug] [Thread-4 (]: SQL status: COMMIT in 0.006 seconds
[0m03:48:37.405296 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m03:48:37.408408 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:48:37.410609 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m03:48:37.413138 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:48:37.419722 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m03:48:37.424425 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d690c4500>]}
[0m03:48:37.428404 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 8.37s]
[0m03:48:37.433099 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m03:48:37.549555 [debug] [Thread-3 (]: SQL status: SELECT 19279 in 0.701 seconds
[0m03:48:37.558564 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:48:37.560448 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m03:48:37.562673 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:37.566986 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m03:48:37.569827 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:48:37.572639 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m03:48:37.615091 [debug] [Thread-3 (]: SQL status: COMMIT in 0.040 seconds
[0m03:48:37.621700 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m03:48:37.624164 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:48:37.626062 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m03:48:37.628496 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:48:37.632991 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m03:48:37.635919 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d68728d10>]}
[0m03:48:37.639497 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 19279[0m in 0.91s]
[0m03:48:37.642846 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m03:48:40.444809 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 10.724 seconds
[0m03:48:40.455502 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:48:40.457966 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m03:48:40.460661 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:40.466431 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m03:48:40.468915 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:48:40.470855 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m03:48:40.515839 [debug] [Thread-2 (]: SQL status: COMMIT in 0.043 seconds
[0m03:48:40.526167 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m03:48:40.528515 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:48:40.530874 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m03:48:40.534094 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:48:40.539386 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m03:48:40.542152 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d68705700>]}
[0m03:48:40.545248 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 10.90s]
[0m03:48:40.549033 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m03:48:45.454698 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 9.812 seconds
[0m03:48:45.462518 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:48:45.464735 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m03:48:45.467293 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:48:45.471153 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m03:48:45.472892 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:48:45.474605 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m03:48:45.482525 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m03:48:45.488567 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m03:48:45.490720 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:48:45.493080 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m03:48:45.496476 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:48:45.500651 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m03:48:45.502863 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '73bf245c-a7b9-4a50-a20a-01c02a6cd94d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6875fb30>]}
[0m03:48:45.505328 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 9.96s]
[0m03:48:45.508204 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m03:48:45.515073 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:45.517005 [debug] [MainThread]: On master: BEGIN
[0m03:48:45.518777 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:48:45.533177 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m03:48:45.535478 [debug] [MainThread]: On master: COMMIT
[0m03:48:45.537389 [debug] [MainThread]: Using postgres connection "master"
[0m03:48:45.539077 [debug] [MainThread]: On master: COMMIT
[0m03:48:45.540985 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:48:45.543344 [debug] [MainThread]: On master: Close
[0m03:48:45.546494 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:48:45.548607 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m03:48:45.550289 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m03:48:45.551793 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m03:48:45.553315 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m03:48:45.555188 [info ] [MainThread]: 
[0m03:48:45.557142 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 16.81 seconds (16.81s).
[0m03:48:45.563873 [debug] [MainThread]: Command end result
[0m03:48:45.654031 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:48:45.665246 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:48:45.690641 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:48:45.693647 [info ] [MainThread]: 
[0m03:48:45.696806 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:48:45.699470 [info ] [MainThread]: 
[0m03:48:45.702063 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m03:48:45.705691 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.49423, "process_in_blocks": "0", "process_kernel_time": 0.399699, "process_mem_max_rss": "122700", "process_out_blocks": "0", "process_user_time": 4.816375}
[0m03:48:45.709620 [debug] [MainThread]: Command `dbt run` succeeded at 03:48:45.709155 after 18.50 seconds
[0m03:48:45.712566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6e121730>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d68721550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0d6d3897f0>]}
[0m03:48:45.714917 [debug] [MainThread]: Flushing usage events
[0m03:48:47.089668 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:49:03.073799 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c6df7290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c6df6f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c6df72f0>]}


============================== 03:49:03.087534 | a17fd513-ef65-4042-b5a5-3e4f2554bcbd ==============================
[0m03:49:03.087534 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:49:03.090080 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:49:03.535065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c532bf80>]}
[0m03:49:03.671664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c61c3da0>]}
[0m03:49:03.674685 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:49:03.923602 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:49:04.619827 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:49:04.621881 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:49:04.712726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c670e720>]}
[0m03:49:04.905434 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:49:04.921552 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:49:04.983137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3f21cd0>]}
[0m03:49:04.985571 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:49:04.988328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c53fe6f0>]}
[0m03:49:04.994463 [info ] [MainThread]: 
[0m03:49:04.996475 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:49:04.998309 [info ] [MainThread]: 
[0m03:49:05.000414 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:49:05.011330 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:49:05.012550 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m03:49:05.013678 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:49:05.087458 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:49:05.088249 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:49:05.088922 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:49:05.090321 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:49:05.092127 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:49:05.093953 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:49:05.095572 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:49:05.097248 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:49:05.098898 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:49:05.110794 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m03:49:05.111640 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:49:05.112949 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m03:49:05.113742 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:49:05.115679 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:49:05.117552 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:49:05.119881 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:49:05.121841 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:49:05.123788 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:49:05.129687 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m03:49:05.130454 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m03:49:05.131248 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m03:49:05.134206 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:49:05.137944 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:49:05.141354 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:49:05.143655 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:49:05.145459 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:49:05.147217 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:49:05.164736 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.166919 [debug] [MainThread]: On master: BEGIN
[0m03:49:05.170303 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:49:05.181075 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:49:05.183181 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.185511 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:49:05.196566 [debug] [MainThread]: SQL status: SELECT 1 in 0.009 seconds
[0m03:49:05.200086 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a17fd513-ef65-4042-b5a5-3e4f2554bcbd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c3f07230>]}
[0m03:49:05.202410 [debug] [MainThread]: On master: ROLLBACK
[0m03:49:05.204563 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.206272 [debug] [MainThread]: On master: BEGIN
[0m03:49:05.208510 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:49:05.210304 [debug] [MainThread]: On master: COMMIT
[0m03:49:05.211991 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.213634 [debug] [MainThread]: On master: COMMIT
[0m03:49:05.215614 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:49:05.217173 [debug] [MainThread]: On master: Close
[0m03:49:05.226459 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:49:05.227327 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:49:05.229100 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m03:49:05.230850 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m03:49:05.232865 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m03:49:05.234923 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m03:49:05.237194 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:49:05.238810 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:49:05.271588 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:49:05.275877 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:49:05.284686 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:49:05.292822 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:49:05.318309 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:49:05.321349 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:49:05.328986 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:49:05.330922 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m03:49:05.332085 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:49:05.333716 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:49:05.336071 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m03:49:05.339642 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:49:05.347750 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m03:49:05.349878 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:49:05.351529 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m03:49:05.353079 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m03:49:05.355357 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:49:05.358453 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m03:49:05.359319 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m03:49:05.362216 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m03:49:05.369167 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m03:49:05.372713 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m03:49:05.375034 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m03:49:05.377054 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m03:49:05.379146 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.14s]
[0m03:49:05.381391 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.15s]
[0m03:49:05.383435 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:49:05.386105 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:49:05.391570 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.393319 [debug] [MainThread]: On master: BEGIN
[0m03:49:05.395113 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:49:05.405978 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:49:05.408184 [debug] [MainThread]: On master: COMMIT
[0m03:49:05.410551 [debug] [MainThread]: Using postgres connection "master"
[0m03:49:05.412422 [debug] [MainThread]: On master: COMMIT
[0m03:49:05.414504 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:49:05.416358 [debug] [MainThread]: On master: Close
[0m03:49:05.418592 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:49:05.420470 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m03:49:05.422163 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m03:49:05.423880 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m03:49:05.425773 [info ] [MainThread]: 
[0m03:49:05.427647 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.43 seconds (0.43s).
[0m03:49:05.430409 [debug] [MainThread]: Command end result
[0m03:49:05.509378 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:49:05.518776 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:49:05.537225 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:49:05.539137 [info ] [MainThread]: 
[0m03:49:05.541122 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:49:05.543002 [info ] [MainThread]: 
[0m03:49:05.544900 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m03:49:05.547578 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.586868, "process_in_blocks": "1384", "process_kernel_time": 0.431369, "process_mem_max_rss": "125076", "process_out_blocks": "0", "process_user_time": 4.73503}
[0m03:49:05.549780 [debug] [MainThread]: Command `dbt test` succeeded at 03:49:05.549563 after 2.59 seconds
[0m03:49:05.551808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c616f8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c6537f80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f13c6c56390>]}
[0m03:49:05.553819 [debug] [MainThread]: Flushing usage events
[0m03:49:06.832070 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:52:27.237188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef2343110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef1c390a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef16ee750>]}


============================== 03:52:27.249755 | 8c7ecb71-907f-4585-8bf2-2590f8c11f12 ==============================
[0m03:52:27.249755 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:52:27.251886 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:52:27.624328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef0ee0500>]}
[0m03:52:27.728883 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef0e83860>]}
[0m03:52:27.731328 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:52:27.882326 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:52:28.585387 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:52:28.587643 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:52:28.700452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef3469010>]}
[0m03:52:28.931519 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:52:28.949319 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:52:28.993375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0eeff47e00>]}
[0m03:52:28.995363 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:52:28.997395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef07a9fa0>]}
[0m03:52:29.002502 [info ] [MainThread]: 
[0m03:52:29.004688 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:52:29.006805 [info ] [MainThread]: 
[0m03:52:29.009056 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:52:29.017800 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:52:29.018984 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:52:29.020286 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:52:29.099815 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:52:29.100682 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:52:29.101407 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:52:29.103064 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:52:29.105210 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:52:29.107317 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:52:29.109098 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:29.110914 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:29.112695 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:52:29.126618 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m03:52:29.131236 [debug] [ThreadPool]: On list_airflow: Close
[0m03:52:29.133583 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.021 seconds
[0m03:52:29.134381 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.023 seconds
[0m03:52:29.137448 [debug] [ThreadPool]: On list_airflow: Close
[0m03:52:29.141695 [debug] [ThreadPool]: On list_airflow: Close
[0m03:52:29.148713 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m03:52:29.149967 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m03:52:29.151071 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m03:52:29.162009 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:52:29.166313 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:52:29.170939 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:52:29.173073 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:52:29.174950 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:52:29.176833 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:52:29.178649 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:29.180304 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:29.182145 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:52:29.194285 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:52:29.196089 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:52:29.196919 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m03:52:29.198140 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:52:29.200085 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:52:29.202014 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:52:29.204202 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:52:29.206345 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:52:29.208575 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:52:29.214531 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m03:52:29.215319 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.004 seconds
[0m03:52:29.216694 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m03:52:29.219051 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:52:29.222727 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:52:29.226193 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:52:29.228639 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:52:29.230583 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:52:29.232515 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:52:29.249171 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.251218 [debug] [MainThread]: On master: BEGIN
[0m03:52:29.253011 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:52:29.265519 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m03:52:29.267586 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.270209 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:52:29.284258 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m03:52:29.288481 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef0325b20>]}
[0m03:52:29.290887 [debug] [MainThread]: On master: ROLLBACK
[0m03:52:29.293189 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.295296 [debug] [MainThread]: On master: BEGIN
[0m03:52:29.297855 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:52:29.299760 [debug] [MainThread]: On master: COMMIT
[0m03:52:29.301457 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.303286 [debug] [MainThread]: On master: COMMIT
[0m03:52:29.305290 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:52:29.307325 [debug] [MainThread]: On master: Close
[0m03:52:29.315520 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m03:52:29.317796 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m03:52:29.319783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m03:52:29.321645 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m03:52:29.336346 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m03:52:29.349241 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m03:52:29.414794 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m03:52:29.426820 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:52:29.428450 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m03:52:29.429915 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:52:29.443094 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m03:52:29.445268 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:52:29.447349 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m03:52:29.456876 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m03:52:29.468605 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:52:29.471110 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m03:52:29.473915 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:52:29.501145 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:52:29.503434 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:52:29.505407 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:52:29.514741 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m03:52:29.527568 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m03:52:29.539074 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:52:29.541376 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m03:52:29.544256 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m03:52:29.550398 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m03:52:29.555706 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef3877530>]}
[0m03:52:29.558501 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.23s]
[0m03:52:29.561112 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m03:52:29.564210 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m03:52:29.566587 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m03:52:29.568648 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m03:52:29.570878 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m03:52:29.580685 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m03:52:29.597295 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m03:52:29.639026 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m03:52:29.652689 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:52:29.654852 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m03:52:29.656681 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:52:29.668061 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m03:52:29.670252 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:52:29.672574 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = dateadd(day, -1, p.prediction_date)
)

SELECT * FROM lstm_processed
  );
  
[0m03:52:29.675561 [debug] [Thread-3 (]: Postgres adapter: Postgres error: subquery in FROM must have an alias
LINE 29:     FROM (
                  ^
HINT:  For example, FROM (SELECT ...) [AS] foo.

[0m03:52:29.677631 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: ROLLBACK
[0m03:52:29.679918 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m03:52:29.696106 [debug] [Thread-3 (]: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m03:52:29.698213 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8c7ecb71-907f-4585-8bf2-2590f8c11f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0eed7e9310>]}
[0m03:52:29.700435 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model public_core.fct_stock_predictions ........ [[31mERROR[0m in 0.13s]
[0m03:52:29.702853 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m03:52:29.705311 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.fct_stock_predictions' to be skipped because of status 'error'.  Reason: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql.
[0m03:52:29.709021 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m03:52:29.709907 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m03:52:29.711614 [info ] [Thread-2 (]: 3 of 4 SKIP relation public_analytics.lstm_performance_metrics ................. [[33mSKIP[0m]
[0m03:52:29.713906 [info ] [Thread-1 (]: 4 of 4 SKIP relation public_analytics.stock_prediction_dashboard ............... [[33mSKIP[0m]
[0m03:52:29.716208 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m03:52:29.718175 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m03:52:29.723333 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.725056 [debug] [MainThread]: On master: BEGIN
[0m03:52:29.726658 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:52:29.737948 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m03:52:29.740393 [debug] [MainThread]: On master: COMMIT
[0m03:52:29.742212 [debug] [MainThread]: Using postgres connection "master"
[0m03:52:29.744073 [debug] [MainThread]: On master: COMMIT
[0m03:52:29.746041 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:52:29.747730 [debug] [MainThread]: On master: Close
[0m03:52:29.749634 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:52:29.751066 [debug] [MainThread]: Connection 'model.idx_stock.stg_stock_predictions' was properly closed.
[0m03:52:29.752900 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m03:52:29.754803 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m03:52:29.756578 [info ] [MainThread]: 
[0m03:52:29.758378 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m03:52:29.761331 [debug] [MainThread]: Command end result
[0m03:52:29.844220 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:52:29.854519 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:52:29.872538 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:52:29.874540 [info ] [MainThread]: 
[0m03:52:29.876613 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:52:29.878563 [info ] [MainThread]: 
[0m03:52:29.880634 [error] [MainThread]:   Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m03:52:29.882520 [info ] [MainThread]: 
[0m03:52:29.884627 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=2 TOTAL=4
[0m03:52:29.887827 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7530034, "process_in_blocks": "280", "process_kernel_time": 0.48061, "process_mem_max_rss": "122888", "process_out_blocks": "0", "process_user_time": 5.066436}
[0m03:52:29.890079 [debug] [MainThread]: Command `dbt run` failed at 03:52:29.889866 after 2.76 seconds
[0m03:52:29.891927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef19248c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef53771d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ef21d32c0>]}
[0m03:52:29.893854 [debug] [MainThread]: Flushing usage events
[0m03:52:31.288900 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:43.003736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdea357080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde99ba2a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdea3571a0>]}


============================== 03:57:43.017807 | 9d2f055d-fee1-4220-be55-76a1ebd10780 ==============================
[0m03:57:43.017807 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:57:43.019870 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m03:57:43.408236 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdea2ee0f0>]}
[0m03:57:43.533808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde977bc20>]}
[0m03:57:43.536293 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:57:43.704228 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:57:44.546845 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:57:44.549529 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:57:44.673043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde98d8bf0>]}
[0m03:57:44.919887 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:57:44.939433 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:57:44.988519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde7d3bce0>]}
[0m03:57:44.991639 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:57:44.994123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde8da3410>]}
[0m03:57:45.000003 [info ] [MainThread]: 
[0m03:57:45.002259 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:57:45.004476 [info ] [MainThread]: 
[0m03:57:45.006757 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:57:45.018488 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:45.019839 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:45.021152 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:45.109938 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:45.110831 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:45.111709 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:45.113282 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:45.115385 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:45.117765 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:45.119728 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:45.121637 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:45.123533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:45.139054 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m03:57:45.140232 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m03:57:45.141384 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m03:57:45.145049 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:45.148910 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:45.152580 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:45.161891 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m03:57:45.163260 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m03:57:45.164621 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m03:57:45.177887 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:57:45.181974 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:57:45.187120 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:57:45.189221 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:57:45.195577 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:57:45.197671 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:57:45.199883 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:45.201637 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:45.203597 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:45.217656 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m03:57:45.219904 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:57:45.222139 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:57:45.223204 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m03:57:45.226410 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m03:57:45.228634 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:57:45.230318 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m03:57:45.231806 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:57:45.234443 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:57:45.239241 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:57:45.242308 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:57:45.246628 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:57:45.252149 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m03:57:45.256122 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:57:45.257167 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.008 seconds
[0m03:57:45.259916 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:57:45.264131 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:57:45.269337 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:57:45.289838 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.292700 [debug] [MainThread]: On master: BEGIN
[0m03:57:45.294596 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:57:45.307576 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m03:57:45.310065 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.312837 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:57:45.326490 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m03:57:45.330485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde9736d80>]}
[0m03:57:45.332580 [debug] [MainThread]: On master: ROLLBACK
[0m03:57:45.334766 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.336752 [debug] [MainThread]: On master: BEGIN
[0m03:57:45.339162 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:57:45.341494 [debug] [MainThread]: On master: COMMIT
[0m03:57:45.343439 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.345246 [debug] [MainThread]: On master: COMMIT
[0m03:57:45.347206 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:57:45.348970 [debug] [MainThread]: On master: Close
[0m03:57:45.360912 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m03:57:45.363171 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m03:57:45.365399 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m03:57:45.367440 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m03:57:45.383059 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m03:57:45.396845 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m03:57:45.467141 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m03:57:45.478620 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.480572 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m03:57:45.482289 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:45.495001 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m03:57:45.496872 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.498643 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m03:57:45.503257 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m03:57:45.520614 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.522691 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m03:57:45.525602 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:57:45.534675 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.536982 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m03:57:45.541207 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m03:57:45.576703 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:57:45.579200 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.581457 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:57:45.589331 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m03:57:45.605362 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m03:57:45.617065 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:45.619332 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m03:57:45.628745 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.007 seconds
[0m03:57:45.634187 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m03:57:45.638301 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efdeb98a960>]}
[0m03:57:45.641584 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.27s]
[0m03:57:45.644098 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m03:57:45.647115 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m03:57:45.649101 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m03:57:45.651054 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m03:57:45.652990 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m03:57:45.661198 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m03:57:45.677996 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m03:57:45.721027 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m03:57:45.738222 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:45.740473 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m03:57:45.742457 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:57:45.754024 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m03:57:45.756384 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:45.759039 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = dateadd(day, -1, p.prediction_date)
)

SELECT * FROM lstm_processed
  );
  
[0m03:57:45.762018 [debug] [Thread-3 (]: Postgres adapter: Postgres error: subquery in FROM must have an alias
LINE 29:     FROM (
                  ^
HINT:  For example, FROM (SELECT ...) [AS] foo.

[0m03:57:45.764131 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: ROLLBACK
[0m03:57:45.766784 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m03:57:45.774954 [debug] [Thread-3 (]: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m03:57:45.777926 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d2f055d-fee1-4220-be55-76a1ebd10780', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde588ec30>]}
[0m03:57:45.780430 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model public_core.fct_stock_predictions ........ [[31mERROR[0m in 0.13s]
[0m03:57:45.782997 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m03:57:45.785452 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.fct_stock_predictions' to be skipped because of status 'error'.  Reason: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql.
[0m03:57:45.788968 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m03:57:45.790802 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m03:57:45.792484 [info ] [Thread-2 (]: 3 of 4 SKIP relation public_analytics.lstm_performance_metrics ................. [[33mSKIP[0m]
[0m03:57:45.795042 [info ] [Thread-1 (]: 4 of 4 SKIP relation public_analytics.stock_prediction_dashboard ............... [[33mSKIP[0m]
[0m03:57:45.797295 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m03:57:45.799391 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m03:57:45.804864 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.807096 [debug] [MainThread]: On master: BEGIN
[0m03:57:45.809320 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:57:45.821251 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m03:57:45.823460 [debug] [MainThread]: On master: COMMIT
[0m03:57:45.826111 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:45.828121 [debug] [MainThread]: On master: COMMIT
[0m03:57:45.830331 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:57:45.832195 [debug] [MainThread]: On master: Close
[0m03:57:45.834099 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:57:45.835840 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m03:57:45.837567 [debug] [MainThread]: Connection 'model.idx_stock.stg_stock_predictions' was properly closed.
[0m03:57:45.839266 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m03:57:45.841517 [info ] [MainThread]: 
[0m03:57:45.843518 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.83 seconds (0.83s).
[0m03:57:45.846301 [debug] [MainThread]: Command end result
[0m03:57:45.928889 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:57:45.938957 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:57:45.957808 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:57:45.959988 [info ] [MainThread]: 
[0m03:57:45.962166 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m03:57:45.964157 [info ] [MainThread]: 
[0m03:57:45.966438 [error] [MainThread]:   Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  subquery in FROM must have an alias
  LINE 29:     FROM (
                    ^
  HINT:  For example, FROM (SELECT ...) [AS] foo.
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m03:57:45.968711 [info ] [MainThread]: 
[0m03:57:45.970905 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=2 TOTAL=4
[0m03:57:45.974329 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0766037, "process_in_blocks": "0", "process_kernel_time": 0.42851, "process_mem_max_rss": "125340", "process_out_blocks": "0", "process_user_time": 5.091115}
[0m03:57:45.977046 [debug] [MainThread]: Command `dbt run` failed at 03:57:45.976809 after 3.08 seconds
[0m03:57:45.979029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde9dfbec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efded4771a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efde8d4ce30>]}
[0m03:57:45.980991 [debug] [MainThread]: Flushing usage events
[0m03:57:47.333683 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:02:47.369061 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff9aa2630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff9bfb500>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff9906bd0>]}


============================== 04:02:47.382764 | 1af1c034-1b75-4d06-81f9-6f9071b0939a ==============================
[0m04:02:47.382764 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:02:47.384996 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:02:47.707438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff97cbf50>]}
[0m04:02:47.806653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff9a380b0>]}
[0m04:02:47.809042 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:02:47.968977 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:02:48.684587 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:02:48.687178 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m04:02:49.474405 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff7977110>]}
[0m04:02:49.661153 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:02:49.677036 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:02:49.717703 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff799d130>]}
[0m04:02:49.719974 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:02:49.722210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff71ef2c0>]}
[0m04:02:49.726939 [info ] [MainThread]: 
[0m04:02:49.729083 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:02:49.730931 [info ] [MainThread]: 
[0m04:02:49.733265 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:02:49.741342 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:02:49.742540 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:02:49.743606 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:02:49.812136 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:02:49.812908 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:02:49.813687 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:02:49.815356 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:02:49.817282 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:02:49.819151 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:02:49.820718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:02:49.822384 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:02:49.823920 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:02:49.837217 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m04:02:49.838209 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m04:02:49.838928 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.015 seconds
[0m04:02:49.841781 [debug] [ThreadPool]: On list_airflow: Close
[0m04:02:49.844938 [debug] [ThreadPool]: On list_airflow: Close
[0m04:02:49.848621 [debug] [ThreadPool]: On list_airflow: Close
[0m04:02:49.856925 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:02:49.858233 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:02:49.859508 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:02:49.870358 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:02:49.874513 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:02:49.880685 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:02:49.882820 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:02:49.884735 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:02:49.886492 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:02:49.888131 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:02:49.889958 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:02:49.891733 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:02:49.903538 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:02:49.905623 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:02:49.907025 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:02:49.907785 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:02:49.908741 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:02:49.910933 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:02:49.912777 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:02:49.915972 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:02:49.918088 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:02:49.919711 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m04:02:49.924739 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:02:49.925880 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m04:02:49.926948 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.005 seconds
[0m04:02:49.928536 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:02:49.931907 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:02:49.935556 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:02:49.939699 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:02:49.941497 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:02:49.956180 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:49.958213 [debug] [MainThread]: On master: BEGIN
[0m04:02:49.959918 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:02:49.971350 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:02:49.973408 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:49.975582 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:02:49.986573 [debug] [MainThread]: SQL status: SELECT 2 in 0.009 seconds
[0m04:02:49.990233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff5da3ef0>]}
[0m04:02:49.992357 [debug] [MainThread]: On master: ROLLBACK
[0m04:02:49.994493 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:49.996297 [debug] [MainThread]: On master: BEGIN
[0m04:02:49.998834 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:02:50.000853 [debug] [MainThread]: On master: COMMIT
[0m04:02:50.002566 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:50.004284 [debug] [MainThread]: On master: COMMIT
[0m04:02:50.006251 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:02:50.007952 [debug] [MainThread]: On master: Close
[0m04:02:50.015922 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:02:50.018339 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:02:50.021535 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m04:02:50.023368 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:02:50.037346 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:02:50.050466 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:02:50.110427 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:02:50.124885 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.126577 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:02:50.128088 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:02:50.139964 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:02:50.141872 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.143717 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:02:50.149168 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:02:50.160654 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.162601 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:02:50.165539 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:02:50.171724 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.173723 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:02:50.176253 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:02:50.205873 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:02:50.208067 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.210094 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:02:50.217484 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m04:02:50.228740 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:02:50.238584 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:02:50.240640 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:02:50.248320 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m04:02:50.253297 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:02:50.257001 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ffb5a44d0>]}
[0m04:02:50.259415 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.23s]
[0m04:02:50.261566 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:02:50.266308 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:02:50.268483 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:02:50.270593 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_stock_predictions)
[0m04:02:50.272532 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:02:50.278999 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:02:50.295596 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:02:50.339056 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:02:50.356460 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:02:50.358546 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:02:50.360354 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:02:50.372113 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m04:02:50.374286 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:02:50.376585 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = dateadd(day, -1, p.prediction_date)
)

SELECT * FROM lstm_processed
  );
  
[0m04:02:50.380847 [debug] [Thread-3 (]: Postgres adapter: Postgres error: column "day" does not exist
LINE 71:         AND s.date = dateadd(day, -1, p.prediction_date)
                                      ^

[0m04:02:50.383245 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: ROLLBACK
[0m04:02:50.385710 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:02:50.393068 [debug] [Thread-3 (]: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  column "day" does not exist
  LINE 71:         AND s.date = dateadd(day, -1, p.prediction_date)
                                        ^
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m04:02:50.395324 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1af1c034-1b75-4d06-81f9-6f9071b0939a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff7974230>]}
[0m04:02:50.397922 [error] [Thread-3 (]: 2 of 4 ERROR creating sql table model public_core.fct_stock_predictions ........ [[31mERROR[0m in 0.12s]
[0m04:02:50.400522 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:02:50.402885 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.fct_stock_predictions' to be skipped because of status 'error'.  Reason: Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  column "day" does not exist
  LINE 71:         AND s.date = dateadd(day, -1, p.prediction_date)
                                        ^
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql.
[0m04:02:50.406131 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:02:50.407121 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:02:50.409105 [info ] [Thread-2 (]: 3 of 4 SKIP relation public_analytics.lstm_performance_metrics ................. [[33mSKIP[0m]
[0m04:02:50.411190 [info ] [Thread-1 (]: 4 of 4 SKIP relation public_analytics.stock_prediction_dashboard ............... [[33mSKIP[0m]
[0m04:02:50.413698 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:02:50.415917 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:02:50.421401 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:50.423211 [debug] [MainThread]: On master: BEGIN
[0m04:02:50.424874 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:02:50.436203 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:02:50.438143 [debug] [MainThread]: On master: COMMIT
[0m04:02:50.439991 [debug] [MainThread]: Using postgres connection "master"
[0m04:02:50.441787 [debug] [MainThread]: On master: COMMIT
[0m04:02:50.443775 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:02:50.445637 [debug] [MainThread]: On master: Close
[0m04:02:50.447721 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:02:50.449806 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m04:02:50.451543 [debug] [MainThread]: Connection 'model.idx_stock.stg_stock_predictions' was properly closed.
[0m04:02:50.453174 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:02:50.454988 [info ] [MainThread]: 
[0m04:02:50.456750 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.72 seconds (0.72s).
[0m04:02:50.459542 [debug] [MainThread]: Command end result
[0m04:02:50.603924 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:02:50.612756 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:02:50.629792 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:02:50.631994 [info ] [MainThread]: 
[0m04:02:50.633963 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m04:02:50.635785 [info ] [MainThread]: 
[0m04:02:50.637930 [error] [MainThread]:   Database Error in model fct_stock_predictions (models/marts/core/fct_stock_predictions.sql)
  column "day" does not exist
  LINE 71:         AND s.date = dateadd(day, -1, p.prediction_date)
                                        ^
  compiled code at target/run/idx_stock/models/marts/core/fct_stock_predictions.sql
[0m04:02:50.639843 [info ] [MainThread]: 
[0m04:02:50.641825 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=2 TOTAL=4
[0m04:02:50.644438 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.3742707, "process_in_blocks": "0", "process_kernel_time": 0.322859, "process_mem_max_rss": "131264", "process_out_blocks": "0", "process_user_time": 5.2162}
[0m04:02:50.647139 [debug] [MainThread]: Command `dbt run` failed at 04:02:50.646798 after 3.38 seconds
[0m04:02:50.649217 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff972f6b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff42c9d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ff42c82f0>]}
[0m04:02:50.651177 [debug] [MainThread]: Flushing usage events
[0m04:02:51.876777 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:05:31.457248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9269a092e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f926844f080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f926844f3b0>]}


============================== 04:05:31.469540 | 5b6aa72e-3471-478a-99ba-17804adb1bd6 ==============================
[0m04:05:31.469540 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:05:31.471649 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m04:05:31.861582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9267762c90>]}
[0m04:05:31.973017 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92677ee2a0>]}
[0m04:05:31.975598 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:05:32.132251 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:05:32.786041 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:05:32.788303 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m04:05:33.768367 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92659413a0>]}
[0m04:05:33.973351 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:05:33.988647 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:05:34.029538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92655be690>]}
[0m04:05:34.031609 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:05:34.033549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92661e9eb0>]}
[0m04:05:34.038440 [info ] [MainThread]: 
[0m04:05:34.040673 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:05:34.042991 [info ] [MainThread]: 
[0m04:05:34.044984 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:05:34.053417 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:05:34.054621 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:05:34.055677 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:05:34.124495 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:05:34.125722 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:05:34.126490 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:05:34.127964 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:05:34.129796 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:05:34.131700 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:05:34.133460 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:05:34.135075 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:05:34.136771 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:05:34.149807 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m04:05:34.150673 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m04:05:34.151733 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.015 seconds
[0m04:05:34.154361 [debug] [ThreadPool]: On list_airflow: Close
[0m04:05:34.157770 [debug] [ThreadPool]: On list_airflow: Close
[0m04:05:34.161421 [debug] [ThreadPool]: On list_airflow: Close
[0m04:05:34.169355 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:05:34.170508 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:05:34.171702 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:05:34.182124 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:05:34.186101 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:05:34.190627 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:05:34.192852 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:05:34.194915 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:05:34.196750 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:05:34.198583 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:05:34.200202 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:05:34.201881 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:05:34.213450 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:05:34.215007 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:05:34.215936 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m04:05:34.216653 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:05:34.218558 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:05:34.220449 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:05:34.222287 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:05:34.224296 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:05:34.226553 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:05:34.232041 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m04:05:34.232871 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m04:05:34.233667 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.003 seconds
[0m04:05:34.236341 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:05:34.239725 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:05:34.243476 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:05:34.245874 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:05:34.247590 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:05:34.249275 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:05:34.265607 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:34.267945 [debug] [MainThread]: On master: BEGIN
[0m04:05:34.270082 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:05:34.283375 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m04:05:34.285626 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:34.288314 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:05:34.301462 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m04:05:34.305342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92641ab8f0>]}
[0m04:05:34.308076 [debug] [MainThread]: On master: ROLLBACK
[0m04:05:34.311018 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:34.313032 [debug] [MainThread]: On master: BEGIN
[0m04:05:34.315625 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:05:34.317610 [debug] [MainThread]: On master: COMMIT
[0m04:05:34.319455 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:34.321576 [debug] [MainThread]: On master: COMMIT
[0m04:05:34.324179 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:05:34.326566 [debug] [MainThread]: On master: Close
[0m04:05:34.336021 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:05:34.338371 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:05:34.341075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m04:05:34.343476 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:05:34.357431 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:05:34.373787 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:05:34.457223 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:05:34.469290 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.470792 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:05:34.472311 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:05:34.483994 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:05:34.486082 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.488060 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:05:34.492539 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:05:34.504563 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.507395 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:05:34.511373 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:05:34.518099 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.520420 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:05:34.523418 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:05:34.560231 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:05:34.562463 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.564661 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:05:34.573435 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m04:05:34.588417 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:05:34.602188 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:05:34.604651 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:05:34.612353 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m04:05:34.618056 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:05:34.622369 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92682b0a70>]}
[0m04:05:34.625323 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.28s]
[0m04:05:34.627936 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:05:34.630665 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:05:34.633057 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:05:34.635123 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m04:05:34.636851 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:05:34.644160 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:05:34.656884 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:05:34.699197 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:05:34.712224 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:05:34.714081 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:05:34.715934 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:05:34.727634 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m04:05:34.730222 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:05:34.732605 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:05:36.531370 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.796 seconds
[0m04:05:36.543316 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:05:36.545269 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:05:36.547505 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:05:36.552697 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:05:36.554581 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:05:36.556366 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:05:36.563300 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m04:05:36.567873 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:05:36.573388 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:05:36.575206 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:05:36.577229 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:05:36.580413 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:05:36.582392 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92464b0d10>]}
[0m04:05:36.584490 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 1.95s]
[0m04:05:36.586525 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:05:36.589366 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:05:36.590678 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:05:36.592579 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:05:36.594686 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:05:36.596712 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m04:05:36.598625 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:05:36.600523 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:05:36.602374 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:05:36.609390 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:05:36.616991 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:05:36.627180 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:05:36.628823 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:05:36.637052 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:05:36.645131 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:05:36.655580 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:05:36.658545 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:05:36.660099 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:05:36.661979 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:05:36.664628 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:05:36.668484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:05:36.680066 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m04:05:36.682543 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:05:36.683438 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:05:36.685592 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:05:36.688008 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        AVG(error_percentage) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Tambahkan kalkulasi metrik yang sebelumnya ada di model_performance_metrics
        SQRT(AVG(POWER(predicted_close - actual_close, 2))) AS rmse,
        AVG(ABS(predicted_close - actual_close)) AS mae,
        AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100 AS mape
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol using ROW_NUMBER (instead of DISTINCT ON)
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Final output
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    lp.prediction_date AS latest_prediction_date,
    lp.predicted_close AS latest_predicted_close,
    lp.prediction_direction AS latest_prediction_direction,
    lp.error_percentage AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol
  );
  
[0m04:05:36.691598 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= DATEADD(day, -90, CURRENT_DATE)  -- More warehouse-agnostic
)

SELECT * FROM combined_data
  );
  
[0m04:05:36.695887 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:05:36.698632 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:05:36.699751 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:05:36.701996 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:05:36.703895 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:05:36.711701 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:05:36.715723 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:05:36.722015 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:05:36.723868 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9244305e20>]}
[0m04:05:36.726124 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5b6aa72e-3471-478a-99ba-17804adb1bd6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9244314dd0>]}
[0m04:05:36.728472 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.13s]
[0m04:05:36.731150 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.13s]
[0m04:05:36.733562 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:05:36.735809 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:05:36.738137 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:05:36.742676 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:05:36.746483 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:36.748325 [debug] [MainThread]: On master: BEGIN
[0m04:05:36.750164 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:05:36.761932 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:05:36.763910 [debug] [MainThread]: On master: COMMIT
[0m04:05:36.765685 [debug] [MainThread]: Using postgres connection "master"
[0m04:05:36.767430 [debug] [MainThread]: On master: COMMIT
[0m04:05:36.769494 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:05:36.771666 [debug] [MainThread]: On master: Close
[0m04:05:36.774087 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:05:36.776098 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:05:36.777841 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:05:36.779817 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:05:36.781857 [info ] [MainThread]: 
[0m04:05:36.783741 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 2.74 seconds (2.74s).
[0m04:05:36.787153 [debug] [MainThread]: Command end result
[0m04:05:36.941126 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:05:36.949718 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:05:36.968143 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:05:36.969825 [info ] [MainThread]: 
[0m04:05:36.971629 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:05:36.973757 [info ] [MainThread]: 
[0m04:05:36.976186 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:05:36.978108 [info ] [MainThread]: 
[0m04:05:36.980165 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:05:36.982320 [info ] [MainThread]: 
[0m04:05:36.984295 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:05:36.986808 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.6282134, "process_in_blocks": "0", "process_kernel_time": 0.364121, "process_mem_max_rss": "131432", "process_out_blocks": "0", "process_user_time": 5.776738}
[0m04:05:36.988881 [debug] [MainThread]: Command `dbt run` failed at 04:05:36.988655 after 5.63 seconds
[0m04:05:36.991005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f926923d580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92464cd910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f92464cd880>]}
[0m04:05:36.992912 [debug] [MainThread]: Flushing usage events
[0m04:05:38.209677 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:10:50.844358 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b31b592e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b3026df10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b3026dc40>]}


============================== 04:10:50.857005 | a8d6d777-191c-462e-8367-87ca7eb6bc5a ==============================
[0m04:10:50.857005 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:10:50.859075 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:10:51.173211 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2f7c0b60>]}
[0m04:10:51.285831 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2f47c050>]}
[0m04:10:51.288394 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:10:51.434578 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:10:52.166136 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:10:52.168685 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m04:10:52.691087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2d77c320>]}
[0m04:10:52.882364 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:10:52.899093 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:10:52.946834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2d73be00>]}
[0m04:10:52.948895 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:10:52.950790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2e37dfa0>]}
[0m04:10:52.955884 [info ] [MainThread]: 
[0m04:10:52.958151 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:10:52.960657 [info ] [MainThread]: 
[0m04:10:52.963100 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:10:52.971505 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:10:52.972755 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:10:52.973973 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:10:53.045538 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:10:53.046740 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:10:53.047854 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:10:53.050083 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:10:53.053544 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:10:53.055902 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:10:53.058091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:10:53.060346 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:10:53.063055 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:10:53.080044 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m04:10:53.084759 [debug] [ThreadPool]: On list_airflow: Close
[0m04:10:53.085982 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.028 seconds
[0m04:10:53.086953 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.024 seconds
[0m04:10:53.092937 [debug] [ThreadPool]: On list_airflow: Close
[0m04:10:53.097154 [debug] [ThreadPool]: On list_airflow: Close
[0m04:10:53.106564 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:10:53.108220 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:10:53.110536 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:10:53.122247 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:10:53.127486 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:10:53.134093 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:10:53.135756 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:10:53.137823 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:10:53.139509 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:10:53.141373 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:10:53.143753 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:10:53.145428 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:10:53.161190 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m04:10:53.163238 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:10:53.164319 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:10:53.166304 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:10:53.167314 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m04:10:53.168939 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:10:53.171120 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:10:53.174129 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:10:53.178944 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:10:53.182289 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m04:10:53.183309 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m04:10:53.186797 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:10:53.187662 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m04:10:53.190731 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:10:53.193639 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:10:53.197264 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:10:53.199190 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:10:53.203389 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:10:53.219683 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:53.221333 [debug] [MainThread]: On master: BEGIN
[0m04:10:53.222826 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:10:53.235036 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:10:53.237141 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:53.239545 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:10:53.252288 [debug] [MainThread]: SQL status: SELECT 2 in 0.010 seconds
[0m04:10:53.256467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b266806e0>]}
[0m04:10:53.259219 [debug] [MainThread]: On master: ROLLBACK
[0m04:10:53.261891 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:53.263896 [debug] [MainThread]: On master: BEGIN
[0m04:10:53.266444 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:10:53.268373 [debug] [MainThread]: On master: COMMIT
[0m04:10:53.270267 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:53.272274 [debug] [MainThread]: On master: COMMIT
[0m04:10:53.274438 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:10:53.277457 [debug] [MainThread]: On master: Close
[0m04:10:53.286338 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:10:53.288832 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:10:53.291203 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m04:10:53.294118 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:10:53.310958 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:10:53.326243 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:10:53.406440 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:10:53.421641 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.423491 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:10:53.425606 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:10:53.438236 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:10:53.440434 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.443908 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:10:53.449679 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:10:53.462491 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.464429 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:10:53.466966 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:10:53.474829 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.477441 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:10:53.479949 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:10:53.511292 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:10:53.513327 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.515190 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:10:53.519704 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:10:53.532086 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:10:53.542462 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:10:53.544676 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:10:53.552923 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m04:10:53.559440 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:10:53.563689 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2d3592b0>]}
[0m04:10:53.566260 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.27s]
[0m04:10:53.568695 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:10:53.571848 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:10:53.574079 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:10:53.576910 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m04:10:53.579016 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:10:53.585914 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:10:53.602808 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:10:53.644522 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:10:53.661898 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:53.663858 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:10:53.665746 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:10:53.677691 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m04:10:53.679776 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:53.681952 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:10:55.662433 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.978 seconds
[0m04:10:55.675388 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:55.677690 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:10:55.680489 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:10:55.686913 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:55.689209 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:10:55.692467 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:10:55.696346 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:10:55.698560 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:55.700803 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:10:55.707581 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m04:10:55.714226 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:10:55.720902 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:10:55.723665 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:10:55.733329 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m04:10:55.737172 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:10:55.740120 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b26648680>]}
[0m04:10:55.742991 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 2.16s]
[0m04:10:55.746018 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:10:55.749181 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:10:55.750092 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:10:55.752088 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:10:55.754677 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:10:55.757145 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.lstm_performance_metrics)
[0m04:10:55.759605 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:10:55.761841 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:10:55.764054 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:10:55.771226 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:10:55.780072 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:10:55.791044 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:10:55.792764 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:10:55.799470 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:10:55.808134 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:10:55.819895 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:10:55.821512 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:10:55.823721 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:10:55.826512 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:10:55.828990 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:10:55.831476 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:10:55.845186 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m04:10:55.847507 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:10:55.849374 [debug] [Thread-1 (]: SQL status: BEGIN in 0.018 seconds
[0m04:10:55.850732 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        AVG(error_percentage) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Tambahkan kalkulasi metrik yang sebelumnya ada di model_performance_metrics
        SQRT(AVG(POWER(predicted_close - actual_close, 2))) AS rmse,
        AVG(ABS(predicted_close - actual_close)) AS mae,
        AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100 AS mape
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol using ROW_NUMBER (instead of DISTINCT ON)
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Final output
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    lp.prediction_date AS latest_prediction_date,
    lp.predicted_close AS latest_predicted_close,
    lp.prediction_direction AS latest_prediction_direction,
    lp.error_percentage AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol
  );
  
[0m04:10:55.853622 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:10:55.857783 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:10:55.859717 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:10:55.862646 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:10:55.866843 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:10:55.867898 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:10:55.872493 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:10:55.876784 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:10:55.880149 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:10:55.886005 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:10:55.887747 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b265711f0>]}
[0m04:10:55.891096 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a8d6d777-191c-462e-8367-87ca7eb6bc5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2653d730>]}
[0m04:10:55.893684 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.13s]
[0m04:10:55.896286 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.13s]
[0m04:10:55.898884 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:10:55.901308 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:10:55.903651 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:10:55.909169 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:10:55.913888 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:55.915720 [debug] [MainThread]: On master: BEGIN
[0m04:10:55.917390 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:10:55.931877 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m04:10:55.933881 [debug] [MainThread]: On master: COMMIT
[0m04:10:55.935859 [debug] [MainThread]: Using postgres connection "master"
[0m04:10:55.937873 [debug] [MainThread]: On master: COMMIT
[0m04:10:55.940247 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:10:55.942385 [debug] [MainThread]: On master: Close
[0m04:10:55.944678 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:10:55.946562 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:10:55.948444 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:10:55.950288 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:10:55.952206 [info ] [MainThread]: 
[0m04:10:55.954034 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 2.99 seconds (2.99s).
[0m04:10:55.959149 [debug] [MainThread]: Command end result
[0m04:10:56.047298 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:10:56.055280 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:10:56.074390 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:10:56.076974 [info ] [MainThread]: 
[0m04:10:56.079979 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:10:56.082828 [info ] [MainThread]: 
[0m04:10:56.085950 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:10:56.088146 [info ] [MainThread]: 
[0m04:10:56.091636 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:10:56.094831 [info ] [MainThread]: 
[0m04:10:56.098275 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:10:56.101899 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.3523483, "process_in_blocks": "0", "process_kernel_time": 0.373178, "process_mem_max_rss": "127564", "process_out_blocks": "0", "process_user_time": 5.012699}
[0m04:10:56.104460 [debug] [MainThread]: Command `dbt run` failed at 04:10:56.104196 after 5.36 seconds
[0m04:10:56.106648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b311dccb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2f533890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b24102f60>]}
[0m04:10:56.109201 [debug] [MainThread]: Flushing usage events
[0m04:10:57.279799 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:12:41.204391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff549f52b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff549ed2ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff549f130b0>]}


============================== 04:12:41.224687 | b5684063-b33a-49b8-9a41-07282791a5bb ==============================
[0m04:12:41.224687 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:12:41.228170 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:12:41.755518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff548d38650>]}
[0m04:12:41.912580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff548d389b0>]}
[0m04:12:41.916058 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:12:42.170721 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:12:42.974357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:12:42.976361 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:12:43.126681 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff548914dd0>]}
[0m04:12:43.454372 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:12:43.474607 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:12:43.583996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff547d2c9b0>]}
[0m04:12:43.586394 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:12:43.588724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff549adc9e0>]}
[0m04:12:43.594545 [info ] [MainThread]: 
[0m04:12:43.596806 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:12:43.599146 [info ] [MainThread]: 
[0m04:12:43.601850 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:12:43.613018 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:12:43.614925 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:12:43.617656 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:12:43.718265 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:12:43.719192 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:12:43.720156 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:12:43.722091 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:12:43.723981 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:12:43.726046 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:12:43.727972 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:12:43.730141 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:12:43.732734 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:12:43.751135 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.023 seconds
[0m04:12:43.755458 [debug] [ThreadPool]: On list_airflow: Close
[0m04:12:43.756558 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.026 seconds
[0m04:12:43.759664 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.027 seconds
[0m04:12:43.762790 [debug] [ThreadPool]: On list_airflow: Close
[0m04:12:43.768106 [debug] [ThreadPool]: On list_airflow: Close
[0m04:12:43.777975 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:12:43.779380 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:12:43.780942 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:12:43.796876 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:12:43.802938 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:12:43.809927 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:12:43.811790 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:12:43.813569 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:12:43.815799 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:12:43.818075 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:12:43.819771 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:12:43.821839 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:12:43.839073 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:12:43.840272 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:12:43.842105 [debug] [ThreadPool]: SQL status: BEGIN in 0.024 seconds
[0m04:12:43.843070 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:12:43.845103 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:12:43.847081 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:12:43.849443 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:12:43.852096 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:12:43.854321 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:12:43.863049 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m04:12:43.864006 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m04:12:43.865416 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m04:12:43.869267 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:12:43.873398 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:12:43.877418 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:12:43.879805 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:12:43.882202 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:12:43.884628 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:12:43.906443 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:43.908416 [debug] [MainThread]: On master: BEGIN
[0m04:12:43.910095 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:12:43.927467 [debug] [MainThread]: SQL status: BEGIN in 0.017 seconds
[0m04:12:43.929341 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:43.931553 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:12:43.953599 [debug] [MainThread]: SQL status: SELECT 2 in 0.019 seconds
[0m04:12:43.957443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff548dd88f0>]}
[0m04:12:43.959266 [debug] [MainThread]: On master: ROLLBACK
[0m04:12:43.961122 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:43.962620 [debug] [MainThread]: On master: BEGIN
[0m04:12:43.964683 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:12:43.967390 [debug] [MainThread]: On master: COMMIT
[0m04:12:43.969140 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:43.970726 [debug] [MainThread]: On master: COMMIT
[0m04:12:43.972555 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:12:43.974103 [debug] [MainThread]: On master: Close
[0m04:12:43.985263 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:12:43.987455 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:12:43.989744 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m04:12:43.991763 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:12:44.012816 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:12:44.025401 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:12:44.116394 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:12:44.128282 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.130041 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:12:44.132138 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:12:44.145039 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:12:44.147037 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.149212 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:12:44.153932 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:12:44.169064 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.171434 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:12:44.174086 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:12:44.182256 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.184387 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:12:44.186982 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:12:44.226377 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:12:44.228335 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.230467 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:12:44.235121 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m04:12:44.252815 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:12:44.265114 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:12:44.268090 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:12:44.273573 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m04:12:44.280007 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:12:44.285734 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff54bc75250>]}
[0m04:12:44.288413 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.29s]
[0m04:12:44.291031 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:12:44.294239 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:12:44.296717 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:12:44.299665 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m04:12:44.302211 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:12:44.310046 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:12:44.324088 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:12:44.393256 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:12:44.410690 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:44.412417 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:12:44.414218 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:12:44.428086 [debug] [Thread-3 (]: SQL status: BEGIN in 0.014 seconds
[0m04:12:44.430697 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:44.433785 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:12:46.711058 [debug] [Thread-3 (]: SQL status: SELECT 1 in 2.274 seconds
[0m04:12:46.722447 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:46.724370 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:12:46.726631 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:12:46.732966 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:46.734932 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:12:46.737119 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:12:46.740272 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:12:46.742038 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:46.743802 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:12:46.752083 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m04:12:46.756905 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:12:46.761970 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:12:46.764049 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:12:46.768987 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:12:46.772278 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:12:46.774398 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff545be13a0>]}
[0m04:12:46.776640 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 2.48s]
[0m04:12:46.778917 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:12:46.781868 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:12:46.782688 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:12:46.784391 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:12:46.786407 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:12:46.788502 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m04:12:46.790326 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:12:46.792106 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:12:46.793884 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:12:46.800437 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:12:46.807894 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:12:46.818024 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:12:46.819356 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:12:46.824946 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:12:46.831503 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:12:46.840465 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:12:46.842098 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:12:46.843278 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:12:46.844920 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:12:46.846846 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:12:46.848867 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:12:46.859042 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:12:46.860473 [debug] [Thread-2 (]: SQL status: BEGIN in 0.012 seconds
[0m04:12:46.861683 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:12:46.863690 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:12:46.866231 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:12:46.868843 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        AVG(error_percentage) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Tambahkan kalkulasi metrik yang sebelumnya ada di model_performance_metrics
        SQRT(AVG(POWER(predicted_close - actual_close, 2))) AS rmse,
        AVG(ABS(predicted_close - actual_close)) AS mae,
        AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100 AS mape
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol using ROW_NUMBER (instead of DISTINCT ON)
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Final output
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    lp.prediction_date AS latest_prediction_date,
    lp.predicted_close AS latest_predicted_close,
    lp.prediction_direction AS latest_prediction_direction,
    lp.error_percentage AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol
  );
  
[0m04:12:46.872684 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:12:46.873610 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:12:46.875226 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:12:46.876997 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:12:46.879359 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:12:46.881723 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:12:46.891857 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:12:46.894813 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:12:46.896931 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff544244080>]}
[0m04:12:46.899237 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b5684063-b33a-49b8-9a41-07282791a5bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff545df2bd0>]}
[0m04:12:46.901571 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.11s]
[0m04:12:46.903759 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.11s]
[0m04:12:46.906008 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:12:46.908135 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:12:46.910279 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:12:46.915012 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:12:46.918670 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:46.920343 [debug] [MainThread]: On master: BEGIN
[0m04:12:46.922064 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:12:46.932786 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:12:46.934728 [debug] [MainThread]: On master: COMMIT
[0m04:12:46.936472 [debug] [MainThread]: Using postgres connection "master"
[0m04:12:46.938119 [debug] [MainThread]: On master: COMMIT
[0m04:12:46.939964 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:12:46.941924 [debug] [MainThread]: On master: Close
[0m04:12:46.943893 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:12:46.945685 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:12:46.947598 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:12:46.949295 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:12:46.950899 [info ] [MainThread]: 
[0m04:12:46.952630 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 3.35 seconds (3.35s).
[0m04:12:46.955701 [debug] [MainThread]: Command end result
[0m04:12:47.032597 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:12:47.041594 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:12:47.059350 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:12:47.061142 [info ] [MainThread]: 
[0m04:12:47.063114 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:12:47.065306 [info ] [MainThread]: 
[0m04:12:47.067302 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:12:47.069295 [info ] [MainThread]: 
[0m04:12:47.071402 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:12:47.073287 [info ] [MainThread]: 
[0m04:12:47.075104 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:12:47.077632 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 6.0133595, "process_in_blocks": "0", "process_kernel_time": 0.560923, "process_mem_max_rss": "124624", "process_out_blocks": "2360", "process_user_time": 6.03239}
[0m04:12:47.079618 [debug] [MainThread]: Command `dbt run` failed at 04:12:47.079389 after 6.02 seconds
[0m04:12:47.082023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff549ed2ea0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff548d0f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff545df27b0>]}
[0m04:12:47.083878 [debug] [MainThread]: Flushing usage events
[0m04:12:48.401300 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:18:01.737669 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286c713140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286cfe4c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286c713620>]}


============================== 04:18:01.750091 | 54727d30-19f3-4d31-a736-a3631c1d7a4f ==============================
[0m04:18:01.750091 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:18:01.752182 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:18:02.075227 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286c6e56a0>]}
[0m04:18:02.174637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286c6af530>]}
[0m04:18:02.177036 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:18:02.326472 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:18:02.962542 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m04:18:02.964339 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m04:18:03.087293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286bd52780>]}
[0m04:18:03.303871 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:18:03.320668 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:18:03.363861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286ad46ff0>]}
[0m04:18:03.366355 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:18:03.369037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286c54fcb0>]}
[0m04:18:03.374211 [info ] [MainThread]: 
[0m04:18:03.376699 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:18:03.379445 [info ] [MainThread]: 
[0m04:18:03.381805 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:18:03.392047 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:18:03.393283 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:18:03.394383 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:18:03.524267 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:18:03.525195 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:18:03.525964 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:18:03.527752 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:18:03.529957 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:18:03.532022 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:18:03.534661 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:18:03.536777 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:18:03.538940 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:18:03.553985 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m04:18:03.554988 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m04:18:03.558582 [debug] [ThreadPool]: On list_airflow: Close
[0m04:18:03.559464 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.021 seconds
[0m04:18:03.562484 [debug] [ThreadPool]: On list_airflow: Close
[0m04:18:03.567865 [debug] [ThreadPool]: On list_airflow: Close
[0m04:18:03.576027 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:18:03.577325 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:18:03.578671 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:18:03.590921 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:18:03.595128 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:18:03.600969 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:18:03.603392 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:18:03.606031 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:18:03.608419 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:18:03.610621 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:18:03.612787 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:18:03.614926 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:18:03.629105 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:18:03.631101 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:18:03.632466 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:18:03.633606 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:18:03.635640 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:18:03.637775 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:18:03.639949 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:18:03.641661 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:18:03.644885 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:18:03.647820 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m04:18:03.652771 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:18:03.653708 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.007 seconds
[0m04:18:03.654500 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m04:18:03.656406 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:18:03.659596 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:18:03.663080 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:18:03.668103 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:18:03.670093 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:18:03.686074 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:03.688236 [debug] [MainThread]: On master: BEGIN
[0m04:18:03.690095 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:18:03.702208 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:18:03.704257 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:03.706493 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:18:03.718159 [debug] [MainThread]: SQL status: SELECT 2 in 0.009 seconds
[0m04:18:03.722027 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286adf1ca0>]}
[0m04:18:03.724185 [debug] [MainThread]: On master: ROLLBACK
[0m04:18:03.726347 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:03.728190 [debug] [MainThread]: On master: BEGIN
[0m04:18:03.730589 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:18:03.732553 [debug] [MainThread]: On master: COMMIT
[0m04:18:03.734338 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:03.736092 [debug] [MainThread]: On master: COMMIT
[0m04:18:03.738163 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:18:03.740038 [debug] [MainThread]: On master: Close
[0m04:18:03.748117 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:18:03.750336 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:18:03.752475 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m04:18:03.754353 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:18:03.769458 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:18:03.784819 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:18:03.849470 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:18:03.864339 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.867132 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:18:03.869090 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:18:03.880337 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m04:18:03.882447 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.884396 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:18:03.888812 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m04:18:03.900577 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.902722 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:18:03.905218 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:18:03.911317 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.913464 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:18:03.916154 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:18:03.944485 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:18:03.946612 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.948760 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:18:03.956371 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m04:18:03.969870 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:18:03.979122 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:18:03.981231 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:18:03.988876 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m04:18:03.993850 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:18:03.997528 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286e5cade0>]}
[0m04:18:04.000047 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.24s]
[0m04:18:04.002302 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:18:04.004934 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:18:04.007049 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:18:04.008881 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_stock_predictions)
[0m04:18:04.010769 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:18:04.017265 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:18:04.030415 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:18:04.066294 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:18:04.079233 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:04.080679 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:18:04.082049 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:18:04.094106 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m04:18:04.095897 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:04.098172 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:18:06.042939 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.943 seconds
[0m04:18:06.054308 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:06.056672 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:18:06.059006 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:18:06.064652 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:06.066383 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:18:06.068563 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:18:06.071700 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:18:06.073432 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:06.075091 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:18:06.078604 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m04:18:06.083133 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:18:06.088602 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:18:06.090540 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:18:06.095405 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.003 seconds
[0m04:18:06.099005 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:18:06.101347 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f28685b3590>]}
[0m04:18:06.104024 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 2.09s]
[0m04:18:06.106694 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:18:06.109699 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:18:06.110766 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:18:06.112732 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:18:06.115045 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:18:06.117298 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.lstm_performance_metrics)
[0m04:18:06.119033 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:18:06.120917 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:18:06.122654 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:18:06.128686 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:18:06.136760 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:18:06.145823 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:18:06.147785 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:18:06.152955 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:18:06.159415 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:18:06.168792 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:18:06.170314 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:18:06.171605 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:18:06.173464 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:18:06.175476 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:18:06.177533 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:18:06.190165 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:18:06.191102 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m04:18:06.192704 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:18:06.194426 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:18:06.196776 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:18:06.199400 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        AVG(error_percentage) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Tambahkan kalkulasi metrik yang sebelumnya ada di model_performance_metrics
        SQRT(AVG(POWER(predicted_close - actual_close, 2))) AS rmse,
        AVG(ABS(predicted_close - actual_close)) AS mae,
        AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100 AS mape
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol using ROW_NUMBER (instead of DISTINCT ON)
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Final output
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    lp.prediction_date AS latest_prediction_date,
    lp.predicted_close AS latest_predicted_close,
    lp.prediction_direction AS latest_prediction_direction,
    lp.error_percentage AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol
  );
  
[0m04:18:06.203610 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:18:06.204626 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:18:06.206051 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:18:06.207566 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:18:06.209851 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:18:06.211850 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:18:06.223504 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:18:06.226439 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:18:06.228322 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286bcca570>]}
[0m04:18:06.230488 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54727d30-19f3-4d31-a736-a3631c1d7a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2868453f80>]}
[0m04:18:06.232872 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.11s]
[0m04:18:06.235231 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.11s]
[0m04:18:06.237413 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:18:06.239573 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:18:06.241470 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:18:06.245141 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:18:06.249306 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:06.251181 [debug] [MainThread]: On master: BEGIN
[0m04:18:06.252797 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:18:06.264169 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:18:06.266330 [debug] [MainThread]: On master: COMMIT
[0m04:18:06.268381 [debug] [MainThread]: Using postgres connection "master"
[0m04:18:06.270079 [debug] [MainThread]: On master: COMMIT
[0m04:18:06.271905 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:18:06.273480 [debug] [MainThread]: On master: Close
[0m04:18:06.275681 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:18:06.277547 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:18:06.279314 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:18:06.281014 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:18:06.282914 [info ] [MainThread]: 
[0m04:18:06.285162 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 2.90 seconds (2.90s).
[0m04:18:06.288345 [debug] [MainThread]: Command end result
[0m04:18:06.368006 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:18:06.377500 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:18:06.394532 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:18:06.396767 [info ] [MainThread]: 
[0m04:18:06.398767 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:18:06.400635 [info ] [MainThread]: 
[0m04:18:06.402624 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:18:06.404784 [info ] [MainThread]: 
[0m04:18:06.406936 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:18:06.408973 [info ] [MainThread]: 
[0m04:18:06.410988 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:18:06.413600 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 4.7704496, "process_in_blocks": "0", "process_kernel_time": 0.365802, "process_mem_max_rss": "123656", "process_out_blocks": "0", "process_user_time": 5.192363}
[0m04:18:06.415736 [debug] [MainThread]: Command `dbt run` failed at 04:18:06.415518 after 4.77 seconds
[0m04:18:06.417505 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286d04b7a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286caefef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f286ad46570>]}
[0m04:18:06.419274 [debug] [MainThread]: Flushing usage events
[0m04:18:07.600636 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:23:17.541075 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1afbad6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ae9ed670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1aee5f110>]}


============================== 04:23:17.554598 | 86b8961a-aef0-4caf-8c4a-db144dda73c0 ==============================
[0m04:23:17.554598 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:23:17.556652 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m04:23:17.922736 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ad763f80>]}
[0m04:23:18.025941 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ae62e1e0>]}
[0m04:23:18.028241 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:23:18.183516 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:23:18.765901 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:23:18.768423 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m04:23:19.300345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ad7a55e0>]}
[0m04:23:19.528800 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:23:19.548997 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:23:19.600105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ac3955b0>]}
[0m04:23:19.603014 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:23:19.606014 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1ae5194f0>]}
[0m04:23:19.611820 [info ] [MainThread]: 
[0m04:23:19.614160 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:23:19.616509 [info ] [MainThread]: 
[0m04:23:19.619171 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:23:19.628658 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:23:19.630043 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:23:19.631633 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:23:19.710766 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:23:19.711715 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:23:19.712542 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:23:19.714116 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:23:19.716171 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:23:19.718483 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:23:19.720446 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:23:19.722165 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:23:19.724053 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:23:19.739835 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m04:23:19.740790 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m04:23:19.744285 [debug] [ThreadPool]: On list_airflow: Close
[0m04:23:19.748812 [debug] [ThreadPool]: On list_airflow: Close
[0m04:23:19.749958 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.026 seconds
[0m04:23:19.757028 [debug] [ThreadPool]: On list_airflow: Close
[0m04:23:19.763110 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:23:19.764466 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:23:19.766009 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:23:19.778302 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:23:19.782757 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:23:19.789583 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:23:19.791727 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:23:19.794027 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:23:19.796346 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:23:19.798337 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:23:19.800975 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:23:19.803176 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:23:19.817420 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m04:23:19.819003 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:23:19.820366 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:23:19.821445 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:23:19.823038 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:23:19.825008 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:23:19.827274 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:23:19.829656 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:23:19.833233 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:23:19.837371 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m04:23:19.841844 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:23:19.842685 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.007 seconds
[0m04:23:19.844369 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m04:23:19.845174 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:23:19.848573 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:23:19.852935 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:23:19.857642 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:23:19.859727 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:23:19.879163 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:19.881406 [debug] [MainThread]: On master: BEGIN
[0m04:23:19.883647 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:23:19.896308 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m04:23:19.898589 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:19.901339 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:23:19.914442 [debug] [MainThread]: SQL status: SELECT 2 in 0.010 seconds
[0m04:23:19.918710 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1afe30aa0>]}
[0m04:23:19.921282 [debug] [MainThread]: On master: ROLLBACK
[0m04:23:19.923800 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:19.925995 [debug] [MainThread]: On master: BEGIN
[0m04:23:19.928664 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:23:19.930699 [debug] [MainThread]: On master: COMMIT
[0m04:23:19.932613 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:19.934760 [debug] [MainThread]: On master: COMMIT
[0m04:23:19.937268 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:23:19.939242 [debug] [MainThread]: On master: Close
[0m04:23:19.949192 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:23:19.951831 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:23:19.954233 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m04:23:19.956468 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:23:19.971552 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:23:19.986947 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:23:20.054885 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:23:20.070057 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.071750 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:23:20.073646 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:23:20.086729 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:23:20.089074 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.091417 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:23:20.096312 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:23:20.109949 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.112191 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:23:20.115221 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:23:20.122479 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.124744 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:23:20.127507 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:23:20.161579 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:23:20.163835 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.166092 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:23:20.174107 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m04:23:20.187094 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:23:20.197291 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:23:20.199770 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:23:20.206754 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.005 seconds
[0m04:23:20.212463 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:23:20.217018 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1b02d3290>]}
[0m04:23:20.219675 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.26s]
[0m04:23:20.222093 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:23:20.224810 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:23:20.227112 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:23:20.229183 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_stock_predictions)
[0m04:23:20.231072 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:23:20.238319 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:23:20.252967 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:23:20.295136 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:23:20.311545 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:20.313353 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:23:20.315285 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:23:20.326620 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m04:23:20.328675 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:20.330878 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:23:22.145107 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.812 seconds
[0m04:23:22.158002 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:22.160065 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:23:22.162973 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:23:22.174039 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:22.176488 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:23:22.181446 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:23:22.186595 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:23:22.188802 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:22.191068 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:23:22.198829 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m04:23:22.205104 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:23:22.213007 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:23:22.216287 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:23:22.226133 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.007 seconds
[0m04:23:22.230146 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:23:22.233269 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1a9086030>]}
[0m04:23:22.235884 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 2.00s]
[0m04:23:22.239557 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:23:22.243121 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:23:22.244239 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:23:22.246980 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:23:22.250079 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:23:22.252490 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m04:23:22.254638 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:23:22.256958 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:23:22.259400 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:23:22.269407 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:23:22.278362 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:23:22.288333 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:23:22.289969 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:23:22.299281 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:23:22.307502 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:23:22.319229 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:23:22.321163 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:23:22.322639 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:23:22.324833 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:23:22.326890 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:23:22.328807 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:23:22.342492 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m04:23:22.344399 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:23:22.346013 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m04:23:22.348123 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker dengan penanganan nilai NULL
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        COALESCE(AVG(error_percentage), 0) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Penanganan NULL untuk perhitungan metrik
        COALESCE(SQRT(AVG(POWER(predicted_close - actual_close, 2))), 0) AS rmse,
        COALESCE(AVG(ABS(predicted_close - actual_close)), 0) AS mae,
        COALESCE(AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100, 0) AS mape
    FROM lstm_predictions
    GROUP BY symbol
),

-- Prediksi terbaru per simbol dengan ROW_NUMBER
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Output akhir dengan LEFT JOIN untuk menghindari missing data
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    COALESCE(lp.prediction_date, 'N/A') AS latest_prediction_date,
    COALESCE(lp.predicted_close, 0) AS latest_predicted_close,
    COALESCE(lp.prediction_direction, 'Unknown') AS latest_prediction_direction,
    COALESCE(lp.error_percentage, 0) AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol;
  );
  
[0m04:23:22.350805 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:23:22.353698 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near ";"
LINE 75: LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol;
                                                                  ^

[0m04:23:22.355552 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:23:22.358080 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:23:22.361757 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:23:22.362774 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:23:22.368115 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:23:22.371286 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:23:22.375121 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near ";"
  LINE 75: LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol;
                                                                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:23:22.381848 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:23:22.383136 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1a9027320>]}
[0m04:23:22.385542 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86b8961a-aef0-4caf-8c4a-db144dda73c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1a9071280>]}
[0m04:23:22.387961 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.13s]
[0m04:23:22.390196 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.13s]
[0m04:23:22.392320 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:23:22.394564 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:23:22.397248 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near ";"
  LINE 75: LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol;
                                                                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:23:22.401456 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:23:22.405607 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:22.407406 [debug] [MainThread]: On master: BEGIN
[0m04:23:22.409047 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:23:22.421801 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m04:23:22.428033 [debug] [MainThread]: On master: COMMIT
[0m04:23:22.430358 [debug] [MainThread]: Using postgres connection "master"
[0m04:23:22.432887 [debug] [MainThread]: On master: COMMIT
[0m04:23:22.435352 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:23:22.437598 [debug] [MainThread]: On master: Close
[0m04:23:22.440049 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:23:22.442204 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:23:22.444082 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:23:22.445933 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:23:22.448767 [info ] [MainThread]: 
[0m04:23:22.451197 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 2.83 seconds (2.83s).
[0m04:23:22.455184 [debug] [MainThread]: Command end result
[0m04:23:22.551999 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:23:22.562732 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:23:22.583688 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:23:22.585491 [info ] [MainThread]: 
[0m04:23:22.587635 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:23:22.589581 [info ] [MainThread]: 
[0m04:23:22.591710 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near ";"
  LINE 75: LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol;
                                                                    ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:23:22.593653 [info ] [MainThread]: 
[0m04:23:22.596312 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:23:22.599113 [info ] [MainThread]: 
[0m04:23:22.601356 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:23:22.604286 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.168358, "process_in_blocks": "0", "process_kernel_time": 0.412575, "process_mem_max_rss": "128696", "process_out_blocks": "0", "process_user_time": 5.232666}
[0m04:23:22.606604 [debug] [MainThread]: Command `dbt run` failed at 04:23:22.606370 after 5.17 seconds
[0m04:23:22.608526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1aebe4800>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1a8712e40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1a8712de0>]}
[0m04:23:22.610469 [debug] [MainThread]: Flushing usage events
[0m04:23:23.792476 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:25:06.127336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe28091dd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27ec66f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27ed4b200>]}


============================== 04:25:06.145410 | 2dfab2fc-44dd-4a30-b495-f1bd5effc0ee ==============================
[0m04:25:06.145410 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:25:06.149523 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:25:06.645372 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27e6cb500>]}
[0m04:25:06.754386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27ea4cda0>]}
[0m04:25:06.757116 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:25:06.913773 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:25:07.575929 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:25:07.578376 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m04:25:08.130879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27ea33c20>]}
[0m04:25:08.330728 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:25:08.348329 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:25:08.417626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27c527e30>]}
[0m04:25:08.421243 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:25:08.424520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27d9a80e0>]}
[0m04:25:08.433526 [info ] [MainThread]: 
[0m04:25:08.437994 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:25:08.440660 [info ] [MainThread]: 
[0m04:25:08.446141 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:25:08.459635 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:25:08.461220 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:25:08.463072 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:25:08.624158 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:25:08.625664 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:25:08.627171 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:25:08.629160 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:25:08.631460 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:25:08.633363 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:25:08.635544 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:25:08.637683 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:25:08.639559 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:25:08.661298 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.024 seconds
[0m04:25:08.662352 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.027 seconds
[0m04:25:08.666221 [debug] [ThreadPool]: On list_airflow: Close
[0m04:25:08.667336 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.028 seconds
[0m04:25:08.671196 [debug] [ThreadPool]: On list_airflow: Close
[0m04:25:08.676776 [debug] [ThreadPool]: On list_airflow: Close
[0m04:25:08.686933 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:25:08.688970 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:25:08.691032 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:25:08.707715 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:25:08.712486 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:25:08.721280 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:25:08.723231 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:25:08.725196 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:25:08.727693 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:25:08.730837 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:25:08.733276 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:25:08.736442 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:25:08.755375 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m04:25:08.757706 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:25:08.759585 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m04:25:08.761440 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:25:08.762584 [debug] [ThreadPool]: SQL status: BEGIN in 0.029 seconds
[0m04:25:08.764357 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:25:08.767599 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:25:08.770338 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:25:08.772712 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:25:08.773959 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.008 seconds
[0m04:25:08.780294 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:25:08.782630 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m04:25:08.783588 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:25:08.784854 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.008 seconds
[0m04:25:08.788935 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:25:08.795695 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:25:08.797979 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:25:08.800093 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:25:08.826201 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:08.828996 [debug] [MainThread]: On master: BEGIN
[0m04:25:08.831447 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:25:08.847017 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m04:25:08.849052 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:08.851590 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:25:08.866489 [debug] [MainThread]: SQL status: SELECT 2 in 0.012 seconds
[0m04:25:08.872933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27d9cba70>]}
[0m04:25:08.875847 [debug] [MainThread]: On master: ROLLBACK
[0m04:25:08.878124 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:08.880308 [debug] [MainThread]: On master: BEGIN
[0m04:25:08.882948 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:25:08.885185 [debug] [MainThread]: On master: COMMIT
[0m04:25:08.887568 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:08.889534 [debug] [MainThread]: On master: COMMIT
[0m04:25:08.891703 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:25:08.893656 [debug] [MainThread]: On master: Close
[0m04:25:08.905823 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:25:08.908250 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:25:08.910491 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m04:25:08.912506 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:25:08.930483 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:25:08.944442 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:25:09.020296 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:25:09.032094 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.034163 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:25:09.036582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:25:09.050257 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:25:09.052689 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.054937 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:25:09.059667 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m04:25:09.073204 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.075335 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:25:09.078204 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:25:09.086374 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.088760 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:25:09.091622 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:25:09.131159 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:25:09.133726 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.136347 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:25:09.147676 [debug] [Thread-1 (]: SQL status: COMMIT in 0.009 seconds
[0m04:25:09.161476 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:25:09.175937 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:25:09.178525 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:25:09.184532 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.003 seconds
[0m04:25:09.192229 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:25:09.198445 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27f28c380>]}
[0m04:25:09.202062 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.28s]
[0m04:25:09.205637 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:25:09.210062 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:25:09.212892 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:25:09.215528 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m04:25:09.217943 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:25:09.230103 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:25:09.248610 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:25:09.306634 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:25:09.319874 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:09.321579 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:25:09.323086 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:25:09.335165 [debug] [Thread-3 (]: SQL status: BEGIN in 0.012 seconds
[0m04:25:09.337779 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:09.340358 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:25:11.133988 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.791 seconds
[0m04:25:11.144706 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:11.146576 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:25:11.148962 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:25:11.154891 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:11.156783 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:25:11.159083 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:25:11.162189 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:25:11.163982 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:11.165821 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:25:11.174669 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m04:25:11.179465 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:25:11.184907 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:25:11.186846 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:25:11.194995 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:25:11.198561 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:25:11.200811 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe278562fc0>]}
[0m04:25:11.203107 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 1.99s]
[0m04:25:11.205278 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:25:11.207714 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:25:11.208752 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:25:11.210444 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:25:11.212260 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:25:11.214316 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m04:25:11.215963 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:25:11.218152 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:25:11.219913 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:25:11.225909 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:25:11.234240 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:25:11.242390 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:25:11.249212 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:25:11.250495 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:25:11.257375 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:25:11.264457 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:25:11.266607 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:25:11.268138 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:25:11.269749 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:25:11.271445 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:25:11.273809 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:25:11.282103 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m04:25:11.284434 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:25:11.285940 [debug] [Thread-2 (]: SQL status: BEGIN in 0.012 seconds
[0m04:25:11.287532 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:25:11.299000 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:25:11.303190 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker dengan penanganan nilai NULL
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) AS total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) AS predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS correct_direction_predictions,
        COALESCE(AVG(error_percentage), 0) AS avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0 THEN 
                CAST(SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) AS FLOAT) / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END AS direction_accuracy_pct,
        -- Penanganan NULL untuk perhitungan metrik
        COALESCE(SQRT(AVG(POWER(predicted_close - actual_close, 2))), 0) AS rmse,
        COALESCE(AVG(ABS(predicted_close - actual_close)), 0) AS mae,
        COALESCE(AVG(CASE WHEN actual_close <> 0 THEN ABS(predicted_close - actual_close) / actual_close ELSE NULL END) * 100, 0) AS mape
    FROM lstm_predictions
    GROUP BY symbol
),

-- Prediksi terbaru per simbol dengan ROW_NUMBER
latest_predictions AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            prediction_date,
            predicted_close,
            actual_close,
            error_percentage,
            prediction_direction,
            created_at,
            ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY prediction_date DESC) AS rn
        FROM lstm_predictions
    ) t
    WHERE rn = 1
)

-- Output akhir dengan LEFT JOIN untuk menghindari missing data
SELECT
    acc.symbol,
    acc.total_predictions,
    acc.predictions_with_actuals,
    acc.correct_direction_predictions,
    acc.avg_error_percentage,
    acc.direction_accuracy_pct,
    acc.rmse,
    acc.mae,
    acc.mape,
    acc.predictions_with_actuals AS metrics_prediction_count, -- Gunakan jumlah prediksi aktual sebagai metrics_prediction_count
    COALESCE(lp.prediction_date, 'N/A') AS latest_prediction_date,
    COALESCE(lp.predicted_close, 0) AS latest_predicted_close,
    COALESCE(lp.prediction_direction, 'Unknown') AS latest_prediction_direction,
    COALESCE(lp.error_percentage, 0) AS latest_error_percentage
FROM lstm_accuracy acc
LEFT JOIN latest_predictions lp ON acc.symbol = lp.symbol
  );
  
[0m04:25:11.304410 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:25:11.306993 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:25:11.308685 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:25:11.310508 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:25:11.312809 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:25:11.314792 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:25:11.326011 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:25:11.328593 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:25:11.330346 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe278563e00>]}
[0m04:25:11.332597 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2dfab2fc-44dd-4a30-b495-f1bd5effc0ee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27851ede0>]}
[0m04:25:11.335427 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.11s]
[0m04:25:11.337994 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.12s]
[0m04:25:11.340439 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:25:11.342645 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:25:11.344768 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:25:11.348653 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:25:11.352170 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:11.353804 [debug] [MainThread]: On master: BEGIN
[0m04:25:11.355300 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:25:11.365903 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m04:25:11.368170 [debug] [MainThread]: On master: COMMIT
[0m04:25:11.369768 [debug] [MainThread]: Using postgres connection "master"
[0m04:25:11.371426 [debug] [MainThread]: On master: COMMIT
[0m04:25:11.373360 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:25:11.375028 [debug] [MainThread]: On master: Close
[0m04:25:11.376854 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:25:11.378467 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:25:11.380143 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:25:11.381625 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:25:11.383365 [info ] [MainThread]: 
[0m04:25:11.385292 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 2.94 seconds (2.94s).
[0m04:25:11.388351 [debug] [MainThread]: Command end result
[0m04:25:11.463501 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:25:11.472332 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:25:11.490329 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:25:11.492106 [info ] [MainThread]: 
[0m04:25:11.494152 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:25:11.496093 [info ] [MainThread]: 
[0m04:25:11.498225 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:25:11.500837 [info ] [MainThread]: 
[0m04:25:11.503427 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 23:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:25:11.505994 [info ] [MainThread]: 
[0m04:25:11.508653 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:25:11.513150 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 5.493542, "process_in_blocks": "0", "process_kernel_time": 0.420724, "process_mem_max_rss": "128788", "process_out_blocks": "0", "process_user_time": 6.050418}
[0m04:25:11.515566 [debug] [MainThread]: Command `dbt run` failed at 04:25:11.515306 after 5.50 seconds
[0m04:25:11.517876 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27eee69c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27e79c380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe27857ef00>]}
[0m04:25:11.519836 [debug] [MainThread]: Flushing usage events
[0m04:25:12.727549 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:27:07.184900 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143a4ea540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143a5f5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143a5f4e00>]}


============================== 04:27:07.201244 | f0033c13-4b4b-4759-9093-5893d72952ff ==============================
[0m04:27:07.201244 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:27:07.203687 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:27:07.666102 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1439537500>]}
[0m04:27:07.971312 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143b3c7740>]}
[0m04:27:07.978985 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:27:08.523944 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:27:09.465067 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m04:27:09.489513 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m04:27:10.139253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1438168170>]}
[0m04:27:10.385191 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:27:10.409167 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:27:10.461164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143813f680>]}
[0m04:27:10.464128 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:27:10.466506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1438168d40>]}
[0m04:27:10.473533 [info ] [MainThread]: 
[0m04:27:10.476208 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:27:10.478686 [info ] [MainThread]: 
[0m04:27:10.481181 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:27:10.491088 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:27:10.492554 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:27:10.493983 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:27:10.580269 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:27:10.581168 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:27:10.581957 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:27:10.583737 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:27:10.585881 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:27:10.587770 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:27:10.589774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:27:10.591425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:27:10.593180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:27:10.609365 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m04:27:10.610215 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.020 seconds
[0m04:27:10.613538 [debug] [ThreadPool]: On list_airflow: Close
[0m04:27:10.617358 [debug] [ThreadPool]: On list_airflow: Close
[0m04:27:10.618382 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.025 seconds
[0m04:27:10.624357 [debug] [ThreadPool]: On list_airflow: Close
[0m04:27:10.630155 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:27:10.631579 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:27:10.633266 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:27:10.644882 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:27:10.648891 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:27:10.655840 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:27:10.657609 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:27:10.659429 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:27:10.661450 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:27:10.663261 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:27:10.664900 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:27:10.666632 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:27:10.679808 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m04:27:10.682077 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m04:27:10.683370 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:27:10.685934 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:27:10.686952 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m04:27:10.688701 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:27:10.690805 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:27:10.693127 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:27:10.700955 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m04:27:10.702156 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:27:10.703395 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m04:27:10.707799 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:27:10.714518 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:27:10.716342 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m04:27:10.718341 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:27:10.720545 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:27:10.724075 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:27:10.732822 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:27:10.748110 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:10.750400 [debug] [MainThread]: On master: BEGIN
[0m04:27:10.752977 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:27:10.767181 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m04:27:10.769563 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:10.771945 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:27:10.786244 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m04:27:10.790574 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143910a0f0>]}
[0m04:27:10.792985 [debug] [MainThread]: On master: ROLLBACK
[0m04:27:10.795199 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:10.797533 [debug] [MainThread]: On master: BEGIN
[0m04:27:10.800625 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:27:10.803118 [debug] [MainThread]: On master: COMMIT
[0m04:27:10.805128 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:10.807480 [debug] [MainThread]: On master: COMMIT
[0m04:27:10.809944 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:27:10.811914 [debug] [MainThread]: On master: Close
[0m04:27:10.822118 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:27:10.824652 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:27:10.827075 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m04:27:10.829189 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:27:10.845576 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:27:10.861303 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:27:10.944164 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:27:10.959346 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:10.961635 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:27:10.964020 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:27:10.977520 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:27:10.979450 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:10.981279 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:27:10.987848 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m04:27:11.005759 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:11.007932 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:27:11.011586 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:27:11.019378 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:11.021250 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:27:11.023529 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:27:11.059439 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:27:11.061762 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:11.063771 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:27:11.071343 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m04:27:11.084544 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:27:11.095825 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:27:11.098115 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:27:11.105699 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.005 seconds
[0m04:27:11.111474 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:27:11.116184 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143c1939e0>]}
[0m04:27:11.118781 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.29s]
[0m04:27:11.121387 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:27:11.124663 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:27:11.126716 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:27:11.128919 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m04:27:11.130998 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:27:11.139360 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:27:11.154010 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:27:11.214430 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:27:11.235056 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:11.237655 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:27:11.240670 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:27:11.258813 [debug] [Thread-3 (]: SQL status: BEGIN in 0.018 seconds
[0m04:27:11.261489 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:11.264336 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

-- Ambil harga penutupan terakhir sebelum tanggal prediksi
stock_data AS (
    SELECT *
    FROM (
        SELECT 
            symbol,
            date,
            close,
            volume,
            percent_change,
            ROW_NUMBER() OVER (PARTITION BY symbol, date ORDER BY date DESC) AS rn
        FROM "airflow"."public_core"."fct_daily_stock_metrics"
    ) AS ranked_data  -- Tambahkan alias di sini
    WHERE rn = 1
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close AS predicted_close_price,
        p.actual_close AS actual_close_price,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close AS prev_close_price,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END AS prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END AS direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:27:13.985523 [debug] [Thread-3 (]: SQL status: SELECT 1 in 2.717 seconds
[0m04:27:14.000020 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:14.002396 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:27:14.005251 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:27:14.012088 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:14.014289 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:27:14.017230 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:27:14.020899 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:27:14.022730 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:14.024619 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:27:14.028691 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m04:27:14.034976 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:27:14.041498 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:27:14.043508 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:27:14.049460 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:27:14.054719 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:27:14.057775 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f14346261b0>]}
[0m04:27:14.060590 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 2.93s]
[0m04:27:14.063177 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:27:14.067808 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:27:14.069214 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:27:14.071745 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:27:14.074281 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:27:14.076328 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m04:27:14.078535 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:27:14.081196 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:27:14.084039 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:27:14.091895 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:27:14.102156 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:27:14.111334 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:27:14.113729 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:27:14.121203 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:27:14.129548 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:27:14.140186 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:27:14.142106 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:27:14.144217 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:27:14.146931 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:27:14.149722 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:27:14.152140 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:27:14.168769 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m04:27:14.170589 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m04:27:14.172450 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:27:14.175254 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:27:14.178763 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:27:14.183119 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    -- models/marts/analytics/lstm_performance_metrics.sql


WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Data tren LSTM per bulan
lstm_trend AS (
    SELECT
        symbol,
        DATE_TRUNC('month', prediction_date) as month,
        COUNT(*) as predictions_count,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN COUNT(*) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(COUNT(*), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol, DATE_TRUNC('month', prediction_date)
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m04:27:14.188464 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column ld.predicted_close does not exist
LINE 66:         ld.predicted_close,
                 ^

[0m04:27:14.190482 [debug] [Thread-2 (]: Postgres adapter: Postgres error: column "actual_close" does not exist
LINE 24:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                               ^

[0m04:27:14.192807 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m04:27:14.195548 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:27:14.199761 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:27:14.203204 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:27:14.220996 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 24:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:27:14.224854 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:27:14.227129 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1437d44830>]}
[0m04:27:14.229288 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0033c13-4b4b-4759-9093-5893d72952ff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143816af90>]}
[0m04:27:14.231816 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.15s]
[0m04:27:14.235169 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.15s]
[0m04:27:14.237503 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:27:14.239726 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:27:14.242257 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 24:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:27:14.247479 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m04:27:14.252919 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:14.254781 [debug] [MainThread]: On master: BEGIN
[0m04:27:14.256543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:27:14.269836 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m04:27:14.271627 [debug] [MainThread]: On master: COMMIT
[0m04:27:14.273312 [debug] [MainThread]: Using postgres connection "master"
[0m04:27:14.274956 [debug] [MainThread]: On master: COMMIT
[0m04:27:14.276951 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:27:14.278615 [debug] [MainThread]: On master: Close
[0m04:27:14.280573 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:27:14.282959 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:27:14.285058 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:27:14.286640 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:27:14.288393 [info ] [MainThread]: 
[0m04:27:14.290330 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 3.81 seconds (3.81s).
[0m04:27:14.294081 [debug] [MainThread]: Command end result
[0m04:27:14.398225 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:27:14.407951 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:27:14.435372 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:27:14.438005 [info ] [MainThread]: 
[0m04:27:14.440936 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m04:27:14.443779 [info ] [MainThread]: 
[0m04:27:14.447083 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  column "actual_close" does not exist
  LINE 24:         SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0...
                                 ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:27:14.450124 [info ] [MainThread]: 
[0m04:27:14.452782 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column ld.predicted_close does not exist
  LINE 66:         ld.predicted_close,
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m04:27:14.454983 [info ] [MainThread]: 
[0m04:27:14.457046 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 TOTAL=4
[0m04:27:14.460052 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 7.412994, "process_in_blocks": "0", "process_kernel_time": 0.586552, "process_mem_max_rss": "128508", "process_out_blocks": "0", "process_user_time": 6.591254}
[0m04:27:14.462580 [debug] [MainThread]: Command `dbt run` failed at 04:27:14.462311 after 7.42 seconds
[0m04:27:14.465208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143ad22ff0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143a9cbe30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f143ab80500>]}
[0m04:27:14.467387 [debug] [MainThread]: Flushing usage events
[0m04:27:15.618915 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:29:23.533526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54733f82c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f547109f290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f54711c0740>]}


============================== 04:29:23.548463 | 46d3dad6-14a3-4757-906b-f30db54c4922 ==============================
[0m04:29:23.548463 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:29:23.550725 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m04:29:23.899717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5471166000>]}
[0m04:29:24.001802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5470377860>]}
[0m04:29:24.004085 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:29:24.159525 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:29:24.790976 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m04:29:24.793200 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m04:29:24.795835 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m04:29:25.607988 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546f3d3b60>]}
[0m04:29:25.820269 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:29:25.841822 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:29:25.895570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546eba27e0>]}
[0m04:29:25.897775 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:29:25.900112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546fb62840>]}
[0m04:29:25.905427 [info ] [MainThread]: 
[0m04:29:25.907520 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:29:25.909770 [info ] [MainThread]: 
[0m04:29:25.912519 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:29:25.923026 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:29:25.924356 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:29:25.925781 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:29:26.007483 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:29:26.008540 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:29:26.009346 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:29:26.011793 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:29:26.014131 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:29:26.016398 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:29:26.018573 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:29:26.020715 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:29:26.022826 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:29:26.037997 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.019 seconds
[0m04:29:26.038935 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m04:29:26.043569 [debug] [ThreadPool]: On list_airflow: Close
[0m04:29:26.048535 [debug] [ThreadPool]: On list_airflow: Close
[0m04:29:26.049703 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.027 seconds
[0m04:29:26.056116 [debug] [ThreadPool]: On list_airflow: Close
[0m04:29:26.063053 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:29:26.064409 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:29:26.065738 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:29:26.079540 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:29:26.083626 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:29:26.088962 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:29:26.091226 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:29:26.093396 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:29:26.096271 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:29:26.098489 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:29:26.100538 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:29:26.102966 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:29:26.119855 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m04:29:26.121782 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m04:29:26.122875 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:29:26.125343 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:29:26.127647 [debug] [ThreadPool]: SQL status: BEGIN in 0.024 seconds
[0m04:29:26.129454 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:29:26.131958 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:29:26.134288 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:29:26.137810 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:29:26.142556 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.006 seconds
[0m04:29:26.143929 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.007 seconds
[0m04:29:26.145471 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m04:29:26.149467 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:29:26.153116 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:29:26.156562 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:29:26.158883 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:29:26.160833 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:29:26.163867 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:29:26.183828 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:26.185869 [debug] [MainThread]: On master: BEGIN
[0m04:29:26.187886 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:29:26.200528 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m04:29:26.205837 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:26.207915 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:29:26.221230 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m04:29:26.225073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546d763c80>]}
[0m04:29:26.229188 [debug] [MainThread]: On master: ROLLBACK
[0m04:29:26.231460 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:26.233254 [debug] [MainThread]: On master: BEGIN
[0m04:29:26.235657 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:29:26.237484 [debug] [MainThread]: On master: COMMIT
[0m04:29:26.239197 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:26.240852 [debug] [MainThread]: On master: COMMIT
[0m04:29:26.242918 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:29:26.245298 [debug] [MainThread]: On master: Close
[0m04:29:26.253555 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:29:26.255587 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:29:26.257478 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m04:29:26.259157 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:29:26.274272 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:29:26.292045 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:29:26.367280 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:29:26.382767 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.384860 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:29:26.386603 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:29:26.399209 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m04:29:26.401364 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.403343 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:29:26.407676 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m04:29:26.421302 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.423405 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:29:26.425919 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:29:26.433724 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.435696 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:29:26.438096 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:29:26.473064 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:29:26.474935 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.476813 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:29:26.481791 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:29:26.493475 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:29:26.503486 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:29:26.505174 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:29:26.512660 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m04:29:26.517706 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:29:26.521365 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5471948860>]}
[0m04:29:26.523597 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.26s]
[0m04:29:26.526233 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:29:26.529390 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:29:26.531602 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:29:26.533700 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m04:29:26.535639 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:29:26.542552 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:29:26.556074 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:29:26.596280 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:29:26.611787 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:26.613688 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:29:26.615429 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:29:26.626957 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m04:29:26.629100 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:26.631205 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
EOF
  );
  
[0m04:29:27.157521 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.524 seconds
[0m04:29:27.171062 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:27.172833 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:29:27.177723 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m04:29:27.184660 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:27.186287 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:29:27.188444 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m04:29:27.192025 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:29:27.194350 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:27.195884 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:29:27.201916 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m04:29:27.207281 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:29:27.215913 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:29:27.217906 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:29:27.225505 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m04:29:27.229584 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:29:27.231592 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546c485880>]}
[0m04:29:27.233749 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.70s]
[0m04:29:27.235951 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:29:27.238954 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:29:27.240038 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:29:27.241808 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:29:27.244351 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:29:27.246145 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m04:29:27.247740 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:29:27.249438 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:29:27.250961 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:29:27.258309 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:29:27.267808 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:29:27.280192 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:29:27.281684 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:29:27.289609 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:29:27.302314 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:29:27.311485 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:29:27.314670 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:29:27.316114 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:29:27.317738 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:29:27.319621 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:29:27.322856 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:29:27.337772 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m04:29:27.341372 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:29:27.347061 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:29:27.351834 [debug] [Thread-2 (]: SQL status: BEGIN in 0.028 seconds
[0m04:29:27.354478 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:29:27.356881 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
EOF
  );
  
[0m04:29:27.360973 [debug] [Thread-2 (]: Postgres adapter: Postgres error: syntax error at or near "EOF"
LINE 65: EOF
         ^

[0m04:29:27.363263 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: ROLLBACK
[0m04:29:27.365774 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:29:27.377689 [debug] [Thread-2 (]: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near "EOF"
  LINE 65: EOF
           ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:29:27.380594 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546c3cd2b0>]}
[0m04:29:27.382871 [error] [Thread-2 (]: 3 of 4 ERROR creating sql table model public_analytics.lstm_performance_metrics  [[31mERROR[0m in 0.13s]
[0m04:29:27.385870 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:29:27.388232 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.lstm_performance_metrics' to be skipped because of status 'error'.  Reason: Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near "EOF"
  LINE 65: EOF
           ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql.
[0m04:29:35.548905 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 8.195 seconds
[0m04:29:35.633333 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:29:35.635854 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m04:29:35.638713 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:29:35.642423 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m04:29:35.644524 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:29:35.646637 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m04:29:35.665904 [debug] [Thread-1 (]: SQL status: COMMIT in 0.017 seconds
[0m04:29:35.671832 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m04:29:35.674301 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:29:35.676382 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m04:29:35.678892 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:29:35.683065 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:29:35.685985 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46d3dad6-14a3-4757-906b-f30db54c4922', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546c3ccdd0>]}
[0m04:29:35.688612 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 8.44s]
[0m04:29:35.691336 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:29:35.695888 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:35.698128 [debug] [MainThread]: On master: BEGIN
[0m04:29:35.700140 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:29:35.712027 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m04:29:35.714289 [debug] [MainThread]: On master: COMMIT
[0m04:29:35.716242 [debug] [MainThread]: Using postgres connection "master"
[0m04:29:35.718125 [debug] [MainThread]: On master: COMMIT
[0m04:29:35.720626 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:29:35.722678 [debug] [MainThread]: On master: Close
[0m04:29:35.724783 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:29:35.726584 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:29:35.728501 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:29:35.730308 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:29:35.732206 [info ] [MainThread]: 
[0m04:29:35.734073 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 9.82 seconds (9.82s).
[0m04:29:35.737483 [debug] [MainThread]: Command end result
[0m04:29:35.823778 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:29:35.834781 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:29:35.859070 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:29:35.861202 [info ] [MainThread]: 
[0m04:29:35.863347 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m04:29:35.865821 [info ] [MainThread]: 
[0m04:29:35.867981 [error] [MainThread]:   Database Error in model lstm_performance_metrics (models/marts/analytics/lstm_performance_metrics.sql)
  syntax error at or near "EOF"
  LINE 65: EOF
           ^
  compiled code at target/run/idx_stock/models/marts/analytics/lstm_performance_metrics.sql
[0m04:29:35.870316 [info ] [MainThread]: 
[0m04:29:35.872846 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m04:29:35.876026 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 12.450299, "process_in_blocks": "0", "process_kernel_time": 0.375564, "process_mem_max_rss": "129272", "process_out_blocks": "0", "process_user_time": 5.856772}
[0m04:29:35.878465 [debug] [MainThread]: Command `dbt run` failed at 04:29:35.878210 after 12.45 seconds
[0m04:29:35.880345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5472028530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f546ebcfe30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f547194b2c0>]}
[0m04:29:35.882261 [debug] [MainThread]: Flushing usage events
[0m04:29:37.160278 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m04:32:01.741748 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb5c98c20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb77f6750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb57182f0>]}


============================== 04:32:01.757611 | 22de480e-c83c-48fa-a1a0-0b58fba762d2 ==============================
[0m04:32:01.757611 [info ] [MainThread]: Running with dbt=1.9.4
[0m04:32:01.760026 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m04:32:02.225763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb4fd6e70>]}
[0m04:32:02.365537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb52e8b60>]}
[0m04:32:02.368158 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m04:32:02.571565 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m04:32:03.271733 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m04:32:03.274307 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/core/fct_stock_predictions.sql
[0m04:32:03.276411 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/lstm_performance_metrics.sql
[0m04:32:04.013001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb3560680>]}
[0m04:32:04.209166 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:32:04.225811 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:32:04.269438 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb3d5eae0>]}
[0m04:32:04.271961 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m04:32:04.274171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb459ecf0>]}
[0m04:32:04.279285 [info ] [MainThread]: 
[0m04:32:04.281222 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m04:32:04.283037 [info ] [MainThread]: 
[0m04:32:04.285207 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m04:32:04.293465 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:32:04.295049 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:32:04.296416 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m04:32:04.365512 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:32:04.366306 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:32:04.367034 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m04:32:04.368607 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:32:04.370417 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:32:04.372233 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m04:32:04.374037 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:32:04.375917 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:32:04.377651 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m04:32:04.391366 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.015 seconds
[0m04:32:04.392256 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m04:32:04.395435 [debug] [ThreadPool]: On list_airflow: Close
[0m04:32:04.396328 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.019 seconds
[0m04:32:04.399042 [debug] [ThreadPool]: On list_airflow: Close
[0m04:32:04.403719 [debug] [ThreadPool]: On list_airflow: Close
[0m04:32:04.410796 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m04:32:04.412075 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m04:32:04.413288 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m04:32:04.423858 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:32:04.427582 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:32:04.431775 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:32:04.433799 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m04:32:04.435356 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m04:32:04.437374 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m04:32:04.439249 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:32:04.440752 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:32:04.442537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m04:32:04.456495 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m04:32:04.457608 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:32:04.459085 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m04:32:04.459821 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m04:32:04.461547 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m04:32:04.463295 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m04:32:04.465154 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m04:32:04.467073 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m04:32:04.469189 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m04:32:04.474898 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m04:32:04.476510 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m04:32:04.477382 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m04:32:04.479543 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m04:32:04.482649 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m04:32:04.486172 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m04:32:04.488419 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m04:32:04.490128 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m04:32:04.491792 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m04:32:04.508626 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:04.510659 [debug] [MainThread]: On master: BEGIN
[0m04:32:04.512850 [debug] [MainThread]: Opening a new connection, currently in state init
[0m04:32:04.524136 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m04:32:04.526059 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:04.528121 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m04:32:04.539418 [debug] [MainThread]: SQL status: SELECT 2 in 0.009 seconds
[0m04:32:04.543238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb19879e0>]}
[0m04:32:04.545273 [debug] [MainThread]: On master: ROLLBACK
[0m04:32:04.547569 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:04.549398 [debug] [MainThread]: On master: BEGIN
[0m04:32:04.551614 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m04:32:04.553375 [debug] [MainThread]: On master: COMMIT
[0m04:32:04.555051 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:04.556774 [debug] [MainThread]: On master: COMMIT
[0m04:32:04.558775 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:32:04.560501 [debug] [MainThread]: On master: Close
[0m04:32:04.569540 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m04:32:04.571683 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m04:32:04.573568 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m04:32:04.575316 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m04:32:04.588286 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m04:32:04.601855 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m04:32:04.660316 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m04:32:04.673243 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.674817 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m04:32:04.676441 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:32:04.686703 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m04:32:04.688766 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.690530 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m04:32:04.694671 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.002 seconds
[0m04:32:04.705330 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.707256 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m04:32:04.709506 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:04.715245 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.716975 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m04:32:04.719395 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:04.746925 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:32:04.750412 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.752860 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m04:32:04.758328 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m04:32:04.771357 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m04:32:04.780596 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m04:32:04.782518 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m04:32:04.787082 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m04:32:04.791696 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m04:32:04.795282 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb5a90140>]}
[0m04:32:04.797653 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.22s]
[0m04:32:04.799854 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m04:32:04.802399 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m04:32:04.804326 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m04:32:04.806157 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m04:32:04.808016 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m04:32:04.814405 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m04:32:04.827511 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m04:32:04.864152 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m04:32:04.877594 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:04.879227 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m04:32:04.880741 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m04:32:04.891893 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m04:32:04.894065 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:04.896098 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m04:32:05.324450 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.426 seconds
[0m04:32:05.339013 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:05.341141 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m04:32:05.343999 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:05.350605 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:05.353006 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m04:32:05.357716 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:05.362762 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:32:05.364872 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:05.367177 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m04:32:05.376060 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m04:32:05.384841 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m04:32:05.393266 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m04:32:05.395460 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m04:32:05.402181 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m04:32:05.406744 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m04:32:05.409381 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf83ca5700>]}
[0m04:32:05.413457 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.60s]
[0m04:32:05.417876 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m04:32:05.420951 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m04:32:05.422041 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m04:32:05.424213 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m04:32:05.426558 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m04:32:05.428812 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m04:32:05.430713 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m04:32:05.432864 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m04:32:05.434513 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m04:32:05.440896 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.449752 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m04:32:05.458717 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m04:32:05.460534 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m04:32:05.467144 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.474068 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m04:32:05.482870 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.484452 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:05.485711 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m04:32:05.487747 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m04:32:05.489678 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m04:32:05.491647 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m04:32:05.503704 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m04:32:05.505380 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m04:32:05.506324 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.508569 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:05.510633 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m04:32:05.513317 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m04:32:05.530489 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.015 seconds
[0m04:32:05.538963 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.540849 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m04:32:05.543170 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:05.546482 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m04:32:05.548289 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.549966 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m04:32:05.556771 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m04:32:05.643867 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m04:32:05.646281 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m04:32:05.648358 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m04:32:05.650517 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m04:32:05.654422 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m04:32:05.656950 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf81b02660>]}
[0m04:32:05.659588 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.23s]
[0m04:32:05.662004 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m04:32:11.806102 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 6.290 seconds
[0m04:32:11.814155 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:11.816750 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m04:32:11.819816 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:11.826866 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:11.829253 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m04:32:11.832255 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m04:32:11.836292 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m04:32:11.838566 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:11.840830 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m04:32:11.860361 [debug] [Thread-1 (]: SQL status: COMMIT in 0.017 seconds
[0m04:32:11.866460 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m04:32:11.869027 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m04:32:11.871229 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m04:32:11.879115 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m04:32:11.883136 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m04:32:11.885749 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '22de480e-c83c-48fa-a1a0-0b58fba762d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdf81b0ec00>]}
[0m04:32:11.888485 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 6.45s]
[0m04:32:11.891237 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m04:32:11.898215 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:11.900344 [debug] [MainThread]: On master: BEGIN
[0m04:32:11.902575 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m04:32:11.917195 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m04:32:11.919456 [debug] [MainThread]: On master: COMMIT
[0m04:32:11.921510 [debug] [MainThread]: Using postgres connection "master"
[0m04:32:11.923634 [debug] [MainThread]: On master: COMMIT
[0m04:32:11.926005 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m04:32:11.928161 [debug] [MainThread]: On master: Close
[0m04:32:11.930477 [debug] [MainThread]: Connection 'master' was properly closed.
[0m04:32:11.932597 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m04:32:11.934582 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m04:32:11.942822 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m04:32:11.944853 [info ] [MainThread]: 
[0m04:32:11.946591 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 7.66 seconds (7.66s).
[0m04:32:11.950480 [debug] [MainThread]: Command end result
[0m04:32:12.115740 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m04:32:12.125173 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m04:32:12.143660 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m04:32:12.146064 [info ] [MainThread]: 
[0m04:32:12.148364 [info ] [MainThread]: [32mCompleted successfully[0m
[0m04:32:12.150288 [info ] [MainThread]: 
[0m04:32:12.152300 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m04:32:12.155717 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 10.544894, "process_in_blocks": "0", "process_kernel_time": 0.488102, "process_mem_max_rss": "130952", "process_out_blocks": "0", "process_user_time": 6.674055}
[0m04:32:12.158232 [debug] [MainThread]: Command `dbt run` succeeded at 04:32:12.157918 after 10.55 seconds
[0m04:32:12.160346 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb598d460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb3544050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfb3547bc0>]}
[0m04:32:12.163198 [debug] [MainThread]: Flushing usage events
[0m04:32:13.554705 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:33:08.025893 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34be4116d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bc7a3f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bce5b2f0>]}


============================== 06:33:08.040414 | 64878466-fd7f-4453-ad93-a0a82e779f9b ==============================
[0m06:33:08.040414 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:33:08.042849 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:33:08.382525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bc21b620>]}
[0m06:33:08.499097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bc3e4860>]}
[0m06:33:08.501693 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:33:08.657268 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:33:09.200044 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:33:09.201986 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:33:09.286518 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bbb6b590>]}
[0m06:33:09.486862 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:33:09.500787 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:33:09.546230 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bab4ff20>]}
[0m06:33:09.548269 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:33:09.550225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bab17140>]}
[0m06:33:09.555249 [info ] [MainThread]: 
[0m06:33:09.557114 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:33:09.559028 [info ] [MainThread]: 
[0m06:33:09.561140 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:33:09.570667 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:33:09.571844 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:33:09.573020 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:33:09.653944 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:33:09.654801 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:33:09.655553 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:33:09.657174 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:33:09.659242 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:33:09.661383 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:33:09.663227 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:33:09.665269 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:33:09.667113 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:33:09.682465 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.019 seconds
[0m06:33:09.683812 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m06:33:09.687557 [debug] [ThreadPool]: On list_airflow: Close
[0m06:33:09.688469 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.021 seconds
[0m06:33:09.692116 [debug] [ThreadPool]: On list_airflow: Close
[0m06:33:09.697592 [debug] [ThreadPool]: On list_airflow: Close
[0m06:33:09.704878 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m06:33:09.706044 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m06:33:09.707196 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m06:33:09.717800 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:33:09.722105 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:33:09.726311 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:33:09.728302 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:33:09.730088 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:33:09.731687 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:33:09.733375 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:33:09.735401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:33:09.736889 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:33:09.749049 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m06:33:09.749955 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m06:33:09.751374 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m06:33:09.752142 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:33:09.754457 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:33:09.756234 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:33:09.758341 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:33:09.760345 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:33:09.762900 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:33:09.769550 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m06:33:09.770782 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m06:33:09.771592 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m06:33:09.774528 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:33:09.777646 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:33:09.781342 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:33:09.783614 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:33:09.785343 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:33:09.787337 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:33:09.805359 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:09.807172 [debug] [MainThread]: On master: BEGIN
[0m06:33:09.808867 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:33:09.820698 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m06:33:09.822515 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:09.824448 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:33:09.839229 [debug] [MainThread]: SQL status: SELECT 2 in 0.013 seconds
[0m06:33:09.842798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b9fee5a0>]}
[0m06:33:09.844594 [debug] [MainThread]: On master: ROLLBACK
[0m06:33:09.846470 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:09.848234 [debug] [MainThread]: On master: BEGIN
[0m06:33:09.850458 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:33:09.852122 [debug] [MainThread]: On master: COMMIT
[0m06:33:09.853846 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:09.855542 [debug] [MainThread]: On master: COMMIT
[0m06:33:09.857633 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:33:09.859303 [debug] [MainThread]: On master: Close
[0m06:33:09.868793 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m06:33:09.871233 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m06:33:09.873718 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m06:33:09.876337 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m06:33:09.891534 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m06:33:09.904277 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m06:33:09.979342 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m06:33:09.994959 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:09.996826 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m06:33:09.998285 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:33:10.009722 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m06:33:10.011719 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:10.013802 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m06:33:10.021060 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m06:33:10.032996 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:10.034924 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m06:33:10.037746 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:10.045678 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:10.048465 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m06:33:10.051119 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:10.082771 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:33:10.084834 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:10.086665 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:33:10.091270 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m06:33:10.105138 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m06:33:10.116286 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:33:10.118178 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m06:33:10.126175 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m06:33:10.131973 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m06:33:10.136432 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bcdd4b00>]}
[0m06:33:10.139067 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.26s]
[0m06:33:10.141374 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m06:33:10.144753 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m06:33:10.147370 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m06:33:10.149559 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m06:33:10.151429 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m06:33:10.158829 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m06:33:10.172804 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m06:33:10.213718 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m06:33:10.227004 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:10.228633 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m06:33:10.230242 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:33:10.241601 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m06:33:10.243595 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:10.245595 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m06:33:11.620527 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.373 seconds
[0m06:33:11.633450 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:11.636139 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m06:33:11.639053 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:11.647566 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:11.649817 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m06:33:11.652870 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:11.658309 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:33:11.660905 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:11.663312 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:33:11.672714 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m06:33:11.679145 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m06:33:11.686558 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:33:11.688371 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m06:33:11.693637 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.003 seconds
[0m06:33:11.697238 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m06:33:11.699419 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bc246c60>]}
[0m06:33:11.702102 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 1.55s]
[0m06:33:11.705896 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m06:33:11.708500 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m06:33:11.709671 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m06:33:11.712133 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m06:33:11.714439 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m06:33:11.717121 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m06:33:11.719685 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m06:33:11.721940 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m06:33:11.724060 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m06:33:11.731799 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.741871 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m06:33:11.752292 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m06:33:11.760895 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m06:33:11.762301 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.770979 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m06:33:11.781387 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.784130 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m06:33:11.785565 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:11.787409 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:33:11.789767 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m06:33:11.793720 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:33:11.805274 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m06:33:11.807504 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.810151 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m06:33:11.812275 [debug] [Thread-1 (]: SQL status: BEGIN in 0.019 seconds
[0m06:33:11.814601 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:11.816946 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m06:33:11.831514 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.018 seconds
[0m06:33:11.843708 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.846078 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m06:33:11.848846 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:33:11.861221 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.863772 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m06:33:11.866698 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:11.872994 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:33:11.875384 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.877551 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:33:11.885176 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m06:33:11.893084 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m06:33:11.895921 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:33:11.897843 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m06:33:11.905708 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.006 seconds
[0m06:33:11.909593 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m06:33:11.912152 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b824dee0>]}
[0m06:33:11.915784 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.20s]
[0m06:33:11.918590 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m06:33:19.345619 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 7.525 seconds
[0m06:33:19.358145 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:19.360716 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m06:33:19.365267 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:19.373940 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:19.376176 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m06:33:19.380430 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:33:19.385135 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m06:33:19.387707 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:19.390179 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m06:33:19.434732 [debug] [Thread-1 (]: SQL status: COMMIT in 0.042 seconds
[0m06:33:19.440689 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m06:33:19.442850 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:33:19.444682 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m06:33:19.458033 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.010 seconds
[0m06:33:19.462891 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m06:33:19.465906 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64878466-fd7f-4453-ad93-a0a82e779f9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b825ca40>]}
[0m06:33:19.468345 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 7.75s]
[0m06:33:19.471246 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m06:33:19.476045 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:19.477866 [debug] [MainThread]: On master: BEGIN
[0m06:33:19.480227 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:33:19.493270 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m06:33:19.495735 [debug] [MainThread]: On master: COMMIT
[0m06:33:19.498015 [debug] [MainThread]: Using postgres connection "master"
[0m06:33:19.500162 [debug] [MainThread]: On master: COMMIT
[0m06:33:19.503016 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:33:19.505170 [debug] [MainThread]: On master: Close
[0m06:33:19.507567 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:33:19.509776 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m06:33:19.512979 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m06:33:19.515348 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m06:33:19.517705 [info ] [MainThread]: 
[0m06:33:19.519772 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 9.96 seconds (9.96s).
[0m06:33:19.523654 [debug] [MainThread]: Command end result
[0m06:33:19.621670 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:33:19.634058 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:33:19.656140 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:33:19.658193 [info ] [MainThread]: 
[0m06:33:19.660320 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:33:19.662990 [info ] [MainThread]: 
[0m06:33:19.666059 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m06:33:19.670219 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.741175, "process_in_blocks": "0", "process_kernel_time": 0.528364, "process_mem_max_rss": "123024", "process_out_blocks": "0", "process_user_time": 4.715403}
[0m06:33:19.673295 [debug] [MainThread]: Command `dbt run` succeeded at 06:33:19.672988 after 11.74 seconds
[0m06:33:19.675428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bff77170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34bded1580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f34b839e690>]}
[0m06:33:19.677444 [debug] [MainThread]: Flushing usage events
[0m06:33:20.944761 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:49:01.854441 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc85dd7710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc858dffb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8520e600>]}


============================== 16:49:01.871340 | bb1dee5c-c591-404c-86e6-3543704f70c3 ==============================
[0m16:49:01.871340 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:49:01.874459 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:49:02.544984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc85c9c800>]}
[0m16:49:02.710411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc850bdb80>]}
[0m16:49:02.713464 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:49:02.946079 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:49:04.068370 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:49:04.070228 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:49:04.191008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc83f3dca0>]}
[0m16:49:04.452920 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:04.472269 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:04.534386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8334be30>]}
[0m16:49:04.538309 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:49:04.541316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8333bc80>]}
[0m16:49:04.549435 [info ] [MainThread]: 
[0m16:49:04.552760 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:49:04.555818 [info ] [MainThread]: 
[0m16:49:04.559034 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:49:04.567124 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:49:04.687678 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:49:04.690372 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:49:04.693270 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:04.714852 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.021 seconds
[0m16:49:04.719130 [debug] [ThreadPool]: On list_airflow: Close
[0m16:49:04.722126 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m16:49:04.724464 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m16:49:04.737622 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:49:04.745456 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m16:49:04.748928 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:04.762108 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m16:49:04.765631 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:49:04.767514 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m16:49:04.770672 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:49:04.773699 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:49:04.775464 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m16:49:04.777029 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m16:49:04.780937 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m16:49:04.783080 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m16:49:04.795327 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_staging)
[0m16:49:04.797479 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:49:04.799247 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m16:49:04.811484 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:04.816660 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:04.823453 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:04.825136 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:49:04.827119 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:49:04.829530 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:49:04.832035 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:04.834171 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:04.835824 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:04.851149 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:49:04.853997 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m16:49:04.855939 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m16:49:04.857746 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:04.860309 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:04.863273 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:04.866131 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:49:04.868362 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:49:04.870283 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:49:04.877751 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.005 seconds
[0m16:49:04.879130 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m16:49:04.880286 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m16:49:04.884141 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:49:04.887862 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:49:04.891406 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:49:04.893619 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:49:04.895390 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:49:04.897527 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:49:04.916211 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:04.918200 [debug] [MainThread]: On master: BEGIN
[0m16:49:04.919951 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:49:04.935303 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m16:49:04.938030 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:04.940350 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:49:04.948662 [debug] [MainThread]: SQL status: SELECT 0 in 0.006 seconds
[0m16:49:04.952671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc850bf440>]}
[0m16:49:04.955103 [debug] [MainThread]: On master: ROLLBACK
[0m16:49:04.956978 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:04.958619 [debug] [MainThread]: On master: BEGIN
[0m16:49:04.960749 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m16:49:04.964457 [debug] [MainThread]: On master: COMMIT
[0m16:49:04.966470 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:04.968280 [debug] [MainThread]: On master: COMMIT
[0m16:49:04.970205 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:49:04.971876 [debug] [MainThread]: On master: Close
[0m16:49:04.984031 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m16:49:04.986208 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m16:49:04.988147 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m16:49:04.989807 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m16:49:05.006733 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.021460 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m16:49:05.103019 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.118274 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.120308 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m16:49:05.122436 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:49:05.136430 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m16:49:05.139211 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.142386 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m16:49:05.152318 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.007 seconds
[0m16:49:05.167674 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.169819 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m16:49:05.172768 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:05.204464 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:49:05.206861 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.208958 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m16:49:05.213989 [debug] [Thread-1 (]: SQL status: COMMIT in 0.003 seconds
[0m16:49:05.228304 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m16:49:05.240196 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m16:49:05.242460 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m16:49:05.245358 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m16:49:05.251768 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m16:49:05.256921 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb1dee5c-c591-404c-86e6-3543704f70c3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc8724fa10>]}
[0m16:49:05.259679 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.27s]
[0m16:49:05.262593 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m16:49:05.267701 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:05.270059 [debug] [MainThread]: On master: BEGIN
[0m16:49:05.272188 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:49:05.285909 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m16:49:05.289000 [debug] [MainThread]: On master: COMMIT
[0m16:49:05.291040 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:05.293146 [debug] [MainThread]: On master: COMMIT
[0m16:49:05.295840 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:49:05.298574 [debug] [MainThread]: On master: Close
[0m16:49:05.301312 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:49:05.303462 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m16:49:05.305522 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m16:49:05.307368 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m16:49:05.309276 [info ] [MainThread]: 
[0m16:49:05.310965 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m16:49:05.313953 [debug] [MainThread]: Command end result
[0m16:49:05.400137 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:05.408999 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:05.429054 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:49:05.431276 [info ] [MainThread]: 
[0m16:49:05.433380 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:49:05.435298 [info ] [MainThread]: 
[0m16:49:05.437156 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m16:49:05.439783 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.760784, "process_in_blocks": "43096", "process_kernel_time": 0.598589, "process_mem_max_rss": "122260", "process_out_blocks": "1056", "process_user_time": 6.913714}
[0m16:49:05.442023 [debug] [MainThread]: Command `dbt run` succeeded at 16:49:05.441788 after 3.76 seconds
[0m16:49:05.444071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc85425520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc88d47380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efc851e0740>]}
[0m16:49:05.446048 [debug] [MainThread]: Flushing usage events
[0m16:49:06.808385 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:49:12.590144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a7d31c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a7cbd0a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a7d329f0>]}


============================== 16:49:12.622274 | a4fc1d4e-334b-4cfd-a22e-b78b273a15af ==============================
[0m16:49:12.622274 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:49:12.627336 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'send_anonymous_usage_stats': 'True'}
[0m16:49:13.273694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a7832210>]}
[0m16:49:13.440546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a976d880>]}
[0m16:49:13.444070 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:49:13.666703 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:49:14.461085 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:49:14.463873 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:49:14.622923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a79a3020>]}
[0m16:49:14.977005 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:15.005720 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:15.086146 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a5b48230>]}
[0m16:49:15.091812 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:49:15.095120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a6beeae0>]}
[0m16:49:15.101588 [info ] [MainThread]: 
[0m16:49:15.104296 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:49:15.108096 [info ] [MainThread]: 
[0m16:49:15.110959 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:49:15.124425 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:49:15.247735 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:49:15.250937 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:49:15.253919 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:15.278019 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.024 seconds
[0m16:49:15.282128 [debug] [ThreadPool]: On list_airflow: Close
[0m16:49:15.285934 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m16:49:15.289998 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m16:49:15.308506 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:49:15.310802 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m16:49:15.313251 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:15.332866 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m16:49:15.336695 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:49:15.340064 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m16:49:15.344098 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:49:15.347336 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:49:15.349262 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m16:49:15.351288 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m16:49:15.359604 [debug] [ThreadPool]: SQL status: COMMIT in 0.006 seconds
[0m16:49:15.362039 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m16:49:15.369141 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m16:49:15.371171 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m16:49:15.375964 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:49:15.397257 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:15.404524 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:15.411210 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:15.413488 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:49:15.415583 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:49:15.417661 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:49:15.419721 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:15.422371 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:15.425506 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:15.445072 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m16:49:15.448925 [debug] [ThreadPool]: SQL status: BEGIN in 0.029 seconds
[0m16:49:15.450503 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:15.453243 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m16:49:15.456446 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:15.459595 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:49:15.461884 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:15.464221 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:49:15.467752 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:49:15.475253 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.009 seconds
[0m16:49:15.478294 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m16:49:15.480563 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m16:49:15.484033 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:49:15.488426 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:49:15.494853 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:49:15.497877 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:49:15.499965 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:49:15.501934 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:49:15.523674 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:15.526371 [debug] [MainThread]: On master: BEGIN
[0m16:49:15.528871 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:49:15.546135 [debug] [MainThread]: SQL status: BEGIN in 0.017 seconds
[0m16:49:15.549535 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:15.552084 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:49:15.579579 [debug] [MainThread]: SQL status: SELECT 1 in 0.023 seconds
[0m16:49:15.584089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a6b3fb60>]}
[0m16:49:15.586507 [debug] [MainThread]: On master: ROLLBACK
[0m16:49:15.590368 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:15.592925 [debug] [MainThread]: On master: BEGIN
[0m16:49:15.596235 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:49:15.599035 [debug] [MainThread]: On master: COMMIT
[0m16:49:15.601344 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:15.604671 [debug] [MainThread]: On master: COMMIT
[0m16:49:15.608742 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m16:49:15.611601 [debug] [MainThread]: On master: Close
[0m16:49:15.623212 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m16:49:15.625408 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m16:49:15.627926 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m16:49:15.630395 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m16:49:15.632752 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.dim_companies)
[0m16:49:15.635244 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_daily_stock_metrics)
[0m16:49:15.637587 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m16:49:15.641162 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m16:49:15.662680 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m16:49:15.672763 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:15.684028 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m16:49:15.686076 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m16:49:15.920829 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m16:49:15.926815 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:15.942888 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:49:15.944883 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:15.947013 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m16:49:15.950487 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m16:49:15.954023 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:49:15.958313 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:49:15.977470 [debug] [Thread-1 (]: SQL status: BEGIN in 0.023 seconds
[0m16:49:15.981553 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m16:49:15.984059 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:49:15.987309 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:15.992226 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m16:49:15.995908 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m16:49:22.364206 [debug] [Thread-1 (]: SQL status: SELECT 963 in 6.363 seconds
[0m16:49:22.424199 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:49:22.430211 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m16:49:22.435161 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:22.522049 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:49:22.524675 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:49:22.526903 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m16:49:22.533588 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:49:22.562297 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m16:49:22.587544 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m16:49:22.590469 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m16:49:22.594215 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:22.605579 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m16:49:22.614507 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a9b8b350>]}
[0m16:49:22.619897 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 6.98s]
[0m16:49:22.624230 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m16:49:23.197028 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 7.197 seconds
[0m16:49:23.209859 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:23.212329 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m16:49:23.216370 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:23.222706 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m16:49:23.226101 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:23.236977 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m16:49:23.250069 [debug] [Thread-2 (]: SQL status: COMMIT in 0.010 seconds
[0m16:49:23.259114 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m16:49:23.262441 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m16:49:23.265579 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m16:49:23.268841 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:23.273160 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m16:49:23.275680 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a4fc1d4e-334b-4cfd-a22e-b78b273a15af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a49bde80>]}
[0m16:49:23.278899 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 7.64s]
[0m16:49:23.282517 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m16:49:23.290436 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:23.292533 [debug] [MainThread]: On master: BEGIN
[0m16:49:23.294874 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:49:23.314129 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m16:49:23.317443 [debug] [MainThread]: On master: COMMIT
[0m16:49:23.319770 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:23.321710 [debug] [MainThread]: On master: COMMIT
[0m16:49:23.324260 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:49:23.326936 [debug] [MainThread]: On master: Close
[0m16:49:23.329926 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:49:23.333690 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m16:49:23.336748 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m16:49:23.338678 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m16:49:23.341314 [info ] [MainThread]: 
[0m16:49:23.343635 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 8.23 seconds (8.23s).
[0m16:49:23.346961 [debug] [MainThread]: Command end result
[0m16:49:23.489974 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:23.506977 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:23.537137 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:49:23.539768 [info ] [MainThread]: 
[0m16:49:23.542942 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:49:23.545931 [info ] [MainThread]: 
[0m16:49:23.551232 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:49:23.556637 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 11.1446295, "process_in_blocks": "0", "process_kernel_time": 0.566777, "process_mem_max_rss": "121256", "process_out_blocks": "0", "process_user_time": 6.721777}
[0m16:49:23.560561 [debug] [MainThread]: Command `dbt run` succeeded at 16:49:23.559777 after 11.15 seconds
[0m16:49:23.563273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a81a5520>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a7bdfe00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f53a94c2690>]}
[0m16:49:23.567084 [debug] [MainThread]: Flushing usage events
[0m16:49:25.259186 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:49:32.612580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0adc6f12e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0adaccbd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0adacc9520>]}


============================== 16:49:32.626655 | ecf00392-1422-4b73-b88c-7ce7307a89fb ==============================
[0m16:49:32.626655 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:49:32.628810 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m16:49:33.094685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad935ff80>]}
[0m16:49:33.242315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0adad33740>]}
[0m16:49:33.245341 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:49:33.448183 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:49:34.184883 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:49:34.186903 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:49:34.284979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad93d2690>]}
[0m16:49:34.509178 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:34.527077 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:34.576769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad8348050>]}
[0m16:49:34.579414 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:49:34.582000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad93f7ce0>]}
[0m16:49:34.588640 [info ] [MainThread]: 
[0m16:49:34.591756 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:49:34.593950 [info ] [MainThread]: 
[0m16:49:34.596530 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:49:34.607998 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:49:34.678387 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:49:34.680505 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:49:34.682724 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:34.697182 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.014 seconds
[0m16:49:34.700951 [debug] [ThreadPool]: On list_airflow: Close
[0m16:49:34.704308 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m16:49:34.708249 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m16:49:34.729088 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:49:34.731395 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m16:49:34.733727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:34.751137 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:49:34.753630 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:49:34.757088 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m16:49:34.760772 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m16:49:34.763907 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m16:49:34.765999 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m16:49:34.768141 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m16:49:34.774164 [debug] [ThreadPool]: SQL status: COMMIT in 0.004 seconds
[0m16:49:34.776625 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m16:49:34.782313 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_analytics)
[0m16:49:34.783739 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:49:34.785168 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m16:49:34.800441 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:34.805722 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:34.811467 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:34.813799 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:49:34.815555 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:49:34.817765 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:49:34.819537 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:49:34.821410 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:34.824435 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:49:34.840309 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m16:49:34.842346 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m16:49:34.844182 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m16:49:34.845912 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:49:34.847858 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:49:34.849880 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:49:34.851952 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:49:34.854122 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:49:34.857199 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:49:34.863847 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m16:49:34.867402 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:49:34.868435 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m16:49:34.869337 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m16:49:34.871096 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:49:34.875231 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:49:34.878711 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:49:34.882758 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:49:34.884162 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:49:34.898981 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:34.900827 [debug] [MainThread]: On master: BEGIN
[0m16:49:34.902411 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:49:34.914598 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m16:49:34.917125 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:34.919345 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:49:34.932894 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m16:49:34.936840 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad72f0350>]}
[0m16:49:34.939244 [debug] [MainThread]: On master: ROLLBACK
[0m16:49:34.941435 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:34.943637 [debug] [MainThread]: On master: BEGIN
[0m16:49:34.946247 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:49:34.948998 [debug] [MainThread]: On master: COMMIT
[0m16:49:34.951581 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:34.954015 [debug] [MainThread]: On master: COMMIT
[0m16:49:34.956539 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:49:34.958456 [debug] [MainThread]: On master: Close
[0m16:49:34.969033 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m16:49:34.970553 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m16:49:34.971764 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m16:49:34.973061 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m16:49:34.974983 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m16:49:34.978010 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m16:49:34.981024 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m16:49:34.983925 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m16:49:34.986617 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m16:49:34.989745 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_daily)
[0m16:49:34.992379 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m16:49:34.995005 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m16:49:34.997332 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m16:49:34.999804 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m16:49:35.001944 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m16:49:35.005056 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m16:49:35.035337 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m16:49:35.041067 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m16:49:35.050881 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m16:49:35.062366 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m16:49:35.073604 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m16:49:35.075692 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m16:49:35.078425 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m16:49:35.086264 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m16:49:35.345889 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m16:49:35.362258 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m16:49:35.363968 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m16:49:35.367122 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m16:49:35.378022 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:49:35.380771 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:49:35.382256 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:49:35.384067 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m16:49:35.386286 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:49:35.389877 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m16:49:35.393094 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m16:49:35.396460 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m16:49:35.399247 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m16:49:35.401498 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:49:35.403509 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:49:35.408022 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:49:35.426187 [debug] [Thread-4 (]: SQL status: BEGIN in 0.030 seconds
[0m16:49:35.430025 [debug] [Thread-2 (]: SQL status: BEGIN in 0.028 seconds
[0m16:49:35.432287 [debug] [Thread-1 (]: SQL status: BEGIN in 0.028 seconds
[0m16:49:35.434209 [debug] [Thread-3 (]: SQL status: BEGIN in 0.026 seconds
[0m16:49:35.435423 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:49:35.437775 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:49:35.440032 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:49:35.442735 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:49:35.445496 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m16:49:35.449335 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m16:49:35.452363 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m16:49:35.455130 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m16:49:35.734455 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.275 seconds
[0m16:49:35.772735 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:49:35.775006 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m16:49:35.778045 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:35.831515 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:49:35.834057 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:49:35.836104 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m16:49:35.845635 [debug] [Thread-2 (]: SQL status: COMMIT in 0.007 seconds
[0m16:49:35.862280 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m16:49:35.876702 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m16:49:35.879359 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m16:49:35.882624 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:35.891457 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m16:49:35.897196 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad73b6780>]}
[0m16:49:35.900366 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.90s]
[0m16:49:35.903608 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m16:49:35.906269 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m16:49:35.909694 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m16:49:35.912289 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m16:49:35.914235 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m16:49:35.925642 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m16:49:35.940848 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m16:49:35.952710 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m16:49:35.970834 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:49:35.973960 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m16:49:35.976401 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:49:35.994446 [debug] [Thread-2 (]: SQL status: BEGIN in 0.018 seconds
[0m16:49:35.998097 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:49:36.001434 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m16:49:42.417772 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 6.958 seconds
[0m16:49:42.426717 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:49:42.428914 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m16:49:42.431785 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:42.436022 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:49:42.438184 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:49:42.440436 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m16:49:42.446919 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:49:42.453628 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m16:49:42.456374 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m16:49:42.458687 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m16:49:42.461640 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:49:42.466334 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m16:49:42.469129 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad71e59d0>]}
[0m16:49:42.471995 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 7.48s]
[0m16:49:42.474759 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m16:49:42.477041 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m16:49:42.479887 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m16:49:42.482449 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m16:49:42.484875 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m16:49:42.495094 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m16:49:42.512673 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m16:49:42.521069 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m16:49:42.541875 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:49:42.544624 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m16:49:42.547345 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:49:42.567441 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m16:49:42.570660 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:49:42.573628 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m16:49:43.325695 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.864 seconds
[0m16:49:43.334673 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:49:43.336819 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m16:49:43.339339 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:43.343384 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:49:43.345280 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:49:43.347008 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m16:49:43.353735 [debug] [Thread-3 (]: SQL status: COMMIT in 0.004 seconds
[0m16:49:43.359674 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m16:49:43.361889 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m16:49:43.363832 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m16:49:43.366494 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:49:43.370536 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m16:49:43.374161 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ab7f4bc80>]}
[0m16:49:43.377105 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 8.38s]
[0m16:49:43.379902 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m16:49:43.382396 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m16:49:43.384754 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m16:49:43.387023 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m16:49:43.388911 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m16:49:43.398223 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m16:49:43.414047 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m16:49:43.425316 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m16:49:43.441861 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:49:43.444163 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m16:49:43.446870 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:49:43.463287 [debug] [Thread-3 (]: SQL status: BEGIN in 0.016 seconds
[0m16:49:43.466324 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:49:43.469645 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m16:49:44.242014 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.784 seconds
[0m16:49:44.254500 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:49:44.257167 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m16:49:44.261512 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:44.268778 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:49:44.271543 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:49:44.274645 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m16:49:44.325734 [debug] [Thread-4 (]: SQL status: COMMIT in 0.048 seconds
[0m16:49:44.327585 [debug] [Thread-3 (]: SQL status: SELECT 18321 in 0.854 seconds
[0m16:49:44.337847 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m16:49:44.350620 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:49:44.353478 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m16:49:44.356399 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m16:49:44.358786 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m16:49:44.362433 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:44.366743 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:44.371947 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:49:44.376957 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m16:49:44.379218 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:49:44.384470 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ada136420>]}
[0m16:49:44.388814 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m16:49:44.392022 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 9.39s]
[0m16:49:44.396505 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m16:49:44.399591 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m16:49:44.409927 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m16:49:44.413846 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m16:49:44.418308 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m16:49:44.421992 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:44.427757 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m16:49:44.431272 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ad71bda00>]}
[0m16:49:44.436511 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 18321[0m in 1.04s]
[0m16:49:44.440514 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m16:49:47.803095 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 11.797 seconds
[0m16:49:47.821612 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:49:47.823959 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m16:49:47.827084 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:47.833593 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:49:47.836072 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:49:47.838488 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m16:49:47.843564 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m16:49:47.859344 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m16:49:47.864017 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m16:49:47.868330 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m16:49:47.872207 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:47.880780 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m16:49:47.885231 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ab7f93c20>]}
[0m16:49:47.890212 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 11.97s]
[0m16:49:47.894002 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m16:49:54.396477 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 11.820 seconds
[0m16:49:54.404222 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:49:54.407136 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m16:49:54.411144 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:49:54.415129 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:49:54.417309 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:49:54.419336 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m16:49:54.427053 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m16:49:54.433707 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m16:49:54.436552 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m16:49:54.439524 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m16:49:54.443090 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:49:54.447407 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m16:49:54.449851 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ecf00392-1422-4b73-b88c-7ce7307a89fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ab7f3fdd0>]}
[0m16:49:54.452512 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 11.97s]
[0m16:49:54.455358 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m16:49:54.463844 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:54.465849 [debug] [MainThread]: On master: BEGIN
[0m16:49:54.467998 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:49:54.482849 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m16:49:54.485625 [debug] [MainThread]: On master: COMMIT
[0m16:49:54.487860 [debug] [MainThread]: Using postgres connection "master"
[0m16:49:54.491269 [debug] [MainThread]: On master: COMMIT
[0m16:49:54.494314 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:49:54.496573 [debug] [MainThread]: On master: Close
[0m16:49:54.498913 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:49:54.500962 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m16:49:54.502655 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m16:49:54.504579 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m16:49:54.507704 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m16:49:54.510119 [info ] [MainThread]: 
[0m16:49:54.513032 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 19.91 seconds (19.91s).
[0m16:49:54.518042 [debug] [MainThread]: Command end result
[0m16:49:54.613216 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:49:54.623909 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:49:54.646535 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:49:54.648561 [info ] [MainThread]: 
[0m16:49:54.650827 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:49:54.652933 [info ] [MainThread]: 
[0m16:49:54.655434 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m16:49:54.659502 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 22.15655, "process_in_blocks": "0", "process_kernel_time": 0.596191, "process_mem_max_rss": "122892", "process_out_blocks": "0", "process_user_time": 7.053247}
[0m16:49:54.662365 [debug] [MainThread]: Command `dbt run` succeeded at 16:49:54.662097 after 22.16 seconds
[0m16:49:54.664587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ada3cec30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ada2b4770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ada0e7f80>]}
[0m16:49:54.666698 [debug] [MainThread]: Flushing usage events
[0m16:49:55.988464 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:50:00.752123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976b4b440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976b494f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976b4ad20>]}


============================== 16:50:00.768985 | b784fe23-a4b1-42e0-a3b1-2c0379920dd0 ==============================
[0m16:50:00.768985 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:50:00.771391 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'log_format': 'default', 'static_parser': 'True', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:50:01.386869 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976507200>]}
[0m16:50:01.531821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f597725b080>]}
[0m16:50:01.535347 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:50:01.779482 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:50:02.606808 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:02.609083 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:02.733528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5975bc0860>]}
[0m16:50:02.953537 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:50:02.969995 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:50:03.047240 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5974729100>]}
[0m16:50:03.049739 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:50:03.051852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5975bc0440>]}
[0m16:50:03.058075 [info ] [MainThread]: 
[0m16:50:03.060413 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:50:03.062585 [info ] [MainThread]: 
[0m16:50:03.065145 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:50:03.075908 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m16:50:03.077212 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m16:50:03.078558 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m16:50:03.162933 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:50:03.164182 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:50:03.165121 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:50:03.166641 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:50:03.168677 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:50:03.170599 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:50:03.172412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:03.174305 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:03.176206 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:03.194620 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m16:50:03.197493 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:50:03.200028 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m16:50:03.201907 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m16:50:03.203005 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:50:03.205262 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:50:03.207042 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:50:03.210366 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:50:03.212678 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:50:03.215109 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m16:50:03.221820 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:50:03.223271 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.008 seconds
[0m16:50:03.225033 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.008 seconds
[0m16:50:03.227486 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:50:03.232861 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:50:03.237732 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:50:03.243793 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:50:03.246198 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:50:03.277062 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.279180 [debug] [MainThread]: On master: BEGIN
[0m16:50:03.281721 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:50:03.296684 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m16:50:03.302649 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.305331 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:50:03.325263 [debug] [MainThread]: SQL status: SELECT 1 in 0.017 seconds
[0m16:50:03.329050 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b784fe23-a4b1-42e0-a3b1-2c0379920dd0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f597279bc80>]}
[0m16:50:03.331684 [debug] [MainThread]: On master: ROLLBACK
[0m16:50:03.334662 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.336916 [debug] [MainThread]: On master: BEGIN
[0m16:50:03.339317 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:50:03.342068 [debug] [MainThread]: On master: COMMIT
[0m16:50:03.343803 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.345763 [debug] [MainThread]: On master: COMMIT
[0m16:50:03.348361 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:50:03.351224 [debug] [MainThread]: On master: Close
[0m16:50:03.360261 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:50:03.361380 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:50:03.362976 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m16:50:03.366280 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m16:50:03.368827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m16:50:03.371163 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m16:50:03.373086 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:50:03.375181 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:50:03.470938 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:50:03.473138 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:50:03.493623 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:50:03.495460 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:50:03.560561 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:50:03.568972 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:50:03.578382 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:50:03.580222 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:50:03.582652 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m16:50:03.585397 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m16:50:03.587723 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:50:03.590232 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:50:03.604505 [debug] [Thread-2 (]: SQL status: BEGIN in 0.017 seconds
[0m16:50:03.607167 [debug] [Thread-1 (]: SQL status: BEGIN in 0.017 seconds
[0m16:50:03.608848 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m16:50:03.611075 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m16:50:03.613307 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m16:50:03.616039 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m16:50:03.620925 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m16:50:03.621986 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.004 seconds
[0m16:50:03.631433 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m16:50:03.635303 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m16:50:03.637854 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m16:50:03.640440 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m16:50:03.643074 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.27s]
[0m16:50:03.645564 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.27s]
[0m16:50:03.648671 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m16:50:03.651292 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m16:50:03.656901 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.658872 [debug] [MainThread]: On master: BEGIN
[0m16:50:03.660482 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:50:03.673938 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m16:50:03.677460 [debug] [MainThread]: On master: COMMIT
[0m16:50:03.679746 [debug] [MainThread]: Using postgres connection "master"
[0m16:50:03.682059 [debug] [MainThread]: On master: COMMIT
[0m16:50:03.684709 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:50:03.687226 [debug] [MainThread]: On master: Close
[0m16:50:03.690397 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:50:03.692688 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m16:50:03.694835 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m16:50:03.696591 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m16:50:03.699194 [info ] [MainThread]: 
[0m16:50:03.701545 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m16:50:03.706770 [debug] [MainThread]: Command end result
[0m16:50:03.797326 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:50:03.808774 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:50:03.834348 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:50:03.836779 [info ] [MainThread]: 
[0m16:50:03.839232 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:50:03.841354 [info ] [MainThread]: 
[0m16:50:03.843430 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m16:50:03.846837 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 3.2381835, "process_in_blocks": "1120", "process_kernel_time": 0.34027, "process_mem_max_rss": "122104", "process_out_blocks": "0", "process_user_time": 5.344255}
[0m16:50:03.849895 [debug] [MainThread]: Command `dbt test` succeeded at 16:50:03.849494 after 3.24 seconds
[0m16:50:03.852870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976a2b380>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5976cf85c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5974b2bfb0>]}
[0m16:50:03.856006 [debug] [MainThread]: Flushing usage events
[0m16:50:04.956256 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:52:24.090772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f44308116d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442e997020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442ecd4500>]}


============================== 16:52:24.116276 | 6850dcd1-9448-46ae-98e5-88365accf7d4 ==============================
[0m16:52:24.116276 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:52:24.120670 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m16:52:25.100282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442d9347a0>]}
[0m16:52:25.393521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442e610110>]}
[0m16:52:25.413112 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:52:25.777137 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:52:27.196053 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:52:27.203202 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:52:27.422707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442d9c6db0>]}
[0m16:52:27.969908 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:52:28.050782 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:52:28.227115 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442c92c440>]}
[0m16:52:28.231815 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:52:28.235284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442d989fa0>]}
[0m16:52:28.250292 [info ] [MainThread]: 
[0m16:52:28.254270 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:52:28.264119 [info ] [MainThread]: 
[0m16:52:28.282325 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:52:28.307028 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:52:28.327674 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:52:28.339053 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:52:28.472992 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:52:28.474596 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:52:28.475944 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:52:28.478085 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:52:28.481143 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:52:28.483937 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:52:28.486711 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:52:28.490311 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:52:28.493184 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:52:28.520523 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.034 seconds
[0m16:52:28.528626 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.038 seconds
[0m16:52:28.536347 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.043 seconds
[0m16:52:28.533727 [debug] [ThreadPool]: On list_airflow: Close
[0m16:52:28.550561 [debug] [ThreadPool]: On list_airflow: Close
[0m16:52:28.557902 [debug] [ThreadPool]: On list_airflow: Close
[0m16:52:28.577066 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m16:52:28.579746 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m16:52:28.582287 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m16:52:28.606590 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:52:28.612672 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:52:28.622642 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:52:28.625503 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:52:28.628117 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:52:28.635232 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:52:28.637997 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:52:28.640351 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:52:28.642479 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:52:28.660613 [debug] [ThreadPool]: SQL status: BEGIN in 0.020 seconds
[0m16:52:28.666999 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:52:28.670018 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:52:28.673253 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m16:52:28.675994 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m16:52:28.684891 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:52:28.681340 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:52:28.686525 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.011 seconds
[0m16:52:28.688965 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:52:28.692178 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:52:28.698621 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:52:28.704709 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:52:28.712420 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.010 seconds
[0m16:52:28.714183 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.011 seconds
[0m16:52:28.720031 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:52:28.726789 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:52:28.730618 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:52:28.734021 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:52:28.762755 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:28.766668 [debug] [MainThread]: On master: BEGIN
[0m16:52:28.770342 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:52:28.791605 [debug] [MainThread]: SQL status: BEGIN in 0.021 seconds
[0m16:52:28.797491 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:28.803586 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:52:28.830322 [debug] [MainThread]: SQL status: SELECT 1 in 0.023 seconds
[0m16:52:28.839008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442c9120c0>]}
[0m16:52:28.841592 [debug] [MainThread]: On master: ROLLBACK
[0m16:52:28.844783 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:28.849271 [debug] [MainThread]: On master: BEGIN
[0m16:52:28.853696 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:52:28.856824 [debug] [MainThread]: On master: COMMIT
[0m16:52:28.858877 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:28.861279 [debug] [MainThread]: On master: COMMIT
[0m16:52:28.866251 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:52:28.869339 [debug] [MainThread]: On master: Close
[0m16:52:28.885850 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m16:52:28.888856 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m16:52:28.891582 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m16:52:28.893626 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m16:52:28.922303 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m16:52:28.936685 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m16:52:29.080007 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m16:52:29.094919 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:52:29.098519 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m16:52:29.104990 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:52:29.131554 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m16:52:29.134916 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:52:29.137902 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m16:52:29.147168 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.006 seconds
[0m16:52:29.171325 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:52:29.173879 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m16:52:29.176661 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:52:29.238682 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m16:52:29.242727 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:52:29.250762 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m16:52:29.259716 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m16:52:29.288617 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m16:52:29.320184 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:52:29.322805 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m16:52:29.325835 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m16:52:29.336300 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m16:52:29.345701 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443087cec0>]}
[0m16:52:29.352334 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.45s]
[0m16:52:29.356118 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m16:52:29.360342 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m16:52:29.364639 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m16:52:29.368239 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m16:52:29.371417 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m16:52:29.390766 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m16:52:29.414737 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m16:52:29.504586 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m16:52:29.530565 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:52:29.534097 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m16:52:29.536962 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:52:29.560396 [debug] [Thread-3 (]: SQL status: BEGIN in 0.023 seconds
[0m16:52:29.564564 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:52:29.568098 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m16:52:29.592722 [debug] [Thread-3 (]: SQL status: SELECT 0 in 0.021 seconds
[0m16:52:29.616235 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:52:29.618864 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m16:52:29.621865 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:52:29.625900 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m16:52:29.628192 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:52:29.631251 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m16:52:29.640049 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m16:52:29.650732 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m16:52:29.660222 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:52:29.664848 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m16:52:29.669069 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:52:29.675524 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m16:52:29.679171 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442cde7fe0>]}
[0m16:52:29.686154 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 0[0m in 0.31s]
[0m16:52:29.689512 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m16:52:29.692840 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m16:52:29.694182 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m16:52:29.698119 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m16:52:29.701732 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m16:52:29.704642 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m16:52:29.707516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m16:52:29.709939 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m16:52:29.714077 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m16:52:29.725693 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.739541 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m16:52:29.751776 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m16:52:29.754123 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m16:52:29.766036 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.779842 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m16:52:29.790262 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:52:29.793599 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m16:52:29.795508 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.798223 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:52:29.801105 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m16:52:29.806353 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:52:29.822361 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m16:52:29.827081 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:52:29.831820 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m16:52:29.835146 [debug] [Thread-2 (]: SQL status: BEGIN in 0.029 seconds
[0m16:52:29.838447 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.841592 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m16:52:29.864230 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.019 seconds
[0m16:52:29.876978 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.880421 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m16:52:29.883463 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:52:29.888519 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m16:52:29.891037 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.893648 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m16:52:29.901936 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m16:52:29.915723 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m16:52:29.920236 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:52:29.922556 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m16:52:29.925834 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m16:52:29.931922 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m16:52:29.935955 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442a775130>]}
[0m16:52:29.940806 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.23s]
[0m16:52:29.951959 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m16:52:37.861768 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 8.025 seconds
[0m16:52:37.883454 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:52:37.886487 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m16:52:37.891462 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:52:37.896116 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m16:52:37.898730 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:52:37.901079 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m16:52:37.908004 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m16:52:37.919275 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m16:52:37.923074 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:52:37.925478 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m16:52:37.928289 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m16:52:37.934304 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m16:52:37.937296 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6850dcd1-9448-46ae-98e5-88365accf7d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4428625820>]}
[0m16:52:37.940487 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 8.23s]
[0m16:52:37.944614 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m16:52:37.950387 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:37.952989 [debug] [MainThread]: On master: BEGIN
[0m16:52:37.955990 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:52:37.979744 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m16:52:37.982994 [debug] [MainThread]: On master: COMMIT
[0m16:52:37.985650 [debug] [MainThread]: Using postgres connection "master"
[0m16:52:37.988008 [debug] [MainThread]: On master: COMMIT
[0m16:52:37.991083 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:52:37.993476 [debug] [MainThread]: On master: Close
[0m16:52:37.995968 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:52:37.998671 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m16:52:38.001304 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m16:52:38.003525 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m16:52:38.006172 [info ] [MainThread]: 
[0m16:52:38.008978 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 9.72 seconds (9.72s).
[0m16:52:38.018845 [debug] [MainThread]: Command end result
[0m16:52:38.205234 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:52:38.224937 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:52:38.267881 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:52:38.270688 [info ] [MainThread]: 
[0m16:52:38.275451 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:52:38.278785 [info ] [MainThread]: 
[0m16:52:38.281965 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:52:38.286576 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.486829, "process_in_blocks": "0", "process_kernel_time": 1.00284, "process_mem_max_rss": "121708", "process_out_blocks": "0", "process_user_time": 10.940987}
[0m16:52:38.291620 [debug] [MainThread]: Command `dbt run` succeeded at 16:52:38.291077 after 14.49 seconds
[0m16:52:38.295032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f443236f260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442c9f4530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f442a8d83b0>]}
[0m16:52:38.298364 [debug] [MainThread]: Flushing usage events
[0m16:52:39.676272 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m16:57:57.190334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cee201d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cec66b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cec66900>]}


============================== 16:57:57.203180 | 385712e7-a6b9-4f72-a7de-2b9f7d101c00 ==============================
[0m16:57:57.203180 [info ] [MainThread]: Running with dbt=1.9.4
[0m16:57:57.205259 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m16:57:57.540927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48d090b860>]}
[0m16:57:57.647512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cf9c31a0>]}
[0m16:57:57.650406 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m16:57:57.823289 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m16:57:58.418217 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:57:58.420176 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:57:58.511455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ce134890>]}
[0m16:57:58.700774 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:57:58.715399 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:57:58.778744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cd1460c0>]}
[0m16:57:58.782559 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m16:57:58.787210 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ce8063c0>]}
[0m16:57:58.799131 [info ] [MainThread]: 
[0m16:57:58.801161 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m16:57:58.802979 [info ] [MainThread]: 
[0m16:57:58.806110 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m16:57:58.816539 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:57:58.817896 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:57:58.819205 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m16:57:58.906440 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:57:58.907638 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:57:58.908859 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m16:57:58.910734 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:57:58.912685 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:57:58.914868 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m16:57:58.916912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:58.918742 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:58.920597 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:57:58.934881 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m16:57:58.938768 [debug] [ThreadPool]: On list_airflow: Close
[0m16:57:58.941719 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.023 seconds
[0m16:57:58.942796 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.022 seconds
[0m16:57:58.946214 [debug] [ThreadPool]: On list_airflow: Close
[0m16:57:58.949809 [debug] [ThreadPool]: On list_airflow: Close
[0m16:57:58.957048 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m16:57:58.958783 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m16:57:58.960335 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m16:57:58.971984 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:57:58.977164 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:57:58.982075 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:57:58.984156 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m16:57:58.986395 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m16:57:58.988335 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m16:57:58.990413 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:57:58.993025 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:57:58.995107 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m16:57:59.007291 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:57:59.010186 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m16:57:59.011636 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m16:57:59.013289 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m16:57:59.015339 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m16:57:59.017396 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m16:57:59.019543 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m16:57:59.021723 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m16:57:59.025007 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m16:57:59.029233 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m16:57:59.034629 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m16:57:59.035548 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.008 seconds
[0m16:57:59.036385 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.008 seconds
[0m16:57:59.038273 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m16:57:59.042758 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m16:57:59.047147 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m16:57:59.052118 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m16:57:59.054119 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m16:57:59.070832 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:59.072996 [debug] [MainThread]: On master: BEGIN
[0m16:57:59.074973 [debug] [MainThread]: Opening a new connection, currently in state init
[0m16:57:59.087450 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m16:57:59.089820 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:59.092643 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m16:57:59.105349 [debug] [MainThread]: SQL status: SELECT 2 in 0.010 seconds
[0m16:57:59.109602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ce82aa20>]}
[0m16:57:59.111943 [debug] [MainThread]: On master: ROLLBACK
[0m16:57:59.114245 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:59.116176 [debug] [MainThread]: On master: BEGIN
[0m16:57:59.118657 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m16:57:59.120926 [debug] [MainThread]: On master: COMMIT
[0m16:57:59.122774 [debug] [MainThread]: Using postgres connection "master"
[0m16:57:59.124777 [debug] [MainThread]: On master: COMMIT
[0m16:57:59.127668 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:57:59.129709 [debug] [MainThread]: On master: Close
[0m16:57:59.137949 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m16:57:59.140484 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m16:57:59.143196 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m16:57:59.145722 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m16:57:59.160625 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m16:57:59.173855 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m16:57:59.241592 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m16:57:59.254768 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.256685 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m16:57:59.259205 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:57:59.270742 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m16:57:59.273139 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.275560 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m16:57:59.280722 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m16:57:59.292895 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.295217 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m16:57:59.297855 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:57:59.304278 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.306429 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m16:57:59.309878 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:57:59.340491 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m16:57:59.343003 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.345125 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m16:57:59.351273 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m16:57:59.365257 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m16:57:59.375053 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m16:57:59.377419 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m16:57:59.385303 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m16:57:59.390594 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m16:57:59.395197 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cf390680>]}
[0m16:57:59.397763 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.25s]
[0m16:57:59.400078 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m16:57:59.402992 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m16:57:59.405211 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m16:57:59.407578 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m16:57:59.410328 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m16:57:59.417357 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m16:57:59.432098 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m16:57:59.470739 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m16:57:59.486968 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:57:59.488956 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m16:57:59.490948 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m16:57:59.502197 [debug] [Thread-3 (]: SQL status: BEGIN in 0.011 seconds
[0m16:57:59.504630 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:57:59.507116 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m16:58:00.039150 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.529 seconds
[0m16:58:00.051306 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:58:00.053406 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m16:58:00.055906 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:58:00.062507 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:58:00.064616 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m16:58:00.067016 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:58:00.070437 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m16:58:00.072400 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:58:00.074775 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m16:58:00.084644 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m16:58:00.090420 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m16:58:00.096386 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m16:58:00.098579 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m16:58:00.106681 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m16:58:00.110582 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m16:58:00.112908 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48ca9ae510>]}
[0m16:58:00.115171 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.71s]
[0m16:58:00.117556 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m16:58:00.120155 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m16:58:00.121258 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m16:58:00.123466 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m16:58:00.126146 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m16:58:00.128351 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m16:58:00.130308 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m16:58:00.132387 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m16:58:00.134209 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m16:58:00.140918 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.149320 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m16:58:00.159611 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m16:58:00.160919 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m16:58:00.166886 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.173285 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m16:58:00.184174 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.185864 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:00.187139 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m16:58:00.189203 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m16:58:00.191792 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m16:58:00.194109 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m16:58:00.205901 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m16:58:00.208570 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m16:58:00.210313 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.212186 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:00.214525 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m16:58:00.217140 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m16:58:00.233907 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.014 seconds
[0m16:58:00.244207 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.246853 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m16:58:00.249742 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:58:00.256500 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.259132 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m16:58:00.261710 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m16:58:00.266014 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m16:58:00.268336 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.270557 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m16:58:00.282706 [debug] [Thread-2 (]: SQL status: COMMIT in 0.010 seconds
[0m16:58:00.292082 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m16:58:00.295294 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m16:58:00.297783 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m16:58:00.307259 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.007 seconds
[0m16:58:00.311830 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m16:58:00.314457 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48c884fe90>]}
[0m16:58:00.316968 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 1[0m in 0.19s]
[0m16:58:00.319734 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m16:58:04.184352 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 3.964 seconds
[0m16:58:04.192079 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:04.194175 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m16:58:04.197060 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:58:04.203474 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:04.205593 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m16:58:04.208047 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m16:58:04.211671 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m16:58:04.213562 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:04.215278 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m16:58:04.235237 [debug] [Thread-1 (]: SQL status: COMMIT in 0.018 seconds
[0m16:58:04.241566 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m16:58:04.244234 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m16:58:04.246422 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m16:58:04.253414 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.005 seconds
[0m16:58:04.257798 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m16:58:04.260415 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '385712e7-a6b9-4f72-a7de-2b9f7d101c00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48c8863bc0>]}
[0m16:58:04.263049 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 4.13s]
[0m16:58:04.265585 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m16:58:04.270010 [debug] [MainThread]: Using postgres connection "master"
[0m16:58:04.272379 [debug] [MainThread]: On master: BEGIN
[0m16:58:04.274298 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m16:58:04.285882 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m16:58:04.288968 [debug] [MainThread]: On master: COMMIT
[0m16:58:04.291136 [debug] [MainThread]: Using postgres connection "master"
[0m16:58:04.293158 [debug] [MainThread]: On master: COMMIT
[0m16:58:04.295355 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m16:58:04.297343 [debug] [MainThread]: On master: Close
[0m16:58:04.299457 [debug] [MainThread]: Connection 'master' was properly closed.
[0m16:58:04.301446 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m16:58:04.303427 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m16:58:04.305804 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m16:58:04.307901 [info ] [MainThread]: 
[0m16:58:04.309807 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 5.50 seconds (5.50s).
[0m16:58:04.313146 [debug] [MainThread]: Command end result
[0m16:58:04.396430 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m16:58:04.406354 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m16:58:04.425228 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m16:58:04.427112 [info ] [MainThread]: 
[0m16:58:04.429023 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:58:04.430857 [info ] [MainThread]: 
[0m16:58:04.432690 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m16:58:04.435735 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.3455353, "process_in_blocks": "0", "process_kernel_time": 0.379189, "process_mem_max_rss": "121824", "process_out_blocks": "0", "process_user_time": 4.660035}
[0m16:58:04.438739 [debug] [MainThread]: Command `dbt run` succeeded at 16:58:04.438473 after 7.35 seconds
[0m16:58:04.440806 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cf527140>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cf393470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48cef816a0>]}
[0m16:58:04.442680 [debug] [MainThread]: Flushing usage events
[0m16:58:05.774212 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m18:26:12.781502 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811b5aae0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc812f9fc80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811b5ac00>]}


============================== 18:26:12.796120 | 8a52d4e9-42fd-4f43-bd5c-5ebe5d322487 ==============================
[0m18:26:12.796120 [info ] [MainThread]: Running with dbt=1.9.4
[0m18:26:12.799053 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'send_anonymous_usage_stats': 'True'}
[0m18:26:13.176255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811613500>]}
[0m18:26:13.281049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811611b20>]}
[0m18:26:13.283833 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m18:26:13.471262 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m18:26:14.135390 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m18:26:14.137373 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m18:26:14.224700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8107c8da0>]}
[0m18:26:14.414358 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m18:26:14.430216 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m18:26:14.476096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80f712750>]}
[0m18:26:14.478166 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m18:26:14.480821 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8107cbce0>]}
[0m18:26:14.486100 [info ] [MainThread]: 
[0m18:26:14.488001 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m18:26:14.489809 [info ] [MainThread]: 
[0m18:26:14.491882 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m18:26:14.501443 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m18:26:14.502654 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m18:26:14.503703 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m18:26:14.589054 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m18:26:14.589885 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m18:26:14.590591 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m18:26:14.592022 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m18:26:14.593735 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m18:26:14.595616 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m18:26:14.597959 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:26:14.599784 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:26:14.601654 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m18:26:14.614808 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.015 seconds
[0m18:26:14.615645 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m18:26:14.618892 [debug] [ThreadPool]: On list_airflow: Close
[0m18:26:14.619731 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.018 seconds
[0m18:26:14.622620 [debug] [ThreadPool]: On list_airflow: Close
[0m18:26:14.627097 [debug] [ThreadPool]: On list_airflow: Close
[0m18:26:14.634477 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m18:26:14.635616 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m18:26:14.636631 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m18:26:14.647224 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m18:26:14.651495 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m18:26:14.655709 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m18:26:14.657564 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m18:26:14.659349 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m18:26:14.661050 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m18:26:14.662999 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:26:14.665166 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:26:14.667245 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m18:26:14.684678 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m18:26:14.686112 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m18:26:14.688220 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m18:26:14.689520 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m18:26:14.691918 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m18:26:14.694083 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m18:26:14.696576 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m18:26:14.699378 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m18:26:14.702329 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m18:26:14.712106 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m18:26:14.713553 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m18:26:14.714833 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.010 seconds
[0m18:26:14.718365 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m18:26:14.722361 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m18:26:14.726024 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m18:26:14.729637 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m18:26:14.731992 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m18:26:14.734521 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m18:26:14.756175 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:14.758392 [debug] [MainThread]: On master: BEGIN
[0m18:26:14.760644 [debug] [MainThread]: Opening a new connection, currently in state init
[0m18:26:14.773065 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m18:26:14.776157 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:14.778529 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m18:26:14.792605 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m18:26:14.796829 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8114e6ff0>]}
[0m18:26:14.799229 [debug] [MainThread]: On master: ROLLBACK
[0m18:26:14.801542 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:14.803323 [debug] [MainThread]: On master: BEGIN
[0m18:26:14.805861 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m18:26:14.808128 [debug] [MainThread]: On master: COMMIT
[0m18:26:14.809961 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:14.812039 [debug] [MainThread]: On master: COMMIT
[0m18:26:14.814907 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m18:26:14.817110 [debug] [MainThread]: On master: Close
[0m18:26:14.826358 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m18:26:14.829158 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m18:26:14.831893 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m18:26:14.833962 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m18:26:14.849477 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m18:26:14.865562 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m18:26:14.931210 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m18:26:14.946256 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:14.948402 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m18:26:14.950484 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:26:14.962485 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m18:26:14.965350 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:14.967378 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m18:26:14.978640 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m18:26:14.990691 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:14.992735 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m18:26:14.996399 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:15.002999 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:15.004901 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m18:26:15.007387 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:15.037232 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m18:26:15.039317 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:15.041092 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m18:26:15.050005 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m18:26:15.064163 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m18:26:15.073515 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m18:26:15.075682 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m18:26:15.086281 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.009 seconds
[0m18:26:15.091371 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m18:26:15.095371 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc8120b0da0>]}
[0m18:26:15.098467 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.26s]
[0m18:26:15.100757 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m18:26:15.103483 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m18:26:15.105636 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m18:26:15.107611 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m18:26:15.109393 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m18:26:15.116264 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m18:26:15.129092 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m18:26:15.167320 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m18:26:15.181602 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:15.183241 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m18:26:15.184849 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m18:26:15.195461 [debug] [Thread-3 (]: SQL status: BEGIN in 0.010 seconds
[0m18:26:15.198294 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:15.200274 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m18:26:16.448681 [debug] [Thread-3 (]: SQL status: SELECT 2 in 1.246 seconds
[0m18:26:16.460142 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:16.462742 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m18:26:16.465292 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:16.472507 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:16.474519 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m18:26:16.476943 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:16.481192 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m18:26:16.483254 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:16.485191 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m18:26:16.493898 [debug] [Thread-3 (]: SQL status: COMMIT in 0.007 seconds
[0m18:26:16.499662 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m18:26:16.505393 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m18:26:16.507356 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m18:26:16.512931 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.004 seconds
[0m18:26:16.517279 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m18:26:16.519339 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80d56ed50>]}
[0m18:26:16.521601 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 2[0m in 1.41s]
[0m18:26:16.523837 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m18:26:16.526510 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m18:26:16.527485 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m18:26:16.529951 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m18:26:16.532256 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m18:26:16.534362 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m18:26:16.536148 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m18:26:16.537990 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m18:26:16.539715 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m18:26:16.546268 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.553953 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m18:26:16.561414 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m18:26:16.568349 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.569236 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m18:26:16.576796 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m18:26:16.584630 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.586508 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:16.587829 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m18:26:16.589693 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m18:26:16.591527 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m18:26:16.593387 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m18:26:16.606011 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m18:26:16.608061 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m18:26:16.609491 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.612114 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:16.615222 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m18:26:16.618007 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m18:26:16.636325 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.016 seconds
[0m18:26:16.645934 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.647894 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m18:26:16.650344 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:16.656242 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.658258 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m18:26:16.661865 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:16.666299 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m18:26:16.668129 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.669831 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m18:26:16.676840 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m18:26:16.685990 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m18:26:16.688907 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m18:26:16.691071 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m18:26:16.700019 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.007 seconds
[0m18:26:16.703760 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m18:26:16.706189 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c429fa0>]}
[0m18:26:16.709031 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 1[0m in 0.17s]
[0m18:26:16.711881 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m18:26:21.620160 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 4.998 seconds
[0m18:26:21.629955 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:21.632099 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard" rename to "stock_prediction_dashboard__dbt_backup"
[0m18:26:21.635115 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:21.642984 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:21.645387 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m18:26:21.647853 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m18:26:21.651996 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m18:26:21.653984 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:21.656076 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m18:26:21.698234 [debug] [Thread-1 (]: SQL status: COMMIT in 0.040 seconds
[0m18:26:21.704385 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m18:26:21.707177 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m18:26:21.709621 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m18:26:21.718730 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.007 seconds
[0m18:26:21.722534 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m18:26:21.725406 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8a52d4e9-42fd-4f43-bd5c-5ebe5d322487', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80c437b30>]}
[0m18:26:21.728081 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 5.19s]
[0m18:26:21.730466 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m18:26:21.735169 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:21.737205 [debug] [MainThread]: On master: BEGIN
[0m18:26:21.738797 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m18:26:21.754006 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m18:26:21.757157 [debug] [MainThread]: On master: COMMIT
[0m18:26:21.760228 [debug] [MainThread]: Using postgres connection "master"
[0m18:26:21.772278 [debug] [MainThread]: On master: COMMIT
[0m18:26:21.781944 [debug] [MainThread]: SQL status: COMMIT in 0.003 seconds
[0m18:26:21.785602 [debug] [MainThread]: On master: Close
[0m18:26:21.800878 [debug] [MainThread]: Connection 'master' was properly closed.
[0m18:26:21.804555 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m18:26:21.807304 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m18:26:21.810322 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m18:26:21.812868 [info ] [MainThread]: 
[0m18:26:21.815361 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 7.32 seconds (7.32s).
[0m18:26:21.821202 [debug] [MainThread]: Command end result
[0m18:26:21.933371 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m18:26:21.942680 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m18:26:21.961784 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m18:26:21.963550 [info ] [MainThread]: 
[0m18:26:21.965401 [info ] [MainThread]: [32mCompleted successfully[0m
[0m18:26:21.967144 [info ] [MainThread]: 
[0m18:26:21.969134 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m18:26:21.971963 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 9.298917, "process_in_blocks": "0", "process_kernel_time": 0.765112, "process_mem_max_rss": "122992", "process_out_blocks": "0", "process_user_time": 5.365594}
[0m18:26:21.974699 [debug] [MainThread]: Command `dbt run` succeeded at 18:26:21.974413 after 9.30 seconds
[0m18:26:21.976834 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811806030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc811631310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc80d5e57f0>]}
[0m18:26:21.978783 [debug] [MainThread]: Flushing usage events
[0m18:26:23.228493 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:01:01.464628 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad5fa7920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad59ff020>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad5757710>]}


============================== 19:01:01.479925 | 41ef9e17-0612-428e-8c34-0b6fc16b124f ==============================
[0m19:01:01.479925 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:01:01.482552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:01:01.999089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad495e8d0>]}
[0m19:01:02.162606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad5f23a40>]}
[0m19:01:02.164902 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:01:02.432523 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:01:03.798808 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:03.802832 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:04.031347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad49ea090>]}
[0m19:01:04.679412 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:04.706280 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:04.843136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad3911b50>]}
[0m19:01:04.846059 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m19:01:04.849652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad53be8a0>]}
[0m19:01:04.856532 [info ] [MainThread]: 
[0m19:01:04.859191 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:01:04.861374 [info ] [MainThread]: 
[0m19:01:04.864025 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:01:04.869715 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:01:04.970629 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:01:04.972883 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:01:04.975522 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:04.995123 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.019 seconds
[0m19:01:05.000185 [debug] [ThreadPool]: On list_airflow: Close
[0m19:01:05.018596 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m19:01:05.022091 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m19:01:05.024097 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m19:01:05.038771 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:05.044199 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:05.050266 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:05.052996 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m19:01:05.056013 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m19:01:05.059226 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m19:01:05.061824 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:01:05.064352 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:05.067709 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:05.090123 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m19:01:05.094746 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m19:01:05.098010 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:05.101286 [debug] [ThreadPool]: SQL status: BEGIN in 0.037 seconds
[0m19:01:05.103794 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:05.106638 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m19:01:05.109396 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:05.111935 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m19:01:05.116327 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m19:01:05.123104 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.009 seconds
[0m19:01:05.125164 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m19:01:05.129340 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m19:01:05.130600 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.010 seconds
[0m19:01:05.135856 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m19:01:05.138883 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m19:01:05.144771 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m19:01:05.148434 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m19:01:05.155530 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m19:01:05.181568 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.184094 [debug] [MainThread]: On master: BEGIN
[0m19:01:05.186020 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:05.199711 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m19:01:05.202441 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.204734 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:01:05.227986 [debug] [MainThread]: SQL status: SELECT 2 in 0.021 seconds
[0m19:01:05.232120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad414e6c0>]}
[0m19:01:05.234546 [debug] [MainThread]: On master: ROLLBACK
[0m19:01:05.236444 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.238099 [debug] [MainThread]: On master: BEGIN
[0m19:01:05.242338 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m19:01:05.245343 [debug] [MainThread]: On master: COMMIT
[0m19:01:05.247381 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.249485 [debug] [MainThread]: On master: COMMIT
[0m19:01:05.251590 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:05.253220 [debug] [MainThread]: On master: Close
[0m19:01:05.263418 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m19:01:05.266254 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m19:01:05.268999 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m19:01:05.270861 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m19:01:05.289122 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.301439 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m19:01:05.375254 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.388329 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.390118 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m19:01:05.391810 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:01:05.405026 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m19:01:05.407723 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.410031 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m19:01:05.421516 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.009 seconds
[0m19:01:05.435446 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.437954 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary" rename to "stg_daily_stock_summary__dbt_backup"
[0m19:01:05.441599 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:05.449255 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.451774 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m19:01:05.454881 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:05.500968 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m19:01:05.503206 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.505376 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m19:01:05.514096 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m19:01:05.529520 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m19:01:05.540817 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m19:01:05.543090 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m19:01:05.549236 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.004 seconds
[0m19:01:05.555390 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m19:01:05.559562 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '41ef9e17-0612-428e-8c34-0b6fc16b124f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad755b470>]}
[0m19:01:05.561858 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.29s]
[0m19:01:05.564174 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m19:01:05.569719 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.572030 [debug] [MainThread]: On master: BEGIN
[0m19:01:05.574026 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:01:05.587627 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m19:01:05.590162 [debug] [MainThread]: On master: COMMIT
[0m19:01:05.591987 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:05.593689 [debug] [MainThread]: On master: COMMIT
[0m19:01:05.595809 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:05.597577 [debug] [MainThread]: On master: Close
[0m19:01:05.599977 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:05.602205 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m19:01:05.604149 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m19:01:05.606151 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m19:01:05.607943 [info ] [MainThread]: 
[0m19:01:05.609748 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.74 seconds (0.74s).
[0m19:01:05.612064 [debug] [MainThread]: Command end result
[0m19:01:05.724168 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:05.734483 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:05.757206 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m19:01:05.759549 [info ] [MainThread]: 
[0m19:01:05.762107 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:05.764524 [info ] [MainThread]: 
[0m19:01:05.767177 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m19:01:05.770438 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 4.429266, "process_in_blocks": "0", "process_kernel_time": 0.56184, "process_mem_max_rss": "122684", "process_out_blocks": "2360", "process_user_time": 5.6184}
[0m19:01:05.774045 [debug] [MainThread]: Command `dbt run` succeeded at 19:01:05.773615 after 4.43 seconds
[0m19:01:05.775847 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad5fa7920>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad6e3a600>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6ad49ebb30>]}
[0m19:01:05.783756 [debug] [MainThread]: Flushing usage events
[0m19:01:07.211789 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:01:13.181425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c4f8bbc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c4c0bc20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c6e6c770>]}


============================== 19:01:13.196372 | 5fbf4b4e-d303-4c5e-b212-627d14fc7847 ==============================
[0m19:01:13.196372 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:01:13.199298 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:01:13.626186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c6a07350>]}
[0m19:01:13.748355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c53acef0>]}
[0m19:01:13.751012 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:01:13.945822 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:01:14.601350 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:14.603339 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:14.695676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c3f03410>]}
[0m19:01:14.887816 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:14.903932 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:14.946008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c476a300>]}
[0m19:01:14.948457 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m19:01:14.950774 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c33d1520>]}
[0m19:01:14.955207 [info ] [MainThread]: 
[0m19:01:14.957477 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:01:14.960364 [info ] [MainThread]: 
[0m19:01:14.962995 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:01:14.970858 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:01:15.035008 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:01:15.036755 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:01:15.038528 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:15.051759 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.013 seconds
[0m19:01:15.055019 [debug] [ThreadPool]: On list_airflow: Close
[0m19:01:15.062344 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m19:01:15.065397 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m19:01:15.066701 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m19:01:15.077954 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:15.082189 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:15.088618 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:15.090445 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m19:01:15.092778 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m19:01:15.095127 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m19:01:15.096909 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:01:15.098791 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:15.100686 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:15.115155 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m19:01:15.116299 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m19:01:15.118089 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m19:01:15.119747 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:15.121674 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:15.123769 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:15.126477 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m19:01:15.128808 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m19:01:15.130875 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m19:01:15.137029 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.004 seconds
[0m19:01:15.138850 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m19:01:15.143072 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m19:01:15.144837 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.011 seconds
[0m19:01:15.149533 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m19:01:15.153710 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m19:01:15.158877 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m19:01:15.161361 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m19:01:15.168718 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m19:01:15.186761 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:15.188947 [debug] [MainThread]: On master: BEGIN
[0m19:01:15.191190 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:15.206103 [debug] [MainThread]: SQL status: BEGIN in 0.015 seconds
[0m19:01:15.209620 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:15.212417 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:01:15.225822 [debug] [MainThread]: SQL status: SELECT 2 in 0.010 seconds
[0m19:01:15.230652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c3ff4050>]}
[0m19:01:15.233312 [debug] [MainThread]: On master: ROLLBACK
[0m19:01:15.236220 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:15.238569 [debug] [MainThread]: On master: BEGIN
[0m19:01:15.241669 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m19:01:15.246032 [debug] [MainThread]: On master: COMMIT
[0m19:01:15.248652 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:15.250491 [debug] [MainThread]: On master: COMMIT
[0m19:01:15.252811 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:15.254661 [debug] [MainThread]: On master: Close
[0m19:01:15.266415 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m19:01:15.267541 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m19:01:15.269914 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m19:01:15.272376 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m19:01:15.274396 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.dim_companies)
[0m19:01:15.277471 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_daily_stock_metrics)
[0m19:01:15.279599 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m19:01:15.281662 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m19:01:15.298825 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m19:01:15.305359 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:15.317441 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m19:01:15.326513 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m19:01:15.467412 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m19:01:15.468689 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:15.480440 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:15.482183 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:15.484089 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m19:01:15.486020 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m19:01:15.488031 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:01:15.489686 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:01:15.503119 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m19:01:15.505219 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m19:01:15.507059 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:15.510081 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:15.512781 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m19:01:15.515390 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m19:01:20.526618 [debug] [Thread-1 (]: SQL status: SELECT 963 in 5.009 seconds
[0m19:01:20.556752 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:20.559555 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies" rename to "dim_companies__dbt_backup"
[0m19:01:20.563125 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:20.573884 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:20.576683 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m19:01:20.579490 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:20.630872 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m19:01:20.633011 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:20.635467 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m19:01:20.659082 [debug] [Thread-1 (]: SQL status: COMMIT in 0.020 seconds
[0m19:01:20.681690 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m19:01:20.700551 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m19:01:20.705073 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m19:01:20.730641 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.021 seconds
[0m19:01:20.740616 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m19:01:20.749502 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c54dc5f0>]}
[0m19:01:20.752650 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 5.47s]
[0m19:01:20.757544 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m19:01:21.164628 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 5.645 seconds
[0m19:01:21.174231 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:21.176646 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics" rename to "fct_daily_stock_metrics__dbt_backup"
[0m19:01:21.179796 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:21.189601 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:21.192587 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m19:01:21.195622 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:21.200349 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m19:01:21.202851 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:21.206226 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m19:01:21.225028 [debug] [Thread-2 (]: SQL status: COMMIT in 0.015 seconds
[0m19:01:21.231783 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m19:01:21.234565 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m19:01:21.237677 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m19:01:21.294883 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.054 seconds
[0m19:01:21.299622 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m19:01:21.302503 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fbf4b4e-d303-4c5e-b212-627d14fc7847', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c1a71e20>]}
[0m19:01:21.308074 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 6.02s]
[0m19:01:21.312128 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m19:01:21.317587 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:21.320113 [debug] [MainThread]: On master: BEGIN
[0m19:01:21.323675 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:01:21.345438 [debug] [MainThread]: SQL status: BEGIN in 0.020 seconds
[0m19:01:21.348037 [debug] [MainThread]: On master: COMMIT
[0m19:01:21.350033 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:21.352109 [debug] [MainThread]: On master: COMMIT
[0m19:01:21.356080 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:21.358814 [debug] [MainThread]: On master: Close
[0m19:01:21.362001 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:21.363697 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m19:01:21.365349 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m19:01:21.367194 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m19:01:21.369373 [info ] [MainThread]: 
[0m19:01:21.372877 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 6.41 seconds (6.41s).
[0m19:01:21.377634 [debug] [MainThread]: Command end result
[0m19:01:21.469176 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:21.478760 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:21.505176 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m19:01:21.507236 [info ] [MainThread]: 
[0m19:01:21.509978 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:21.512557 [info ] [MainThread]: 
[0m19:01:21.514814 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:01:21.518031 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 8.484658, "process_in_blocks": "0", "process_kernel_time": 0.462431, "process_mem_max_rss": "122768", "process_out_blocks": "0", "process_user_time": 6.228067}
[0m19:01:21.521290 [debug] [MainThread]: Command `dbt run` succeeded at 19:01:21.520959 after 8.49 seconds
[0m19:01:21.523948 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c4ac4b60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c66bcd70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4c51378c0>]}
[0m19:01:21.526463 [debug] [MainThread]: Flushing usage events
[0m19:01:22.603841 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:01:27.784442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850f15d100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f851053c8f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850f1f1c10>]}


============================== 19:01:27.798113 | 9b1cf889-8593-4bb6-9e0b-e0add47ca5d3 ==============================
[0m19:01:27.798113 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:01:27.800472 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m19:01:28.192823 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850ec4fc50>]}
[0m19:01:28.338462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850f477a40>]}
[0m19:01:28.341434 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:01:28.553596 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:01:29.272191 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:29.274152 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:29.378406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850f4fd8e0>]}
[0m19:01:29.590093 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:29.608645 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:29.655796 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850d103ef0>]}
[0m19:01:29.658166 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m19:01:29.660267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850e1b6f90>]}
[0m19:01:29.666789 [info ] [MainThread]: 
[0m19:01:29.669153 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:01:29.671346 [info ] [MainThread]: 
[0m19:01:29.673561 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:01:29.684302 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m19:01:29.752625 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m19:01:29.754986 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m19:01:29.757044 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:29.773082 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m19:01:29.777650 [debug] [ThreadPool]: On list_airflow: Close
[0m19:01:29.784360 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m19:01:29.787848 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m19:01:29.789820 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m19:01:29.804497 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:29.811302 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:29.818936 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:29.821732 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m19:01:29.824138 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m19:01:29.827466 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m19:01:29.831062 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m19:01:29.834267 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:29.839425 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:29.862783 [debug] [ThreadPool]: SQL status: BEGIN in 0.028 seconds
[0m19:01:29.867864 [debug] [ThreadPool]: SQL status: BEGIN in 0.037 seconds
[0m19:01:29.870685 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:29.872351 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m19:01:29.874846 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:29.877617 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m19:01:29.881012 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:29.884460 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m19:01:29.888235 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m19:01:29.890818 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m19:01:29.898831 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m19:01:29.900298 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.008 seconds
[0m19:01:29.902961 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m19:01:29.904181 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.011 seconds
[0m19:01:29.907891 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m19:01:29.914775 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m19:01:29.917985 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m19:01:29.920850 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m19:01:29.941918 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:29.943608 [debug] [MainThread]: On master: BEGIN
[0m19:01:29.946421 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:29.959673 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m19:01:29.963389 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:29.966924 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:01:29.980472 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m19:01:29.984924 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850e121ee0>]}
[0m19:01:29.986958 [debug] [MainThread]: On master: ROLLBACK
[0m19:01:29.988969 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:29.990581 [debug] [MainThread]: On master: BEGIN
[0m19:01:29.992782 [debug] [MainThread]: SQL status: BEGIN in 0.000 seconds
[0m19:01:29.996324 [debug] [MainThread]: On master: COMMIT
[0m19:01:29.998719 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:30.000688 [debug] [MainThread]: On master: COMMIT
[0m19:01:30.002764 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:30.004539 [debug] [MainThread]: On master: Close
[0m19:01:30.013962 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m19:01:30.015204 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m19:01:30.016221 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m19:01:30.017261 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m19:01:30.018816 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m19:01:30.020631 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m19:01:30.022815 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m19:01:30.025072 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m19:01:30.027739 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m19:01:30.030278 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_daily)
[0m19:01:30.032841 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m19:01:30.035280 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m19:01:30.037569 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m19:01:30.039555 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m19:01:30.041730 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m19:01:30.043776 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m19:01:30.061856 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m19:01:30.069747 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m19:01:30.077933 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m19:01:30.086216 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m19:01:30.097611 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m19:01:30.100147 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m19:01:30.106978 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m19:01:30.107925 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m19:01:30.263717 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m19:01:30.269358 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m19:01:30.272596 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m19:01:30.275012 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m19:01:30.285047 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:30.287147 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:30.289031 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:30.290800 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m19:01:30.293082 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m19:01:30.294684 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:30.298365 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m19:01:30.300610 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:01:30.302927 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m19:01:30.305235 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m19:01:30.307553 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:01:30.312965 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m19:01:30.323361 [debug] [Thread-2 (]: SQL status: BEGIN in 0.023 seconds
[0m19:01:30.326337 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:30.330389 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m19:01:30.332407 [debug] [Thread-1 (]: SQL status: BEGIN in 0.025 seconds
[0m19:01:30.334436 [debug] [Thread-4 (]: SQL status: BEGIN in 0.031 seconds
[0m19:01:30.337694 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:30.340353 [debug] [Thread-3 (]: SQL status: BEGIN in 0.027 seconds
[0m19:01:30.341959 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:30.345175 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m19:01:30.348359 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:30.351145 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m19:01:30.356114 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m19:01:30.926252 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.589 seconds
[0m19:01:30.965675 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:30.971268 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily" rename to "stock_performance_daily__dbt_backup"
[0m19:01:30.974645 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:30.989912 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:30.997139 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m19:01:31.001762 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:31.086949 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m19:01:31.089861 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:31.093329 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m19:01:31.112940 [debug] [Thread-2 (]: SQL status: COMMIT in 0.014 seconds
[0m19:01:31.140587 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m19:01:31.160299 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m19:01:31.164209 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m19:01:31.183302 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.016 seconds
[0m19:01:31.190611 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m19:01:31.197895 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8510dbf470>]}
[0m19:01:31.201196 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 1.16s]
[0m19:01:31.204429 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m19:01:31.207186 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m19:01:31.212049 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m19:01:31.215581 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m19:01:31.217765 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m19:01:31.225725 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m19:01:31.244271 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m19:01:31.253827 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m19:01:31.271707 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:31.274378 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m19:01:31.277039 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:01:31.299430 [debug] [Thread-2 (]: SQL status: BEGIN in 0.022 seconds
[0m19:01:31.302818 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:31.306402 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m19:01:38.310588 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 7.956 seconds
[0m19:01:38.321928 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:38.325043 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics" rename to "daily_stock_metrics__dbt_backup"
[0m19:01:38.329203 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:38.337665 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:38.340912 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m19:01:38.344353 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:38.348803 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m19:01:38.350929 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:38.352918 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m19:01:38.360678 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m19:01:38.372575 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m19:01:38.375735 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m19:01:38.378277 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m19:01:38.441907 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.061 seconds
[0m19:01:38.447926 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m19:01:38.450952 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8508b1caa0>]}
[0m19:01:38.454020 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 8.42s]
[0m19:01:38.458355 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m19:01:38.461151 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m19:01:38.463991 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m19:01:38.467015 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m19:01:38.469696 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m19:01:38.479478 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m19:01:38.497403 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m19:01:38.509125 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m19:01:38.526087 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:38.528825 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m19:01:38.531339 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:01:38.552709 [debug] [Thread-1 (]: SQL status: BEGIN in 0.021 seconds
[0m19:01:38.556462 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:38.560335 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m19:01:39.501094 [debug] [Thread-3 (]: SQL status: SELECT 960 in 9.138 seconds
[0m19:01:39.514149 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:39.516893 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly" rename to "stock_performance_monthly__dbt_backup"
[0m19:01:39.519566 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:39.531551 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:39.534204 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m19:01:39.537733 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:39.544167 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m19:01:39.546764 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:39.549098 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m19:01:39.554579 [debug] [Thread-3 (]: SQL status: COMMIT in 0.003 seconds
[0m19:01:39.563626 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m19:01:39.566544 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m19:01:39.568577 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m19:01:39.577069 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m19:01:39.581960 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m19:01:39.584404 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850bc91eb0>]}
[0m19:01:39.590878 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 9.55s]
[0m19:01:39.594998 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m19:01:39.597613 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m19:01:39.600307 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m19:01:39.603086 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m19:01:39.606063 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m19:01:39.618820 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m19:01:39.634013 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m19:01:39.646642 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m19:01:39.661932 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:39.664650 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m19:01:39.667150 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m19:01:39.683832 [debug] [Thread-3 (]: SQL status: BEGIN in 0.017 seconds
[0m19:01:39.687600 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:39.691676 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m19:01:40.463608 [debug] [Thread-4 (]: SQL status: SELECT 960 in 10.104 seconds
[0m19:01:40.476234 [debug] [Thread-3 (]: SQL status: SELECT 18321 in 0.780 seconds
[0m19:01:40.481215 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:40.494231 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:40.496509 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly" rename to "stock_performance_weekly__dbt_backup"
[0m19:01:40.499627 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis" rename to "news_sentiment_analysis__dbt_backup"
[0m19:01:40.503803 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:40.507494 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:40.523131 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:40.541143 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:40.543537 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m19:01:40.546829 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m19:01:40.550897 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:40.558381 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m19:01:40.564455 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m19:01:40.570688 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m19:01:40.574493 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:40.578968 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:40.582095 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m19:01:40.584984 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m19:01:40.594589 [debug] [Thread-4 (]: SQL status: COMMIT in 0.005 seconds
[0m19:01:40.596318 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m19:01:40.606126 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m19:01:40.615128 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m19:01:40.618219 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m19:01:40.622932 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m19:01:40.626067 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m19:01:40.628574 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m19:01:40.636487 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.005 seconds
[0m19:01:40.643445 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m19:01:40.645259 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.013 seconds
[0m19:01:40.648594 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850bcaf6b0>]}
[0m19:01:40.654470 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m19:01:40.658429 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 10.61s]
[0m19:01:40.661758 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850bcf4170>]}
[0m19:01:40.664112 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m19:01:40.666668 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 18321[0m in 1.06s]
[0m19:01:40.670492 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m19:01:44.028636 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 12.719 seconds
[0m19:01:44.037387 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:44.039686 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd" rename to "technical_indicators_macd__dbt_backup"
[0m19:01:44.042958 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:44.052652 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:44.055138 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m19:01:44.058889 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:44.064555 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m19:01:44.067600 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:44.070760 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m19:01:44.075104 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m19:01:44.082801 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m19:01:44.086151 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m19:01:44.088407 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m19:01:44.114828 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.025 seconds
[0m19:01:44.120436 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m19:01:44.123008 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850bc41eb0>]}
[0m19:01:44.125375 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 12.91s]
[0m19:01:44.127895 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m19:01:48.909537 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 10.346 seconds
[0m19:01:48.918793 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:48.920744 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi" rename to "technical_indicators_rsi__dbt_backup"
[0m19:01:48.923391 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m19:01:48.930615 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:48.933423 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m19:01:48.935745 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m19:01:48.939556 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m19:01:48.941408 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:48.943042 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m19:01:48.957140 [debug] [Thread-1 (]: SQL status: COMMIT in 0.012 seconds
[0m19:01:48.963665 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m19:01:48.966995 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m19:01:48.969198 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m19:01:48.989433 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.018 seconds
[0m19:01:48.993419 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m19:01:48.995789 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9b1cf889-8593-4bb6-9e0b-e0add47ca5d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850bc72f30>]}
[0m19:01:48.999088 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 10.53s]
[0m19:01:49.002906 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m19:01:49.009008 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:49.011217 [debug] [MainThread]: On master: BEGIN
[0m19:01:49.013813 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:01:49.032605 [debug] [MainThread]: SQL status: BEGIN in 0.019 seconds
[0m19:01:49.035355 [debug] [MainThread]: On master: COMMIT
[0m19:01:49.037456 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:49.039470 [debug] [MainThread]: On master: COMMIT
[0m19:01:49.041758 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:49.043871 [debug] [MainThread]: On master: Close
[0m19:01:49.046337 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:49.049233 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m19:01:49.051099 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m19:01:49.052830 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m19:01:49.054670 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m19:01:49.056777 [info ] [MainThread]: 
[0m19:01:49.059002 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 19.38 seconds (19.38s).
[0m19:01:49.065512 [debug] [MainThread]: Command end result
[0m19:01:49.161340 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:49.172859 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:49.197220 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m19:01:49.200082 [info ] [MainThread]: 
[0m19:01:49.202350 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:49.204302 [info ] [MainThread]: 
[0m19:01:49.206304 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m19:01:49.209378 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 21.534937, "process_in_blocks": "0", "process_kernel_time": 0.595752, "process_mem_max_rss": "123124", "process_out_blocks": "0", "process_user_time": 5.705087}
[0m19:01:49.211772 [debug] [MainThread]: Command `dbt run` succeeded at 19:01:49.211517 after 21.54 seconds
[0m19:01:49.214607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f851285b2c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850ec4ab40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f850e123cb0>]}
[0m19:01:49.217707 [debug] [MainThread]: Flushing usage events
[0m19:01:50.573305 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m19:01:55.713022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817f2710a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81814187a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817f40bb90>]}


============================== 19:01:55.725595 | 66ae2f59-4613-4054-97e6-1a787c75ff13 ==============================
[0m19:01:55.725595 [info ] [MainThread]: Running with dbt=1.9.4
[0m19:01:55.727672 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m19:01:56.080376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817f7a6ff0>]}
[0m19:01:56.218912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817edf8380>]}
[0m19:01:56.221944 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m19:01:56.480591 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m19:01:57.117153 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:01:57.119131 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:01:57.209875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817e1b0950>]}
[0m19:01:57.414928 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:57.431647 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:57.490982 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817cd5ab40>]}
[0m19:01:57.493299 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m19:01:57.495482 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817dd34080>]}
[0m19:01:57.501416 [info ] [MainThread]: 
[0m19:01:57.503431 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m19:01:57.505308 [info ] [MainThread]: 
[0m19:01:57.508062 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m19:01:57.517894 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m19:01:57.519299 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m19:01:57.520628 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m19:01:57.591545 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:57.592462 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:57.593169 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:57.594701 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m19:01:57.596518 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m19:01:57.598174 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m19:01:57.600178 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:57.602162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:57.603933 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:01:57.618068 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m19:01:57.619420 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m19:01:57.620927 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m19:01:57.622374 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m19:01:57.625282 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m19:01:57.627364 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m19:01:57.629498 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m19:01:57.631667 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m19:01:57.633762 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m19:01:57.641722 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m19:01:57.642549 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m19:01:57.643277 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.005 seconds
[0m19:01:57.646571 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m19:01:57.649856 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m19:01:57.653052 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m19:01:57.655389 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m19:01:57.657645 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m19:01:57.659521 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m19:01:57.678413 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.680431 [debug] [MainThread]: On master: BEGIN
[0m19:01:57.682212 [debug] [MainThread]: Opening a new connection, currently in state init
[0m19:01:57.693300 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m19:01:57.695718 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.697704 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m19:01:57.710526 [debug] [MainThread]: SQL status: SELECT 2 in 0.011 seconds
[0m19:01:57.714348 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '66ae2f59-4613-4054-97e6-1a787c75ff13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817cd3e8d0>]}
[0m19:01:57.716501 [debug] [MainThread]: On master: ROLLBACK
[0m19:01:57.718759 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.720655 [debug] [MainThread]: On master: BEGIN
[0m19:01:57.723342 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m19:01:57.725734 [debug] [MainThread]: On master: COMMIT
[0m19:01:57.727704 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.729468 [debug] [MainThread]: On master: COMMIT
[0m19:01:57.731642 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:57.733684 [debug] [MainThread]: On master: Close
[0m19:01:57.742556 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m19:01:57.743485 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m19:01:57.745186 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m19:01:57.747176 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m19:01:57.749347 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m19:01:57.751282 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m19:01:57.753127 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m19:01:57.755076 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m19:01:57.793849 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m19:01:57.789104 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m19:01:57.803238 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m19:01:57.811348 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m19:01:57.837821 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m19:01:57.840889 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m19:01:57.850444 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m19:01:57.852378 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m19:01:57.853532 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m19:01:57.855106 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m19:01:57.857480 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m19:01:57.860698 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m19:01:57.868737 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m19:01:57.870837 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m19:01:57.872950 [debug] [Thread-1 (]: SQL status: BEGIN in 0.012 seconds
[0m19:01:57.875342 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m19:01:57.877645 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m19:01:57.880890 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m19:01:57.882149 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m19:01:57.885051 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.001 seconds
[0m19:01:57.892529 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m19:01:57.896037 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m19:01:57.898332 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m19:01:57.900164 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m19:01:57.902211 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.15s]
[0m19:01:57.904585 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m19:01:57.907352 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m19:01:57.909830 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m19:01:57.915176 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.916935 [debug] [MainThread]: On master: BEGIN
[0m19:01:57.918543 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m19:01:57.929641 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m19:01:57.931766 [debug] [MainThread]: On master: COMMIT
[0m19:01:57.933844 [debug] [MainThread]: Using postgres connection "master"
[0m19:01:57.935630 [debug] [MainThread]: On master: COMMIT
[0m19:01:57.937994 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m19:01:57.940331 [debug] [MainThread]: On master: Close
[0m19:01:57.942680 [debug] [MainThread]: Connection 'master' was properly closed.
[0m19:01:57.944533 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m19:01:57.946355 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m19:01:57.948076 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m19:01:57.949832 [info ] [MainThread]: 
[0m19:01:57.951619 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m19:01:57.954373 [debug] [MainThread]: Command end result
[0m19:01:58.035550 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m19:01:58.046181 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m19:01:58.065572 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m19:01:58.067454 [info ] [MainThread]: 
[0m19:01:58.069369 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:01:58.071406 [info ] [MainThread]: 
[0m19:01:58.074382 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m19:01:58.077357 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.4652948, "process_in_blocks": "0", "process_kernel_time": 0.326232, "process_mem_max_rss": "123744", "process_out_blocks": "0", "process_user_time": 4.537593}
[0m19:01:58.079765 [debug] [MainThread]: Command `dbt test` succeeded at 19:01:58.079474 after 2.47 seconds
[0m19:01:58.081743 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8181c358b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817ef7eb40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f817ef7e960>]}
[0m19:01:58.083649 [debug] [MainThread]: Flushing usage events
[0m19:01:59.195685 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:45:00.869867 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb3341a000>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb33c536b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb3584d8e0>]}


============================== 03:45:00.891876 | 5a0e8e54-1188-4ed4-9d80-fa5b277a5669 ==============================
[0m03:45:00.891876 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:45:00.895087 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:45:01.803734 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb328c11c0>]}
[0m03:45:02.086465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb32863ce0>]}
[0m03:45:02.097509 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:45:02.529650 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:45:04.810815 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:45:04.817716 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:45:05.216327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb3250a510>]}
[0m03:45:05.741349 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:45:05.780468 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:45:06.142894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb3191b1a0>]}
[0m03:45:06.152696 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:45:06.159647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb32509220>]}
[0m03:45:06.175647 [info ] [MainThread]: 
[0m03:45:06.184805 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:45:06.193101 [info ] [MainThread]: 
[0m03:45:06.202892 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:45:06.224622 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:45:06.541653 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:45:06.548483 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:45:06.556093 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:06.595171 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.039 seconds
[0m03:45:06.604781 [debug] [ThreadPool]: On list_airflow: Close
[0m03:45:06.612312 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m03:45:06.616707 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m03:45:06.636296 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:45:06.638689 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m03:45:06.640691 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:45:06.657181 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:45:06.659399 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:45:06.661507 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m03:45:06.667302 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.004 seconds
[0m03:45:06.671371 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m03:45:06.673733 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m03:45:06.676387 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m03:45:06.684012 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m03:45:06.686435 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m03:45:06.702093 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_analytics)
[0m03:45:06.705554 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:45:06.707551 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m03:45:06.722303 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:45:06.727677 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:45:06.734346 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:45:06.737386 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:45:06.740128 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:45:06.742927 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:45:06.745608 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:45:06.749162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:06.752036 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:06.771732 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m03:45:06.773888 [debug] [ThreadPool]: SQL status: BEGIN in 0.025 seconds
[0m03:45:06.775838 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:45:06.778394 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m03:45:06.781274 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:45:06.784988 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:45:06.788588 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:45:06.792030 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:45:06.797614 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:45:06.807467 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.006 seconds
[0m03:45:06.808649 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.013 seconds
[0m03:45:06.811415 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.008 seconds
[0m03:45:06.815573 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:45:06.820980 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:45:06.827385 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:45:06.832886 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:45:06.837664 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:45:06.842987 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:45:06.890364 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:06.895951 [debug] [MainThread]: On master: BEGIN
[0m03:45:06.902282 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:45:06.939723 [debug] [MainThread]: SQL status: BEGIN in 0.037 seconds
[0m03:45:06.945546 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:06.952384 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:45:06.974196 [debug] [MainThread]: SQL status: SELECT 0 in 0.015 seconds
[0m03:45:06.986218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb34d24e00>]}
[0m03:45:06.992535 [debug] [MainThread]: On master: ROLLBACK
[0m03:45:06.999940 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:07.005601 [debug] [MainThread]: On master: BEGIN
[0m03:45:07.012458 [debug] [MainThread]: SQL status: BEGIN in 0.002 seconds
[0m03:45:07.019456 [debug] [MainThread]: On master: COMMIT
[0m03:45:07.024780 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:07.030027 [debug] [MainThread]: On master: COMMIT
[0m03:45:07.037595 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:45:07.045098 [debug] [MainThread]: On master: Close
[0m03:45:07.082108 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m03:45:07.089789 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m03:45:07.096385 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_daily_stock_summary)
[0m03:45:07.103336 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m03:45:07.156709 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.204807 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m03:45:07.428400 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.491278 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.500345 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m03:45:07.510240 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:45:07.575953 [debug] [Thread-1 (]: SQL status: BEGIN in 0.066 seconds
[0m03:45:07.586348 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.594508 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m03:45:07.652263 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.046 seconds
[0m03:45:07.710360 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.713925 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m03:45:07.724504 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m03:45:07.779016 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m03:45:07.785113 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.787520 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m03:45:07.794884 [debug] [Thread-1 (]: SQL status: COMMIT in 0.005 seconds
[0m03:45:07.810162 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m03:45:07.823758 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m03:45:07.826004 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m03:45:07.828916 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m03:45:07.836050 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m03:45:07.841709 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a0e8e54-1188-4ed4-9d80-fa5b277a5669', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb351c7410>]}
[0m03:45:07.844543 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.74s]
[0m03:45:07.848764 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m03:45:07.855105 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:07.857723 [debug] [MainThread]: On master: BEGIN
[0m03:45:07.860530 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:45:07.884036 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m03:45:07.887835 [debug] [MainThread]: On master: COMMIT
[0m03:45:07.892098 [debug] [MainThread]: Using postgres connection "master"
[0m03:45:07.898141 [debug] [MainThread]: On master: COMMIT
[0m03:45:07.903885 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:45:07.908980 [debug] [MainThread]: On master: Close
[0m03:45:07.915349 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:45:07.920554 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m03:45:07.925802 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m03:45:07.930725 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m03:45:07.936575 [info ] [MainThread]: 
[0m03:45:07.941603 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 1.74 seconds (1.74s).
[0m03:45:07.949437 [debug] [MainThread]: Command end result
[0m03:45:08.307935 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:45:08.353193 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:45:08.434525 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:45:08.441696 [info ] [MainThread]: 
[0m03:45:08.450357 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:45:08.457581 [info ] [MainThread]: 
[0m03:45:08.465839 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m03:45:08.479932 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 7.8986382, "process_in_blocks": "28496", "process_kernel_time": 1.389779, "process_mem_max_rss": "121472", "process_out_blocks": "2360", "process_user_time": 12.058089}
[0m03:45:08.496841 [debug] [MainThread]: Command `dbt run` succeeded at 03:45:08.495296 after 7.92 seconds
[0m03:45:08.507247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb33bcb830>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb33bca930>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feb3344b9e0>]}
[0m03:45:08.517554 [debug] [MainThread]: Flushing usage events
[0m03:45:10.263060 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:45:53.932032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f3b263c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f4461ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f3b26300>]}


============================== 03:45:53.966417 | cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a ==============================
[0m03:45:53.966417 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:45:53.971406 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'profiles_dir': '/opt/airflow/dbt', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m03:45:55.351671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f5c9b230>]}
[0m03:45:55.863894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f3bb0230>]}
[0m03:45:55.868584 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:45:56.162151 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:45:58.649493 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:45:58.653668 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:45:58.915328 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f2db3d10>]}
[0m03:45:59.353649 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:45:59.383812 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:45:59.463990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f2d773e0>]}
[0m03:45:59.467689 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:45:59.473740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f38a6300>]}
[0m03:45:59.481728 [info ] [MainThread]: 
[0m03:45:59.485144 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:45:59.490620 [info ] [MainThread]: 
[0m03:45:59.495209 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:45:59.515785 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:45:59.649551 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:45:59.653569 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:45:59.657388 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:59.687231 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.030 seconds
[0m03:45:59.694929 [debug] [ThreadPool]: On list_airflow: Close
[0m03:45:59.700837 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m03:45:59.706287 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m03:45:59.727062 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:45:59.730540 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m03:45:59.734560 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:45:59.760952 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m03:45:59.763921 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:45:59.767093 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m03:45:59.772656 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.002 seconds
[0m03:45:59.778744 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m03:45:59.782014 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m03:45:59.785474 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m03:45:59.798239 [debug] [ThreadPool]: SQL status: COMMIT in 0.008 seconds
[0m03:45:59.801401 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m03:45:59.814781 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_staging)
[0m03:45:59.817396 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:45:59.820054 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:45:59.856158 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:45:59.857801 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:45:59.865103 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:45:59.867985 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:45:59.872327 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:45:59.875465 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:45:59.878747 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:59.881772 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:45:59.884589 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:45:59.912146 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m03:45:59.915209 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m03:45:59.916561 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:45:59.917853 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m03:45:59.920811 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:45:59.924603 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:45:59.927878 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:45:59.931864 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:45:59.937361 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:45:59.946669 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.011 seconds
[0m03:45:59.953662 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:45:59.955963 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.014 seconds
[0m03:45:59.957698 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.012 seconds
[0m03:45:59.961772 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:45:59.975982 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:45:59.982290 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:45:59.990878 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:45:59.996617 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:46:00.052607 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:00.058032 [debug] [MainThread]: On master: BEGIN
[0m03:46:00.060192 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:46:00.080276 [debug] [MainThread]: SQL status: BEGIN in 0.020 seconds
[0m03:46:00.083639 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:00.087841 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:46:00.121739 [debug] [MainThread]: SQL status: SELECT 1 in 0.030 seconds
[0m03:46:00.127168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f2d03b90>]}
[0m03:46:00.129528 [debug] [MainThread]: On master: ROLLBACK
[0m03:46:00.131862 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:00.134970 [debug] [MainThread]: On master: BEGIN
[0m03:46:00.138253 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:46:00.140486 [debug] [MainThread]: On master: COMMIT
[0m03:46:00.142272 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:00.144023 [debug] [MainThread]: On master: COMMIT
[0m03:46:00.146023 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:46:00.147756 [debug] [MainThread]: On master: Close
[0m03:46:00.159015 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m03:46:00.160305 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m03:46:00.162718 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m03:46:00.165105 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m03:46:00.167727 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.dim_companies)
[0m03:46:00.170288 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_daily_stock_metrics)
[0m03:46:00.173901 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m03:46:00.176699 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m03:46:00.200019 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m03:46:00.209298 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:00.224295 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m03:46:00.233623 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m03:46:00.541631 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m03:46:00.563804 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:00.602424 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:00.613163 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m03:46:00.618370 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:46:00.625881 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:46:00.634188 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m03:46:00.650350 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:46:00.694188 [debug] [Thread-2 (]: SQL status: BEGIN in 0.068 seconds
[0m03:46:00.702928 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:00.712378 [debug] [Thread-1 (]: SQL status: BEGIN in 0.062 seconds
[0m03:46:00.717021 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m03:46:00.727147 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:46:00.740584 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m03:46:06.195284 [debug] [Thread-1 (]: SQL status: SELECT 963 in 5.446 seconds
[0m03:46:06.245693 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:46:06.250321 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m03:46:06.256596 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:06.318944 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m03:46:06.321951 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:46:06.324833 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m03:46:06.339565 [debug] [Thread-1 (]: SQL status: COMMIT in 0.012 seconds
[0m03:46:06.358606 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m03:46:06.371959 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m03:46:06.374602 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m03:46:06.377567 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:06.385227 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m03:46:06.391796 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f4618680>]}
[0m03:46:06.395642 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 6.22s]
[0m03:46:06.398989 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m03:46:07.341927 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 6.607 seconds
[0m03:46:07.369755 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:07.377166 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m03:46:07.387791 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.002 seconds
[0m03:46:07.403252 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m03:46:07.410933 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:07.419051 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m03:46:07.442548 [debug] [Thread-2 (]: SQL status: COMMIT in 0.015 seconds
[0m03:46:07.465191 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m03:46:07.475399 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m03:46:07.484453 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m03:46:07.493699 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:07.510161 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m03:46:07.520933 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbbdb1e5-8883-4532-b0d9-ed2bcc913c6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f0b6a060>]}
[0m03:46:07.529758 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 7.35s]
[0m03:46:07.540473 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m03:46:07.559447 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:07.566709 [debug] [MainThread]: On master: BEGIN
[0m03:46:07.573901 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:46:07.628676 [debug] [MainThread]: SQL status: BEGIN in 0.054 seconds
[0m03:46:07.636177 [debug] [MainThread]: On master: COMMIT
[0m03:46:07.642683 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:07.651026 [debug] [MainThread]: On master: COMMIT
[0m03:46:07.672105 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:46:07.683745 [debug] [MainThread]: On master: Close
[0m03:46:07.701634 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:46:07.710267 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m03:46:07.725174 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m03:46:07.741107 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m03:46:07.753620 [info ] [MainThread]: 
[0m03:46:07.757993 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 8.26 seconds (8.26s).
[0m03:46:07.763736 [debug] [MainThread]: Command end result
[0m03:46:07.890354 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:46:07.906887 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:46:07.941999 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:46:07.945759 [info ] [MainThread]: 
[0m03:46:07.950949 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:46:07.954606 [info ] [MainThread]: 
[0m03:46:07.958458 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m03:46:07.966679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 14.32219, "process_in_blocks": "0", "process_kernel_time": 0.995873, "process_mem_max_rss": "121132", "process_out_blocks": "0", "process_user_time": 12.119776}
[0m03:46:07.971291 [debug] [MainThread]: Command `dbt run` succeeded at 03:46:07.970817 after 14.33 seconds
[0m03:46:07.975103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f3b801d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f4461ac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f81f461b3e0>]}
[0m03:46:07.978972 [debug] [MainThread]: Flushing usage events
[0m03:46:09.451163 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:46:30.043002 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6defa40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6da7530>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6deffb0>]}


============================== 03:46:30.086146 | b7222dbf-876a-4c9b-891f-79958b3c06ce ==============================
[0m03:46:30.086146 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:46:30.091090 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:46:30.745626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f8452840>]}
[0m03:46:30.915101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f7474350>]}
[0m03:46:30.918559 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:46:31.186555 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:46:33.280405 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:46:33.282966 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:46:33.428801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f5baec90>]}
[0m03:46:33.775935 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:46:33.804294 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:46:33.873950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f4b5b200>]}
[0m03:46:33.878947 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:46:33.895779 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f57030e0>]}
[0m03:46:33.903933 [info ] [MainThread]: 
[0m03:46:33.907539 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:46:33.912032 [info ] [MainThread]: 
[0m03:46:33.915796 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:46:33.933903 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:46:34.047826 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:46:34.050068 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:46:34.053311 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:46:34.071811 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.018 seconds
[0m03:46:34.076193 [debug] [ThreadPool]: On list_airflow: Close
[0m03:46:34.080512 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m03:46:34.083510 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m03:46:34.097705 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:46:34.100267 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m03:46:34.102462 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:46:34.118975 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m03:46:34.121534 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:46:34.124154 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m03:46:34.127924 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m03:46:34.132561 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m03:46:34.135134 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m03:46:34.137606 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m03:46:34.147056 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m03:46:34.149531 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m03:46:34.157099 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m03:46:34.159353 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:46:34.162200 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:46:34.179966 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:46:34.186900 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:46:34.192588 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:46:34.195423 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:46:34.197975 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:46:34.200227 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:46:34.202605 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:46:34.205049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:46:34.207541 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:46:34.228440 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m03:46:34.230804 [debug] [ThreadPool]: SQL status: BEGIN in 0.023 seconds
[0m03:46:34.232414 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m03:46:34.233417 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:46:34.236204 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:46:34.238595 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:46:34.241104 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:46:34.244133 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:46:34.247271 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:46:34.257211 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m03:46:34.258479 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.007 seconds
[0m03:46:34.260493 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.007 seconds
[0m03:46:34.264461 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:46:34.269602 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:46:34.274111 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:46:34.277413 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:46:34.280102 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:46:34.282344 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:46:34.304490 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:34.307237 [debug] [MainThread]: On master: BEGIN
[0m03:46:34.309714 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:46:34.326849 [debug] [MainThread]: SQL status: BEGIN in 0.017 seconds
[0m03:46:34.329707 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:34.332517 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:46:34.350895 [debug] [MainThread]: SQL status: SELECT 1 in 0.015 seconds
[0m03:46:34.356305 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f53ae510>]}
[0m03:46:34.359112 [debug] [MainThread]: On master: ROLLBACK
[0m03:46:34.362293 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:34.364774 [debug] [MainThread]: On master: BEGIN
[0m03:46:34.367860 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:46:34.371128 [debug] [MainThread]: On master: COMMIT
[0m03:46:34.373665 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:34.376286 [debug] [MainThread]: On master: COMMIT
[0m03:46:34.384284 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:46:34.386868 [debug] [MainThread]: On master: Close
[0m03:46:34.398673 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m03:46:34.399935 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m03:46:34.401081 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m03:46:34.402414 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m03:46:34.404681 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m03:46:34.407128 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m03:46:34.410382 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m03:46:34.413932 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m03:46:34.417650 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.daily_stock_metrics)
[0m03:46:34.420490 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_daily)
[0m03:46:34.423360 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stock_performance_monthly)
[0m03:46:34.427071 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m03:46:34.430100 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m03:46:34.432729 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m03:46:34.435281 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m03:46:34.437838 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m03:46:34.458705 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m03:46:34.467167 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m03:46:34.478192 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m03:46:34.487271 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m03:46:34.503339 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m03:46:34.505146 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m03:46:34.513821 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m03:46:34.515614 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m03:46:34.914082 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m03:46:34.965199 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m03:46:35.014867 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m03:46:35.020198 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m03:46:35.051251 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:46:35.070404 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:46:35.066175 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m03:46:35.075409 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:46:35.083006 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m03:46:35.085644 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:46:35.089498 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m03:46:35.094942 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m03:46:35.099158 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:46:35.103189 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m03:46:35.109529 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:46:35.124986 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:46:35.128266 [debug] [Thread-4 (]: SQL status: BEGIN in 0.039 seconds
[0m03:46:35.134915 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:46:35.138384 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m03:46:35.141274 [debug] [Thread-3 (]: SQL status: BEGIN in 0.042 seconds
[0m03:46:35.146027 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:46:35.150423 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m03:46:35.155197 [debug] [Thread-1 (]: SQL status: BEGIN in 0.046 seconds
[0m03:46:35.157898 [debug] [Thread-2 (]: SQL status: BEGIN in 0.033 seconds
[0m03:46:35.160259 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:46:35.164398 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:46:35.167602 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m03:46:35.170986 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m03:46:35.326991 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.152 seconds
[0m03:46:35.357524 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:46:35.361262 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m03:46:35.364660 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:35.408690 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m03:46:35.412383 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:46:35.414321 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m03:46:35.424865 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m03:46:35.446434 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m03:46:35.463431 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m03:46:35.465637 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m03:46:35.468698 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:35.475223 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m03:46:35.482999 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f53ae510>]}
[0m03:46:35.486520 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 1.06s]
[0m03:46:35.489790 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m03:46:35.493281 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m03:46:35.496565 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m03:46:35.499367 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m03:46:35.501947 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m03:46:35.513254 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m03:46:35.531179 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m03:46:35.540686 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m03:46:35.556823 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:46:35.560522 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m03:46:35.563672 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:46:35.584810 [debug] [Thread-2 (]: SQL status: BEGIN in 0.021 seconds
[0m03:46:35.587820 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:46:35.590203 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m03:46:41.957170 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 6.783 seconds
[0m03:46:41.969948 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:46:41.973727 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m03:46:41.977194 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:41.981878 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m03:46:41.984306 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:46:41.986580 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m03:46:41.996334 [debug] [Thread-1 (]: SQL status: COMMIT in 0.006 seconds
[0m03:46:42.003258 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m03:46:42.006779 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m03:46:42.009235 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m03:46:42.012164 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:42.018240 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m03:46:42.023594 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f39ddb20>]}
[0m03:46:42.027777 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 7.61s]
[0m03:46:42.030891 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m03:46:42.033532 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m03:46:42.036431 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m03:46:42.041201 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m03:46:42.044035 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m03:46:42.058552 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m03:46:42.074876 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m03:46:42.090597 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m03:46:42.118001 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:46:42.122105 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m03:46:42.124394 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:46:42.144291 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m03:46:42.147210 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:46:42.150079 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m03:46:43.000796 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.846 seconds
[0m03:46:43.009899 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:46:43.012526 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m03:46:43.015760 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:43.022378 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m03:46:43.025105 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:46:43.027410 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m03:46:43.040672 [debug] [Thread-3 (]: SQL status: COMMIT in 0.011 seconds
[0m03:46:43.050967 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m03:46:43.055110 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m03:46:43.057672 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m03:46:43.060702 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:43.066064 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m03:46:43.069420 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f0857ef0>]}
[0m03:46:43.073260 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 8.65s]
[0m03:46:43.076850 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m03:46:43.079744 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m03:46:43.083052 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m03:46:43.085868 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m03:46:43.089274 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m03:46:43.099336 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.117415 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m03:46:43.130073 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.149226 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.152043 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m03:46:43.155538 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:46:43.176964 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m03:46:43.179517 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.182270 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m03:46:43.626114 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.481 seconds
[0m03:46:43.639273 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:46:43.642549 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m03:46:43.646474 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:43.651063 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m03:46:43.655282 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:46:43.657997 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m03:46:43.712886 [debug] [Thread-4 (]: SQL status: COMMIT in 0.052 seconds
[0m03:46:43.723860 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m03:46:43.726884 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m03:46:43.730865 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m03:46:43.735626 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:43.742304 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m03:46:43.745258 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f08201a0>]}
[0m03:46:43.749119 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 9.32s]
[0m03:46:43.754890 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m03:46:43.843122 [debug] [Thread-3 (]: SQL status: SELECT 18321 in 0.658 seconds
[0m03:46:43.855842 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.859330 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m03:46:43.864980 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.003 seconds
[0m03:46:43.870966 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m03:46:43.873185 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.875394 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m03:46:43.879954 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m03:46:43.888561 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m03:46:43.892119 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m03:46:43.894814 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m03:46:43.897947 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:46:43.902294 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m03:46:43.906154 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f39c4560>]}
[0m03:46:43.909116 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 18321[0m in 0.82s]
[0m03:46:43.912087 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m03:46:47.203991 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 11.611 seconds
[0m03:46:47.215617 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:46:47.219875 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m03:46:47.223928 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:47.228990 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m03:46:47.232000 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:46:47.235451 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m03:46:47.284475 [debug] [Thread-2 (]: SQL status: COMMIT in 0.046 seconds
[0m03:46:47.295615 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m03:46:47.299324 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m03:46:47.303686 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m03:46:47.308142 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:46:47.313976 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m03:46:47.318024 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f083c0b0>]}
[0m03:46:47.321814 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 11.82s]
[0m03:46:47.325242 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m03:46:56.211414 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 14.060 seconds
[0m03:46:56.222406 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:46:56.226003 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m03:46:56.229831 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:46:56.234340 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m03:46:56.236885 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:46:56.239444 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m03:46:56.249319 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m03:46:56.258790 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m03:46:56.262392 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m03:46:56.265148 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m03:46:56.268283 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m03:46:56.273443 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m03:46:56.277028 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7222dbf-876a-4c9b-891f-79958b3c06ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f08922d0>]}
[0m03:46:56.280252 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 14.24s]
[0m03:46:56.283793 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m03:46:56.290007 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:56.292880 [debug] [MainThread]: On master: BEGIN
[0m03:46:56.295496 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:46:56.311167 [debug] [MainThread]: SQL status: BEGIN in 0.016 seconds
[0m03:46:56.314207 [debug] [MainThread]: On master: COMMIT
[0m03:46:56.316607 [debug] [MainThread]: Using postgres connection "master"
[0m03:46:56.319084 [debug] [MainThread]: On master: COMMIT
[0m03:46:56.322382 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:46:56.325380 [debug] [MainThread]: On master: Close
[0m03:46:56.329332 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:46:56.332208 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m03:46:56.334553 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m03:46:56.337271 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m03:46:56.339832 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m03:46:56.342766 [info ] [MainThread]: 
[0m03:46:56.345361 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 22.43 seconds (22.43s).
[0m03:46:56.351975 [debug] [MainThread]: Command end result
[0m03:46:56.469208 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:46:56.484073 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:46:56.515798 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:46:56.518395 [info ] [MainThread]: 
[0m03:46:56.521271 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:46:56.524919 [info ] [MainThread]: 
[0m03:46:56.528152 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m03:46:56.532054 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 26.900969, "process_in_blocks": "0", "process_kernel_time": 0.884052, "process_mem_max_rss": "122632", "process_out_blocks": "0", "process_user_time": 12.798675}
[0m03:46:56.535509 [debug] [MainThread]: Command `dbt run` succeeded at 03:46:56.535127 after 26.90 seconds
[0m03:46:56.538408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f74af170>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f7564f20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff3f6f8efc0>]}
[0m03:46:56.542406 [debug] [MainThread]: Flushing usage events
[0m03:46:58.601119 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:47:41.084152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d191f0230>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d18ff13a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d19702390>]}


============================== 03:47:41.112835 | 10033cdd-bccd-4950-919f-fe546f1ac353 ==============================
[0m03:47:41.112835 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:47:41.117634 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:47:42.712822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1952e120>]}
[0m03:47:42.959273 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d17f07f50>]}
[0m03:47:42.962273 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:47:43.217166 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:47:45.629014 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:47:45.638337 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:47:46.021391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d17ff7950>]}
[0m03:47:46.681689 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:47:46.742501 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:47:46.970950 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d16b5a0f0>]}
[0m03:47:46.975350 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:47:46.979098 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d18a9f2c0>]}
[0m03:47:46.992198 [info ] [MainThread]: 
[0m03:47:46.995739 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:47:46.999085 [info ] [MainThread]: 
[0m03:47:47.005477 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:47:47.027458 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m03:47:47.029844 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m03:47:47.032906 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m03:47:47.221715 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:47:47.223372 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:47:47.224839 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:47:47.227512 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:47:47.231188 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:47:47.235968 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:47:47.239681 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:47.243716 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:47.247630 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:47:47.277445 [debug] [ThreadPool]: SQL status: BEGIN in 0.030 seconds
[0m03:47:47.279004 [debug] [ThreadPool]: SQL status: BEGIN in 0.039 seconds
[0m03:47:47.281852 [debug] [ThreadPool]: SQL status: BEGIN in 0.038 seconds
[0m03:47:47.283541 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:47:47.287961 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:47:47.291593 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:47:47.295329 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:47:47.299067 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:47:47.303873 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:47:47.320784 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.011 seconds
[0m03:47:47.322292 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m03:47:47.324024 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.016 seconds
[0m03:47:47.333288 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:47:47.341088 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:47:47.348928 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:47:47.353142 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:47:47.357867 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:47:47.362066 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:47:47.407879 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:47.411507 [debug] [MainThread]: On master: BEGIN
[0m03:47:47.415131 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:47:47.441426 [debug] [MainThread]: SQL status: BEGIN in 0.026 seconds
[0m03:47:47.447394 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:47.452780 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:47:47.489069 [debug] [MainThread]: SQL status: SELECT 1 in 0.031 seconds
[0m03:47:47.497244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '10033cdd-bccd-4950-919f-fe546f1ac353', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d189cf0b0>]}
[0m03:47:47.502453 [debug] [MainThread]: On master: ROLLBACK
[0m03:47:47.506852 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:47.510313 [debug] [MainThread]: On master: BEGIN
[0m03:47:47.514796 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:47:47.518844 [debug] [MainThread]: On master: COMMIT
[0m03:47:47.522520 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:47.525873 [debug] [MainThread]: On master: COMMIT
[0m03:47:47.529997 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:47:47.533926 [debug] [MainThread]: On master: Close
[0m03:47:47.551981 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:47:47.553930 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:47:47.557327 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m03:47:47.561488 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m03:47:47.565806 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m03:47:47.571190 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m03:47:47.575047 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:47:47.579215 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:47:47.711272 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:47:47.723808 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:47:47.744324 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:47:47.748026 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:47:47.841446 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:47:47.843358 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:47:47.857490 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:47:47.861278 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m03:47:47.862932 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:47:47.865961 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:47:47.870457 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m03:47:47.877359 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:47:47.894013 [debug] [Thread-2 (]: SQL status: BEGIN in 0.028 seconds
[0m03:47:47.898182 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m03:47:47.901606 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m03:47:47.903548 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m03:47:47.907868 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m03:47:47.913700 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m03:47:47.915827 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.004 seconds
[0m03:47:47.928346 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.008 seconds
[0m03:47:47.936491 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m03:47:47.942562 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m03:47:47.946898 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m03:47:47.951288 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m03:47:47.955891 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.38s]
[0m03:47:47.960344 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.39s]
[0m03:47:47.964515 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m03:47:47.969361 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m03:47:47.981615 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:47.985561 [debug] [MainThread]: On master: BEGIN
[0m03:47:47.989063 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:47:48.012534 [debug] [MainThread]: SQL status: BEGIN in 0.023 seconds
[0m03:47:48.016376 [debug] [MainThread]: On master: COMMIT
[0m03:47:48.020518 [debug] [MainThread]: Using postgres connection "master"
[0m03:47:48.024121 [debug] [MainThread]: On master: COMMIT
[0m03:47:48.028327 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:47:48.033115 [debug] [MainThread]: On master: Close
[0m03:47:48.041225 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:47:48.047577 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m03:47:48.054186 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m03:47:48.060193 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m03:47:48.067066 [info ] [MainThread]: 
[0m03:47:48.074642 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 1.06 seconds (1.06s).
[0m03:47:48.085848 [debug] [MainThread]: Command end result
[0m03:47:48.399743 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:47:48.433193 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:47:48.508788 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:47:48.515194 [info ] [MainThread]: 
[0m03:47:48.523498 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:47:48.530298 [info ] [MainThread]: 
[0m03:47:48.539343 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m03:47:48.550282 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 7.7657843, "process_in_blocks": "1120", "process_kernel_time": 0.984233, "process_mem_max_rss": "124012", "process_out_blocks": "0", "process_user_time": 11.971496}
[0m03:47:48.558971 [debug] [MainThread]: Command `dbt test` succeeded at 03:47:48.558284 after 7.78 seconds
[0m03:47:48.565677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1a452f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1ae88ec0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1490e1e0>]}
[0m03:47:48.573296 [debug] [MainThread]: Flushing usage events
[0m03:47:50.310837 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m03:57:31.384242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd738a29790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd736866d20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd736fc2540>]}


============================== 03:57:31.440831 | 6a988aea-a6c7-4f34-93c5-f441d3422b70 ==============================
[0m03:57:31.440831 [info ] [MainThread]: Running with dbt=1.9.4
[0m03:57:31.448492 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m03:57:32.757719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd735560500>]}
[0m03:57:32.993402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd736b96f30>]}
[0m03:57:32.996921 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m03:57:33.275227 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m03:57:35.185138 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m03:57:35.190788 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m03:57:35.598957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd735563d10>]}
[0m03:57:35.960493 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:57:35.986383 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:57:36.072861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd73454fd70>]}
[0m03:57:36.076728 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m03:57:36.080176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd735541ee0>]}
[0m03:57:36.089795 [info ] [MainThread]: 
[0m03:57:36.093776 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m03:57:36.097003 [info ] [MainThread]: 
[0m03:57:36.100982 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m03:57:36.120396 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:36.122940 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:36.125905 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m03:57:36.298438 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:36.300351 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:36.302140 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m03:57:36.305481 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:36.309898 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:36.313558 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m03:57:36.317874 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:36.321771 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:36.326417 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m03:57:36.360803 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.039 seconds
[0m03:57:36.369211 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:36.371105 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.053 seconds
[0m03:57:36.373605 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.047 seconds
[0m03:57:36.384892 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:36.391547 [debug] [ThreadPool]: On list_airflow: Close
[0m03:57:36.413304 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m03:57:36.416469 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m03:57:36.421153 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m03:57:36.445808 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:57:36.452364 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:57:36.462791 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:57:36.467091 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m03:57:36.471105 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m03:57:36.476326 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m03:57:36.480304 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:36.484286 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:36.488174 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m03:57:36.513765 [debug] [ThreadPool]: SQL status: BEGIN in 0.033 seconds
[0m03:57:36.517814 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m03:57:36.519552 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m03:57:36.522210 [debug] [ThreadPool]: SQL status: BEGIN in 0.034 seconds
[0m03:57:36.523936 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m03:57:36.527914 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m03:57:36.531470 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m03:57:36.537685 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m03:57:36.541857 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m03:57:36.543816 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.009 seconds
[0m03:57:36.554946 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m03:57:36.556649 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.009 seconds
[0m03:57:36.559205 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.010 seconds
[0m03:57:36.562013 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m03:57:36.568403 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m03:57:36.575589 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m03:57:36.587171 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m03:57:36.591127 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m03:57:36.620447 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:36.624186 [debug] [MainThread]: On master: BEGIN
[0m03:57:36.627819 [debug] [MainThread]: Opening a new connection, currently in state init
[0m03:57:36.650300 [debug] [MainThread]: SQL status: BEGIN in 0.022 seconds
[0m03:57:36.654122 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:36.659290 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m03:57:36.688569 [debug] [MainThread]: SQL status: SELECT 1 in 0.024 seconds
[0m03:57:36.697826 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd73410b0e0>]}
[0m03:57:36.702709 [debug] [MainThread]: On master: ROLLBACK
[0m03:57:36.707872 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:36.712171 [debug] [MainThread]: On master: BEGIN
[0m03:57:36.717746 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m03:57:36.722294 [debug] [MainThread]: On master: COMMIT
[0m03:57:36.726592 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:36.731602 [debug] [MainThread]: On master: COMMIT
[0m03:57:36.737278 [debug] [MainThread]: SQL status: COMMIT in 0.001 seconds
[0m03:57:36.741724 [debug] [MainThread]: On master: Close
[0m03:57:36.762043 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m03:57:36.767634 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m03:57:36.772814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stg_stock_predictions)
[0m03:57:36.777775 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m03:57:36.816006 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m03:57:36.865656 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m03:57:37.040593 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m03:57:37.071629 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:37.075204 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m03:57:37.078841 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:37.101191 [debug] [Thread-1 (]: SQL status: BEGIN in 0.022 seconds
[0m03:57:37.105078 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:37.108798 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m03:57:37.120413 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.008 seconds
[0m03:57:37.145229 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:37.149565 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m03:57:37.154974 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:57:37.211949 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:57:37.217112 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:37.221688 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m03:57:37.234098 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m03:57:37.264540 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m03:57:37.291532 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m03:57:37.297912 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m03:57:37.306358 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.002 seconds
[0m03:57:37.326797 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m03:57:37.339551 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7384f7440>]}
[0m03:57:37.348279 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.56s]
[0m03:57:37.356310 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m03:57:37.365566 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m03:57:37.372589 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m03:57:37.379366 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m03:57:37.386809 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m03:57:37.418130 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m03:57:37.475177 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m03:57:37.635146 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m03:57:37.692827 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:37.699881 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m03:57:37.706786 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m03:57:37.745873 [debug] [Thread-3 (]: SQL status: BEGIN in 0.039 seconds
[0m03:57:37.752084 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:37.758686 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m03:57:38.947690 [debug] [Thread-3 (]: SQL status: SELECT 1 in 1.182 seconds
[0m03:57:38.971349 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:38.975017 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m03:57:38.979170 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:57:38.985628 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m03:57:38.989100 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:38.992554 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m03:57:39.002179 [debug] [Thread-3 (]: SQL status: COMMIT in 0.006 seconds
[0m03:57:39.011913 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m03:57:39.022976 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m03:57:39.026523 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m03:57:39.030514 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:57:39.037389 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m03:57:39.041389 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd73021dcd0>]}
[0m03:57:39.045559 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 1.66s]
[0m03:57:39.049873 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m03:57:39.054978 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m03:57:39.057187 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m03:57:39.062231 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m03:57:39.067840 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m03:57:39.075794 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.lstm_performance_metrics)
[0m03:57:39.080584 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m03:57:39.085461 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m03:57:39.090234 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m03:57:39.115244 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.132254 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m03:57:39.153725 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m03:57:39.156805 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m03:57:39.171275 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.186562 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m03:57:39.205516 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.209960 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m03:57:39.212544 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m03:57:39.216075 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m03:57:39.220236 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m03:57:39.228080 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m03:57:39.248363 [debug] [Thread-2 (]: SQL status: BEGIN in 0.032 seconds
[0m03:57:39.252314 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.255059 [debug] [Thread-1 (]: SQL status: BEGIN in 0.027 seconds
[0m03:57:39.258287 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m03:57:39.262529 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m03:57:39.268539 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m03:57:39.289993 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.023 seconds
[0m03:57:39.303283 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.307615 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m03:57:39.312992 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:57:39.319669 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m03:57:39.323530 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.327310 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m03:57:39.336804 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m03:57:39.348167 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m03:57:39.352607 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m03:57:39.356821 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m03:57:39.361228 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:57:39.368217 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m03:57:39.373641 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7323d0860>]}
[0m03:57:39.379950 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.30s]
[0m03:57:39.385869 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m03:57:46.262510 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 6.989 seconds
[0m03:57:46.283236 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m03:57:46.286135 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m03:57:46.289823 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m03:57:46.295400 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m03:57:46.298807 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m03:57:46.301898 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m03:57:46.341054 [debug] [Thread-1 (]: SQL status: COMMIT in 0.037 seconds
[0m03:57:46.348872 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m03:57:46.351977 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m03:57:46.354602 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m03:57:46.358129 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m03:57:46.368949 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m03:57:46.387528 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6a988aea-a6c7-4f34-93c5-f441d3422b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd730232e10>]}
[0m03:57:46.391262 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 7.31s]
[0m03:57:46.395310 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m03:57:46.407622 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:46.410578 [debug] [MainThread]: On master: BEGIN
[0m03:57:46.412750 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m03:57:46.477089 [debug] [MainThread]: SQL status: BEGIN in 0.064 seconds
[0m03:57:46.479614 [debug] [MainThread]: On master: COMMIT
[0m03:57:46.482454 [debug] [MainThread]: Using postgres connection "master"
[0m03:57:46.485398 [debug] [MainThread]: On master: COMMIT
[0m03:57:46.488504 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m03:57:46.490828 [debug] [MainThread]: On master: Close
[0m03:57:46.494734 [debug] [MainThread]: Connection 'master' was properly closed.
[0m03:57:46.497188 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m03:57:46.500127 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m03:57:46.503268 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m03:57:46.506666 [info ] [MainThread]: 
[0m03:57:46.509254 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 10.41 seconds (10.41s).
[0m03:57:46.515609 [debug] [MainThread]: Command end result
[0m03:57:46.634023 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m03:57:46.647892 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m03:57:46.674728 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m03:57:46.677840 [info ] [MainThread]: 
[0m03:57:46.680734 [info ] [MainThread]: [32mCompleted successfully[0m
[0m03:57:46.683361 [info ] [MainThread]: 
[0m03:57:46.686259 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m03:57:46.691903 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 15.731369, "process_in_blocks": "0", "process_kernel_time": 0.762497, "process_mem_max_rss": "121776", "process_out_blocks": "0", "process_user_time": 10.444203}
[0m03:57:46.695840 [debug] [MainThread]: Command `dbt run` succeeded at 03:57:46.695406 after 15.74 seconds
[0m03:57:46.698313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd739ff7260>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd736e2f320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd7345f8200>]}
[0m03:57:46.700849 [debug] [MainThread]: Flushing usage events
[0m03:57:48.439188 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:09:25.415136 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a55590cb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a55593440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a554b2e70>]}


============================== 06:09:25.429867 | d6b168ec-69b6-436d-abbc-59cf8f193b00 ==============================
[0m06:09:25.429867 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:09:25.432701 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/opt/airflow/dbt', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select staging --exclude stg_stock_predictions', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m06:09:25.854032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a55e0c8f0>]}
[0m06:09:25.962343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a54ac0b90>]}
[0m06:09:25.965054 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:09:26.139194 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:09:26.914387 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:09:26.916464 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:09:27.008216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a53b1fe30>]}
[0m06:09:27.215739 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:09:27.232547 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:09:27.340015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a54ad0140>]}
[0m06:09:27.342577 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:09:27.345858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a53f03f50>]}
[0m06:09:27.351720 [info ] [MainThread]: 
[0m06:09:27.354019 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:09:27.356258 [info ] [MainThread]: 
[0m06:09:27.358556 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:09:27.363884 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:09:27.447958 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:09:27.449705 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:09:27.451480 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:27.466202 [debug] [ThreadPool]: SQL status: SELECT 4 in 0.015 seconds
[0m06:09:27.472588 [debug] [ThreadPool]: On list_airflow: Close
[0m06:09:27.475940 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_staging)
[0m06:09:27.479256 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_staging"
"
[0m06:09:27.493489 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m06:09:27.497177 [debug] [ThreadPool]: On create_airflow_public_staging: BEGIN
[0m06:09:27.499024 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:27.512231 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m06:09:27.514956 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m06:09:27.516883 [debug] [ThreadPool]: On create_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_staging"} */
create schema if not exists "public_staging"
[0m06:09:27.519962 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m06:09:27.522917 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m06:09:27.524799 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_staging"
[0m06:09:27.527245 [debug] [ThreadPool]: On create_airflow_public_staging: COMMIT
[0m06:09:27.535090 [debug] [ThreadPool]: SQL status: COMMIT in 0.005 seconds
[0m06:09:27.537624 [debug] [ThreadPool]: On create_airflow_public_staging: Close
[0m06:09:27.555623 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_staging, now list_airflow_public_core)
[0m06:09:27.559960 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m06:09:27.562613 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m06:09:27.582908 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:27.589948 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:27.601315 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:27.603608 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:09:27.606299 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:09:27.608916 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:09:27.611650 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:27.614802 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:27.617707 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:27.637497 [debug] [ThreadPool]: SQL status: BEGIN in 0.026 seconds
[0m06:09:27.647639 [debug] [ThreadPool]: SQL status: BEGIN in 0.032 seconds
[0m06:09:27.650259 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:27.653055 [debug] [ThreadPool]: SQL status: BEGIN in 0.035 seconds
[0m06:09:27.657157 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:27.662590 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:09:27.666742 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:27.669873 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:09:27.674496 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:09:27.683689 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.011 seconds
[0m06:09:27.691034 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:09:27.692401 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.012 seconds
[0m06:09:27.693890 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.011 seconds
[0m06:09:27.698181 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:09:27.702937 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:09:27.709727 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:09:27.716256 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:09:27.721034 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:09:27.750129 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:27.760118 [debug] [MainThread]: On master: BEGIN
[0m06:09:27.772420 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:09:27.809705 [debug] [MainThread]: SQL status: BEGIN in 0.037 seconds
[0m06:09:27.815290 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:27.819971 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:09:27.842457 [debug] [MainThread]: SQL status: SELECT 0 in 0.012 seconds
[0m06:09:27.851547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a51aa61b0>]}
[0m06:09:27.855570 [debug] [MainThread]: On master: ROLLBACK
[0m06:09:27.859726 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:27.863135 [debug] [MainThread]: On master: BEGIN
[0m06:09:27.866917 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:09:27.871473 [debug] [MainThread]: On master: COMMIT
[0m06:09:27.874302 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:27.877259 [debug] [MainThread]: On master: COMMIT
[0m06:09:27.881098 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:09:27.883916 [debug] [MainThread]: On master: Close
[0m06:09:27.899901 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_daily_stock_summary
[0m06:09:27.902602 [info ] [Thread-1 (]: 1 of 1 START sql view model public_staging.stg_daily_stock_summary ............. [RUN]
[0m06:09:27.905125 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_daily_stock_summary)
[0m06:09:27.907357 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_daily_stock_summary
[0m06:09:27.939366 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_daily_stock_summary"
[0m06:09:27.970260 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_daily_stock_summary
[0m06:09:28.068750 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.086209 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.088469 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: BEGIN
[0m06:09:28.091011 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:09:28.105857 [debug] [Thread-1 (]: SQL status: BEGIN in 0.015 seconds
[0m06:09:28.108954 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.112698 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */

  create view "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp"
    
    
  as (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    volume,
    value,
    frequency,
    index_individual,
    weight_for_index,
    foreign_buy,
    foreign_sell,
    offer,
    offer_volume,
    bid,
    bid_volume,
    listed_shares,
    tradable_shares,
    non_regular_volume,
    non_regular_value,
    non_regular_frequency,
    upload_file
FROM public.daily_stock_summary
  );
[0m06:09:28.120182 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.005 seconds
[0m06:09:28.136888 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.139071 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
alter table "airflow"."public_staging"."stg_daily_stock_summary__dbt_tmp" rename to "stg_daily_stock_summary"
[0m06:09:28.141979 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:28.179051 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m06:09:28.181418 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.183718 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: COMMIT
[0m06:09:28.190110 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m06:09:28.206121 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup"
[0m06:09:28.219631 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_daily_stock_summary"
[0m06:09:28.222338 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_daily_stock_summary"} */
drop view if exists "airflow"."public_staging"."stg_daily_stock_summary__dbt_backup" cascade
[0m06:09:28.228790 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.001 seconds
[0m06:09:28.238010 [debug] [Thread-1 (]: On model.idx_stock.stg_daily_stock_summary: Close
[0m06:09:28.246163 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd6b168ec-69b6-436d-abbc-59cf8f193b00', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a56b9d3d0>]}
[0m06:09:28.249278 [info ] [Thread-1 (]: 1 of 1 OK created sql view model public_staging.stg_daily_stock_summary ........ [[32mCREATE VIEW[0m in 0.34s]
[0m06:09:28.252737 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_daily_stock_summary
[0m06:09:28.258823 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:28.261315 [debug] [MainThread]: On master: BEGIN
[0m06:09:28.263497 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:09:28.277006 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m06:09:28.280053 [debug] [MainThread]: On master: COMMIT
[0m06:09:28.282747 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:28.285032 [debug] [MainThread]: On master: COMMIT
[0m06:09:28.287765 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:09:28.290103 [debug] [MainThread]: On master: Close
[0m06:09:28.292768 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:09:28.295270 [debug] [MainThread]: Connection 'list_airflow_public_core' was properly closed.
[0m06:09:28.297437 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m06:09:28.299751 [debug] [MainThread]: Connection 'model.idx_stock.stg_daily_stock_summary' was properly closed.
[0m06:09:28.302026 [info ] [MainThread]: 
[0m06:09:28.304754 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.94 seconds (0.94s).
[0m06:09:28.308609 [debug] [MainThread]: Command end result
[0m06:09:28.445412 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:09:28.461649 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:09:28.487999 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:09:28.489837 [info ] [MainThread]: 
[0m06:09:28.493178 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:09:28.497105 [info ] [MainThread]: 
[0m06:09:28.499882 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m06:09:28.504538 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.200825, "process_in_blocks": "0", "process_kernel_time": 0.657959, "process_mem_max_rss": "122780", "process_out_blocks": "2360", "process_user_time": 5.506614}
[0m06:09:28.508038 [debug] [MainThread]: Command `dbt run` succeeded at 06:09:28.507497 after 3.20 seconds
[0m06:09:28.512351 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a54ac3fe0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a55593b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3a55592c60>]}
[0m06:09:28.515203 [debug] [MainThread]: Flushing usage events
[0m06:09:29.690157 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:09:34.929607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a5e17c80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a8b919d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a5f35b20>]}


============================== 06:09:34.943273 | be04171d-ba47-458a-830a-1dbf788ecff5 ==============================
[0m06:09:34.943273 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:09:34.945309 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'warn_error': 'None', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.core --exclude fct_stock_predictions', 'static_parser': 'True', 'introspect': 'True', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m06:09:35.324594 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a7317380>]}
[0m06:09:35.449330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a4aa3920>]}
[0m06:09:35.452090 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:09:35.642653 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:09:36.296563 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:09:36.298532 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:09:36.420807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a4ad9a60>]}
[0m06:09:36.669317 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:09:36.687333 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:09:36.733920 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a3b1d460>]}
[0m06:09:36.736206 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:09:36.739126 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a4adbaa0>]}
[0m06:09:36.744816 [info ] [MainThread]: 
[0m06:09:36.747227 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:09:36.749328 [info ] [MainThread]: 
[0m06:09:36.751877 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:09:36.761423 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:09:36.830018 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:09:36.832332 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:09:36.835134 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:36.849558 [debug] [ThreadPool]: SQL status: SELECT 5 in 0.014 seconds
[0m06:09:36.854376 [debug] [ThreadPool]: On list_airflow: Close
[0m06:09:36.857316 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_core)
[0m06:09:36.859765 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_core"
"
[0m06:09:36.872958 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m06:09:36.875063 [debug] [ThreadPool]: On create_airflow_public_core: BEGIN
[0m06:09:36.877116 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:36.889847 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m06:09:36.892282 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m06:09:36.894255 [debug] [ThreadPool]: On create_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_core"} */
create schema if not exists "public_core"
[0m06:09:36.897657 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m06:09:36.901487 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m06:09:36.904054 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_core"
[0m06:09:36.906078 [debug] [ThreadPool]: On create_airflow_public_core: COMMIT
[0m06:09:36.914780 [debug] [ThreadPool]: SQL status: COMMIT in 0.007 seconds
[0m06:09:36.917098 [debug] [ThreadPool]: On create_airflow_public_core: Close
[0m06:09:36.923618 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_core, now list_airflow_public_analytics)
[0m06:09:36.925085 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m06:09:36.926903 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m06:09:36.939781 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:36.946222 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:36.951505 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:36.954284 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:09:36.956518 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:09:36.958716 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:09:36.960846 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:36.963244 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:36.965561 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:36.979406 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m06:09:36.981721 [debug] [ThreadPool]: SQL status: BEGIN in 0.018 seconds
[0m06:09:36.983643 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:36.984916 [debug] [ThreadPool]: SQL status: BEGIN in 0.019 seconds
[0m06:09:36.987557 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:36.989920 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:09:36.992497 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:36.994669 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:09:36.998382 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:09:37.000539 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.004 seconds
[0m06:09:37.007030 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:09:37.008244 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m06:09:37.009120 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.006 seconds
[0m06:09:37.011071 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:09:37.014299 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:09:37.018176 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:09:37.022240 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:09:37.024536 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:09:37.039835 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:37.041978 [debug] [MainThread]: On master: BEGIN
[0m06:09:37.044024 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:09:37.058348 [debug] [MainThread]: SQL status: BEGIN in 0.014 seconds
[0m06:09:37.061423 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:37.064130 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:09:37.079581 [debug] [MainThread]: SQL status: SELECT 1 in 0.013 seconds
[0m06:09:37.083798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a4b4dd00>]}
[0m06:09:37.086459 [debug] [MainThread]: On master: ROLLBACK
[0m06:09:37.089120 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:37.091202 [debug] [MainThread]: On master: BEGIN
[0m06:09:37.093881 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:09:37.096519 [debug] [MainThread]: On master: COMMIT
[0m06:09:37.098611 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:37.100659 [debug] [MainThread]: On master: COMMIT
[0m06:09:37.103538 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:09:37.105946 [debug] [MainThread]: On master: Close
[0m06:09:37.116416 [debug] [Thread-1 (]: Began running node model.idx_stock.dim_companies
[0m06:09:37.117814 [debug] [Thread-2 (]: Began running node model.idx_stock.fct_daily_stock_metrics
[0m06:09:37.121751 [info ] [Thread-1 (]: 1 of 2 START sql table model public_core.dim_companies ......................... [RUN]
[0m06:09:37.125044 [info ] [Thread-2 (]: 2 of 2 START sql table model public_core.fct_daily_stock_metrics ............... [RUN]
[0m06:09:37.128853 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.dim_companies)
[0m06:09:37.132295 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_daily_stock_metrics)
[0m06:09:37.134667 [debug] [Thread-1 (]: Began compiling node model.idx_stock.dim_companies
[0m06:09:37.137647 [debug] [Thread-2 (]: Began compiling node model.idx_stock.fct_daily_stock_metrics
[0m06:09:37.153530 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.dim_companies"
[0m06:09:37.160085 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:37.170937 [debug] [Thread-1 (]: Began executing node model.idx_stock.dim_companies
[0m06:09:37.179446 [debug] [Thread-2 (]: Began executing node model.idx_stock.fct_daily_stock_metrics
[0m06:09:37.293918 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:37.294829 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.dim_companies"
[0m06:09:37.305358 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:37.307243 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m06:09:37.308139 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: BEGIN
[0m06:09:37.310206 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: BEGIN
[0m06:09:37.312230 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:09:37.314273 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:09:37.326192 [debug] [Thread-2 (]: SQL status: BEGIN in 0.014 seconds
[0m06:09:37.328317 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m06:09:37.330243 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:37.332420 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m06:09:37.334620 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */

  
    

  create  table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    -- /opt/airflow/dbt/models/marts/core/fct_daily_stock_metrics.sql


WITH daily_data AS (
    SELECT
        symbol,
        name,
        date,
        prev_close,
        open_price,
        high,
        low,
        close,
        change,
        volume,
        value,
        frequency,
        foreign_buy,
        foreign_sell
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM daily_data
  );
  
[0m06:09:37.337463 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */

  
    

  create  table "airflow"."public_core"."dim_companies__dbt_tmp"
  
  
    as
  
  (
    WITH ranked_companies AS (
    SELECT *,
           ROW_NUMBER() OVER (PARTITION BY symbol ORDER BY date DESC) as rank
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT 
    symbol,
    name,
    listed_shares,
    tradable_shares,
    date as last_updated_date
FROM ranked_companies
WHERE rank = 1
  );
  
[0m06:09:40.866310 [debug] [Thread-1 (]: SQL status: SELECT 963 in 3.525 seconds
[0m06:09:40.893667 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m06:09:40.895893 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
alter table "airflow"."public_core"."dim_companies__dbt_tmp" rename to "dim_companies"
[0m06:09:40.898248 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:40.935468 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m06:09:40.938167 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m06:09:40.940303 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: COMMIT
[0m06:09:40.981235 [debug] [Thread-1 (]: SQL status: COMMIT in 0.039 seconds
[0m06:09:40.995692 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_core"."dim_companies__dbt_backup"
[0m06:09:41.007253 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.dim_companies"
[0m06:09:41.009416 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.dim_companies"} */
drop table if exists "airflow"."public_core"."dim_companies__dbt_backup" cascade
[0m06:09:41.011988 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:09:41.018075 [debug] [Thread-1 (]: On model.idx_stock.dim_companies: Close
[0m06:09:41.022384 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a5df0b60>]}
[0m06:09:41.025004 [info ] [Thread-1 (]: 1 of 2 OK created sql table model public_core.dim_companies .................... [[32mSELECT 963[0m in 3.89s]
[0m06:09:41.027774 [debug] [Thread-1 (]: Finished running node model.idx_stock.dim_companies
[0m06:09:41.441874 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 4.102 seconds
[0m06:09:41.448737 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:41.450919 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
alter table "airflow"."public_core"."fct_daily_stock_metrics__dbt_tmp" rename to "fct_daily_stock_metrics"
[0m06:09:41.453184 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:09:41.456457 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m06:09:41.458307 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:41.459812 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: COMMIT
[0m06:09:41.470504 [debug] [Thread-2 (]: SQL status: COMMIT in 0.009 seconds
[0m06:09:41.476752 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup"
[0m06:09:41.479085 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.fct_daily_stock_metrics"
[0m06:09:41.481020 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_daily_stock_metrics"} */
drop table if exists "airflow"."public_core"."fct_daily_stock_metrics__dbt_backup" cascade
[0m06:09:41.483616 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m06:09:41.487501 [debug] [Thread-2 (]: On model.idx_stock.fct_daily_stock_metrics: Close
[0m06:09:41.490045 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'be04171d-ba47-458a-830a-1dbf788ecff5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a23cfb90>]}
[0m06:09:41.492505 [info ] [Thread-2 (]: 2 of 2 OK created sql table model public_core.fct_daily_stock_metrics .......... [[32mSELECT 701981[0m in 4.36s]
[0m06:09:41.494845 [debug] [Thread-2 (]: Finished running node model.idx_stock.fct_daily_stock_metrics
[0m06:09:41.499288 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:41.502005 [debug] [MainThread]: On master: BEGIN
[0m06:09:41.504173 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:09:41.515792 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m06:09:41.519058 [debug] [MainThread]: On master: COMMIT
[0m06:09:41.521268 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:41.523083 [debug] [MainThread]: On master: COMMIT
[0m06:09:41.525300 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:09:41.527308 [debug] [MainThread]: On master: Close
[0m06:09:41.529392 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:09:41.531314 [debug] [MainThread]: Connection 'list_airflow_public_analytics' was properly closed.
[0m06:09:41.533502 [debug] [MainThread]: Connection 'model.idx_stock.fct_daily_stock_metrics' was properly closed.
[0m06:09:41.536082 [debug] [MainThread]: Connection 'model.idx_stock.dim_companies' was properly closed.
[0m06:09:41.538721 [info ] [MainThread]: 
[0m06:09:41.540939 [info ] [MainThread]: Finished running 2 table models in 0 hours 0 minutes and 4.79 seconds (4.79s).
[0m06:09:41.543841 [debug] [MainThread]: Command end result
[0m06:09:41.636809 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:09:41.647308 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:09:41.669797 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:09:41.672350 [info ] [MainThread]: 
[0m06:09:41.674995 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:09:41.677623 [info ] [MainThread]: 
[0m06:09:41.679961 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:09:41.683703 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 6.861612, "process_in_blocks": "0", "process_kernel_time": 0.351813, "process_mem_max_rss": "122292", "process_out_blocks": "0", "process_user_time": 4.814814}
[0m06:09:41.686718 [debug] [MainThread]: Command `dbt run` succeeded at 06:09:41.686423 after 6.86 seconds
[0m06:09:41.689198 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a532ed50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a532e8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f47a5c7f2c0>]}
[0m06:09:41.691800 [debug] [MainThread]: Flushing usage events
[0m06:09:42.777041 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:09:48.198570 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe712f16180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713773350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713772b70>]}


============================== 06:09:48.212464 | 0555cacc-a714-423f-8391-38da78b6e703 ==============================
[0m06:09:48.212464 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:09:48.215176 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select marts.analytics --exclude lstm_performance_metrics stock_prediction_dashboard', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:09:48.648922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe715324d40>]}
[0m06:09:48.770907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe71210bb30>]}
[0m06:09:48.773423 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:09:48.979800 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:09:49.791083 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:09:49.793798 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:09:49.895239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7121f7110>]}
[0m06:09:50.150594 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:09:50.170187 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:09:50.219403 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe711146fc0>]}
[0m06:09:50.221741 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:09:50.223927 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe71210bc50>]}
[0m06:09:50.230004 [info ] [MainThread]: 
[0m06:09:50.232269 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:09:50.234599 [info ] [MainThread]: 
[0m06:09:50.237097 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:09:50.248897 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:09:50.320079 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:09:50.322087 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:09:50.323926 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:50.338035 [debug] [ThreadPool]: SQL status: SELECT 6 in 0.014 seconds
[0m06:09:50.341602 [debug] [ThreadPool]: On list_airflow: Close
[0m06:09:50.344644 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now create_airflow_public_analytics)
[0m06:09:50.346898 [debug] [ThreadPool]: Creating schema "database: "airflow"
schema: "public_analytics"
"
[0m06:09:50.357603 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m06:09:50.359926 [debug] [ThreadPool]: On create_airflow_public_analytics: BEGIN
[0m06:09:50.362383 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:50.374836 [debug] [ThreadPool]: SQL status: BEGIN in 0.012 seconds
[0m06:09:50.377542 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m06:09:50.379528 [debug] [ThreadPool]: On create_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "create_airflow_public_analytics"} */
create schema if not exists "public_analytics"
[0m06:09:50.382514 [debug] [ThreadPool]: SQL status: CREATE SCHEMA in 0.001 seconds
[0m06:09:50.385956 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m06:09:50.388131 [debug] [ThreadPool]: Using postgres connection "create_airflow_public_analytics"
[0m06:09:50.390194 [debug] [ThreadPool]: On create_airflow_public_analytics: COMMIT
[0m06:09:50.394436 [debug] [ThreadPool]: SQL status: COMMIT in 0.002 seconds
[0m06:09:50.396664 [debug] [ThreadPool]: On create_airflow_public_analytics: Close
[0m06:09:50.402440 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_airflow_public_analytics, now list_airflow_public_staging)
[0m06:09:50.405501 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m06:09:50.407005 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m06:09:50.421083 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:50.425581 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:50.431210 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:50.433595 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:09:50.435934 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:09:50.438156 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:09:50.440343 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:09:50.442594 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:50.444886 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:09:50.459236 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m06:09:50.461726 [debug] [ThreadPool]: SQL status: BEGIN in 0.021 seconds
[0m06:09:50.463314 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:09:50.465481 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:09:50.466863 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m06:09:50.469184 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:09:50.471685 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:09:50.474194 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:09:50.479510 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:09:50.481247 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m06:09:50.482809 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m06:09:50.488925 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:09:50.490164 [debug] [ThreadPool]: SQL status: SELECT 0 in 0.007 seconds
[0m06:09:50.494103 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:09:50.496904 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:09:50.499706 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:09:50.502264 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:09:50.506553 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:09:50.525639 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:50.528646 [debug] [MainThread]: On master: BEGIN
[0m06:09:50.530834 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:09:50.543662 [debug] [MainThread]: SQL status: BEGIN in 0.013 seconds
[0m06:09:50.546212 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:50.548441 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:09:50.560603 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m06:09:50.564571 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7148bd250>]}
[0m06:09:50.566963 [debug] [MainThread]: On master: ROLLBACK
[0m06:09:50.569407 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:50.571476 [debug] [MainThread]: On master: BEGIN
[0m06:09:50.574489 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:09:50.577596 [debug] [MainThread]: On master: COMMIT
[0m06:09:50.579568 [debug] [MainThread]: Using postgres connection "master"
[0m06:09:50.581517 [debug] [MainThread]: On master: COMMIT
[0m06:09:50.583925 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:09:50.586194 [debug] [MainThread]: On master: Close
[0m06:09:50.597300 [debug] [Thread-1 (]: Began running node model.idx_stock.daily_stock_metrics
[0m06:09:50.598311 [debug] [Thread-2 (]: Began running node model.idx_stock.stock_performance_daily
[0m06:09:50.599273 [debug] [Thread-3 (]: Began running node model.idx_stock.stock_performance_monthly
[0m06:09:50.600255 [debug] [Thread-4 (]: Began running node model.idx_stock.stock_performance_weekly
[0m06:09:50.601878 [info ] [Thread-1 (]: 1 of 7 START sql table model public_analytics.daily_stock_metrics .............. [RUN]
[0m06:09:50.604647 [info ] [Thread-2 (]: 2 of 7 START sql table model public_analytics.stock_performance_daily .......... [RUN]
[0m06:09:50.607087 [info ] [Thread-3 (]: 3 of 7 START sql table model public_analytics.stock_performance_monthly ........ [RUN]
[0m06:09:50.610044 [info ] [Thread-4 (]: 4 of 7 START sql table model public_analytics.stock_performance_weekly ......... [RUN]
[0m06:09:50.613363 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.daily_stock_metrics)
[0m06:09:50.615697 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.stock_performance_daily)
[0m06:09:50.617956 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stock_performance_monthly)
[0m06:09:50.620557 [debug] [Thread-4 (]: Acquiring new postgres connection 'model.idx_stock.stock_performance_weekly'
[0m06:09:50.622785 [debug] [Thread-1 (]: Began compiling node model.idx_stock.daily_stock_metrics
[0m06:09:50.625450 [debug] [Thread-2 (]: Began compiling node model.idx_stock.stock_performance_daily
[0m06:09:50.628111 [debug] [Thread-3 (]: Began compiling node model.idx_stock.stock_performance_monthly
[0m06:09:50.630421 [debug] [Thread-4 (]: Began compiling node model.idx_stock.stock_performance_weekly
[0m06:09:50.648462 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.daily_stock_metrics"
[0m06:09:50.655830 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.stock_performance_daily"
[0m06:09:50.664065 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.stock_performance_monthly"
[0m06:09:50.672386 [debug] [Thread-4 (]: Writing injected SQL for node "model.idx_stock.stock_performance_weekly"
[0m06:09:50.684135 [debug] [Thread-3 (]: Began executing node model.idx_stock.stock_performance_monthly
[0m06:09:50.686537 [debug] [Thread-4 (]: Began executing node model.idx_stock.stock_performance_weekly
[0m06:09:50.693628 [debug] [Thread-2 (]: Began executing node model.idx_stock.stock_performance_daily
[0m06:09:50.694916 [debug] [Thread-1 (]: Began executing node model.idx_stock.daily_stock_metrics
[0m06:09:50.849896 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.stock_performance_monthly"
[0m06:09:50.857086 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.stock_performance_daily"
[0m06:09:50.864147 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.daily_stock_metrics"
[0m06:09:50.869037 [debug] [Thread-4 (]: Writing runtime sql for node "model.idx_stock.stock_performance_weekly"
[0m06:09:50.881003 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m06:09:50.882606 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m06:09:50.884834 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: BEGIN
[0m06:09:50.886034 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m06:09:50.888506 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: BEGIN
[0m06:09:50.890124 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m06:09:50.892489 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:09:50.894627 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: BEGIN
[0m06:09:50.896761 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m06:09:50.899199 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: BEGIN
[0m06:09:50.902593 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:09:50.906438 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:09:50.913464 [debug] [Thread-3 (]: SQL status: BEGIN in 0.021 seconds
[0m06:09:50.916071 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m06:09:50.919038 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

monthly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('month', date) as month_starting,
        MIN(date) as first_date_of_month,
        MAX(date) as last_date_of_month,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as monthly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('month', date)
),

latest_month AS (
    SELECT MAX(month_starting) AS latest_month_start FROM monthly_aggregates
),

monthly_prices AS (
    SELECT
        ma.symbol,
        ma.month_starting,
        ma.avg_daily_return,
        ma.monthly_volume,
        open_prices.close as month_open,
        close_prices.close as month_close
    FROM monthly_aggregates ma
    JOIN latest_month lm ON ma.month_starting = lm.latest_month_start
    LEFT JOIN daily_metrics open_prices
        ON ma.symbol = open_prices.symbol AND ma.first_date_of_month = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON ma.symbol = close_prices.symbol AND ma.last_date_of_month = close_prices.date
)

SELECT DISTINCT ON (mp.symbol)
    mp.symbol,
    c.name,
    mp.month_starting,
    mp.avg_daily_return,
    mp.monthly_volume,
    mp.month_open,
    mp.month_close,
    CASE
        WHEN mp.month_open > 0 THEN (mp.month_close - mp.month_open) / mp.month_open
        ELSE 0
    END as monthly_return
FROM monthly_prices mp
JOIN "airflow"."public_core"."dim_companies" c ON mp.symbol = c.symbol
ORDER BY mp.symbol, mp.month_starting DESC
  );
  
[0m06:09:50.921696 [debug] [Thread-4 (]: SQL status: BEGIN in 0.025 seconds
[0m06:09:50.928001 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m06:09:50.929514 [debug] [Thread-2 (]: SQL status: BEGIN in 0.027 seconds
[0m06:09:50.930708 [debug] [Thread-1 (]: SQL status: BEGIN in 0.024 seconds
[0m06:09:50.933178 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_metrics AS (
    SELECT 
        symbol,
        date,
        close,
        prev_close,
        volume,
        CASE 
            WHEN prev_close > 0 THEN (close - prev_close) / prev_close 
            ELSE 0
        END as daily_return
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

weekly_aggregates AS (
    SELECT
        symbol,
        DATE_TRUNC('week', date) as week_starting,
        MIN(date) as first_date_of_week,
        MAX(date) as last_date_of_week,
        AVG(daily_return) as avg_daily_return,
        SUM(volume) as weekly_volume
    FROM daily_metrics
    GROUP BY symbol, DATE_TRUNC('week', date)
),

latest_week AS (
    SELECT MAX(week_starting) AS latest_week_start FROM weekly_aggregates
),

weekly_prices AS (
    SELECT
        wa.symbol,
        wa.week_starting,
        wa.avg_daily_return,
        wa.weekly_volume,
        open_prices.close as week_open,
        close_prices.close as week_close
    FROM weekly_aggregates wa
    JOIN latest_week lw ON wa.week_starting = lw.latest_week_start
    LEFT JOIN daily_metrics open_prices
        ON wa.symbol = open_prices.symbol AND wa.first_date_of_week = open_prices.date
    LEFT JOIN daily_metrics close_prices
        ON wa.symbol = close_prices.symbol AND wa.last_date_of_week = close_prices.date
)

SELECT DISTINCT ON (wp.symbol)
    wp.symbol,
    c.name,
    wp.week_starting,
    wp.avg_daily_return,
    wp.weekly_volume,
    wp.week_open,
    wp.week_close,
    CASE
        WHEN wp.week_open > 0 THEN (wp.week_close - wp.week_open) / wp.week_open
        ELSE 0
    END as weekly_return
FROM weekly_prices wp
JOIN "airflow"."public_core"."dim_companies" c ON wp.symbol = c.symbol
ORDER BY wp.symbol, wp.week_starting DESC
  );
  
[0m06:09:50.935930 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m06:09:50.938421 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m06:09:50.942359 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */

  
    

  create  table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp"
  
  
    as
  
  (
    

WITH latest_date AS (
    SELECT MAX(date) as latest_day
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
)

SELECT DISTINCT ON (s.symbol)
    s.symbol,
    c.name,
    s.date as day,
    s.prev_close,
    s.close,
    s.volume,
    s.value,
    CASE 
        WHEN s.prev_close > 0 THEN (s.close - s.prev_close) / s.prev_close
        ELSE 0
    END as daily_return
FROM "airflow"."public_staging"."stg_daily_stock_summary" s
JOIN latest_date l ON s.date = l.latest_day
JOIN "airflow"."public_core"."dim_companies" c ON s.symbol = c.symbol
ORDER BY s.symbol, s.date DESC
  );
  
[0m06:09:50.945509 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */

  
    

  create  table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp"
  
  
    as
  
  (
    

SELECT
    symbol,
    name,
    date,
    prev_close,
    open_price,
    high,
    low,
    close,
    change,
    -- Persentase perubahan
    CASE
        WHEN prev_close IS NOT NULL AND prev_close != 0 
            THEN (close - prev_close) / prev_close * 100
        ELSE NULL
    END AS percent_change,
    
    -- Volatilitas intraday
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS intraday_volatility,
    
    -- Range harian
    (high - low) AS daily_range,
    
    -- Jarak dari terendah ke tertinggi (%)
    CASE
        WHEN low IS NOT NULL AND low != 0
            THEN (high - low) / low * 100
        ELSE NULL
    END AS low_to_high_percent,
    
    -- Volume metrics
    volume,
    value,
    frequency,
    
    -- Aliran dana asing (net)
    (foreign_buy - foreign_sell) AS foreign_net,
    
    -- Update timestamp
    CURRENT_TIMESTAMP AS updated_at
FROM "airflow"."public_staging"."stg_daily_stock_summary"
  );
  
[0m06:09:51.155579 [debug] [Thread-2 (]: SQL status: SELECT 960 in 0.207 seconds
[0m06:09:51.211986 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m06:09:51.215729 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
alter table "airflow"."public_analytics"."stock_performance_daily__dbt_tmp" rename to "stock_performance_daily"
[0m06:09:51.220753 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:51.281955 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m06:09:51.285059 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m06:09:51.288166 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: COMMIT
[0m06:09:51.297234 [debug] [Thread-2 (]: SQL status: COMMIT in 0.006 seconds
[0m06:09:51.321346 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_daily__dbt_backup"
[0m06:09:51.336825 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.stock_performance_daily"
[0m06:09:51.339461 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_daily"} */
drop table if exists "airflow"."public_analytics"."stock_performance_daily__dbt_backup" cascade
[0m06:09:51.343563 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m06:09:51.350874 [debug] [Thread-2 (]: On model.idx_stock.stock_performance_daily: Close
[0m06:09:51.355596 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70fc7ce30>]}
[0m06:09:51.360711 [info ] [Thread-2 (]: 2 of 7 OK created sql table model public_analytics.stock_performance_daily ..... [[32mSELECT 960[0m in 0.74s]
[0m06:09:51.364386 [debug] [Thread-2 (]: Finished running node model.idx_stock.stock_performance_daily
[0m06:09:51.367514 [debug] [Thread-2 (]: Began running node model.idx_stock.technical_indicators_macd
[0m06:09:51.370895 [info ] [Thread-2 (]: 5 of 7 START sql table model public_analytics.technical_indicators_macd ........ [RUN]
[0m06:09:51.373987 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_daily, now model.idx_stock.technical_indicators_macd)
[0m06:09:51.377634 [debug] [Thread-2 (]: Began compiling node model.idx_stock.technical_indicators_macd
[0m06:09:51.386337 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_macd"
[0m06:09:51.403995 [debug] [Thread-2 (]: Began executing node model.idx_stock.technical_indicators_macd
[0m06:09:51.413151 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_macd"
[0m06:09:51.429955 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m06:09:51.432758 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: BEGIN
[0m06:09:51.434878 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:09:51.450621 [debug] [Thread-2 (]: SQL status: BEGIN in 0.016 seconds
[0m06:09:51.453619 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m06:09:51.456584 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp"
  
  
    as
  
  (
    

WITH daily_prices AS (
    SELECT
        symbol,
        date,
        close
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung EMA 12 dan 26 hari
ema_values AS (
    SELECT
        symbol,
        date,
        close,
        -- Simplified EMA calculation using AVG
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 11 PRECEDING AND CURRENT ROW) AS ema_12,
        AVG(close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 25 PRECEDING AND CURRENT ROW) AS ema_26
    FROM daily_prices
),

-- Menghitung MACD Line dan Signal Line
macd_values AS (
    SELECT
        symbol,
        date,
        close,
        (ema_12 - ema_26) AS macd_line,
        AVG(ema_12 - ema_26) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 8 PRECEDING AND CURRENT ROW) AS signal_line
    FROM ema_values
    WHERE ema_12 IS NOT NULL AND ema_26 IS NOT NULL
)

SELECT
    m.symbol,
    m.date,
    m.close,
    m.macd_line,
    m.signal_line,
    (m.macd_line - m.signal_line) AS macd_histogram,
    CASE
        WHEN m.macd_line > m.signal_line THEN 'Bullish'
        WHEN m.macd_line < m.signal_line THEN 'Bearish'
        ELSE 'Neutral'
    END AS macd_signal
FROM macd_values m
WHERE m.signal_line IS NOT NULL
  );
  
[0m06:09:57.094426 [debug] [Thread-1 (]: SQL status: SELECT 701981 in 6.146 seconds
[0m06:09:57.103282 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m06:09:57.105975 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
alter table "airflow"."public_analytics"."daily_stock_metrics__dbt_tmp" rename to "daily_stock_metrics"
[0m06:09:57.109162 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:57.113088 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m06:09:57.115377 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m06:09:57.117576 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: COMMIT
[0m06:09:57.122218 [debug] [Thread-1 (]: SQL status: COMMIT in 0.002 seconds
[0m06:09:57.129295 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."daily_stock_metrics__dbt_backup"
[0m06:09:57.131659 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.daily_stock_metrics"
[0m06:09:57.133665 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.daily_stock_metrics"} */
drop table if exists "airflow"."public_analytics"."daily_stock_metrics__dbt_backup" cascade
[0m06:09:57.137056 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.001 seconds
[0m06:09:57.141511 [debug] [Thread-1 (]: On model.idx_stock.daily_stock_metrics: Close
[0m06:09:57.144220 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70fcc5a30>]}
[0m06:09:57.147252 [info ] [Thread-1 (]: 1 of 7 OK created sql table model public_analytics.daily_stock_metrics ......... [[32mSELECT 701981[0m in 6.53s]
[0m06:09:57.150386 [debug] [Thread-1 (]: Finished running node model.idx_stock.daily_stock_metrics
[0m06:09:57.154414 [debug] [Thread-1 (]: Began running node model.idx_stock.technical_indicators_rsi
[0m06:09:57.157460 [info ] [Thread-1 (]: 6 of 7 START sql table model public_analytics.technical_indicators_rsi ......... [RUN]
[0m06:09:57.160589 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.daily_stock_metrics, now model.idx_stock.technical_indicators_rsi)
[0m06:09:57.162574 [debug] [Thread-1 (]: Began compiling node model.idx_stock.technical_indicators_rsi
[0m06:09:57.175389 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.technical_indicators_rsi"
[0m06:09:57.188180 [debug] [Thread-1 (]: Began executing node model.idx_stock.technical_indicators_rsi
[0m06:09:57.197258 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.technical_indicators_rsi"
[0m06:09:57.213006 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m06:09:57.215390 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: BEGIN
[0m06:09:57.217445 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:09:57.237212 [debug] [Thread-1 (]: SQL status: BEGIN in 0.020 seconds
[0m06:09:57.240236 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m06:09:57.243579 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */

  
    

  create  table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp"
  
  
    as
  
  (
    

WITH price_diff AS (
    SELECT
        symbol,
        date,
        close,
        close - LAG(close, 1) OVER (PARTITION BY symbol ORDER BY date) AS price_change
    FROM "airflow"."public_staging"."stg_daily_stock_summary"
),

-- Menghitung gain dan loss
gains_losses AS (
    SELECT
        symbol,
        date,
        CASE WHEN price_change > 0 THEN price_change ELSE 0 END AS gain,
        CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END AS loss
    FROM price_diff
    WHERE price_change IS NOT NULL
),

-- Menghitung average gain dan loss dengan periode 14 hari
avg_gains_losses AS (
    SELECT
        symbol,
        date,
        AVG(gain) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_gain,
        AVG(loss) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 13 PRECEDING AND CURRENT ROW) AS avg_loss
    FROM gains_losses
),

-- Menghitung Relative Strength dan RSI
rs_rsi AS (
    SELECT
        symbol,
        date,
        CASE 
            WHEN avg_loss = 0 THEN 100
            ELSE 100 - (100 / (1 + (avg_gain / NULLIF(avg_loss, 0))))
        END AS rsi
    FROM avg_gains_losses
    WHERE avg_gain IS NOT NULL AND avg_loss IS NOT NULL
)

SELECT
    r.symbol,
    r.date,
    s.close,
    r.rsi,
    CASE
        WHEN r.rsi > 70 THEN 'Overbought'
        WHEN r.rsi < 30 THEN 'Oversold'
        ELSE 'Neutral'
    END AS rsi_signal
FROM rs_rsi r
JOIN "airflow"."public_staging"."stg_daily_stock_summary" s ON r.symbol = s.symbol AND r.date = s.date
  );
  
[0m06:09:58.351815 [debug] [Thread-3 (]: SQL status: SELECT 960 in 7.428 seconds
[0m06:09:58.361956 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m06:09:58.364042 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
alter table "airflow"."public_analytics"."stock_performance_monthly__dbt_tmp" rename to "stock_performance_monthly"
[0m06:09:58.366668 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:58.371777 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m06:09:58.373716 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m06:09:58.375871 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: COMMIT
[0m06:09:58.380177 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m06:09:58.387684 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_monthly__dbt_backup"
[0m06:09:58.391177 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.stock_performance_monthly"
[0m06:09:58.393680 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_monthly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_monthly__dbt_backup" cascade
[0m06:09:58.396060 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:09:58.399850 [debug] [Thread-3 (]: On model.idx_stock.stock_performance_monthly: Close
[0m06:09:58.403518 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70cb4f290>]}
[0m06:09:58.407101 [info ] [Thread-3 (]: 3 of 7 OK created sql table model public_analytics.stock_performance_monthly ... [[32mSELECT 960[0m in 7.79s]
[0m06:09:58.410262 [debug] [Thread-3 (]: Finished running node model.idx_stock.stock_performance_monthly
[0m06:09:58.412874 [debug] [Thread-3 (]: Began running node model.idx_stock.news_sentiment_analysis
[0m06:09:58.415659 [info ] [Thread-3 (]: 7 of 7 START sql table model public_analytics.news_sentiment_analysis .......... [RUN]
[0m06:09:58.418086 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.idx_stock.stock_performance_monthly, now model.idx_stock.news_sentiment_analysis)
[0m06:09:58.420398 [debug] [Thread-3 (]: Began compiling node model.idx_stock.news_sentiment_analysis
[0m06:09:58.432315 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.news_sentiment_analysis"
[0m06:09:58.448856 [debug] [Thread-3 (]: Began executing node model.idx_stock.news_sentiment_analysis
[0m06:09:58.459289 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.news_sentiment_analysis"
[0m06:09:58.474488 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m06:09:58.476933 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: BEGIN
[0m06:09:58.479093 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:09:58.494947 [debug] [Thread-3 (]: SQL status: BEGIN in 0.016 seconds
[0m06:09:58.497430 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m06:09:58.500384 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */

  
    

  create  table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp"
  
  
    as
  
  (
    

WITH news_sentiment AS (
    SELECT
        ticker AS symbol,
        date,
        avg_sentiment,
        news_count,
        positive_count,
        negative_count,
        neutral_count,
        -- Hitung positive_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (positive_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS positive_percentage,
        -- Hitung negative_percentage
        CASE 
            WHEN news_count > 0 THEN 
                (negative_count::float / NULLIF(news_count, 0)) * 100
            ELSE 0
        END AS negative_percentage,
        -- Flag untuk data yang memiliki jumlah berita yang cukup untuk analisis
        CASE 
            WHEN news_count >= 2 THEN true
            ELSE false
        END AS has_sufficient_data
    FROM public.detik_ticker_sentiment
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'  -- Ambil data 90 hari terakhir untuk cakupan lebih luas
),

stock_data AS (
    -- Ambil data harga saham dari daily_stock_metrics
    SELECT
        symbol,
        date,
        close,
        percent_change
    FROM "airflow"."public_analytics"."daily_stock_metrics"
    WHERE date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT
    -- Data saham
    COALESCE(s.symbol, d.symbol) AS symbol,  -- Gunakan symbol dari salah satu sumber
    c.name,
    COALESCE(s.date, d.date) AS date,        -- Gunakan tanggal dari salah satu sumber
    s.close,
    s.percent_change,
    
    -- Data sentimen
    d.avg_sentiment,
    d.news_count,
    d.positive_count,
    d.negative_count,
    d.neutral_count,
    d.positive_percentage,
    d.negative_percentage,
    d.has_sufficient_data,
    
    -- Korelasi sentimen-harga: hanya valid jika keduanya ada
    CASE
        WHEN d.has_sufficient_data = true AND s.percent_change IS NOT NULL THEN
            CASE
                WHEN d.avg_sentiment > 0.25 AND s.percent_change > 1 THEN 'Positive Alignment'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change < -1 THEN 'Negative Alignment'
                WHEN d.avg_sentiment > 0.25 AND s.percent_change < -1 THEN 'Sentiment-Price Divergence (Bearish)'
                WHEN d.avg_sentiment < -0.25 AND s.percent_change > 1 THEN 'Sentiment-Price Divergence (Bullish)'
                ELSE 'Neutral/No Strong Signal'
            END
        ELSE 'Insufficient Data'
    END AS sentiment_price_signal,
    
    -- Trading signal berdasarkan sentimen: hanya valid jika data sentimen cukup
    CASE
        WHEN d.has_sufficient_data = true THEN
            CASE
                WHEN d.avg_sentiment > 0.4 AND d.news_count >= 3 THEN 'Strong Buy Signal'
                WHEN d.avg_sentiment > 0.2 AND d.news_count >= 2 THEN 'Buy Signal'
                WHEN d.avg_sentiment < -0.4 AND d.news_count >= 3 THEN 'Strong Sell Signal'
                WHEN d.avg_sentiment < -0.2 AND d.news_count >= 2 THEN 'Sell Signal'
                ELSE 'Hold/No Signal'
            END
        ELSE 'Insufficient Data'
    END AS trading_signal,
    
    -- Metadata
    CURRENT_TIMESTAMP AS generated_at
FROM stock_data s
FULL OUTER JOIN news_sentiment d 
   ON s.symbol = d.symbol AND s.date = d.date  -- FULL OUTER JOIN untuk mendapatkan semua data
LEFT JOIN "airflow"."public_core"."dim_companies" c 
   ON COALESCE(s.symbol, d.symbol) = c.symbol  -- Gunakan symbol dari salah satu tabel
WHERE 
   -- Filter untuk mendapatkan data dalam jendela waktu yang diinginkan
   (s.date >= CURRENT_DATE - INTERVAL '30 day' OR d.date >= CURRENT_DATE - INTERVAL '30 day')
   -- Exclude data yang tidak memiliki salah satu dari dua input utama
   AND (s.symbol IS NOT NULL OR d.symbol IS NOT NULL)
ORDER BY 
   -- Urutkan berdasarkan tanggal (terbaru lebih dulu) dan symbol
   COALESCE(s.date, d.date) DESC, 
   COALESCE(s.symbol, d.symbol)
  );
  
[0m06:09:58.989977 [debug] [Thread-4 (]: SQL status: SELECT 960 in 8.050 seconds
[0m06:09:58.997768 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m06:09:58.999838 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
alter table "airflow"."public_analytics"."stock_performance_weekly__dbt_tmp" rename to "stock_performance_weekly"
[0m06:09:59.003849 [debug] [Thread-4 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:59.008657 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m06:09:59.011082 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m06:09:59.013242 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: COMMIT
[0m06:09:59.019779 [debug] [Thread-4 (]: SQL status: COMMIT in 0.004 seconds
[0m06:09:59.027993 [debug] [Thread-4 (]: Applying DROP to: "airflow"."public_analytics"."stock_performance_weekly__dbt_backup"
[0m06:09:59.030790 [debug] [Thread-4 (]: Using postgres connection "model.idx_stock.stock_performance_weekly"
[0m06:09:59.032964 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_performance_weekly"} */
drop table if exists "airflow"."public_analytics"."stock_performance_weekly__dbt_backup" cascade
[0m06:09:59.036583 [debug] [Thread-4 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:09:59.041533 [debug] [Thread-4 (]: On model.idx_stock.stock_performance_weekly: Close
[0m06:09:59.044234 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70fcd4740>]}
[0m06:09:59.047301 [info ] [Thread-4 (]: 4 of 7 OK created sql table model public_analytics.stock_performance_weekly .... [[32mSELECT 960[0m in 8.42s]
[0m06:09:59.050483 [debug] [Thread-4 (]: Finished running node model.idx_stock.stock_performance_weekly
[0m06:09:59.101972 [debug] [Thread-3 (]: SQL status: SELECT 18321 in 0.597 seconds
[0m06:09:59.109823 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m06:09:59.111628 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
alter table "airflow"."public_analytics"."news_sentiment_analysis__dbt_tmp" rename to "news_sentiment_analysis"
[0m06:09:59.113886 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:09:59.117927 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m06:09:59.120254 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m06:09:59.122353 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: COMMIT
[0m06:09:59.134266 [debug] [Thread-3 (]: SQL status: COMMIT in 0.010 seconds
[0m06:09:59.140609 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup"
[0m06:09:59.142921 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.news_sentiment_analysis"
[0m06:09:59.144762 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.news_sentiment_analysis"} */
drop table if exists "airflow"."public_analytics"."news_sentiment_analysis__dbt_backup" cascade
[0m06:09:59.147112 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:09:59.151858 [debug] [Thread-3 (]: On model.idx_stock.news_sentiment_analysis: Close
[0m06:09:59.154458 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70cb440b0>]}
[0m06:09:59.156780 [info ] [Thread-3 (]: 7 of 7 OK created sql table model public_analytics.news_sentiment_analysis ..... [[32mSELECT 18321[0m in 0.74s]
[0m06:09:59.159147 [debug] [Thread-3 (]: Finished running node model.idx_stock.news_sentiment_analysis
[0m06:10:01.407521 [debug] [Thread-2 (]: SQL status: SELECT 701981 in 9.949 seconds
[0m06:10:01.415062 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m06:10:01.417833 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
alter table "airflow"."public_analytics"."technical_indicators_macd__dbt_tmp" rename to "technical_indicators_macd"
[0m06:10:01.420733 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:10:01.424520 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m06:10:01.426708 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m06:10:01.428741 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: COMMIT
[0m06:10:01.473163 [debug] [Thread-2 (]: SQL status: COMMIT in 0.042 seconds
[0m06:10:01.481518 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_macd__dbt_backup"
[0m06:10:01.484665 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.technical_indicators_macd"
[0m06:10:01.486936 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_macd"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_macd__dbt_backup" cascade
[0m06:10:01.489971 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:10:01.494043 [debug] [Thread-2 (]: On model.idx_stock.technical_indicators_macd: Close
[0m06:10:01.496622 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70cb2c3b0>]}
[0m06:10:01.500414 [info ] [Thread-2 (]: 5 of 7 OK created sql table model public_analytics.technical_indicators_macd ... [[32mSELECT 701981[0m in 10.12s]
[0m06:10:01.503727 [debug] [Thread-2 (]: Finished running node model.idx_stock.technical_indicators_macd
[0m06:10:06.274148 [debug] [Thread-1 (]: SQL status: SELECT 701018 in 9.027 seconds
[0m06:10:06.287862 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m06:10:06.291020 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
alter table "airflow"."public_analytics"."technical_indicators_rsi__dbt_tmp" rename to "technical_indicators_rsi"
[0m06:10:06.294104 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:10:06.300137 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m06:10:06.302925 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m06:10:06.305291 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: COMMIT
[0m06:10:06.317361 [debug] [Thread-1 (]: SQL status: COMMIT in 0.010 seconds
[0m06:10:06.322779 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup"
[0m06:10:06.325427 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.technical_indicators_rsi"
[0m06:10:06.327923 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.technical_indicators_rsi"} */
drop table if exists "airflow"."public_analytics"."technical_indicators_rsi__dbt_backup" cascade
[0m06:10:06.330951 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:10:06.334812 [debug] [Thread-1 (]: On model.idx_stock.technical_indicators_rsi: Close
[0m06:10:06.337119 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0555cacc-a714-423f-8391-38da78b6e703', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe70cb4bbf0>]}
[0m06:10:06.339757 [info ] [Thread-1 (]: 6 of 7 OK created sql table model public_analytics.technical_indicators_rsi .... [[32mSELECT 701018[0m in 9.18s]
[0m06:10:06.342019 [debug] [Thread-1 (]: Finished running node model.idx_stock.technical_indicators_rsi
[0m06:10:06.346597 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:06.348391 [debug] [MainThread]: On master: BEGIN
[0m06:10:06.350260 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:10:06.361544 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m06:10:06.364552 [debug] [MainThread]: On master: COMMIT
[0m06:10:06.366751 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:06.368584 [debug] [MainThread]: On master: COMMIT
[0m06:10:06.370942 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:10:06.372999 [debug] [MainThread]: On master: Close
[0m06:10:06.375309 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:10:06.377380 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_macd' was properly closed.
[0m06:10:06.379583 [debug] [MainThread]: Connection 'model.idx_stock.news_sentiment_analysis' was properly closed.
[0m06:10:06.381769 [debug] [MainThread]: Connection 'model.idx_stock.technical_indicators_rsi' was properly closed.
[0m06:10:06.383788 [debug] [MainThread]: Connection 'model.idx_stock.stock_performance_weekly' was properly closed.
[0m06:10:06.385793 [info ] [MainThread]: 
[0m06:10:06.387764 [info ] [MainThread]: Finished running 7 table models in 0 hours 0 minutes and 16.15 seconds (16.15s).
[0m06:10:06.392030 [debug] [MainThread]: Command end result
[0m06:10:06.478397 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:10:06.489026 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:10:06.509470 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:10:06.511537 [info ] [MainThread]: 
[0m06:10:06.514378 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:10:06.517690 [info ] [MainThread]: 
[0m06:10:06.519788 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
[0m06:10:06.522810 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 18.460346, "process_in_blocks": "0", "process_kernel_time": 0.398818, "process_mem_max_rss": "122460", "process_out_blocks": "0", "process_user_time": 5.772895}
[0m06:10:06.525204 [debug] [MainThread]: Command `dbt run` succeeded at 06:10:06.524995 after 18.46 seconds
[0m06:10:06.527264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe7131e3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713aebe60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe713531df0>]}
[0m06:10:06.529394 [debug] [MainThread]: Flushing usage events
[0m06:10:07.843117 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:10:12.943228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5405b9940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53e69c770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53e614920>]}


============================== 06:10:12.957769 | ae1749d0-776f-450f-b22a-dd9fca9fba72 ==============================
[0m06:10:12.957769 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:10:12.960643 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt test --profiles-dir /opt/airflow/dbt --exclude stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:10:13.293248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53ea029f0>]}
[0m06:10:13.390737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53e360110>]}
[0m06:10:13.393330 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:10:13.539398 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:10:14.125991 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:10:14.128027 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:10:14.223179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53d9baf90>]}
[0m06:10:14.413061 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:10:14.428603 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:10:14.495846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53c522150>]}
[0m06:10:14.497916 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:10:14.500139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53d9bb200>]}
[0m06:10:14.508925 [info ] [MainThread]: 
[0m06:10:14.511045 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:10:14.513072 [info ] [MainThread]: 
[0m06:10:14.515443 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:10:14.528837 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_core'
[0m06:10:14.530352 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_analytics'
[0m06:10:14.531647 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow_public_staging'
[0m06:10:14.612053 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:10:14.613124 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:10:14.614354 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:10:14.616388 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:10:14.618528 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:10:14.620698 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:10:14.622768 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:10:14.625832 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:10:14.628271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:10:14.645755 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m06:10:14.648240 [debug] [ThreadPool]: SQL status: BEGIN in 0.022 seconds
[0m06:10:14.649666 [debug] [ThreadPool]: SQL status: BEGIN in 0.027 seconds
[0m06:10:14.650819 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:10:14.652967 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:10:14.655598 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:10:14.658867 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:10:14.661443 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:10:14.665750 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:10:14.673642 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.005 seconds
[0m06:10:14.674576 [debug] [ThreadPool]: SQL status: SELECT 7 in 0.005 seconds
[0m06:10:14.675910 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m06:10:14.678883 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:10:14.682806 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:10:14.686729 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:10:14.689385 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:10:14.692080 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:10:14.694163 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:10:14.714693 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.716997 [debug] [MainThread]: On master: BEGIN
[0m06:10:14.719158 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:10:14.731597 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m06:10:14.733906 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.736043 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:10:14.749572 [debug] [MainThread]: SQL status: SELECT 1 in 0.011 seconds
[0m06:10:14.753787 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ae1749d0-776f-450f-b22a-dd9fca9fba72', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53d907080>]}
[0m06:10:14.756284 [debug] [MainThread]: On master: ROLLBACK
[0m06:10:14.758899 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.761079 [debug] [MainThread]: On master: BEGIN
[0m06:10:14.763969 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:10:14.766933 [debug] [MainThread]: On master: COMMIT
[0m06:10:14.768929 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.770801 [debug] [MainThread]: On master: COMMIT
[0m06:10:14.773517 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:10:14.775668 [debug] [MainThread]: On master: Close
[0m06:10:14.784026 [debug] [Thread-1 (]: Began running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m06:10:14.785063 [debug] [Thread-2 (]: Began running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m06:10:14.786986 [info ] [Thread-1 (]: 1 of 2 START test not_null_dim_companies_symbol ................................ [RUN]
[0m06:10:14.789428 [info ] [Thread-2 (]: 2 of 2 START test unique_dim_companies_symbol .................................. [RUN]
[0m06:10:14.792176 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066)
[0m06:10:14.794237 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now test.idx_stock.unique_dim_companies_symbol.2c3a54e99b)
[0m06:10:14.796304 [debug] [Thread-1 (]: Began compiling node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m06:10:14.798304 [debug] [Thread-2 (]: Began compiling node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m06:10:14.840362 [debug] [Thread-1 (]: Writing injected SQL for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m06:10:14.838065 [debug] [Thread-2 (]: Writing injected SQL for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m06:10:14.850697 [debug] [Thread-1 (]: Began executing node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m06:10:14.858999 [debug] [Thread-2 (]: Began executing node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m06:10:14.887520 [debug] [Thread-2 (]: Writing runtime sql for node "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m06:10:14.886505 [debug] [Thread-1 (]: Writing runtime sql for node "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m06:10:14.897997 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m06:10:14.899216 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m06:10:14.900848 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: BEGIN
[0m06:10:14.902767 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: BEGIN
[0m06:10:14.904543 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:10:14.906898 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:10:14.919137 [debug] [Thread-2 (]: SQL status: BEGIN in 0.015 seconds
[0m06:10:14.920396 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m06:10:14.922613 [debug] [Thread-2 (]: Using postgres connection "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"
[0m06:10:14.924812 [debug] [Thread-1 (]: Using postgres connection "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"
[0m06:10:14.926840 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.unique_dim_companies_symbol.2c3a54e99b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    symbol as unique_field,
    count(*) as n_records

from "airflow"."public_core"."dim_companies"
where symbol is not null
group by symbol
having count(*) > 1



      
    ) dbt_internal_test
[0m06:10:14.929144 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    



select symbol
from "airflow"."public_core"."dim_companies"
where symbol is null



      
    ) dbt_internal_test
[0m06:10:14.933174 [debug] [Thread-2 (]: SQL status: SELECT 1 in 0.002 seconds
[0m06:10:14.934091 [debug] [Thread-1 (]: SQL status: SELECT 1 in 0.002 seconds
[0m06:10:14.942072 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: ROLLBACK
[0m06:10:14.945987 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: ROLLBACK
[0m06:10:14.948215 [debug] [Thread-2 (]: On test.idx_stock.unique_dim_companies_symbol.2c3a54e99b: Close
[0m06:10:14.950174 [debug] [Thread-1 (]: On test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066: Close
[0m06:10:14.952152 [info ] [Thread-2 (]: 2 of 2 PASS unique_dim_companies_symbol ........................................ [[32mPASS[0m in 0.16s]
[0m06:10:14.954463 [info ] [Thread-1 (]: 1 of 2 PASS not_null_dim_companies_symbol ...................................... [[32mPASS[0m in 0.16s]
[0m06:10:14.956679 [debug] [Thread-2 (]: Finished running node test.idx_stock.unique_dim_companies_symbol.2c3a54e99b
[0m06:10:14.959303 [debug] [Thread-1 (]: Finished running node test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066
[0m06:10:14.964971 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.967017 [debug] [MainThread]: On master: BEGIN
[0m06:10:14.968760 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:10:14.980392 [debug] [MainThread]: SQL status: BEGIN in 0.012 seconds
[0m06:10:14.982697 [debug] [MainThread]: On master: COMMIT
[0m06:10:14.984628 [debug] [MainThread]: Using postgres connection "master"
[0m06:10:14.986472 [debug] [MainThread]: On master: COMMIT
[0m06:10:14.988538 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:10:14.990747 [debug] [MainThread]: On master: Close
[0m06:10:14.992850 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:10:14.994705 [debug] [MainThread]: Connection 'test.idx_stock.not_null_dim_companies_symbol.5a4f3b5066' was properly closed.
[0m06:10:14.996812 [debug] [MainThread]: Connection 'test.idx_stock.unique_dim_companies_symbol.2c3a54e99b' was properly closed.
[0m06:10:14.998727 [debug] [MainThread]: Connection 'list_airflow_public_staging' was properly closed.
[0m06:10:15.000784 [info ] [MainThread]: 
[0m06:10:15.002860 [info ] [MainThread]: Finished running 2 data tests in 0 hours 0 minutes and 0.49 seconds (0.49s).
[0m06:10:15.006478 [debug] [MainThread]: Command end result
[0m06:10:15.093990 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:10:15.103368 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:10:15.124426 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:10:15.126339 [info ] [MainThread]: 
[0m06:10:15.128338 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:10:15.130668 [info ] [MainThread]: 
[0m06:10:15.132769 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
[0m06:10:15.135672 [debug] [MainThread]: Resource report: {"command_name": "test", "command_success": true, "command_wall_clock_time": 2.3005383, "process_in_blocks": "0", "process_kernel_time": 0.340409, "process_mem_max_rss": "122124", "process_out_blocks": "0", "process_user_time": 4.4854}
[0m06:10:15.138254 [debug] [MainThread]: Command `dbt test` succeeded at 06:10:15.137886 after 2.30 seconds
[0m06:10:15.140975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc5405b9940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53c543e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc53c543d40>]}
[0m06:10:15.143142 [debug] [MainThread]: Flushing usage events
[0m06:10:16.204946 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:21:30.030956 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7953a8a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7953a840>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7953b9e0>]}


============================== 06:21:30.043245 | 79e912df-6b97-43c3-b239-3f0fb14dea11 ==============================
[0m06:21:30.043245 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:21:30.045451 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:21:30.368195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7953b9e0>]}
[0m06:21:30.461707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c78307ec0>]}
[0m06:21:30.464213 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:21:30.601788 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:21:31.137687 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:21:31.139658 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:21:31.223255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c783f6270>]}
[0m06:21:31.404231 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:21:31.421405 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:21:31.461649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c783f65a0>]}
[0m06:21:31.463752 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:21:31.465775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7919fb00>]}
[0m06:21:31.470639 [info ] [MainThread]: 
[0m06:21:31.473119 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:21:31.475158 [info ] [MainThread]: 
[0m06:21:31.477274 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:21:31.486353 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:21:31.487515 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:21:31.488529 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:21:31.554204 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:21:31.554992 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:21:31.555645 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:21:31.557101 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:21:31.558969 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:21:31.560611 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:21:31.562299 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:21:31.563966 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:21:31.565497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:21:31.577865 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.014 seconds
[0m06:21:31.578635 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.013 seconds
[0m06:21:31.579319 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m06:21:31.582104 [debug] [ThreadPool]: On list_airflow: Close
[0m06:21:31.585345 [debug] [ThreadPool]: On list_airflow: Close
[0m06:21:31.588669 [debug] [ThreadPool]: On list_airflow: Close
[0m06:21:31.595946 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m06:21:31.597055 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m06:21:31.598045 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m06:21:31.608709 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:21:31.612769 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:21:31.616923 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:21:31.618720 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:21:31.620567 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:21:31.622377 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:21:31.624099 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:21:31.625950 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:21:31.627709 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:21:31.638405 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m06:21:31.640284 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m06:21:31.641377 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:21:31.642734 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m06:21:31.644096 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:21:31.645999 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:21:31.647884 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:21:31.649747 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:21:31.652986 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:21:31.656072 [debug] [ThreadPool]: SQL status: SELECT 1 in 0.004 seconds
[0m06:21:31.659412 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:21:31.660207 [debug] [ThreadPool]: SQL status: SELECT 8 in 0.005 seconds
[0m06:21:31.660908 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.004 seconds
[0m06:21:31.662635 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:21:31.665645 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:21:31.668975 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:21:31.672862 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:21:31.674766 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:21:31.688656 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:31.690365 [debug] [MainThread]: On master: BEGIN
[0m06:21:31.691910 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:21:31.702540 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m06:21:31.704573 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:31.706646 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:21:31.718788 [debug] [MainThread]: SQL status: SELECT 1 in 0.010 seconds
[0m06:21:31.722601 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c78342990>]}
[0m06:21:31.724702 [debug] [MainThread]: On master: ROLLBACK
[0m06:21:31.726821 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:31.728570 [debug] [MainThread]: On master: BEGIN
[0m06:21:31.730928 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:21:31.732809 [debug] [MainThread]: On master: COMMIT
[0m06:21:31.734611 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:31.736173 [debug] [MainThread]: On master: COMMIT
[0m06:21:31.738042 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:21:31.739733 [debug] [MainThread]: On master: Close
[0m06:21:31.748594 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m06:21:31.750911 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m06:21:31.752965 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m06:21:31.754829 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m06:21:31.767431 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m06:21:31.779941 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m06:21:31.835841 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m06:21:31.850469 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:21:31.852111 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m06:21:31.853932 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:21:31.864346 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m06:21:31.866538 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:21:31.868544 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m06:21:31.873704 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m06:21:31.884076 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:21:31.886076 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m06:21:31.888562 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:21:31.913074 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:21:31.914905 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:21:31.916765 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:21:31.925332 [debug] [Thread-1 (]: SQL status: COMMIT in 0.007 seconds
[0m06:21:31.936257 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m06:21:31.945111 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:21:31.947244 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m06:21:31.949796 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.000 seconds
[0m06:21:31.954699 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m06:21:31.958469 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7b271220>]}
[0m06:21:31.960718 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.20s]
[0m06:21:31.963093 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m06:21:31.965749 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m06:21:31.967970 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m06:21:31.969896 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.fct_stock_predictions)
[0m06:21:31.971676 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m06:21:31.980059 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m06:21:32.000125 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m06:21:32.043507 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m06:21:32.060228 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:21:32.062422 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m06:21:32.064367 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:21:32.078751 [debug] [Thread-3 (]: SQL status: BEGIN in 0.014 seconds
[0m06:21:32.081922 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:21:32.084638 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m06:21:32.631717 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.545 seconds
[0m06:21:32.644411 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:21:32.646521 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m06:21:32.649065 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:21:32.652887 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:21:32.655049 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:21:32.657003 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:21:32.664174 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m06:21:32.669687 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m06:21:32.675440 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:21:32.677488 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m06:21:32.679846 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:21:32.683545 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m06:21:32.685851 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c5ef19b20>]}
[0m06:21:32.688061 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.72s]
[0m06:21:32.690312 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m06:21:32.693192 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m06:21:32.694067 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m06:21:32.695972 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m06:21:32.698456 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m06:21:32.700891 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.lstm_performance_metrics)
[0m06:21:32.703006 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m06:21:32.705059 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m06:21:32.707080 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m06:21:32.713604 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.722008 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m06:21:32.732473 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m06:21:32.734191 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m06:21:32.740028 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.746730 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m06:21:32.757457 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.759163 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:21:32.760060 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m06:21:32.761957 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m06:21:32.763795 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:21:32.765742 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:21:32.777295 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m06:21:32.779419 [debug] [Thread-1 (]: SQL status: BEGIN in 0.014 seconds
[0m06:21:32.781289 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.783410 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:21:32.785787 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m06:21:32.788426 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m06:21:32.793923 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column m.macd_histogram does not exist
LINE 28:         m.macd_histogram
                 ^

[0m06:21:32.800047 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m06:21:32.802963 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m06:21:32.809214 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.018 seconds
[0m06:21:32.815883 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.818150 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m06:21:32.821179 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:21:32.824744 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:21:32.827167 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.830145 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m06:21:32.831922 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:21:32.834114 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c5ef34170>]}
[0m06:21:32.837781 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.13s]
[0m06:21:32.840058 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m06:21:32.841337 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m06:21:32.842998 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m06:21:32.848405 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m06:21:32.853073 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:21:32.855082 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m06:21:32.857459 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.001 seconds
[0m06:21:32.861108 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m06:21:32.863303 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '79e912df-6b97-43c3-b239-3f0fb14dea11', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7519d670>]}
[0m06:21:32.865741 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.16s]
[0m06:21:32.868016 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m06:21:32.871891 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:32.873863 [debug] [MainThread]: On master: BEGIN
[0m06:21:32.875597 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:21:32.886446 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m06:21:32.888774 [debug] [MainThread]: On master: COMMIT
[0m06:21:32.890487 [debug] [MainThread]: Using postgres connection "master"
[0m06:21:32.892262 [debug] [MainThread]: On master: COMMIT
[0m06:21:32.894305 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:21:32.896108 [debug] [MainThread]: On master: Close
[0m06:21:32.898089 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:21:32.899737 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m06:21:32.901433 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m06:21:32.903117 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m06:21:32.904981 [info ] [MainThread]: 
[0m06:21:32.906675 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 1.43 seconds (1.43s).
[0m06:21:32.909818 [debug] [MainThread]: Command end result
[0m06:21:32.985179 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:21:32.994224 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:21:33.010394 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:21:33.012040 [info ] [MainThread]: 
[0m06:21:33.013946 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m06:21:33.015535 [info ] [MainThread]: 
[0m06:21:33.017263 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m06:21:33.018873 [info ] [MainThread]: 
[0m06:21:33.020831 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m06:21:33.023509 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 3.0990174, "process_in_blocks": "280", "process_kernel_time": 0.282052, "process_mem_max_rss": "123208", "process_out_blocks": "0", "process_user_time": 4.133521}
[0m06:21:33.025567 [debug] [MainThread]: Command `dbt run` failed at 06:21:33.025391 after 3.10 seconds
[0m06:21:33.027279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c79d79100>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c7966abd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1c5ef37a70>]}
[0m06:21:33.029075 [debug] [MainThread]: Flushing usage events
[0m06:21:34.259706 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:26:41.372090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd951aab0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd9998200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd951bc20>]}


============================== 06:26:41.384056 | 75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2 ==============================
[0m06:26:41.384056 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:26:41.386011 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'debug': 'False', 'version_check': 'True', 'log_path': '/opt/airflow/dbt/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m06:26:41.679533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd8360380>]}
[0m06:26:41.766928 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd9590050>]}
[0m06:26:41.769150 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:26:41.906997 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:26:42.375102 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m06:26:42.376962 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m06:26:42.449018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd83b56d0>]}
[0m06:26:42.613172 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:26:42.628371 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:26:42.664679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd735c620>]}
[0m06:26:42.666325 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:26:42.668022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd83d4bc0>]}
[0m06:26:42.672322 [info ] [MainThread]: 
[0m06:26:42.674195 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:26:42.675858 [info ] [MainThread]: 
[0m06:26:42.677895 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:26:42.686544 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:26:42.687598 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:26:42.688515 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:26:42.754578 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:26:42.755300 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:26:42.755942 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:26:42.757440 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:26:42.759186 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:26:42.760804 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:26:42.762351 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:42.763900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:42.765447 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:26:42.776624 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.014 seconds
[0m06:26:42.779780 [debug] [ThreadPool]: On list_airflow: Close
[0m06:26:42.780480 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.017 seconds
[0m06:26:42.781092 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.016 seconds
[0m06:26:42.785229 [debug] [ThreadPool]: On list_airflow: Close
[0m06:26:42.787979 [debug] [ThreadPool]: On list_airflow: Close
[0m06:26:42.794035 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m06:26:42.795375 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m06:26:42.796419 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m06:26:42.805406 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:26:42.809175 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:26:42.813194 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:26:42.814886 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:26:42.816556 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:26:42.818221 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:26:42.819622 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:26:42.821191 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:26:42.822765 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:26:42.833213 [debug] [ThreadPool]: SQL status: BEGIN in 0.014 seconds
[0m06:26:42.834178 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m06:26:42.835804 [debug] [ThreadPool]: SQL status: BEGIN in 0.013 seconds
[0m06:26:42.836940 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:26:42.839042 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:26:42.840757 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:26:42.842351 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:26:42.844106 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:26:42.845975 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:26:42.850698 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.003 seconds
[0m06:26:42.851477 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.003 seconds
[0m06:26:42.854511 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:26:42.855329 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.006 seconds
[0m06:26:42.857834 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:26:42.859680 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:26:42.862260 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:26:42.864358 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:26:42.869362 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:26:42.881249 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:42.883039 [debug] [MainThread]: On master: BEGIN
[0m06:26:42.884841 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:26:42.894311 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m06:26:42.896339 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:42.898014 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:26:42.907335 [debug] [MainThread]: SQL status: SELECT 2 in 0.008 seconds
[0m06:26:42.910340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd91eff20>]}
[0m06:26:42.911949 [debug] [MainThread]: On master: ROLLBACK
[0m06:26:42.913780 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:42.915258 [debug] [MainThread]: On master: BEGIN
[0m06:26:42.917138 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:26:42.918711 [debug] [MainThread]: On master: COMMIT
[0m06:26:42.920213 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:42.921675 [debug] [MainThread]: On master: COMMIT
[0m06:26:42.923271 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:26:42.924646 [debug] [MainThread]: On master: Close
[0m06:26:42.931519 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m06:26:42.933372 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m06:26:42.935059 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.stg_stock_predictions)
[0m06:26:42.936590 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m06:26:42.948265 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m06:26:42.957219 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m06:26:43.007752 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m06:26:43.018904 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.020344 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m06:26:43.021608 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:26:43.031470 [debug] [Thread-1 (]: SQL status: BEGIN in 0.010 seconds
[0m06:26:43.033311 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.034831 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m06:26:43.039180 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.003 seconds
[0m06:26:43.048822 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.050538 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m06:26:43.052567 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:26:43.058009 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.059672 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m06:26:43.061771 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:26:43.088055 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:26:43.090014 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.091833 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:26:43.097664 [debug] [Thread-1 (]: SQL status: COMMIT in 0.004 seconds
[0m06:26:43.107369 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m06:26:43.115625 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:26:43.117436 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m06:26:43.125085 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m06:26:43.129499 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m06:26:43.132837 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd51d2270>]}
[0m06:26:43.135134 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.20s]
[0m06:26:43.137252 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m06:26:43.139895 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m06:26:43.141677 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m06:26:43.143531 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.fct_stock_predictions)
[0m06:26:43.145070 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m06:26:43.151270 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m06:26:43.162658 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m06:26:43.195359 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m06:26:43.207108 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.208294 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m06:26:43.209494 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:26:43.219328 [debug] [Thread-3 (]: SQL status: BEGIN in 0.010 seconds
[0m06:26:43.221097 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.222815 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m06:26:43.612572 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.388 seconds
[0m06:26:43.622479 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.624352 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m06:26:43.626720 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:26:43.631806 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.633663 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m06:26:43.635829 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:26:43.638806 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:26:43.640582 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.642269 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:26:43.649248 [debug] [Thread-3 (]: SQL status: COMMIT in 0.005 seconds
[0m06:26:43.653792 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m06:26:43.658424 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:26:43.660257 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m06:26:43.668299 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.006 seconds
[0m06:26:43.671450 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m06:26:43.673413 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd83b7e00>]}
[0m06:26:43.675609 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.53s]
[0m06:26:43.677721 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m06:26:43.680276 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m06:26:43.681037 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m06:26:43.682677 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m06:26:43.684637 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m06:26:43.686509 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m06:26:43.688139 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m06:26:43.689821 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m06:26:43.691419 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m06:26:43.696963 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.703782 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m06:26:43.712065 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m06:26:43.713436 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m06:26:43.718150 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.725711 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m06:26:43.734095 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.735466 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:26:43.736445 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m06:26:43.737854 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m06:26:43.739544 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:26:43.741268 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:26:43.750865 [debug] [Thread-2 (]: SQL status: BEGIN in 0.011 seconds
[0m06:26:43.752430 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m06:26:43.753947 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.755764 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:26:43.757849 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m06:26:43.760228 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.macd_histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.macd_histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m06:26:43.764927 [debug] [Thread-1 (]: Postgres adapter: Postgres error: column m.macd_histogram does not exist
LINE 28:         m.macd_histogram
                 ^

[0m06:26:43.768051 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: ROLLBACK
[0m06:26:43.770879 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m06:26:43.778712 [debug] [Thread-1 (]: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m06:26:43.779505 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.017 seconds
[0m06:26:43.781099 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fbef3ab40>]}
[0m06:26:43.786869 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.789282 [error] [Thread-1 (]: 4 of 4 ERROR creating sql table model public_analytics.stock_prediction_dashboard  [[31mERROR[0m in 0.09s]
[0m06:26:43.791249 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m06:26:43.793394 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m06:26:43.795763 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:26:43.797247 [debug] [Thread-7 (]: Marking all children of 'model.idx_stock.stock_prediction_dashboard' to be skipped because of status 'error'.  Reason: Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql.
[0m06:26:43.802630 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.806582 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m06:26:43.808780 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:26:43.811725 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:26:43.813598 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.815261 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:26:43.821625 [debug] [Thread-2 (]: SQL status: COMMIT in 0.005 seconds
[0m06:26:43.826211 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m06:26:43.828168 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:26:43.829900 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m06:26:43.838087 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.006 seconds
[0m06:26:43.841166 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m06:26:43.843124 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '75bfa01e-56d4-43aa-99ee-71e3c0ae3ed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fbef51250>]}
[0m06:26:43.845217 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.16s]
[0m06:26:43.847254 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m06:26:43.851033 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:43.852568 [debug] [MainThread]: On master: BEGIN
[0m06:26:43.853912 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:26:43.863168 [debug] [MainThread]: SQL status: BEGIN in 0.009 seconds
[0m06:26:43.865537 [debug] [MainThread]: On master: COMMIT
[0m06:26:43.867427 [debug] [MainThread]: Using postgres connection "master"
[0m06:26:43.869307 [debug] [MainThread]: On master: COMMIT
[0m06:26:43.871215 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:26:43.873007 [debug] [MainThread]: On master: Close
[0m06:26:43.876080 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:26:43.877698 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m06:26:43.879288 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m06:26:43.880866 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m06:26:43.882597 [info ] [MainThread]: 
[0m06:26:43.884246 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 1.20 seconds (1.20s).
[0m06:26:43.887466 [debug] [MainThread]: Command end result
[0m06:26:43.960107 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:26:43.968254 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:26:43.983849 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:26:43.985373 [info ] [MainThread]: 
[0m06:26:43.986909 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m06:26:43.988481 [info ] [MainThread]: 
[0m06:26:43.990193 [error] [MainThread]:   Database Error in model stock_prediction_dashboard (models/marts/analytics/stock_prediction_dashboard.sql)
  column m.macd_histogram does not exist
  LINE 28:         m.macd_histogram
                   ^
  compiled code at target/run/idx_stock/models/marts/analytics/stock_prediction_dashboard.sql
[0m06:26:43.991822 [info ] [MainThread]: 
[0m06:26:43.993391 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
[0m06:26:43.995917 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 2.7147863, "process_in_blocks": "0", "process_kernel_time": 0.290137, "process_mem_max_rss": "123108", "process_out_blocks": "0", "process_user_time": 3.901844}
[0m06:26:43.997627 [debug] [MainThread]: Command `dbt run` failed at 06:26:43.997463 after 2.72 seconds
[0m06:26:43.999279 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd9998200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fda07c440>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1fd51d30b0>]}
[0m06:26:44.001021 [debug] [MainThread]: Flushing usage events
[0m06:26:45.289331 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m06:59:17.261958 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9b9e9580>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9abc4200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb99960800>]}


============================== 06:59:17.275056 | aa4af215-b22b-4646-8cba-a367603e7aac ==============================
[0m06:59:17.275056 [info ] [MainThread]: Running with dbt=1.9.4
[0m06:59:17.278250 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/opt/airflow/dbt', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/opt/airflow/dbt/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run --profiles-dir /opt/airflow/dbt --select stg_stock_predictions fct_stock_predictions lstm_performance_metrics stock_prediction_dashboard', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m06:59:17.623106 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb998909b0>]}
[0m06:59:17.732081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9991a1e0>]}
[0m06:59:17.735747 [info ] [MainThread]: Registered adapter: postgres=1.9.0
[0m06:59:17.893720 [debug] [MainThread]: checksum: b5597158181700c50f5bc1c71fe28b37a6fb85633dc5323885263678b6bc782c, vars: {}, profile: , target: , version: 1.9.4
[0m06:59:18.405396 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m06:59:18.410272 [debug] [MainThread]: Partial parsing: updated file: idx_stock://models/marts/analytics/stock_prediction_dashboard.sql
[0m06:59:18.896932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb97d61d00>]}
[0m06:59:19.074881 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:59:19.090227 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:59:19.128943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9795be60>]}
[0m06:59:19.131036 [info ] [MainThread]: Found 14 models, 3 data tests, 6 sources, 434 macros
[0m06:59:19.132934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb97d615b0>]}
[0m06:59:19.137660 [info ] [MainThread]: 
[0m06:59:19.139621 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m06:59:19.141576 [info ] [MainThread]: 
[0m06:59:19.144717 [debug] [MainThread]: Acquiring new postgres connection 'master'
[0m06:59:19.152591 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:59:19.153722 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:59:19.154856 [debug] [ThreadPool]: Acquiring new postgres connection 'list_airflow'
[0m06:59:19.216681 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:59:19.217450 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:59:19.218049 [debug] [ThreadPool]: Using postgres connection "list_airflow"
[0m06:59:19.219552 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:59:19.221283 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:59:19.223046 [debug] [ThreadPool]: On list_airflow: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow"} */

    select distinct nspname from pg_namespace
  
[0m06:59:19.224849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:59:19.226679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:59:19.227946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m06:59:19.239069 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.014 seconds
[0m06:59:19.239850 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.013 seconds
[0m06:59:19.240605 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.013 seconds
[0m06:59:19.244018 [debug] [ThreadPool]: On list_airflow: Close
[0m06:59:19.246902 [debug] [ThreadPool]: On list_airflow: Close
[0m06:59:19.249759 [debug] [ThreadPool]: On list_airflow: Close
[0m06:59:19.256627 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_core)
[0m06:59:19.258137 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_staging)
[0m06:59:19.259819 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_airflow, now list_airflow_public_analytics)
[0m06:59:19.269287 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:59:19.273186 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:59:19.279833 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:59:19.281547 [debug] [ThreadPool]: On list_airflow_public_core: BEGIN
[0m06:59:19.283197 [debug] [ThreadPool]: On list_airflow_public_staging: BEGIN
[0m06:59:19.284928 [debug] [ThreadPool]: On list_airflow_public_analytics: BEGIN
[0m06:59:19.286355 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:59:19.288044 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:59:19.289727 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m06:59:19.301905 [debug] [ThreadPool]: SQL status: BEGIN in 0.015 seconds
[0m06:59:19.303744 [debug] [ThreadPool]: SQL status: BEGIN in 0.016 seconds
[0m06:59:19.305384 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_core"
[0m06:59:19.306848 [debug] [ThreadPool]: SQL status: BEGIN in 0.017 seconds
[0m06:59:19.309301 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_staging"
[0m06:59:19.311940 [debug] [ThreadPool]: On list_airflow_public_core: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_core"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_core'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_core'
  
[0m06:59:19.313765 [debug] [ThreadPool]: Using postgres connection "list_airflow_public_analytics"
[0m06:59:19.315688 [debug] [ThreadPool]: On list_airflow_public_staging: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_staging"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_staging'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_staging'
  
[0m06:59:19.318661 [debug] [ThreadPool]: On list_airflow_public_analytics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "list_airflow_public_analytics"} */
select
      'airflow' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public_analytics'
    union all
    select
      'airflow' as database,
      matviewname as name,
      schemaname as schema,
      'materialized_view' as type
    from pg_matviews
    where schemaname ilike 'public_analytics'
  
[0m06:59:19.321091 [debug] [ThreadPool]: SQL status: SELECT 3 in 0.004 seconds
[0m06:59:19.324891 [debug] [ThreadPool]: On list_airflow_public_core: ROLLBACK
[0m06:59:19.326393 [debug] [ThreadPool]: SQL status: SELECT 2 in 0.006 seconds
[0m06:59:19.327429 [debug] [ThreadPool]: SQL status: SELECT 9 in 0.006 seconds
[0m06:59:19.329185 [debug] [ThreadPool]: On list_airflow_public_core: Close
[0m06:59:19.331809 [debug] [ThreadPool]: On list_airflow_public_staging: ROLLBACK
[0m06:59:19.334786 [debug] [ThreadPool]: On list_airflow_public_analytics: ROLLBACK
[0m06:59:19.339221 [debug] [ThreadPool]: On list_airflow_public_staging: Close
[0m06:59:19.340609 [debug] [ThreadPool]: On list_airflow_public_analytics: Close
[0m06:59:19.355741 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:19.357521 [debug] [MainThread]: On master: BEGIN
[0m06:59:19.360329 [debug] [MainThread]: Opening a new connection, currently in state init
[0m06:59:19.370952 [debug] [MainThread]: SQL status: BEGIN in 0.011 seconds
[0m06:59:19.372936 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:19.375556 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select distinct
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v', 'm')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
[0m06:59:19.387098 [debug] [MainThread]: SQL status: SELECT 2 in 0.009 seconds
[0m06:59:19.390812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb997fca40>]}
[0m06:59:19.393869 [debug] [MainThread]: On master: ROLLBACK
[0m06:59:19.396449 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:19.398578 [debug] [MainThread]: On master: BEGIN
[0m06:59:19.401084 [debug] [MainThread]: SQL status: BEGIN in 0.001 seconds
[0m06:59:19.403374 [debug] [MainThread]: On master: COMMIT
[0m06:59:19.405251 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:19.407022 [debug] [MainThread]: On master: COMMIT
[0m06:59:19.409502 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:59:19.411244 [debug] [MainThread]: On master: Close
[0m06:59:19.420142 [debug] [Thread-1 (]: Began running node model.idx_stock.stg_stock_predictions
[0m06:59:19.422131 [info ] [Thread-1 (]: 1 of 4 START sql view model public_staging.stg_stock_predictions ............... [RUN]
[0m06:59:19.424022 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_airflow_public_analytics, now model.idx_stock.stg_stock_predictions)
[0m06:59:19.426261 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stg_stock_predictions
[0m06:59:19.437856 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stg_stock_predictions"
[0m06:59:19.451757 [debug] [Thread-1 (]: Began executing node model.idx_stock.stg_stock_predictions
[0m06:59:19.505185 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stg_stock_predictions"
[0m06:59:19.519416 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.520923 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: BEGIN
[0m06:59:19.522306 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:59:19.533037 [debug] [Thread-1 (]: SQL status: BEGIN in 0.011 seconds
[0m06:59:19.535091 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.536784 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */

  create view "airflow"."public_staging"."stg_stock_predictions__dbt_tmp"
    
    
  as (
    -- models/staging/stg_stock_predictions.sql
with raw as (
  select 
    symbol,
    prediction_date,
    predicted_close,
    actual_close,
    prediction_error,
    error_percentage,
    created_at
  from "airflow"."public"."stock_predictions"
)

select * from raw
  );
[0m06:59:19.542927 [debug] [Thread-1 (]: SQL status: CREATE VIEW in 0.004 seconds
[0m06:59:19.552899 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.554793 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions" rename to "stg_stock_predictions__dbt_backup"
[0m06:59:19.557604 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:59:19.563494 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.565300 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
alter table "airflow"."public_staging"."stg_stock_predictions__dbt_tmp" rename to "stg_stock_predictions"
[0m06:59:19.567683 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:59:19.594015 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:59:19.596010 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.597737 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: COMMIT
[0m06:59:19.607646 [debug] [Thread-1 (]: SQL status: COMMIT in 0.008 seconds
[0m06:59:19.618031 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_staging"."stg_stock_predictions__dbt_backup"
[0m06:59:19.628100 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stg_stock_predictions"
[0m06:59:19.630145 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stg_stock_predictions"} */
drop view if exists "airflow"."public_staging"."stg_stock_predictions__dbt_backup" cascade
[0m06:59:19.638103 [debug] [Thread-1 (]: SQL status: DROP VIEW in 0.006 seconds
[0m06:59:19.644155 [debug] [Thread-1 (]: On model.idx_stock.stg_stock_predictions: Close
[0m06:59:19.647791 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb975b4380>]}
[0m06:59:19.650182 [info ] [Thread-1 (]: 1 of 4 OK created sql view model public_staging.stg_stock_predictions .......... [[32mCREATE VIEW[0m in 0.22s]
[0m06:59:19.652342 [debug] [Thread-1 (]: Finished running node model.idx_stock.stg_stock_predictions
[0m06:59:19.654868 [debug] [Thread-3 (]: Began running node model.idx_stock.fct_stock_predictions
[0m06:59:19.656691 [info ] [Thread-3 (]: 2 of 4 START sql table model public_core.fct_stock_predictions ................. [RUN]
[0m06:59:19.659364 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly list_airflow_public_core, now model.idx_stock.fct_stock_predictions)
[0m06:59:19.661059 [debug] [Thread-3 (]: Began compiling node model.idx_stock.fct_stock_predictions
[0m06:59:19.666775 [debug] [Thread-3 (]: Writing injected SQL for node "model.idx_stock.fct_stock_predictions"
[0m06:59:19.680744 [debug] [Thread-3 (]: Began executing node model.idx_stock.fct_stock_predictions
[0m06:59:19.716110 [debug] [Thread-3 (]: Writing runtime sql for node "model.idx_stock.fct_stock_predictions"
[0m06:59:19.733298 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:19.734846 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: BEGIN
[0m06:59:19.736215 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m06:59:19.746153 [debug] [Thread-3 (]: SQL status: BEGIN in 0.010 seconds
[0m06:59:19.748236 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:19.750151 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */

  
    

  create  table "airflow"."public_core"."fct_stock_predictions__dbt_tmp"
  
  
    as
  
  (
    

WITH predictions AS (
    SELECT 
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        prediction_error,
        error_percentage,
        created_at
    FROM "airflow"."public_staging"."stg_stock_predictions"
),

stock_data AS (
    SELECT 
        symbol,
        date,
        close,
        volume,
        percent_change
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

lstm_processed AS (
    SELECT
        p.symbol,
        p.prediction_date,
        p.predicted_close,
        p.actual_close,
        p.prediction_error,
        p.error_percentage,
        p.created_at,
        s.close as previous_close,
        s.volume,
        s.percent_change,
        CASE
            WHEN p.predicted_close > s.close THEN 'Bullish'
            WHEN p.predicted_close < s.close THEN 'Bearish'
            ELSE 'Neutral'
        END as prediction_direction,
        CASE
            WHEN p.actual_close IS NOT NULL AND 
                 ((p.predicted_close > s.close AND p.actual_close > s.close) OR
                  (p.predicted_close < s.close AND p.actual_close < s.close))
            THEN true
            WHEN p.actual_close IS NOT NULL
            THEN false
            ELSE NULL
        END as direction_correct
    FROM predictions p
    LEFT JOIN stock_data s 
        ON p.symbol = s.symbol 
        AND s.date = p.prediction_date - INTERVAL '1 day'
)

SELECT * FROM lstm_processed
  );
  
[0m06:59:20.181624 [debug] [Thread-3 (]: SQL status: SELECT 1 in 0.430 seconds
[0m06:59:20.193123 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:20.194942 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions" rename to "fct_stock_predictions__dbt_backup"
[0m06:59:20.197069 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:59:20.202149 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:20.203794 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
alter table "airflow"."public_core"."fct_stock_predictions__dbt_tmp" rename to "fct_stock_predictions"
[0m06:59:20.205897 [debug] [Thread-3 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:59:20.209285 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:59:20.210944 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:20.212553 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: COMMIT
[0m06:59:20.215909 [debug] [Thread-3 (]: SQL status: COMMIT in 0.002 seconds
[0m06:59:20.220394 [debug] [Thread-3 (]: Applying DROP to: "airflow"."public_core"."fct_stock_predictions__dbt_backup"
[0m06:59:20.225756 [debug] [Thread-3 (]: Using postgres connection "model.idx_stock.fct_stock_predictions"
[0m06:59:20.227474 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.fct_stock_predictions"} */
drop table if exists "airflow"."public_core"."fct_stock_predictions__dbt_backup" cascade
[0m06:59:20.232457 [debug] [Thread-3 (]: SQL status: DROP TABLE in 0.003 seconds
[0m06:59:20.235754 [debug] [Thread-3 (]: On model.idx_stock.fct_stock_predictions: Close
[0m06:59:20.237503 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb94639010>]}
[0m06:59:20.239248 [info ] [Thread-3 (]: 2 of 4 OK created sql table model public_core.fct_stock_predictions ............ [[32mSELECT 1[0m in 0.58s]
[0m06:59:20.241692 [debug] [Thread-3 (]: Finished running node model.idx_stock.fct_stock_predictions
[0m06:59:20.244278 [debug] [Thread-2 (]: Began running node model.idx_stock.lstm_performance_metrics
[0m06:59:20.245003 [debug] [Thread-1 (]: Began running node model.idx_stock.stock_prediction_dashboard
[0m06:59:20.246619 [info ] [Thread-2 (]: 3 of 4 START sql table model public_analytics.lstm_performance_metrics ......... [RUN]
[0m06:59:20.248616 [info ] [Thread-1 (]: 4 of 4 START sql table model public_analytics.stock_prediction_dashboard ....... [RUN]
[0m06:59:20.250437 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly list_airflow_public_staging, now model.idx_stock.lstm_performance_metrics)
[0m06:59:20.252174 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.idx_stock.stg_stock_predictions, now model.idx_stock.stock_prediction_dashboard)
[0m06:59:20.253856 [debug] [Thread-2 (]: Began compiling node model.idx_stock.lstm_performance_metrics
[0m06:59:20.255543 [debug] [Thread-1 (]: Began compiling node model.idx_stock.stock_prediction_dashboard
[0m06:59:20.261395 [debug] [Thread-2 (]: Writing injected SQL for node "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.268667 [debug] [Thread-1 (]: Writing injected SQL for node "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.277709 [debug] [Thread-2 (]: Began executing node model.idx_stock.lstm_performance_metrics
[0m06:59:20.283951 [debug] [Thread-2 (]: Writing runtime sql for node "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.284776 [debug] [Thread-1 (]: Began executing node model.idx_stock.stock_prediction_dashboard
[0m06:59:20.292666 [debug] [Thread-1 (]: Writing runtime sql for node "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.299881 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.301606 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: BEGIN
[0m06:59:20.302521 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.303797 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m06:59:20.305625 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: BEGIN
[0m06:59:20.309448 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m06:59:20.316717 [debug] [Thread-2 (]: SQL status: BEGIN in 0.013 seconds
[0m06:59:20.318652 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.320586 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */

  
    

  create  table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp"
  
  
    as
  
  (
    

WITH lstm_predictions AS (
    SELECT * FROM "airflow"."public_core"."fct_stock_predictions"
),

-- Akurasi LSTM per ticker
lstm_accuracy AS (
    SELECT
        symbol,
        COUNT(*) as total_predictions,
        SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) as predictions_with_actuals,
        SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END) as correct_direction_predictions,
        AVG(error_percentage) as avg_error_percentage,
        CASE
            WHEN SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END) > 0
            THEN 
                SUM(CASE WHEN direction_correct = true THEN 1 ELSE 0 END)::float / 
                NULLIF(SUM(CASE WHEN actual_close IS NOT NULL THEN 1 ELSE 0 END), 0) * 100
            ELSE 0
        END as direction_accuracy_pct
    FROM lstm_predictions
    WHERE actual_close IS NOT NULL
    GROUP BY symbol
),

-- Latest predictions per symbol
latest_predictions AS (
    SELECT DISTINCT ON (symbol)
        symbol,
        prediction_date,
        predicted_close,
        actual_close,
        error_percentage,
        prediction_direction,
        created_at
    FROM lstm_predictions
    ORDER BY symbol, prediction_date DESC
)

-- Main output
SELECT
    a.symbol,
    a.total_predictions,
    a.predictions_with_actuals,
    a.correct_direction_predictions,
    a.avg_error_percentage,
    a.direction_accuracy_pct,
    lp.prediction_date as latest_prediction_date,
    lp.predicted_close as latest_predicted_close,
    lp.prediction_direction as latest_prediction_direction
FROM lstm_accuracy a
LEFT JOIN latest_predictions lp ON a.symbol = lp.symbol
  );
  
[0m06:59:20.322057 [debug] [Thread-1 (]: SQL status: BEGIN in 0.013 seconds
[0m06:59:20.325195 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.327171 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */

  
    

  create  table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp"
  
  
    as
  
  (
    

WITH stock_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_daily_stock_metrics"
),

technical_indicators AS (
    SELECT 
        r.symbol,
        r.date,
        r.rsi,
        r.rsi_signal,
        m.macd_line,
        m.signal_line,
        m.macd_signal,
        m.histogram
    FROM "airflow"."public_analytics"."technical_indicators_rsi" r
    JOIN "airflow"."public_analytics"."technical_indicators_macd" m 
        ON r.symbol = m.symbol AND r.date = m.date
),

news_sentiment AS (
    SELECT *
    FROM "airflow"."public_analytics"."news_sentiment_analysis"
),

lstm_data AS (
    SELECT *
    FROM "airflow"."public_core"."fct_stock_predictions"
),

combined_data AS (
    SELECT
        sd.symbol,
        sd.date,
        sd.close,
        sd.volume,
        sd.percent_change,
        
        -- Technical indicators
        ti.rsi,
        ti.rsi_signal,
        ti.macd_line,
        ti.macd_signal,
        ti.histogram,

        -- Sentiment
        ns.avg_sentiment,
        ns.positive_percentage,
        ns.negative_percentage,
        ns.trading_signal AS news_trading_signal,

        -- LSTM
        ld.predicted_close,
        ld.prediction_direction AS lstm_direction,
        ld.actual_close,
        ld.prediction_error,
        ld.error_percentage,

        -- Derived
        ld.predicted_close - sd.close AS prediction_gap,
        CASE 
            WHEN sd.close IS NOT NULL AND ld.predicted_close IS NOT NULL
            THEN ROUND((ld.predicted_close - sd.close) / sd.close * 100, 2)
            ELSE NULL
        END AS prediction_gap_pct,

        -- Aggregated final signal (example logic)
        CASE
            WHEN ti.macd_signal = 'Bullish' AND ti.rsi_signal = 'Overbought' AND ns.trading_signal = 'Buy' THEN 'Bullish Strong'
            WHEN ti.macd_signal = 'Bearish' AND ti.rsi_signal = 'Oversold' AND ns.trading_signal = 'Sell' THEN 'Bearish Strong'
            WHEN ti.macd_signal = 'Bullish' OR ti.rsi_signal = 'Overbought' OR ns.trading_signal = 'Buy' THEN 'Bullish'
            WHEN ti.macd_signal = 'Bearish' OR ti.rsi_signal = 'Oversold' OR ns.trading_signal = 'Sell' THEN 'Bearish'
            ELSE 'Neutral'
        END AS final_signal

    FROM stock_data sd
    LEFT JOIN technical_indicators ti ON sd.symbol = ti.symbol AND sd.date = ti.date
    LEFT JOIN news_sentiment ns ON sd.symbol = ns.symbol AND sd.date = ns.date
    LEFT JOIN lstm_data ld ON sd.symbol = ld.symbol AND sd.date = ld.prediction_date
    WHERE sd.date >= CURRENT_DATE - INTERVAL '90 day'
)

SELECT * FROM combined_data
  );
  
[0m06:59:20.332488 [debug] [Thread-2 (]: SQL status: SELECT 0 in 0.009 seconds
[0m06:59:20.338325 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.340539 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics" rename to "lstm_performance_metrics__dbt_backup"
[0m06:59:20.343207 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:59:20.349054 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.350951 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
alter table "airflow"."public_analytics"."lstm_performance_metrics__dbt_tmp" rename to "lstm_performance_metrics"
[0m06:59:20.353196 [debug] [Thread-2 (]: SQL status: ALTER TABLE in 0.000 seconds
[0m06:59:20.357222 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:59:20.359613 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.361394 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: COMMIT
[0m06:59:20.365596 [debug] [Thread-2 (]: SQL status: COMMIT in 0.002 seconds
[0m06:59:20.370539 [debug] [Thread-2 (]: Applying DROP to: "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup"
[0m06:59:20.372736 [debug] [Thread-2 (]: Using postgres connection "model.idx_stock.lstm_performance_metrics"
[0m06:59:20.375123 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.lstm_performance_metrics"} */
drop table if exists "airflow"."public_analytics"."lstm_performance_metrics__dbt_backup" cascade
[0m06:59:20.379888 [debug] [Thread-2 (]: SQL status: DROP TABLE in 0.003 seconds
[0m06:59:20.383379 [debug] [Thread-2 (]: On model.idx_stock.lstm_performance_metrics: Close
[0m06:59:20.385603 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb94665cd0>]}
[0m06:59:20.388177 [info ] [Thread-2 (]: 3 of 4 OK created sql table model public_analytics.lstm_performance_metrics .... [[32mSELECT 0[0m in 0.13s]
[0m06:59:20.390591 [debug] [Thread-2 (]: Finished running node model.idx_stock.lstm_performance_metrics
[0m06:59:20.642929 [debug] [Thread-1 (]: SQL status: SELECT 53599 in 0.313 seconds
[0m06:59:20.651042 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.653137 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
alter table "airflow"."public_analytics"."stock_prediction_dashboard__dbt_tmp" rename to "stock_prediction_dashboard"
[0m06:59:20.655706 [debug] [Thread-1 (]: SQL status: ALTER TABLE in 0.001 seconds
[0m06:59:20.659604 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m06:59:20.661668 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.663696 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: COMMIT
[0m06:59:20.679689 [debug] [Thread-1 (]: SQL status: COMMIT in 0.014 seconds
[0m06:59:20.684751 [debug] [Thread-1 (]: Applying DROP to: "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup"
[0m06:59:20.687038 [debug] [Thread-1 (]: Using postgres connection "model.idx_stock.stock_prediction_dashboard"
[0m06:59:20.688952 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: /* {"app": "dbt", "dbt_version": "1.9.4", "profile_name": "idx_stock", "target_name": "dev", "node_id": "model.idx_stock.stock_prediction_dashboard"} */
drop table if exists "airflow"."public_analytics"."stock_prediction_dashboard__dbt_backup" cascade
[0m06:59:20.691621 [debug] [Thread-1 (]: SQL status: DROP TABLE in 0.000 seconds
[0m06:59:20.696127 [debug] [Thread-1 (]: On model.idx_stock.stock_prediction_dashboard: Close
[0m06:59:20.698908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa4af215-b22b-4646-8cba-a367603e7aac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9461d220>]}
[0m06:59:20.701579 [info ] [Thread-1 (]: 4 of 4 OK created sql table model public_analytics.stock_prediction_dashboard .. [[32mSELECT 53599[0m in 0.45s]
[0m06:59:20.703933 [debug] [Thread-1 (]: Finished running node model.idx_stock.stock_prediction_dashboard
[0m06:59:20.707908 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:20.709636 [debug] [MainThread]: On master: BEGIN
[0m06:59:20.711144 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m06:59:20.721242 [debug] [MainThread]: SQL status: BEGIN in 0.010 seconds
[0m06:59:20.723628 [debug] [MainThread]: On master: COMMIT
[0m06:59:20.725880 [debug] [MainThread]: Using postgres connection "master"
[0m06:59:20.727534 [debug] [MainThread]: On master: COMMIT
[0m06:59:20.729497 [debug] [MainThread]: SQL status: COMMIT in 0.000 seconds
[0m06:59:20.731142 [debug] [MainThread]: On master: Close
[0m06:59:20.732824 [debug] [MainThread]: Connection 'master' was properly closed.
[0m06:59:20.734432 [debug] [MainThread]: Connection 'model.idx_stock.stock_prediction_dashboard' was properly closed.
[0m06:59:20.735961 [debug] [MainThread]: Connection 'model.idx_stock.lstm_performance_metrics' was properly closed.
[0m06:59:20.737359 [debug] [MainThread]: Connection 'model.idx_stock.fct_stock_predictions' was properly closed.
[0m06:59:20.738916 [info ] [MainThread]: 
[0m06:59:20.741317 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 1.59 seconds (1.59s).
[0m06:59:20.744888 [debug] [MainThread]: Command end result
[0m06:59:20.818607 [debug] [MainThread]: Wrote artifact WritableManifest to /opt/airflow/dbt/target/manifest.json
[0m06:59:20.828316 [debug] [MainThread]: Wrote artifact SemanticManifest to /opt/airflow/dbt/target/semantic_manifest.json
[0m06:59:20.845205 [debug] [MainThread]: Wrote artifact RunExecutionResult to /opt/airflow/dbt/target/run_results.json
[0m06:59:20.847053 [info ] [MainThread]: 
[0m06:59:20.848952 [info ] [MainThread]: [32mCompleted successfully[0m
[0m06:59:20.851130 [info ] [MainThread]: 
[0m06:59:20.852897 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
[0m06:59:20.855534 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.695101, "process_in_blocks": "416", "process_kernel_time": 0.45823, "process_mem_max_rss": "128844", "process_out_blocks": "0", "process_user_time": 5.219842}
[0m06:59:20.858378 [debug] [MainThread]: Command `dbt run` succeeded at 06:59:20.858164 after 3.70 seconds
[0m06:59:20.860204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb99a40a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9853bce0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb975b44d0>]}
[0m06:59:20.861913 [debug] [MainThread]: Flushing usage events
[0m06:59:22.044705 [debug] [MainThread]: An error was encountered while trying to flush usage events
